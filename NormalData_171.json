["Q: Inherited 2nd Gen Ipod Nano - cannot delete iPod music I have acquired (legitimately) a 2nd gen ipod nano.  It is full with music not to my taste.  When I open it up in Rhythmbox I am unable to delete the existing iPod music.\n\nA: One does not simply plug an iPod and expect it work's - unless you're using Mac OS.\nIt's the same with Windows - there you need iTunes.\nWhen I used an iPod, I used to use gtkPod to manage the music on the device.\nAs far as I know there is a iPod plugin for Rhythmbox already installes (can't tell, using Amarok), have a look at this.\n", "Q: How do I install/upgrade r-base to the latest version? I am pretty new to Linux. I installed R-base in my Ubuntu 12.04 using the Software Center (which by default is r-2.14). I want to upgrade to/install R 3.02 or newer. How can I do that? Thank you. \n\nA: Having had to spend time figuring this out and forgetting how it works, and then having to figure it out again multiple times, here's a more complete answer that is future-proof.\n\n\n*\n\n*Edit the sources.list file. This file contains the servers that apt-get consults to check whether software exists and where it can be downloaded from. One can edit the file using the following command:\nsudo -H gedit /etc/apt/sources.list\n\nThis requires the gedit editor. If you get an error, either install this (sudo apt-get install gedit) or use another editor like nano (sudo nano /etc/apt/sources.list).\n\n*Find a working server to download R from that also has the version of R you are interested in. This often means that one has to look for the name of the latest Ubuntu release. A list of releases is maintained on the Ubuntu website. Look for the latest released version and use only the first word in its name without capitalization. For instance, for the 16.04 release, the full name is Xenial Xerus and the name to use is thus xenial. Thus, we add the following line to the sources.list:\ndeb http://cran.rstudio.com/bin/linux/ubuntu xenial/\n\nNote that the above line uses the rstudio.com mirror. One can choose another mirror from this long list and appropriately alter the URL. For instance:\ndeb http://mirrors.dotsrc.org/cran/bin/linux/ubuntu xenial/\n\n\n*Save and close the file. After this, one can install the newest version using:\nsudo apt-get update # update apt-get's list of known releases \nsudo apt-get install r-base # install the newest available version of R\n\n\nA: You need to add R's repository to your system:\n\n\n*\n\n*Use your favorite text editor (I'm using gedit as an example) to open /etc/apt/sources.list:\nsudo -H gedit /etc/apt/sources.list\n\n\n*Add this line to the file (if this is slow, use another mirror. You may also want to change precise into the codename for your Ubuntu version --- e.g., trusty for 14.04):\n deb http://cran.rstudio.com/bin/linux/ubuntu precise/\n\n\n*Update the list of packages\nsudo apt-get update\n\n\n*Install the latest R-base (you can also use the software center again):\nsudo apt-get install r-base\n\n\nA: The answers so far are useful but they all omit the next step which is pretty much going to be required of anyone who intends to use R seriously. Quoted lines are from the canonical R Installation and Administration Manual:\n\nUsers who need to compile R packages from source [e.g. package maintainers, or anyone installing packages with install.packages()] should also install the r-base-dev package:\n\nsudo apt-get install r-base-dev\n\nI think potential installers should be reading that Manual more carefully than the recommendations on this page have so far advised.\n\nA: For Ubuntu 14.04 LTS the commands are\nsudo -H gedit /etc/apt/sources.list\n\ndeb http://cran.rstudio.com/bin/linux/ubuntu quantal/\n\n*Note: the forward slash is required otherwise you get an error \nsudo apt-get update \n\nsudo apt-get install r-base\n\n", "Q: Start-up Situation Recently replaced Windows 8 with Ubuntu. \nAt start-up I receive the following\nUnlocking the disk/dev/disk/by-uuid/b7bc470f-59f7-47d1-b2a7-230cc562c3(sda5_crypt)\nEnter paraphrase \n\nWhat does it mean?  I have 2 other computers utilizing Ubuntu and have never encountered this.\n\nA: Your sda5 (root) partition was encrypted.You have to give the passphrase to unlock it, so that it would bootup.\nThis is because you selected encryption option at the time of installing Ubuntu.Give the same passpharse as you given while encrypting the disk. \n\n", "Q: error mounting /mnt/affe26f1-c669-4794-9015-7aff45393795 i get an error message when I booted after changing a mounting option for a partition  \n\n/mnt/affe26f1-c669-4794-9015-7aff45393795 is not ready or not present\n\ni tried with \n\nmount errors=remount -ro /dev/sda/mnt/affe26f1-c669-4794-9015-7aff45393795\n\nkindly give a solution\n\nA: Try the below commands to mount /dev/sda1 and /dev/sda5 partitions,\nsudo mkdir /media/sda1\nsudo mkdir /media/sda5\nsudo mount /dev/sda1 /media/sda1\nsudo mount /dev/sda5 /media/sda5\n\nNow your sda1 and sda5 partitions are mounted in /media/sda1 and /media/sda5 respectively.\n", "Q: Keep getting error message on k3b when trying to burn a dvd video of a movie when im burning a movie i keep getting this error message\n\nI then clicked on SHOW DEBBUGING OUTPUT and it showed this message\nDevices\n-----------------------\nTSSTcorp DVD+-RW TS-L632H D400 (/dev/sr0, CD-R, CD-RW, CD-ROM, DVD-ROM, DVD-R, DVD-RW, DVD+R, DVD+RW, DVD+R DL) [DVD-ROM, DVD-R Sequential, DVD-R Dual Layer Sequential, DVD-RAM, DVD-RW Restricted Overwrite, DVD-RW Sequential, DVD+RW, DVD+R, DVD+R Dual Layer, CD-ROM, CD-R, CD-RW] [SAO, TAO, RAW, SAO/R96P, SAO/R96R, RAW/R16, RAW/R96P, RAW/R96R, Restricted Overwrite] [%7]\n\nK3b::IsoImager\n-----------------------\nmkisofs print size result: 0 (0 bytes)\n\nSystem\n-----------------------\nK3b Version: 2.0.2\nKDE Version: 4.8.5 (4.8.5)\nQT Version:  4.8.1\nKernel:      3.2.0-60-generic-pae\n\nUsed versions\n-----------------------\nmkisofs: 1.1.11\n\nmkisofs\n-----------------------\n/usr/bin/genisoimage: No such file or directory. Failed to open VIDEO_TS.IFO\n/usr/bin/genisoimage: Can't open VMG info for '/tmp/kde-robert/k3bVideoDvd0/'.\n/usr/bin/genisoimage: Unable to parse DVD-Video structures.\n/usr/bin/genisoimage: Could not find correct 'VIDEO_TS' directory.\nPossible reasons:\n  - VIDEO_TS subdirectory was not found on specified location\n  - VIDEO_TS has invalid contents\n\nmkisofs calculate size command:\n-----------------------\n/usr/bin/genisoimage -gui -graft-points -print-size -quiet -volid Frozen.2013.1080p.BluRay.x264.YI -volset  -appid K3B THE CD KREATOR (C) 1998-2010 SEBASTIAN TRUEG AND MICHAL MALEK -publisher  -preparer  -sysid LINUX -volset-size 1 -volset-seqno 1 -sort /tmp/kde-robert/k3bPR5701.tmp -no-cache-inodes -udf -iso-level 1 -path-list /tmp/kde-robert/k3bJw5701.tmp -dvd-video -f /tmp/kde-robert/k3bVideoDvd0\n\nI need some help i am using QBITTORENT to download the movies. I am not using this to make money i am using it for personal watching.\n\nA: I have this error each time I use K3b. To overcome this I find I need to go into the preferences where it asks for the path to the \"tmp\" folder. When clicking OK, it asks for permission to create the folder. I also find that I need to redo the file permissions to my CD/DVD writer as well.\nIt then works well. The only thing is to remmeber to do these two things each time I use it. \n", "Q: juju can't run wordpress on a local machine and agent-state is pending? Following this instruction and using juju switch local for installing on my laptop as local host, I get the below error when I run juju status,why?\nerror: container \"onrea-local-machine-1\" is already create\nAlso, agent-state is pending. see here: http://paste.ubuntu.com/7056689/\n\nA: It seems that a previous local provider instance did not get destroyed properly.\nYou can destroy the current one with:\n# If using juju 1.17.x\njuju destroy-environment -y local\n# If using juju 1.16.x\njuju destroy-environment -y -e local\n\nAnd then look at the current lxc images:\nsudo lxc-ls --fancy\n\nAny that start with \"onrea-local\" will be ones that juju things it created.\nYou can remove them with:\nsudo lxc-destroy -n onrea-local-machine-1\n\nAnd so on.\nThis is a limitation of the local provider, and one what we are looking to fix very soon (the clean destruction that is).\n", "Q: Chmod crash version 13.10 I was watching a command line reference tutorial and testing out two commands, CHMOD and CHOWN. I ended up changing my root folder's permissions. What should I do? Version 13.10.\n\nA: Try the below command,\nsudo chmod 700 /root\n\n", "Q: Setting up Ubuntu 12.04 to be accessed remotely from anywhere I am extremely new to Ubuntu. I am using Ubuntu for the very first time because this is for a school assignment. My main goal right now is to be able to access my Ubuntu desktop remotely from anywhere. I have Ubuntu running in VirtualBox. I have also installed Ubuntu Server, along with MySQL, Apache,and PHP5. In the network settings I have two adapters enabled. The first adapter is for the \"bridged-network\" and the other is NAT. I have success connecting remotely through my local network, but I want to be able to access Ubuntu from anywhere, using any computer. I am unsure of how to go abouts in doing so. I do feel like I would have to do some port forwarding, but that is all that I am thinking of. Any ideas are greatly appreciated. \n\nA: You have many options; I'll list some then you could choose what to apply and look for its detailed steps :\n\n\n*\n\n*Install Teamviewer on Linux machine and setup unattended access; then you will be able to access it from anywhere\n\n*Set up your Internet gateway, router, modem... etc with port forwarding then connect to the real IP and the configured port.\n\n*On the Ubuntu machine; you may install VNC server, xRDP, FreeNX...etc\n\n", "Q: Removing specific strings from file I have a file containing some data as in the following example:\ndata1: it is my data\ndata2: some more data\ndata3: even some more data\n\nWhat I want is the following output in another file:\nit is my data\nsome more data\neven some more data\n\nPlease guide me how to do it!\n\nA: This should work:\nsed -i .bak 's/[^:]*: *//' file\n\nExplanation: The -i .bak will edit the file in place, and create a backup of the original called filename.bak. s/pat/replacement/ means substitute pat with replacement. [^:]*: * means match the longest string of non-: characters, followed by a : then one or more space. The final result is that it will delete everything up to the first : and following spaces.\nThis approach has the advantage of working with data: or foo: or whatever and will also work if you have multiple : on the same line. For example, it can deal with this:\ndata: a line that contains : a colon!\n\n\nA: It's very simple if you use awk:\nawk -F ': ' '{for (i=2; i<=NF; i++) print $i}' file_name > new_file_name\n\nEach line is separated in more fields using ': ' as separator and print everything except the first field. The output is redirected to the new_file_name.\n\nA: This looks like a job for cut\ncut -d: -f2- file > new_file\n\n\nA: You can use Vim in Ex mode:\nex -sc '%s/[^:]*: *//|x' file\n\n\n\n*\n\n*% search all lines\n\n*s substitute\n\n*x save and close\n\nA: Open the file in vim editor as follows:\nvi <filename>\nand then press esc and then the following:\n:%s/data.: //gc\n\nHere %s is used for string replace\n/ is the delimiter between the command and the strings\ndata.: is the first string, . is used for any single character\ngc is used to find and confirm before replacing\n\nA: Your input file looks like an output of a grep command, say:\ngrep data data*\n\nIf this is really the case, you can use the -h option of grep command itself to get what you need:\ngrep -h data data*\n\n", "Q: Is there a build of Audacity for Ubuntu that can use a local version of FFMpeg? Audacity builds on Ubuntu no longer support FFMpeg because of the libav foolishness.\nIs there maybe a PPA or something with a build of Audacity that supports using a local build of FFMpeg? I could compile it myself, but it would be a set back in terms of being time consuming, especially if there are errors.\nP.S.\nPlease do not suggest the nightly PPA, it doesn't support FFMpeg.\n\nA: Looks like Audacity will actually build against ffmpeg-0.10.12. I have written it all up here:\nAudacity under Trusty Tahr: Building it with FFmpeg \nhttp://ubuntuforums.org/showthread.php?t=2219907\nTest it out and let me know if it all works out...\n\nA: From the Audacity manual we can read that it will not build against FFmpeg libraries newer than 0.8:\n\nAudacity should support building against FFmpeg 0.5 through 0.8. It may not currently be possible to build Audacity against later versions of FFmpeg.Audacity Manual\n\nFrom 14.04 we will have installed libavcodec54 by default. This will conflict with older libavcodec releases. Audacity is already compiled and built against libavcodec and LAME:\n\nSome Linux distributions (for example, Ubuntu) now package Audacity with MP3 encoding and FFmpeg support already linked dynamically to the relevant system libraries. In these packaged builds there is no need to locate LAME or FFmpeg, so Audacity will have no \"Libraries\" Preferences.Audacity Manual\n\nAs it appears to be possible to still compile Audacity with newer FFmpeg releases for file format conversions not natively supported by Audacity. \nIf we only need to export to a non supported file format it may be easier to just use Audacity's option to export using an external application. This unfortunatley is not implemented for file import.\nOn the export file format dialog we can choose (external program) instead of an inbuilt format. On Options... we can then define a pipe to any external converter including avconv which had replaced FFmpeg.\navconv -i - \"%f\"\n\nThe output format will then be determined by the file extension given.\n\n\nA: I installed Audacity from their daily builds and aac/mp4 import works flawlessly for me now.\nhttps://launchpad.net/~audacity-team/+archive/daily\nPlease check and report.\n", "Q: Installing the Intuos CTH-480 drawing tablet in a AMR Chromebook I am trying to get my Intuos drawing tablet to work on my Chromebook, and since it's not compatible with the Google OS, I chose to install Ubuntu 13.10 and get the drivers.\nI did so, and Ubuntu 13.10 is working fine, and I downloaded the kernel driver input-wacom-0.20.0 from http://sourceforge.net/projects/linuxwacom/files/xf86-input-wacom/input-wacom/ \nThen, I tried to follow the directions found at http://sourceforge.net/apps/mediawiki/linuxwacom/index.php?title=Input-wacom\nHowever, I cannot get past the prerequisites section.  For the first step, when I enter:\nsudo apt-get install linux-headers-$(uname -r)\n\nit says:\nE: Unable to locate package linux-headers-3.8-11\nE: Couldn't find any package by regex 'linux-headers-3.8.11'\n\nI know that my kernel is 3.8.11, because when I enter:\nuname -r\n\nI get 3.8.11\nDoes this kernel not have Intuos support?  I'm very new to Linux, so I don't even know if I am asking the right questions here.  Do I need to set the headers to a kernel that DOES have Intuos support?\nCould someone walk me through this?\nAs I said in my comment,\n    apt-get install update\n\ndid not work, so I did\n    apt-cache search linux-headers\n\nThis was the output:\n    linux-headers-3.11.0-12 - Header files related to Linux kernel version 3.11.0\n    linux-headers-generic - Generic Linux kernel headers\n    linux-libc-dev - Linux Kernel headers for development\n    linux-source-3.11.0 - Linux kernel source for 3.11.0 with Ubuntu patches\n    linux-headers-3.11.0-12-generic - Linux kernel headers for version 3.11.0 on ARM (hard float) SMP\n    linux-headers-3.11.0-12-generic-lpae - Linux kernel headers for version 3.11.0 on ARM (hard float) SMP\n    linux-headers-3.5.0-233 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-233-omap4 - Linux kernel headers for version 3.5.0 on TI OMA p4-based systems\n    linux-headers-generic-lpae - Generic Linux kernel headers\n    linux-headers-highbank - Linux kernel headers for the armhf architecture\n    linux-headers-omap - Linux kernel headers for the armhf architecture\n    linux-headers-omap4 - Linux kernel headers for the OMAP4 architecture\n    linux-libc-dev-arm64-cross - Linux Kernel Headers for development (for cross-compiling)\n    linux-libc-dev-armel-cross - Linux Kernel Headers for development (for cross-compiling)\n    linux-libc-dev-armhf-cross - Linux Kernel Headers for development (for cross-compiling)\n    linux-libc-dev-powerpc-cross - Linux Kernel Headers for development (for cross-compiling)\n    linux-headers-3.0.0-3-maguro - Linux kernel headers for version 3.0.0 on Galaxy Nexus\n    linux-headers-3.1.10-6 - Header files related to Linux kernel version 3.1.10\n    linux-headers-3.1.10-6-ac100 - Linux kernel headers for version 3.1.10 on Toshiba AC100-based systems\n    linux-headers-3.1.10-6-grouper - Linux kernel headers for version 3.1.10 on Nexus 7\n    linux-headers-3.11.0-203-exynos5- Linux kernel headers for version 3.11.0 on ARM (hard float) SMP\n    linux-headers-3.4.0-1-goldfish - Linux kernel headers for version 3.4.0 on Android touch emulation\n    linux-headers-3.4.0-3-mako - Linux kenerl headers for version 3.4.0 on Nexus 4\n    linux-headers-3.4.0-4-manta - Linux kernel headers for version 3.4.0 on Nexus 10\n    linux-headers-3.4.0-5-chromebook - Linux kernel headers for version 3.4.0 on Samsung Chromebook\n    linux-headers-ac100 - Linux kernel headers for the ac100 architecture.\n    linux-headers-chromebook - Linux kernel headers for the Samsung ARM Chromebook.\n    linux-headers-exynos5 - Linux kernel headers for Exynos5 architecture.\n    linux-headers-goldfish - Linux kernel headers for the goldfish kernel.\n    linux-headers-grouper - Linux kernel headers for the Nexus7 (grouper).\n    linux-headers-maguro - Linux kernel headers for the Galaxy Nexus (maguro).\n    linux-headers-mako - Linux kernel headers for the Nexus4 (mako).\n    linux-headers-manta - Linux kernel headers for the Nexus10 (manta).\n    linux-headers-nexus4 - Transitional package\n    linux-headers-nexus7 - Transitional package\n    linux-headers-3.11.0-13 - Header files related to Linux kernel version 3.11.0\n    linux-headers-3.11.0-14 - Header files related to Linux kernel version 3.11.0\n    linux-headers-3.11.0-15 - Header files related to Linux kernel version 3.11.0\n    linux-headers-3.11.0-17 - Header files related to Linux kernel version 3.11.0\n    linux-headers-3.11.0-18 - Header files related to Linux kernel version 3.11.0\n    linux-header-3.11.0-13-generic - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-13-generic-lpae - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-14-generic - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-14-generic-lpae - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n   linux-header-3.11.0-15-generic - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-15-generic-lpae - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-17-generic - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-17-generic-lpae - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-18-generic - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-header-3.11.0-18-generic-lpae - Linux kernel headers for 3.11.0 on ARM (hard float) SMP\n    linux-headers-3.5.0-234 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-234-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers-3.5.0-235 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-235-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers-3.5.0-236 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-236-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers-3.5.0-237 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-237-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers-3.5.0-238 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-238-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers-3.5.0-239 - Header files related to Linux kernel version 3.5.0\n    linux-headers-3.5.0-239-omap4 - Header files related to Linux kernel version 3.5.0 on TI OMAP4-based systems\n    linux-headers03.11.0-204-exynos5 - Linux kernel headers for version 3.11.0 on ARM (hard float) SMP\n    linux-headers03.11.0-205-exynos5 - Linux kernel headers for version 3.11.0 on ARM (hard float) SMP\n\nI am looking for one of the header packages for either ARM or exynos, right?  I assume the ones that say Samsung Chromebook?\nI did \n    sudo apt-get install linux-headers-chromebook \n\nand then went to the next step. Unfortunately, I got the same problem when I tried \n    ./configure \n\nIt completed and read \n    BUILD ENVIRONMENT: \n    linux kernel - yes \n    kernel source - no\n\n    We could not find the kernel development environment to build the driver.  Please install the kernel source or the kernel development package and try again.\n\nThere were no other chromebook headers I saw in the list I posted in the pastebin link above. \nMaybe the linux-wacom support doesn't work on the Chromebook?\nUpdate with output from\n    apt-cache search chromebook\n\nhere:\n    vboot-kernel-utils - Chrome OS verified boot utils required to sign kernels\n    vboot-utils - Chome OS verified boot utils\n    linux-headers-3.4.0-5-chromebook - Linux kernel headers for version 3.4.0 on Samsung Chromebook\n    linux-headers-chromebook - Linux kernel image for the Samsung ARM Chromebook.\n    linux-image-chromebook - Linux kernel image for the Samsung ARM Chromebook\n    linux-image-chromebook - Linux kernel image for the Samsung ARM Chromebook.\n    linux-tools-3.4.0-5-chromebook - Linux kernel version specific tools for version 3.4.0-5\n\nUpdate with output of \n    dpkg --get-selections | grep -i chrome | grep -v deinstall\n\nhere:\n    linux-headers-3.4.0-5-chromebook                       install\n    linux-headers-chromebook                               install\n\nUpdate with output of\n    dpkg --get-selections | grep -i linux | grep -v deinstall\n\nhere:\n    libselinux1:armhf                                      install\n    linux-headers-3.4.0-5-chromebook                       install\n    linux-headers-chromebook                               install\n    linux-libc-ev:armhf                                    install\n    util-linux                                             install\n\n\nA: It's possible your package list hasn't been updated. Try running:\nsudo apt-get update\nsudo apt-get install linux-headers-$(uname -r)\n\nIf that still doesn't work, run this command to see other possible packages that may work:\napt-cache search linux-headers\n\nUpdate with the results and we'll take it from there.\n\nA: The kernel headers must be matched to your running kernel because otherwise you can't compile the driver (kernel module) for you kernel. \nI had a similar problem with old kernels hanging around; that meant that there where no headers in the distribution matching the running kernel. There is one relevant question that suggested to reinstall your relevant metapackage for the kernel (in a normal installation is linux-generic, I am not sure about a Chromebook. Maybe it is linux-headers-chromebook?).\nGiven the list of packages, I would try (but this could be dangerous... I am not expert of chromebook) \nsudo apt-get install linux-image-chromebook linux-headers-chromebook \nsudo apt-get update\nsudo apt-get upgrade\n\nand then reboot before compiling the drivers. My doubt here is that I do not see in which package is the kernel you are running now... there should be a linux-chromebook metapackage that solves the problems for you. \nAfter that, you can try to follow my answer here: Wacom Graphics Tablet CTH-480 / CTL-480 Not Detected In Ubuntu 13.10 \n", "Q: (JuJu) How to install \"ubuntu-12.04-server-cloudimg-amd64.tar.gz\" manually? Because of an error over using juju , I've downloaded these two files:\nhttps://cloud-images.ubuntu.com/server/releases/precise/release-20140227/ubuntu-12.04-server-cloudimg-amd64.tar.gz\nhttps://cloud-images.ubuntu.com/server/releases/precise/release-20140227/ubuntu-12.04-server-cloudimg-amd64-root.tar.gz\n\nThese two files are not compile-able. They are VMs! and I don't know where should I extract them. How should I install them?\nHere is ubuntu-12.04-server-cloudimg-amd64.tar.gz content: \nprecise-server-cloudimg-amd64.img\nprecise-server-cloudimg-amd64-floppy\nprecise-server-cloudimg-amd64-loader\nprecise-server-cloudimg-amd64-vmlinuz-virtual\nA new error that I got: http://paste.ubuntu.com/7057154/\n\nA: That vmlinuz file you see over there, is bootable. So you do not need to install. Just append it to a virtual drive.\nUsing Virtualbox, I think you could start using the OS immediately. It says \"virtual\" so you won't be able boot the OS without such third party app.\nSo no manual installation is necessary, because there is no installation at all.\nEDIT: Answer to your first comment. \n\n\n*\n\n*Use your image file in Virtualbox by opening the img file within Virtualbox. \n\n*According to the report, you've already chosen a couple of services. So you're better off asking whether you want to solve the Jojo error or install the OS manually because your question according to the title is the latter one, in which I already explained  its solution above. But if you want to solve the error, then the details are below.\n\n*Your error is: GZIP failed to extract your archive at line 33; saying \"Unexpected EOF in archive\". My guess is the file is corrupt. It is probable that you have failed to completely download the file due to some bad connection.\n\n\nTo check this, generate the MD5 sum of the file on your hard drive with the hash I found here. If they're not same, all you need to do is to retry the download.\nSo you last question was how to introduce it to juju; you need to solve this error beforehand by trying this solution out.\nHope this works out for you.\n", "Q: Cannot change any icon sizes in Kubuntu System Settings...can someone help me please? I'm a newbie when it comes to Ubuntu and I'm using the latest version of Kubuntu.\nWhen I go to System Settings, then Application Appearance, then Icons, then Advanced, all the Size drop-down boxes for all the \"Use of Icon\" options have no numbers in them and do nothing when clicked. This happens every time, and regardless of what Theme I use. Currently  I'm using Humanity. I recently installed a new theme, Oxyfaenza, then removed it, but I don't know if that has anything to do with the error.\nI tried reinstalling System Settings using apt-get, no dice. Does anyone have any suggestions to help me diagnose the problem and fix it? Thank you :)\n\nA: I had the same problem...\nI installed the \"plasma-active-settings\" package and the problem is solved.\n", "Q: Chromium downloads all PDF files initially instead of of opening them within the browser Whenever I click on a link which contain a PDF file, Chromium automatically downloads the file. Instead, I would like to open it for my viewing rather than downloading it.\nHow can I achieve this?\n\nA: You have two main options:\n\n\n*\n\n*Install an extension. For example this one: Docs PDF/PowerPoint Viewer (by Google) which lets you view PDFs in Google Docs.\n\n*While chromium does not provide this, chrome does, so you can steal it from there. First, download the chrome .deb:\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n\nOr, if you are running a 32bit system:\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_i386.deb\n\nNow, extract libpdf.so from the file you downloaded. I don't use Unity but I believe you can do this using by right clicking the file and choosing Open With => File Roller or Archive Manager or similar. From the terminal you can do:\ndpkg -x google-chrome-stable_current_amd64.deb ./ && \ncp ./opt/google/chrome/libpdf.so . && rm -rf etc opt usr\n\nThat will unpack the .deb, copy libpdf.so to the current directory and delete the unpacked data. You can now copy libpdf.so to /usr/lib/chromium-browser/:\nsudo cp libpdf.so /usr/lib/chromium-browser/\n\nNow restart your chromium and you should be able to view PDF files.\n\nA: Install Docs PDF/PowerPoint Viewer in chromium.\nIt will let you open pdf\n file in browser. You can also download those file if you wish.\nBy clicking on a link for a supported document format you'll be taken to the Google Docs Viewer.  On the options page you can also disable any file formats you don't want to use the Viewer for.\n", "Q: unable to stat `./mnt' (which I was about to install): Transport endpoint is not connected When running:\napt-get update && apt-get upgrade\n\non 12.04.3 LTS, kernel 3.2.0-35-virtual \nI get:\nPreparing to replace base-files 6.5ubuntu6.6 (using .../base-files_6.5ubuntu6.7_amd64.deb) ...\nUnpacking replacement base-files ...\ndpkg: error processing /var/cache/apt/archives/base-files_6.5ubuntu6.7_amd64.deb (--unpack):\n unable to stat `./mnt' (which I was about to install): Transport endpoint is not connected\nNo apport report written because MaxReports is reached already\n                                                              Processing triggers for man-db ...\nProcessing triggers for install-info ...\nErrors were encountered while processing:\n /var/cache/apt/archives/base-files_6.5ubuntu6.7_amd64.deb\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nOutput of df -ha : \nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvda1       99G  9.1G   85G  10% /\nnone               0     0     0    - /proc\nsysfs              0     0     0    - /sys\nnone               0     0     0    - /sys/fs/fuse/connections\nnone               0     0     0    - /sys/kernel/debug\nnone               0     0     0    - /sys/kernel/security\nudev            819M   12K  819M   1% /dev\ndevpts             0     0     0    - /dev/pts\ntmpfs           331M  192K  331M   1% /run\nnone            5.0M     0  5.0M   0% /run/lock\nnone            827M     0  827M   0% /run/shm\ncgroup          827M     0  827M   0% /sys/fs/cgroup\ncgroup             0     0     0    - /sys/fs/cgroup/cpuset\ncgroup             0     0     0    - /sys/fs/cgroup/cpu\ncgroup             0     0     0    - /sys/fs/cgroup/cpuacct\ncgroup             0     0     0    - /sys/fs/cgroup/memory\ncgroup             0     0     0    - /sys/fs/cgroup/devices\ncgroup             0     0     0    - /sys/fs/cgroup/freezer\ncgroup             0     0     0    - /sys/fs/cgroup/blkio\ncgroup             0     0     0    - /sys/fs/cgroup/perf_event\n\nOutput of mount :\n/dev/xvda1 on / type ext4 (rw)\nnone on /proc type proc (rw,noexec,nosuid,nodev)\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\nnone on /sys/fs/fuse/connections type fusectl (rw)\nnone on /sys/kernel/debug type debugfs (rw)\nnone on /sys/kernel/security type securityfs (rw)\nudev on /dev type devtmpfs (rw,mode=0755)\ndevpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)\ntmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)\nnone on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\ncgroup on /sys/fs/cgroup type tmpfs (rw,relatime,mode=755)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset,clone_children)\ncgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu,clone_children)\ncgroup on /sys/fs/cgroup/cpuacct type cgroup (rw,relatime,cpuacct,clone_children)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,relatime,memory,clone_children)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,relatime,devices,clone_children)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,relatime,freezer,clone_children)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,relatime,blkio,clone_children)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,relatime,perf_event,clone_children)\n\nI have tried solutions found here such as:\napt-get clean\n\ndpkg --configure -a\n\ndpkg -i --force-overwrite /var/cache/apt/archives/base-files_6.5ubuntu6.7_amd64.deb\n\nrm /var/cache/apt/archives/base-files_6.5ubuntu6.7_amd64.deb\n\nAlso thought I would mention that I am running an LXC container. Anybody know how I can clear this up?\n\nA: This error message indicates that you have a non-default filesystem on /mnt that's in a problematic state. The base-files package provides the /mnt directory on the filesystem, so dpkg assumes it should be able to unpack that directory if necessary. You need to unmount /mnt on your system to upgrade base-files.\nSee https://bugs.launchpad.net/ubuntu/+source/base-files/+bug/1352012 for more info.\n", "Q: Is anybody using juju for mission critical apps? I've been playing with juju for the last month and it is really awesome but it feels like a black box. It feels like something that I \"just have to trust that it will work\".\nI'm very tempted to use it in my company but as awesome as juju is, it just feels like it is very new and not \"proven to work\" in mission critical environments. Of course, I may be completely wrong...\nIs there anybody out ther really using juju? Not testing and playing with it but really deploying aplications into production environment with it?\n\nA: In so many words, yes. There's really nothing black box about what Juju is doing. Everything Juju does is Open Source and the model juju is using is fairly well documented. There are fairly large companies using Juju to deploy and manage OpenStack on bare metal with MaaS and deploying workloads on their OpenStack (again, with juju).\n\nA: Yes, Canonical has many production services running using Juju.\nThere are other companies that we know about too that are also running production services with Juju.\n", "Q: How can I control the KDE monitor configuration from a script? Every morning I come to work, plug in my sleeping laptop into the large monitor on my desk, and then fiddle with this dialog:\n\nI imagine that the result of this fiddling is that the \"Display Settings\" app writes the new monitor configuration to some file, and then sends some signal to the window manager to notice that the settings have changed.  I would like to do this myself and control it directly, for this purpose as well as others.\nIf I could find out the name of the process that produces the ‘Display Settings’ dialog I could run it with strace and see what it is doing, but I haven't been able to find that out either.\nMy questions are:\n\nTo what program does this dialog belong?  What would I look for in the ps output to identify it?  And what is it actually doing when it changes the monitor configuration?\n\nI am using KDE 4.8.5.\n\nA: The xrandr utility can be controlled from a script.  The configuration shown in the screenshot can be obtained by running the command:\n\nxrandr \\\n --output LVDS-1 --mode 1680x1050 --pos 1080x1120 --rotate normal \\ \n --output DVI-D-1 --off --output VGA-1 --mode 1920x1080 --pos 0x0 --rotate left          \n\n\nTo generate this command line, I used arandr.  It presents a dialog something like the one in the original question, but simpler, and then has a \"save\" option which saves the correct xrandr invocation to a file. \nAfter using the arandr dialog to configure the monitors the way I want them, I save the configuration to a file, say ~/.screenlayout/office.sh.  Executing this file as a shell script restores the saved configuration.  I wrote a trivial shell script, disp, which executes $HOME/.screenlayout/$1.sh, so when I get to the office I just type disp office on the command line to restore the office monitor configuration.  When I go home I type disp 1, which runs ~/.screenlayout/1.sh, where I have saved the default one-monitor configuration.\nStill no answers to the other questions in my post, although probably the dialog in the original question is running xrandr itself to change the screen configuration.\n", "Q: Decompressing multiple files at once I have more than 200 .zip files in one folder. I don't want to decompress those one by one. I want to extract those using single command or script. How to do that.\n\nA: You can use find with -exec like so,\nfind . -name \"*.zip\" -exec unzip {} \\;\n\nThis will work if the file has a space in the name.\n\nA: If you really want to uncompress them in parallel, you could do\nfor i in *zip; do unzip \"$i\" & done\n\nThat however, will launch N processes for N .zip files and could be very heavy on your system. For a more controlled approach, launching only 10 parallel processes at a time, try this:\nfind . -name '*.zip' -print0 | xargs -0 -I {} -P 10 unzip {}\n\nTo control the number of parallel processes launched, change -P to whatever you want. If you don't want recurse into subdirectories, do this instead:\nfind . -maxdepth 1 -name '*.zip' -print0 | xargs -0 -I {} -P 10 unzip {}\n\nAlternatively, you can install GNU parallel as suggested by @OleTange in the comments and run\nparallel unzip ::: *zip\n\n\nA: A non terminal method.\nJust select the zip files, right click on one and choose extract here. You can select all or just a number of zip files at a time.\n\nA: The GNU parallel command is well suited to this type of thing.  After:\n$ sudo apt-get install parallel\n\nThen\nls *.zip | parallel unzip\n\nThis will use as many cores as you have, keeping each core busy with an unzip, until they are all done.\n\nA: You can use the following command :\nFirst change directory in terminal to directory that contains .zip files :\ncd /path\n\nThen execute this command to unzip all .zip files :\nfor z in *.zip; do unzip \"$z\"; done\n\n\nA: If you have many .zip files in your folder and you want to decompress all of them then open terminal and go to your folder using:\ncd <path_to_folder>\n\nNow use this command to decompress all your .zip file:\nls *.zip | xargs -n1 unzip\n\n\nA: unzip \\*.zip or unzip '*.zip'\nThe obvious unzip *.zip doesn't work, because the shell expands it to unzip foo.zip bar.zip ... and unzip interprets the first filename as the zip file, and the following filenames as files to extract from that zip file.\nHowever, unzip is a bit unusual among Unix commands in that it does its own glob expansions.  If the * is not expanded by the shell, unzip will do it, and intepret all the resulting filenames as zip files to be processed.  So in this special case, one can get away without a for loop or xargs or the like.\n", "Q: How to download Django 1.6.2 + set the path to python3? I don't know how to set the path.\n\n\n*\n\n*How shall I install  django? \n\n*How do I set the django module to the python3 path?\nPlease answer these 2 questions. I'm a newbie so please bear with me lol.\nThis is my path from python..\nnaveed@naveed-VirtualBox:~$ python3\nPython 3.2.3 (default, Feb 27 2014, 21:31:18) \n[GCC 4.6.3] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import sys\n>>> sys.path\n\n['', '/usr/lib/python3.2', '/usr/lib/python3.2/plat-linux2', '/usr/lib/python3.2/lib-dynload', \n'/usr/local/lib/python3.2/dist-packages', '/usr/lib/python3/dist-packages']\n\n\nA: Use pip to install Django. pip is used to install python packages from PyPI.\nSince you are using Python3, install pip by running:\nsudo apt-get install python3-pip\n\nOnce pip gets installed, you can install the latest version of Django for Python 3 by running:\npip3 install django\n\nThereafter, you can verify that it installed successfully by importing it in your Python 3 interpreter:\n>>> import django\n>>> print(django.getversion())\n1.6.2    # Latest version as of today\n\n\nYou don't need to worry about installing Django to your path.. pip would take care of all those stuff for you.\n", "Q: Delete GRUB after deleting Ubuntu from Mac Dual Boot My question is a bot specific. I installed Ubuntu 12.04 on my MacMini (Mid 2010) and deleted it after some problems. I resized my Mac Partition so that there was no Ubuntu Partition anymore.\nBut it seems, that I installed GRUB in a different section. If I am starting my Mac I am getting in a GRUB menu, there I am typing \"exit\" and my Mac is booting for about 5 minutes (very slow!), but later its working fine. But I woud like to deinstall GRUB now. Some people say its dangerous... Is there a safe way?\nThanks!\n\nA: Much faster and safer solution.\nBoot OSX and in the terminal run these commands:\nmkdir mnt\nsudo mount -t msdos /dev/disk0s1 mnt\n\nYou will see a new drive \"EFI\", open this drive and open the folder \"EFI\". Inside you will have the folders \"APPLE\" and \"UBUNTU\".\nJust delete the \"UBUNTU\".\nRestart and enjoy!\n\nA: It seems you have installed grub to the MBR, which is emulating a legacy boot and causing the slow boot times. The only way I found to remove grub completely on my mbp 5,5 was to boot the recovery partition (hold alt at boot) then do a complete reinstall of OSX from there. Remember to erase and reformat the entire disk, as this will generate a new MBR.\nIf you don't have a recovery partition then boot into OSX, then create a recovery disk/usb using Apple's utility found here. \nIf you do not want to reinstall your system you can change the bootloader to refind, which can be found here.  This should get your mac booting in EFI mode once more.\nGood Luck.\n\nA: Regarding @Deutschland’s answer above, if you have a fusion drive then the files are likely on the HDDs EFI partition which is disk1s1. You may also have to delete a folder called BOOT. Also, holding option at startup gives you the choice of what to boot into, Holding control as you click Macintosh HD will set that as the boot drive, as does choosing a startup disk in System Preferences, both of those will get rid of GRUB on startup with it just hidden away. \n", "Q: which “pactl” : audio source is “curently playing” one I'd like to capture the audio comming out of my soundcard, with :\ngst-launch -v ! pulsesrc device=X ! audioconvert ! vorbisenc ! webmmux ! filesink location=audio.mkv\n\nI don't know which source X to give as argument, pactl gives me to many to try them all.\n\nA: To list the default sink we can issue\npacmd list-sinks\n\nThe default sink is marked with an asterisk *:\n>>> 2 sink(s) available.\n  * index: 0\n    name: <alsa_output.pci-0000_02_00.1.hdmi-stereo-extra1>\n\nAdding .monitor to the default sink will give us an input source for this sink.\nIn case we need to know where a stream is currently playing we can issue:\npacmd list-sink-inputs\n\n", "Q: No permission to automount external HDD using ntfs-3g I wanted to modify my mount options for my NTFS external HDD so that I can execute programs on it.  I added the following line to my fstab accordingly:\nUUID=CE665A3F665A290B  /media/Josh  ntfs-3g defaults,users,nofail 0 0\n\nBut when I plug in my external and I get this error:\nError mounting: mount exited with exit code 1: helper failed with:\nError opening '/dev/sdb1': Permission denied\nFailed to mount '/dev/sdb1': Permission denied\nPlease check '/dev/sdb1' and the ntfs-3g binary permissions, and the mounting user ID. More explanation is provided at http://tuxera.com/community/ntfs-3g-faq/#unprivileged.\n\nSoo I go to the URL provided.  It says:\n\nUnprivileged block device mounts work only if all the below requirements are met:\n\n*\n\n*ntfs-3g is compiled with integrated FUSE support\n\n*the ntfs-3g binary is at least version 1.2506\n\n*the ntfs-3g binary is set to setuid-root\n\n*the user has access right to the volume\n\n*the user has access right to the mount point\n\n\nI believe I have all 5 requirements met (though obviously not, since I'm getting that error).  Anyone have some tips?  In particular, I have:\n\n\n*\n\n*ntfs-3g 2014.2.15 integrated FUSE 27\n\n*ntfs-3g 2014.2.15 integrated FUSE 27\n\n*-rwsr-xr-x 1 root root 504887 Mar  8 12:06 /bin/ntfs-3g*\n\n*brw-rw---- 1 root disk 8, 17 Mar  8 16:43 /dev/sdb1  (my user is in the \"disk\" group)\n\n*drwxrwxrwx  2 josh josh 4096 Mar  8 12:42 Josh/\n\n\nBeen struggling with this for hours.  This link has been the most helpful so far, but notably the last post has my same question and is unanswered.\nThanks!\n\nA: Found an answer that lets me not edit my fstab to get what I want.  Since my disk gets automounted, I added a rule to my udev that told the automount to do something special upon plug-in (that I don't really understand).  But now my disk gets automounted with all files executable.  I created a file /etc/udev/rules.d/99-usb-disks.rules and added:\nENV{ID_FS_TYPE}==\"ntfs\", ENV{ID_FS_TYPE}=\"ntfs-3g\"\n\nSource: http://ubuntuforums.org/showthread.php?t=1914416&p=11636662#post11636662\nStill haven't found a way to get rid of my permissions error when I do use my fstab mod, though.\nThanks terdon for the help.\n", "Q: Unable to download videos using youtube-dl ('sig error'), how to correct? I used to download videos using youtube-dl command line tool, from the past two days whenever i try to download any video I get an error as shown below.\n$ youtube-dl https://www.youtube.com/watch?v=bFew8mgQJ9o\n[youtube] Setting language\n[youtube] bFew8mgQJ9o: Downloading video webpage\n[youtube] bFew8mgQJ9o: Downloading video info webpage\n[youtube] bFew8mgQJ9o: Extracting video information\nTraceback (most recent call last):\n  File \"/usr/bin/youtube-dl\", line 4645, in <module>\n    main()\n  File \"/usr/bin/youtube-dl\", line 4636, in main\n    _real_main()\n  File \"/usr/bin/youtube-dl\", line 4620, in _real_main\n    retcode = fd.download(all_urls)\n  File \"/usr/bin/youtube-dl\", line 869, in download\n    ie.extract(url)\n  File \"/usr/bin/youtube-dl\", line 1135, in extract\n    return self._real_extract(url)\n  File \"/usr/bin/youtube-dl\", line 1406, in _real_extract\n    url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)\n  File \"/usr/bin/youtube-dl\", line 1406, in <genexpr>\n    url_map = dict((ud['itag'][0], ud['url'][0] + '&signature=' + ud['sig'][0]) for ud in url_data)\nKeyError: 'sig'\n\nwhats going on?\n\nA: Had exactly the same problem.\nUpdated youtube-dl via:\nsudo youtube-dl -U\n\nRun youtube-dl via sudo \nsudo youtube-dl\nand it will inform that they have changed distribution and need to update.\nPress enter and you should be good to go.\n\nA: You need to export your proxy settings before you can use youtube-dl to download videos from youtube. To do this, export proxy settings using:\nexport http_proxy=http://username:password@host:port_no/\nexport https_proxy=https://username:password@host:port_no/\nexport HTTP_PROXY=http://username:password@host:port_no/\nexport HTTPS_PROXY=https://username:password@host:port_no/\n\nReplace username, password, host and port_no with your respective variables. Remember to replace any special characters, if any, in your username or password with their HTML codes. Ignore username and password if you don't have one and export them as:\nexport HTTP_PROXY=http://host:port_no/\n\netc.\nFor ex:\nexport HTTP_PROXY=http://123431212:mypassword@192.168.1.2:3128/\n\nYou can also write this to your ~/.bashrc file to avoid writing them again and again for future sessions.\nRetry downloading videos after doing this.\n\nA: When I tried to upgrade with sudo as indicated in the other answer:\nsudo youtube-dl -U\n\nI got a message saying that youtube-dl had been installed using a package manager and I should use the same to upgrade it. But I had already done\nsudo easy_install -U youtube-dl\n\nIn the end, just using sudo to run it worked.\nsudo youtube-dl\n\n\nA: Install youtube-dl with sudo apt-get install youtube-dl from command-line, then use:\nsudo youtube-dl \"https://www.youtube.com/watch?v=bFew8mgQJ9o\"\n\nMake sure, that you use sudo before the above command!\n", "Q: Windows not in GRUB startup screen I recently used Boot Repair to fix GRUB startup, but now when I start my computer, Windows XP, my old OS, doesn't apppear. It shows Ubuntu, Ubuntu (recovery mode), memory test and a second memory test. There is also a subsection for previous Linux versions, but that only contains Ubuntu and its recovery. Help would be greatly appreciated!\n\nA: Sounds like you need to detect your installed OSs again. Boot into your normal Ubuntu, open a terminal and run\nsudo update-grub\n\nThat should detect all installed operating systems and update your grub accordingly. Windows should be there next time you reboot, as long as you see a line similar to this in the output:\nFound Windows XP (loader) on /dev/sda2\n\n", "Q: Can't boot Ubuntu after setting up partitions manually during installation My HDD is approximately 160 GB.\nI've created 4 partitions: \n\n\n*\n\n*the / one (~25000 MB)\n\n*the /boot one, which is about 1 GB\n\n*the swap (another 2 GB)\n\n*a 50000 MB /home partition.\n\n\nNow, on the Device for boot loader installation option, I selected the boot partition (I did so because I am going to dual boot ubuntu with another distro, tell me if something changes). And that's it.\nThe installation ends successfully, so I restart the computer. And the BIOS tells me there's no OS in the system!\nI insert the DVD again, and in the partition scheme, it says that Ubuntu is installed. Where have I failed?\n\nA: You need to install the boot loader on the hard disk device (/sda) and not on the boot partition. So select your hard disk device for \"Device for boot loader installation\".\n\nA: My first suspicion would be that the boot loader isn't where it should be. Note that it needs to match what device your BIOS is set to boot. If that is still the disk or stick you used to install Ubuntu.... \nYou can also boot in to a live instance, perhaps the same one used to install, to take a look around and figure out what happened and maybe re-install your boot loader. \n", "Q: Ubuntu 13.10 and DisplayLink adapter I'm using 13.10, and have upgraded my kernel to 3.14rc5 and blacklisted udlfb.  I boot up, plug in the DisplayLink adapter, and everything appears to be peachy at first blush:\n> lsusb\n  Bus 002 Device 002: ID 17e9:0360 DisplayLink \n\nSo far so good.  Taking a gander at xrandr, I can see the HDMI and DVI outputs. If I look in the display settings (or arandr), I can see both outputs.  When I check the output from dmesg, I see the DisplayLink adapter get picked up, but it never gets attached to a device.  This feels very fishy, but I'm still fairly new at this and hitting a wall.\nAny suggestions?\n\nA: I managed to get some signs of life on the setup I had in my question and after playing with the resolutions (setting to a lower resolution seemed to help).  I'm not sure the resolutions are mapped properly, but at least I'm getting an image.\n\nA: I followed almost the same exact steps. Here's some things that might help that I've done/realized, taken from an ubuntu forums discussion of this\n\n\n*\n\n*It doesn't work for me unless I have the usb monitor plugged in when I start up.\n\n*Instead of blacklisting udlfb, blacklist udl, as explained in that forum. To do this, add blacklist udl to a new file called /etc/modprobe.d/blacklist-custom.conf. Then comment out the blacklist udlfb in /etc/modprobe.d/blacklist-framebuffer.conf. \n\n*To finish it out, I just went to system settings -> display, activated the USB monitor, and it came on. I had booted with the displaylink adapter plugged in.\n\n\nCurrently I'm running two external monitors on a MacBook Pro 9,1. It's a little sluggish at times, and my cursor is blinking a lot when I use the built-in monitor along with the two external. Setting the system to not sleep on closing the lid and closing the lid gets rid of the blinking and sluggishness. \n", "Q: Guide for using Juju in deploying to a Raspberry Pi Where is a small-c canonical guide located for using Juju to deploy services to a Raspberry Pi or similar ARM board?\n\nA: Currently the closest that comes to this is manual provisioning which is noted in the documentation as being experimental at the moment.  LXC is an available option as well but that requires further assessment.\n", "Q: Problem with package management after interrupting ttf-mscorefonts installer I tried sudo apt-get install ubuntu-restricted-extras on 13.10 and it all worked well until something named ttf-mscorefonts installer came. It was not getting downloaded for quite a few minutes. So I quit the process.\nNow I am not able to install any software, not from software center. whenever I try with something like sudo apt-get install ****, it shows something like:\n$ sudo apt-get install pip\nE: dpkg was interrupted, you must manually run 'sudo dpkg --configure -a' to   correct     the problem. \nneel101@neel101-Inspiron-7520:~$ sudo dpkg --configure -a\nSetting up update-notifier-common (0.147) ...\nttf-mscorefonts-installer: downloading http://downloads.sourceforge.net/corefonts/andale32.exe\n\nand this continues for several minutes....\nEDIT\nI pressed Ctrl+C now and this came\n^CTraceback (most recent call last):\n  File \"/usr/lib/update-notifier/package-data-downloader\", line 296, in <module>\n    process_download_requests()\n  File \"/usr/lib/update-notifier/package-data-downloader\", line 234, in    process_download_requests\n    dest_file = urllib.urlretrieve(files[i])[0]\n  File \"/usr/lib/python2.7/urllib.py\", line 94, in urlretrieve\n    return _urlopener.retrieve(url, filename, reporthook, data)\n  File \"/usr/lib/python2.7/urllib.py\", line 268, in retrieve\n    block = fp.read(bs)\n  File \"/usr/lib/python2.7/socket.py\", line 380, in read\n    data = self._sock.recv(left)\nKeyboardInterrupt\ndpkg: error processing update-notifier-common (--configure):\n subprocess installed post-installation script was interrupted\ndpkg: dependency problems prevent configuration of ttf-mscorefonts-installer:\n ttf-mscorefonts-installer depends on update-notifier-common (>= 0.119ubuntu2);     however:\n  Package update-notifier-common is not configured yet.\n\ndpkg: error processing ttf-mscorefonts-installer (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of flashplugin-installer:\n flashplugin-installer depends on update-notifier-common (>= 0.119ubuntu2); however:\n  Package update-notifier-common is not configured yet.\n\ndpkg: error processing flashplugin-installer (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n update-notifier-common\n ttf-mscorefonts-installer\n flashplugin-installer\n\n\nA: Try the below commands,\nsudo apt-get autoremove\nsudo apt-get clean \n\nIt will remove all the unused packages.\nOR\nsudo dpkg -P ttf-mscorefonts-installer\nsudp dpkg -P flashplugin-installer\n\n", "Q: Printer doesn't work with laptop I just recently bought a Canon Pixma MG3550 printer and the disk that was supplied doesn't work with wine, and the driver database doesn't have the model, how can I get it to work with my laptop? I'm running Linux Ubuntu 12.04 LT .\n\nA: The following link upubuntu will show you how install Canon Pixma IP and Pixma MG series.\nBut the source of how to install the Canon drivers for Ubuntu comes from the following website called launchpad where a ppa with stable canon drivers must be installed via the command line terminal.\n", "Q: Troubles with modules after upgrade to kernel 3.2.0-60 Everything worked fine until kernel 3.2.0-58. Then the update manager proposed an update to 3.2.0-59, I did it but the update didn't finished successfully (I was able to boot but windows with error messages popped out continuously). So I uninstalled 3.2.0-59 in favour of -58 again, which I'm currently using.\nToday the update manager proposed to install kernel 3.2.0-60, I said OK but still have problems. For example, wireless doesn't work anymore. I mean that the wifi led is red instead of blue and even pressing F12 doesn't help to activate the interface, which is recognized, though:\n$ sudo lshw -class network -short\nH/W path         Device   Class     Description\n===============================================\n/0/100/1c/0      eth0     network   RTL8111/8168/8411 PCI Express Gigabit Ethernet Controller\n/0/100/1c.1/0    eth1     network   BCM4313 802.11bgn Wireless Network Adapter\n\nTrying to understand what happened I did a module diff between -58 and -60 and surprisingly I noted some modules are missing in 3.2.0-60:\n$ diff -u kernel-3.2.0-58 kernel-3.2.0-60 \n--- kernel-3.2.0-58 2014-03-08 23:56:52.290500167 +0100\n+++ kernel-3.2.0-60 2014-03-08 23:57:01.254500638 +0100\n-fglrx                6179097  0 \n-vboxdrv               252228  3 vboxpci,vboxnetadp,vboxnetflt\n-vboxnetadp             13328  0 \n-vboxnetflt             27240  0 \n-vboxpci                22911  0 \n-wl                   2906597  0 \n\nAmong others, wl module is missing, causing the wifi stop working.\nFinally, still on -58:\n$ modprobe --list\n...output...\nupdates/dkms/vboxnetflt.ko\nupdates/dkms/vboxdrv.ko\nupdates/dkms/fglrx.ko\nupdates/dkms/wl.ko\nupdates/dkms/vboxpci.ko\nupdates/dkms/vboxnetadp.ko\n...output...\n\nAny clue to make things to work with kernel 3.2.0-60?\n\nA: It looks like you need to rebuild some proprietary drivers. While using 3.2.0-60, make sure that you have the linux-headers with the same version installed. Then open jockey-gtk and check if any proprietary drivers are being proposed for the wifi. If it is the case, then try to disable then re-enable the drivers, which will force the system to rebuild them for the kernel that you are currently running. \nTo see which kernel you're running do: \nuname -a\n\n\nA: To sure your kernel has been upgraded in correct way you can do these steps.\nStrategy : clean up the kernel module and install new version of kernel by PPA.\n1- Use following command to pure your kernel: \nsudo apt-get purge <kernel>\n\n2- To know your kernel modules,headers,image you can use search in your cache by following command:\nsudo apt-cache search <headers,image,...>\n\nWhen you find it you can purge it by first command.\n3- And to Upgrade new version of kernel you can use this link ( PPA repo )\nchoose your kernel which you want to install it.\nnote: To know your coding of your distribution you can use sudo lsb_release -a \nnote: To know current version of your kernel and architecture you can use: uname -a\nThen you receive *.deb files and after checking its checksum you can\nmove *.deb files to specified folder and run following command:\nfor example : you can make a directory with this name : kernel by using\nmkdir ~/Desktop/kernel and move them into it.\nThen install them by following command:\nsudo dpkg --install ~/Desktop/kernel/*.deb\n\nthen run following command to restart your system:\nsudo shutdown -r 0\n\nI hope it be useful.\n", "Q: No wireless connection on 12.04 upgrade from ubuntu version 10 with Broadcom network controller I updated to 12.04 from ubuntu version 10 and now I can't connect by wifi. \nIt works in windows and worked in 10., Network controller is a Broadcom BCM4311. I tried to remove and then reinstall, but it did not work. \nThe pull down menu for networking doesn't list wireless as an option. If I try to update/install firmware I get a message that it already is the newest version.   \n\nA: Please run the following commands in your terminal.\n    sudo apt-get update\n\n    sudo apt-get install firmware-b43-installer\n\n    sudo apt-get remove bcmwl-kernel-source\n\nThen reboot\n", "Q: How to use a regular expression with apt-cache search to find all Wine versuons? I am writing a script to install some things and I'm having trouble with a regular expression that I am using. I have the Wine repository in my apt sources (ppa:ubuntu-wine/ppa) and I am using the following command:\napt-cache search wine[0-255].[0-255] | sort -nr\n\nNow I was expecting to get 'wine1.7' at the top of the list, but it isn't even listed. \nInstead if I run:\napt-cache search wine | sort -nr\n\nI get a much longer list (obviously) and it contains 'wine1.7'. The list that fails does show a few correct items that match my regex, but not as many as without. These are a couple of examples:\n\n\n*\n\n*wine1.7-i386 - Microsoft Windows Compatibility Layer (32-bit support)\n\n*wine1.7-amd64 - Microsoft Windows Compatibility Layer (64-bit support)\n\n*wine1.5 - Microsoft Windows Compatibility Layer (dummy package)\n\n*wine1.5-i386 - Microsoft Windows Compatibility Layer (32-bit support)\n\n*wine1.5-dev - Microsoft Windows Compatibility Layer (64-bit support)\n\n\nAs you cane see 'wine1.5' is list, but not 'wine1.7'. Is there a better way to get this type of list?\nOr better yet a simple way of finding the latest version from a list to install?\n\nA: That's not how character classes work, the regex does not differentiate between 26 and 2 followed by 6, so your character class is being interpreted as 1-2 or 5. Also, the . means \"match any character\", not a literal ., I don't think the apt regex engine allows escaping, so you'd have to use a character class to match it ([.]). Finally, you need to have multiple occurrences of each number, so you need something like:\napt-cache search --names-only wine[0-9]+[.]*[0-9]*\n\nThe --names-only ensures that your regex is only matched agaist package names, not descriptions.\n", "Q: How to set nomodeset GRUB2 before I've installed Ubuntu When I hit e this is what I see \n\nwhere do I place nomodeset\n\nA: You put nomodeset between the quiet and splash part.\n\nA: You need to enter the quiet splash text using the arrow keys, as i circled in this picture:\n\nAnd you have to type in between quiet and splash (or you may say, splash and quiet.) the text nomodeset, so now it looks like this:\ngetparams 'Try Ubuntu without installing'\n\n       set gfxpoyload=keep\n       linux /casper/vmlinux.efi file=/cdrom/preseed/ubuntu.seed boot=casper $ quiet nomodeset splash -\n       initrd /casper/initrd.lz\n\n(I'm not sure if the picture says \"set gfxpoyload=keep\" beacuse it's confusing to see the text.)\n\nA: Put your cursor 1 spacebar back behind \"quiet splash\" and type noapic. So it will look like this \"xxxxxxxxxxx noapic quiet splash\" don't use quotes though and the x's are just whatever it says before where I want you to place noapic and I believe it's f10 to save and boot. Please post if it helped you as that's what I've had to do on my Asus laptop for a couple years and has always worked and I just started using bbqlinux and I had to do the same thing as well to get it to boot but it works with bbqlinux as well. Good luck... ~skulldreamz\n", "Q: How do I fix my internet on Ubuntu 12.04 server? I have Ubuntu Server 12.04 installed with no GUI. I installed ownCloud and webmin a few months ago with no problem, so I know my internet used to work. The power went out while the PC was on one day 2 months ago and I did not turn the PC back on until yesterday. Now I have no internet connection. Does anyone know how I can fix this, or should I just reinstall Ubuntu?\nthis is the output of ifconfig -a: \n eth0   link encap:Ethernet  HWaddr 00:06:4f:4a:66:f0\nBROADCAST MULTICAST  MTU:1500  Metric:1\nRX packets:0 errors:0 dropped:0 overruns:0 frame:0\nTX packets:0 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:1000\nRX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\neth1   link encap:Ethernet  HWaddr 00:16:ec:05:c8:9c \n    BROADCAST MULTICAST  MTU:1500  Metric:1\n    RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n    TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n    collisions:0 txqueuelen:1000\n    RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nlo     Link encap:Local Loopback\n    inet addr 127.0.0.1  Mask:255.0.0.0\n    inet6 addr:  ::1/128 Scope:Host\n    UP LOOPBACK RUNNING MTU:65536  Metric:1\n    RX packets:1800 errors:0 dropped:0 overruns:0 frame:0\n    Tx packets:1800 errors:0 dropped:0 overruns:0 carrier:0\n    collisions:0 txqueuelen:0\n    RX bytes:143896 (143.b KB)  TX bytes:143896 (143.8 KB)\n\nI have a wired connection.\n Here are the contents of etc/network/interfaces: \n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# The primary network interface\nauto eth0\niface eth0 inet dhcp\n\nI tried assigning a static IP to eth2, which is a adapter I just added, and now when I run ifconfig it shows a inet addr of 192.168.1.100. So I have an ip now. When trying to add the default gateway, I typed route add default ge 192.168.1.1, and it said,\nUsage: inet route [-vF] del {-host|-net} Target[/prefix] [gw GW] [metric M] [[dev] if]\n\nThere are 5 more lines of writing associated with this route error, but I do not want to type all that out unless it is needed. Does anyone know what to do?\n\nA: Looking at your ifconfig output, I don't see any IP address assigned, there are many ways of troubleshooting this issue, assuming you have your cable connected to the first Ethernet port eth0 on your server. \n\n\n*\n\n*send new DHCP request\ndhclient eth0 \n\n\n*Try and assign static IP if DHCP request failed.\n ifconfig eth0 192.168.1.100/24 up \n\nthen add default gw \nroute add default gw 192.168.1.1 \n\n\n\n*\n\n*try and ping 8.8.8.8 and hopefully you will get a response. \n\n", "Q: Trying to install Ubuntu from DVD get message \"No operating system\" and everything halts I know there is no operating system on my computer, I had the HD 100% wiped. I was intending for Ubuntu to be my operating system. Am I to assume I cannot install from a DVD because I have no operating system? Is there something I'm missing? I tried with Puppy Linux too, because I believed that could be operated from the disc. Same thing, \"No operating system\".\n\nA: Like the comments above change the boot order from the bios so that it boots from disk first.\n", "Q: How to cancel time conversion in librecalc? Whenever I add an \"hour\" entry on a LibreOffice Calc field, it converts into a full hour format after I hit Enter.\ne.g. I get the following conversion: \n17:00 => 05:00:00PM\n\nAny idea how to disable this?\n\nA: Just select a different time format to format the time value:\n\n\n*\n\n*select the cells to format\n\n*right-click on them\n\n*select \"Format Cells...\"\n\n*From the leftmost listbox (\"Category\"), select \"Time\"\n\n*From the listbox in the middle (\"Format\"), select the appropriate entry.\n\n\n\n", "Q: Wireless not working on iMac G4 I have an iMac G4 running Ubuntu 12.4 PPC. When I try to connect to a wifi network, the computer doesn't seem to remember the SSID:\n# iwconfig wlan0 essid <SSID>\n# iwconfig\n...\nwlan0    IEEE 802.11bg ESSID:<SSID>\n         Mode:Managed Frequency:2.427 GHz Access Point: Not-Associated\n         ...\n\nA few minutes later...\n# iwconfig\n...\nwlan0    IEEE 802.11bg ESSID:off/any\n         Mode:Managed Frequency:2.427 GHz Access Point: Not-Associated\n         ...\n\nI can provide other logs/output as needed.\n\nA: Please do:\ngedit /etc/network/interfaces\n\nThis will tell you what is in a file called interfaces. You should see:\nauto lo\niface lo inet loopback \n\nI already know that file is empty according to the information you posted. Please add those two lines and nothing else. Save, close gedit and reboot. If you have another text editor instead of gedit you will use it in the command above in place of gedit.\nIf you did not manually setup interfaces run:\nsudo dpkg-reconfigure resolvconf\n\nif you want to have reslovconfig configured manually then you will want to remove network manager.    \n", "Q: Can a GIF be used as the Ubuntu Splash Screen instead of the boring purple one? I'm using Ubuntu Builder and I really want to change the splash screen. It's my first time using Ubuntu Builder, and most of the work is being done offline (limited access...). By following the instructions in this AU post I've managed to set a custom plymouth background wallpaper. It is just a still image.\nBut I was just curious to know if I could use an animated GIF image for the splash-screen replacing the need for the codes in plymouth script to swap through .png images for boot animation.\n\nA: No.  You can't.  Animated gifs are unsupported by plymouth at this time.  \nYou have to use timers and swap the image yourself.\n", "Q: How do I remove or reinstall Ubuntu in Windows 8 UEFI dual when Ubuntu is set as default? I have a UEFI dual boot with Windows 8 and Ubuntu, with GRUB set as the default boot manager.\nI am looking to do a reinstall of Ubuntu since I accidentally did apt-get remove for some system packages. However, I cannot drop to root shell and do sudo apt-get install --reinstall ubuntu-desktop because it gives me a few errors saying that critical dpkg config files are missing or something like that.\nIf possible, I would just like to reinstall rather than remove and install, as this would save my files (the files have been backed up in a Windows 8 partition).\nIf I would need to reinstall, can I just remove the partition and then reinstall via DVD and Ubuntu GRUB would work, or would I have to set Windows 8 as my default UEFI boot manager?\n\nA: First backup your documents onto an external disk (USB or DVDs), then boot on your Ubuntu disk and follow this procedure from the Community Documentation.\n", "Q: malformed line in source list, getdeb E:Malformed line 2 in source list /etc/apt/sources.list.d/getdeb.list (URI)\n\n^^ This is what I get back, earlier I was trying to get Pokemon Online to install properly, and it wasn't working, so I tried to get getdeb, now it won't check or show updates without giving me the message above, what am I doing wrong?\nEDIT: Now it keeps sending me the information that it's experiencing an error continually.\nEDIT 2:\nThese are the contents of the file /etc/apt/sources.list.d/getdeb.list:\ndeb http://    archive.getdeb.net/ubuntu precise-getdeb apps  \ndeb  \nhttp://   archive.getdeb.net/ubuntu saucy-getdeb apps  \ndeb http://    archive.getdeb.net/ubuntu saucy-getdeb apps  \ndeb http://    archive.getdeb.net/ubuntu precise-getdeb games  \n\n\nA: If I read the question correctly, your /etc/apt/sources.list.d/getdeb.list looks like this:\ndeb http:// archive.getdeb.net/ubuntu precise-getdeb apps\ndeb\nhttp:// archive.getdeb.net/ubuntu saucy-getdeb apps\ndeb http:// archive.getdeb.net/ubuntu saucy-getdeb apps\ndeb http:// archive.getdeb.net/ubuntu precise-getdeb games\n\nIf so, the problem is indeed on the second line. deb lines have this format:\ndeb http://repo.url.com repo_section(s)\n\nSo, open that file in an editor using sudo \nsudo gedit /etc/apt/sources.list.d/getdeb.list\n\nThen, edit the file so that it looks like this:\ndeb http://archive.getdeb.net/ubuntu precise-getdeb apps\ndeb http://archive.getdeb.net/ubuntu saucy-getdeb apps\ndeb http://archive.getdeb.net/ubuntu saucy-getdeb apps\ndeb http://archive.getdeb.net/ubuntu precise-getdeb games\n\nMake sure each lines starts with deb and that there are no spaces between http:// and archive.\n", "Q: Installed fglrx and Selected fglrx-update from Software Settings - Now Black Screen on Boot I have been tinkering around because I find that Ubuntu 13.10 (which I have as dual boot on my Asus laptop) get my computer a little hot and I get some crashing issues sometimes when watching videos, and more crashes when using slimboat.\nReading around a bit, I (wisely or otherwise) installed fglrx, and then I went into System Settings > Software Updates and in one of the tabs there selected \"proprietary driver fglrx update\". On rebooting my laptop into Ubuntu, I hear the login sound, but get a black screen.\nSince I cannot get into System Settings now to change the graphics card driver back, what can I do?\nMy graphics card is an ATI Mobility Radeon HD 5470 1 GB. My laptop is 86_64 bit.\nEDIT: I looked at the page that gives advice about how to fix the problem of booting to a black screen. I installed Ubuntu a few weeks ago successfully, and have been using it just fine with the exception of some crashing with video files and browsers, as explained above. So the advice for a new install doesn't apply, and grub is working just fine so the dual boot advise doesn't apply either.\nI did follow the advise about ATI Radeon drivers:\nIf your graphics card is ATI, follow these steps:\n\n    In the GRUB menu at startup, press \"e\"; then\n    Use the arrow keys to replace quiet splash with radeon.modeset=0.\n    Then press the Ctrl+x key combination to boot.\n\nThis did not work either (and I also tried \"nomodeset\"). Although I did get the purple screen straight out of grub (which I wasn't getting), only to go black before the login screen and the login sound.\nThe issue here is that I messed around with the graphics driver, and would like to be able to get in long enough to change my settings as explained in my opening 3 paragraphs.\n\nA: 1. Open a text-only virtual console by using the keyboard shortcut Ctrl + Alt + F3.\n2. At the login: prompt type your username and press Enter.\n3. At the Password: prompt type your user password and press Enter.\n4. Now you're logged in to a text-only console where you can change your graphics driver from whatever you have now (fglrx-updates???) back to whatever driver you had that was working before (for example, fglrx if that's what driver you were using that was working before). \"Reading around a bit, I (wisely or otherwise) installed fglrx, and then I went into System Settings > Software Updates and in one of the tabs there selected proprietary driver fglrx update.\"\nIf you can't get into a text only console by pressing Ctrl+Alt+F3 you need to boot into recovery mode.\nImmediately after the motherboard / computer manufacturer logo splash screen appears when the computer is booting, with BIOS, quickly press and hold the Shift key, which will bring up the GNU GRUB menu. (If you see the Ubuntu logo, you've missed the point where you can enter the GRUB menu.) With UEFI press (perhaps several times) the Esc key to get to the GRUB menu. Sometimes the manufacturer's splash screen is a part of the Windows bootloader, so when you power up the machine it goes straight to the GRUB screen, and then pressing Shift is unnecessary.\n\nPress the down arrow key until you select the 2nd entry from the top (the one with the recovery mode in the description) and then press Enter.\nNow you should see this recovery menu:\n\nUsing the arrow keys scroll down to network and then press Enter.\nUsing the arrow keys scroll down to root and then press Enter.\nYou should now see a root prompt, something like this:\nroot@ubuntu:~#\n\nAt this stage you should have a read-only filesystem. You have to remount it with write permissions:\nmount -rw -o remount /\n\nNow uninstall the current graphics drivers and then reinstall the one you had before that worked.\napt-get remove fglrx-updates\n\n5. Reboot the system by running the command: reboot\n6. Now you have gone back to the graphics driver you had originally,  whatever Ubuntu 13.10 installed by default. Try it for a while and test if it works. Afterwards you can decide whether or not to try to install the proprietary fglrx driver.\n", "Q: gwibber twitter authorization problem I've tried to authorize my twitter with gwibber before (I've reinstalled ubuntu because some other problem), now I can't authorize any twitter account, it just tells me \"SSL is required\" and I have SSL installed in my system, or do I have the wrong SSL library?\n\nA: I had the same problem and found a fix over on launchpad. Basically, you have to make a few edits to some of the gwibber python scripts. Here's a copy of the instructions:\n\nFile /usr/share/gwibber/plugins/twitter/gtk/twitter/init.py\nLine 78 and 144 - Needs to be \"https\" where it states \"http\"\nFile /usr/share/gwibber/plugins/twitter/init.py\nLine 401 - Needs to be \"https\" where it states \"http\"\n\nThe fix will probably show up in the an ubuntu update at some point.\n", "Q: How do I fix ugly boot screen when using Nvidia drivers Ubuntu 13.10? I have recently installed Ubuntu 13.10 64-bit.\nIt was, by default, using the Nouveau display driver, however, this caused suspend to fail. I installed a proprietary driver which resolved that issue but created an ugly low res boot screen. \nHow can I fix it?\n\nA: This is the solution that worked for me. (for those who have this common issue)\nRun in Terminal\n\n*\n\n*sudo apt-get install v86d\n\n\n*gksu gedit /etc/default/grub\n\n\n*Replace Line: GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nNew Line: GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset video=uvesafb:mode_option=1920x1080-24,mtrr=3,scroll=ywrap\"\n\n\n*Replace Line: #GRUB_GFXMODE=640x480\nNew Line: #GRUB_GFXMODE=1920x1080\n\n\n*Save & Close\n\n\n*gksu gedit /etc/initramfs-tools/modules\n\n\n*Add Line: uvesafb mode_option=1920x1080-24 mtrr=3 scroll=ywrap\n\n\n*Save & Close\n\n\n*sudo update-grub2\n\n\n*sudo update-initramfs -u\n", "Q: How to use Custom Ubuntu Images with Ubuntu Juju? I am using Ubuntu Juju in Windows Azure Platform. I want to use customized Ubuntu Image to create the Virtual Machines using JUJU. How to use Customozed Ubuntu Images to create Virtual machines using Ubuntu Juju ?\n\nA: The Juju way would be to have a collection of charms which customize the vanilla image, rather than having a custom image to start with. \nIf you want to set all sorts of background things in your image, the best way is to have a subordinate charm which handles that. This way, you only need the vanilla, trusted, up to date standard image and all your personal changes are kept in one place.\n", "Q: Booting Lubuntu I get EDIC Checksum is invalid remainder is 8 error On-boot I get  EDID checksum is invalid, remainder is 8 error.  The error doesn't seem to cause any problems and Lubuntu continues to load and everything seems to be OK.  \nI had to add the Battery Indicator and I did set the Laptop=yes thing in the config file to get the power manager to auto load on start but would love to solve the EDID error. Can anyone please help.  \nOn looking at the lspci -v output I can see that the VGA Compatible controller is 945GSE Express Integ and the Display controller is 945GM/GMS/GME, can anyone suggest anything, I am not an experienced Linux user but I have not found much on Google.\n\nA: I tried many things but not the nomodeset and guess what? It works.  Anyone else having the same problem can follow the instructions here:\nhttp://ubuntuforums.org/showthread.php?t=1613132\nBasically the instruction was adding nomodeset option to /etc/default/grub files GRUB_CMDLINE_LINUX_DEFAULT key. Like this\nGRUB_DEFAULT=0\n#GRUB_HIDDEN_TIMEOUT=0\nGRUB_HIDDEN_TIMEOUT_QUIET=true\nGRUB_TIMEOUT=10\nGRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset\"\nGRUB_CMDLINE_LINUX=\"\"\n\nand it worked great.  The boot time is a little longer but no EDID errors.\n", "Q: Installing Ubuntu Touch Failed Nexus 7 2012 I tried to install the trusty version of Ubuntu Touch on my 2012 Nexus 7. I followed the directions here and I entered\nsudo ubuntu-device-flash --channel=devel --bootstrap\n\nuntil my terminal returned\nCannot push /home/nick/.cache/ubuntuimages/devel/grouper/version-194.tar.xz to device\n\n(I also tried to do it manually, with that failing as well)\n\nA: Your problem is that support for the Nexus 7 (gen 1) has been dropped, and this method won't work any more. This was announced on 03-Mar-2014 (as noted below).\n\nIn formal terms:\nSupport (as reference hardware) for the Nexus 7 (original model) is now deprecated, with development now focused on: Nexus 4 smartphone, Nexus 7 (2013) tablet, and Nexus 10 tablet.\nSee: https://wiki.ubuntu.com/Touch/Install\n\nSupported devices and codenames\nThe table below lists the supported devices and their corresponding factory images, ..\n\n\nSee also:\nhttp://www.omgubuntu.co.uk/2014/01/ubuntu-touch-wont-support-nexus-5-will-drop-support-nexus-7-10\n\nNexus Device Support Dropped\nAlong with no dice for the Nexus 5, moving Ubuntu Touch to an Android 4.4 enablement stack has resulted in further decisions on which devices should remain “officially supported”.\nFrom the end of January official builds for three of the four currently supported Nexus devices will be discontinued, affecting users of:\n  \n  \n*\n  \n*Nexus 10 (2012)\n  \n*Nexus 7 (2012)\n  \n*Galaxy Nexus\n  \n  \n  ..\n\nPLEASE NOTE:\nThis article does not exactly match current support, as Nexus 10 in still (for the moment) being supported. However, focus (going forward) is definitely on the Nexus 4 (for phone), and Nexus 7 (2013) (for tablet).\n\nA: The original 2012 model's support has been made deprecate in favour of the newer (per-se) 2013 model.\n", "Q: errors while using 'sudo apt-get update' W: Failed to fetch cdrom://Ubuntu 13.10 _Saucy Salamander_ - Release amd64 (20131016.1)/dists/saucy/restricted/binary-i386/Packages  Please use apt-cdrom to make this CD-ROM recognized by APT. apt-get update cannot be used to add new CD-ROMs\n\nE: Some index files failed to download. They have been ignored, or old ones used instead.\n\nI am new to ubuntu so I dont know how to solve this error. This is shown at the end after executing 'sudo apt-get update' command. I think this is preventing me from installing new apps like wine 1.7.\n\nA: No, it's not preventing you to install wine.Just try to remove or put # before the below line in /etc/apt/sources.list file,\ndeb cdrom:[Ubuntu 13.10 Saucy Salamander - Release amd64 (20131016.1)]/ saucy main restricted\n\nAnd then run an update,\nsudo apt-get update\n\n", "Q: Why does apt removes unwanted packages when giving * as suffix? I did a sudo apt-get remove ruby* and then I saw that some grub packages were being removed too so I went to installed back those packages which log showed to have removed\nI set grub to work on my /sda (in general, not any number) when was installing back.\nShould all be ok or should I fear for my system and plan installing/reconfiguring more of grub.\nAnd, why did this happpen?\n\nA: If you don't know exactly what you are doing, you should not use:\nsudo apt-get remove package.*\n#                          ⤷ or any other character in the place of dot\n\nas this can delete unintended packages and cause more problems than it solves. The package.* will match all packages (and their dependencies) containing the string package in their name. This is from man apt-get, somewhere at the line 110:\n\n       If no package matches the given expression and the expression\n       contains one of '.', '?' or '*' then it is assumed to be a POSIX\n       regular expression, and it is applied to all package names in the\n       database. Any matches are then installed (or removed). Note that\n       matching is done by substring so 'lo.*' matches 'how-lo' and\n       'lowest'. If this is undesired, anchor the regular expression with\n       a '^' or '$' character, or create a more specific regular\n       expression.\n\n\nAnd this is from Regular Expressions/POSIX Basic Regular Expressions Wikibooks:\n\n*   Matches the preceding element zero or more times. For example, ab*c matches \"ac\", \"abc\", \"abbbc\", etc. [xyz]* matches \"\", \"x\", \"y\", \"z\", \"zx\", \"zyx\", \"xyzzy\", and so on. \\(ab\\)* matches \"\", \"ab\", \"abab\", \"ababab\", and so on.\n\nAnyway, if you really want to run something like sudo apt-get remove package.* (or sudo apt-get remove packagey*, or sudo apt-get remove packagec* - all are in this case the same), first run it with -s (--simulate) option to see exactly what it will do (see man apt-get for more info).\nNow, I think that you can solve your problem using the following two steps:\n\n\n*\n\n*Reinstall all the packages that you have removed\n\n*Remove only ruby:\nsudo apt-get remove ruby\n\nOr, if you want to remove all packages starting their names with ruby:\nsudo apt-get remove ^ruby\n\nBut better to simulate first with:\napt-get -s remove ^ruby\n\n\nA: Apt-get works with regular expressions, which means that ruby* selects all packages that contain rub in their name. The correct way to remove all packages starting with ruby is:\napt-get remove ^ruby\n\n\nA: Try this command on terminal,\nsudo grub-install /dev/sda\n\nIt will reinstall grub2 on your disk.\nIf you want to configure your grub then install grub-pc package.Try the below command to install grub-pc package,\nsudo apt-get install grub-pc\n\nNote: Install this package only if you installed Ubuntu in Legacy mode. \n", "Q: What should I do when I get 'There are stopped jobs' error? I face this type of situation many times. \nFor example, whenever I try to open some file in emacs with sudo rights using:\nsudo emacs tet.c &\nInstead of asking me for the password Ubuntu just starts emacs process without any emacs window or any  output on terminal (except for the pid) see the image (if I don't use '&' then it will ask me for the password):\n \nI have two questions related with this:\n\n\n*\n\n*What should I do when I get error that 'There are stopped jobs'? How\ndo I identify all such stopped jobs and kill them? Once I clear the\nterminal I won't have pids of these stopped processes.\n\n*Why is Ubuntu/emacs behaving like this? Why doesn't it ask me for\nthe password?\n\nA: You got the message, because system warns you about active jobs associated with your current shell.\nYou can list these running/stopped jobs by running: jobs,\nThen you can do one of the following:\n\n\n*\n\n*move last job to the foreground by: fg (opposite of bg for background),\n\n*run disown to remove these jobs from your current shell without killing them,\n\n*force logout by killing these tasks by pressing Ctrl+D twice, same as typing exit/logout twice,\n\n*kill these jobs manually by running: kill $(jobs -p) (add -9 for force)\n\n*if you disown them, and you want to still kill all stopped processes, try:\nkill $(ps wuax | awk 'NR>1 && $8 ~ \"T\" {print $2}')\n\nTo answer question about sudo, it won't ask you for the password, as it requires to have active terminal in order to receive the password from standard input, and by running it the background, the shell doesn't wait for the command to finish, so you don't have possibility to interact with the command.\nIn this case, you've 3 possibilities:\n\n\n*\n\n*run command without going into background (&),\n\n*read the password from standard input instead of the terminal device by sudo -S e.g.\necho mypass | sudo emacs tet.c\n\n\n*configure sudo to not ask for the password by: visudo command and editing sudoers file. See: Enable NOPASSWD for user\n\nA: There are stopped jobs message is far, far away to be an error. It's just a notification telling you that you attempt to exit from the shell, but you have one or more suspended jobs/programs (in your case emacs which you putted in background using & at the end of your command). The system doesn't let you to exit from the shell and kill the jobs unless you mean to. You can do a couple of things in response to this message:\n\n\n*\n\n*use jobs command to tell you what job(s) you have suspended\n\n*you can choose to add the job(s) in the foreground using fg command\n\n*if you don't care if the job(s) will terminate, you can just type exit again; typing exit a second time with or without an intervening jobs command will result in the termination of all suspended jobs.\n\n\nTo answer the second question, I will tell you that not Ubuntu or emacs behaving like this. This is a normal behavior when you put an application to run in background. In this case sudo is asking for password, but is asking in background, so you can't see this fact. To see it, you should bring back the job in foreground using fg command:\nradu@Radu: ~ $ sudo emacs tet.c &\n[1] 7732\nradu@Radu: ~ $ # now sudo emacs run in background so you can't see nothing about what's happening\nradu@Radu: ~ $ fg\n[sudo] password for radu:\n\nAfter this you can type Ctrl+Z to put again the job in background if you want. Then you can run again 'fg' command to bring back the job in foreground and so on.\n\nA: When you encounter there are stopped jobs error:\n\n\n*\n\n*typejobs--> you will see the jobs with stopped status\n\n*and then type exit--> you can get out of the terminal\n\n", "Q: Unable to hibernate using sudo pm-hibernate I have recently installed Ubuntu 13.10 alongside Windows 7. The hibernate does not work from command prompt using sudo pm-hibernate, whereas the suspend works fine using sudo pm-suspend.\nWhat could be the problem? How do I solve this?\nOutput of sudo fdisk -l:\nDisk /dev/sda: 100.0 GB, 100030242816 bytes\n255 heads, 63 sectors/track, 12161 cylinders, total 195371568 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0xe0779162\n\n   Device Boot      Start         End      Blocks   Id  System\n/dev/sda1   *          63   195366464    97683201    7  HPFS/NTFS/exFAT\n\nOut put of cat /etc/fstab:\n# /etc/fstab: static file system information.\n#\n# Use 'blkid' to print the universally unique identifier for a\n# device; this may be used with UUID= as a more robust way to name devices\n# that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\n/host/ubuntu/disks/root.disk /               ext4    loop,errors=remount-ro 0       1\n/host/ubuntu/disks/swap.disk none            swap    loop,sw         0       0\n\nOutput of sudo blkid -o full -s UUID:\n/dev/loop0: UUID=\"59cea3d6-37da-4a92-8ccf-f500a76750ff\" \n/dev/sda1: UUID=\"A4D4A3CAD4A39CD4\" \n\n\nA: Hibernation is not supported for wubi installation. You will have to reinstall Ubuntu as a dual booted OS and then create a swap partition to enable hibernation.\nRefer:\n\n\n*\n\n*How to install Ubuntu without removing windows?\n", "Q: Unable to disable Session restore on xubuntu 12.04 I am using Xubuntu 12.04 with the xfce 4.10 ppa, and since updating xfce I can not disable the automatic session restore.\nI have disabled the relevant options in 'Session and Startup', but it makes no differences and all my windows are still restored after login.\nIf I remove the content of .cache/sessions it works for the next reboot but after that the session will be restored again.\nI thought about writing a script to delete it at startup, but I was wondering if there were any proper fixes to this issue.\nThanks,\n\nA: Since there are no other suggestions, here is a quick fix for anyone who comes across this thread :\nemacs _path_/startup.sh\n\nwrite in the file\n#!/bin/bash\n\nrm -rf /home/_name_/.cache/sessions/*\n\nmake it executable\nchmod +x _path_/startup.sh\n\ngo under 'Session and Startup' and add _path_/startup.sh to the applications automatically executed when xfce opens.\n\nA: It is possible that you have stumbled on a bug related to the Action Buttons. For a discussion of a very similar issue reported recently see: \n\n\n*\n\n*How to permanently disable the \"save session\" feature in Xubuntu?\n", "Q: Installing/booting Windows installation from GRUB? I need access to Windows for school. I had an issue dual-booting with Windows 8 so now I only have Ubuntu. I made a Windows 7 USB installer but for some reason the BIOS won't recognize the USB.\nI was hopping and wondering if there is a way to load an USB through grub?\n\nA: have you check you boot settings in biso settings to load from usb first \nand usb devices enebled\nthen load \nhere is step by step\n1) Change the BIOS boot order so the USB device option is listed first.\n2) Attach the USB device to your computer via any available USB port.\n3) Restart your computer.\n4) Watch for a Press any key to boot from external device\ni hope this was helpfull\nif not please let me know i will help trobleshoot this problem :)\n\nA: How to Burn Windows Image:\nStep 1: Download \nUniversal USB Installer\nStep 2: Launch Program\nStep 3: Inside Program Follow Steps (Make sure you use windows xp and above to burn iso image )\na) Choose the OS you want to install\nb) Select the iso image of the Windows\nc) Select the flash drive (Make sure its FAT32 formated)\nd) Click Create and then wait till it says: Process Complete!\nand now try loading windows usb stick.\nlet me know if you still getting problems\n", "Q: ATI Driver issues - 13.10 I am installing Xubuntu 13.10 on an old laptop I have.  When I boot up to the installer, the display is fine, everything seems to be working perfectly, however, on the Xubuntu boot screen, the colours all look weird (they're all pink and green).  I noticed the same when I had Kubuntu running on it, and I just figured that it was because the system wasn't powerful enough for Kubuntu.\nNow I'm thinking it has to be a display driver issue.  But how do I fix it?  The laptop has an ATI Mobile Radeon 7500 card, so I suppose I need to install the right drivers...\n\nA: Installed the driver using\nsudo apt-get install fglrx\n\nand this did the trick!\n", "Q: Ubuntu 13.10 GNOME: visual glitch when hovering over icons I recently installed Ubuntu GNOME 13.10, and this is the only obvious issue so far. Every time I hover over an icon of any sort, a pixelated green glitch occurs on the icon that the mouse is hovering over. I am baffled by this issue, as it doesn't seem like anyone has asked a question relating to this issue before. Someone please help! Further details can be provided.\n00:02.0 VGA compatible controller [0300]: Intel Corporation Haswell-ULT Integrated Graphics Controller [8086:0a16] (rev 09)\n\n\nA: I have the same issue, dell e7440:\n00:02.0 VGA compatible controller [0300]: Intel Corporation Haswell-ULT Integrated Graphics Controller [8086:0a16] (rev 0b). I get the glitch hovering over icons and corrupted pixels while scrolling in the preview pane in thunderbird as well. I have a xps14 that is ivy bridge and it definitely does not have the same corrupt video issue.\n", "Q: Can I have a dhcp interface in /etc/network/interfaces? I have an interface already configured for an internal interface, which is static under eth0. My question is, can I create a dynamic outfacing interface under eth1.\nThe reason I want to so this is because, my ISP doesn't support fixed external IP addresses and I am running a server using DynDns. The problem is, I need to set a rule in iptables to FORWARD traffic to my external IP and I need an interface to specify it to iptables, therefore if I use my current external IP it will change.\nMy output of ifconfig:\nroot@helloworld:~# ifconfig\neth0      Link encap:Ethernet  HWaddr 00:0e:7f:a9:10:54  \n          inet addr:192.168.0.8  Bcast:192.168.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::20e:7fff:fea9:1054/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:357 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:358 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:37555 (37.5 KB)  TX bytes:43900 (43.9 KB)\n          Interrupt:20 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:36 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:36 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:3467 (3.4 KB)  TX bytes:3467 (3.4 KB)\nroot@helloworld:~# \n\n\nA: Without catching what you really want to do you could use multiple instances of your interface: See setting up multiple ips in ubuntu\nHope this helps\n", "Q: Two instances of Conky keeps flickering I would like to have two instances of conky running om my screen (possibly three later on) as I would like to show statistics from my two Raspberry Pi's. I'm running Xubuntu/XFCE4 by the way :)\nI already have the two config files ready and the local script executes like this\nsh -c \"sleep 10; conky;\"\n\nAnd the remote script executes like this\nssh -X pi@192.168.1.190 sh -c \"sleep 10; conky;\"\n\nBoth scripts seem to be working individually - bot not at the same time. When they both run the instances flickers and switch between being visible.\nBoth scripts are almost identical - and really not very fancy - just useful.\n# GENERAL CONFIGURATIONS\nout_to_x yes \n\n# Update interval in seconds\nupdate_interval 5.0\n\n# Text alignment, other possible values are commented\nalignment bottom_left\n\n# Aligning vertical\ngap_y 15\ngap_x 10      <-- This variable is set to 100 in the local script\n\n# Use double buffering (reduces flicker)\ndouble_buffer yes\n\nTEXT\n$nodename - $sysname $kernel on $machine\n$stippled_hr\n${color lightgrey}Uptime:$color $uptime ${color lightgrey}- Load:$color $loadavg\n${color lightgrey}CPU Usage:${color #cc2222} $cpu% ${cpubar}\n${color lightgrey}RAM Usage:$color $mem/$memmax - $memperc% ${membar}\n$color$stippled_hr\n${color lightgrey}File systems:\nROOT $color${fs_used /}/${fs_size /} ${fs_bar /}\nSLAVE $color${fs_used /media/slave}/${fs_size /media/slave} ${fs_bar /media/slave} \n\nCan anyone help me?\n\nA: I don't see why what you're doing would cause flickering, but try adding these to your .conkyrc:\ntext_buffer_size 556\nown_window yes\nown_window_type desktop\nown_window_transparent yes\nown_window_hints undecorated,below,sticky,skip_taskbar,skip_pager\nown_window_argb_visual yes\n\nNot at all sure that this will help but it might.\n", "Q: Failed to Install Grub During Upgrade to 13.10 I have upgraded our Ubuntu 12.10 remote server to 13.10.\nDuring the upgrade process, I was asked which partition to install Grub2 to. I didn't know which drive was the boot drive, thus I checked all drives.\n\nThe GRUB boot loader was previously installed to a disk that is no\n  longer present, or whose unique identifier has changed      for some\n  reason. It is important to make sure that the installed GRUB core\n  image stays in sync with GRUB modules and           grub.cfg. Please\n  check again to make sure that GRUB is written to the appropriate boot\n  devices.\n  If you're unsure which drive is designated as boot drive by your BIOS,\n  it is often a good idea to install GRUB to all of       them.\n  Note: it is possible to install GRUB to partition boot records as\n  well, and some appropriate partitions are offered here.      However,\n  this forces GRUB to use the blocklist mechanism, which makes it less\n  reliable, and therefore is not recommended.\n  GRUB install devices:\n  [*] /dev/sda (3000592 MB; TOSHIBA_DT01ACA300)\n  [*] /dev/sdb (3000592 MB; TOSHIBA_DT01ACA300)\n  [] /dev/md1 (536 MB; :1)\n  [] /dev/md2 (1099510 MB; :2)\n\nLater, I got this message:\n\nGRUB failed to install to the following devices:\n  /dev/md2\n  Do you want to continue anyway? If you do, your computer may not start\n  up properly.\n  Writing GRUB to boot device failed - continue?\n\nI know that /boot is mounted to /dev/md1. However, since it's a remote server, I should be %100 sure before rebooting it.\n$mount\n/dev/md2 on / type ext4 (rw)\nproc on /proc type proc (rw)\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\nnone on /sys/fs/cgroup type tmpfs (rw)\nnone on /sys/fs/fuse/connections type fusectl (rw)\nnone on /sys/kernel/debug type debugfs (rw)\nnone on /sys/kernel/security type securityfs (rw)\nudev on /dev type devtmpfs (rw,mode=0755)\ndevpts on /dev/pts type devpts (rw,gid=5,mode=620)\ntmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)\nnone on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\nnone on /run/user type tmpfs (rw,noexec,nosuid,nodev,size=104857600,mode=0755)\nnone on /sys/fs/pstore type pstore (rw)\n/dev/md1 on /boot type ext3 (rw)\n/dev/md3 on /home type ext4 (rw)\nsystemd on /sys/fs/cgroup/systemd type cgroup (rw,noexec,nosuid,nodev,none,name=systemd)\n\nHow can I be sure that Grub was installed correctly?\n\nthe output of sudo parted -l  is:\n$ sudo parted -l\n\nModel: ATA TOSHIBA DT01ACA3 (scsi)\nDisk /dev/sda: 3001GB\nSector size (logical/physical): 512B/4096B\nPartition Table: gpt\n\nNumber  Start   End     Size    File system  Name  Flags\n 5      1049kB  2097kB  1049kB                     bios_grub\n 1      2097kB  8592MB  8590MB                     raid\n 2      8592MB  9129MB  537MB                      raid\n 3      9129MB  1109GB  1100GB                     raid\n 4      1109GB  3001GB  1892GB                     raid\n\n\nModel: ATA TOSHIBA DT01ACA3 (scsi)\nDisk /dev/sdb: 3001GB\nSector size (logical/physical): 512B/4096B\nPartition Table: gpt\n\nNumber  Start   End     Size    File system  Name  Flags\n 5      1049kB  2097kB  1049kB                     bios_grub\n 1      2097kB  8592MB  8590MB                     raid\n 2      8592MB  9129MB  537MB                      raid\n 3      9129MB  1109GB  1100GB                     raid\n 4      1109GB  3001GB  1892GB                     raid\n\n\nModel: Linux Software RAID Array (md)\nDisk /dev/md0: 8589MB\nSector size (logical/physical): 512B/4096B\nPartition Table: loop\n\nNumber  Start  End     Size    File system     Flags\n 1      0.00B  8589MB  8589MB  linux-swap(v1)\n\n\nModel: Linux Software RAID Array (md)\nDisk /dev/md1: 537MB\nSector size (logical/physical): 512B/4096B\nPartition Table: loop\n\nNumber  Start  End    Size   File system  Flags\n 1      0.00B  537MB  537MB  ext3\n\n\nModel: Linux Software RAID Array (md)\nDisk /dev/md2: 1100GB\nSector size (logical/physical): 512B/4096B\nPartition Table: loop\n\nNumber  Start  End     Size    File system  Flags\n 1      0.00B  1100GB  1100GB  ext4\n\n\nModel: Linux Software RAID Array (md)\nDisk /dev/md3: 1892GB\nSector size (logical/physical): 512B/4096B\nPartition Table: loop\n\nNumber  Start  End     Size    File system  Flags\n 1      0.00B  1892GB  1892GB  ext4\n\n\nA: Actually, /dev/md1 is mounted to /boot, not the other way around. In any case, you seem to have installed GRUB to sda and sdb, neither of which are mounted on your system. That should not be an issue and since installing to sda will install to the MBR of the 1st hard drive, you should be fine. However, to be on the safe side, you can try installing to your system drive as well:\nsudo update-grub\nsudo grub-install /dev/md\n\n", "Q: rsync two existing directories copying everything I have two file servers in two locations. Currently both have the same data, which generally is unmodified (used for read only access).When the second server was set up (the one I'm sshing to) the data was copied over LAN and has since been moved geographically.\nI'm trying to use rsync for the first time on the required directories. An example command;\nsudo rsync -avz --ignore-existing -P --dry-run /media/Storage/OSs/ user@mydomain:/mnt/Storage/OSs/\n\nI've tried using -c -t -u (Additionally went on the remote server and updated the timestamps to today) also but every time I execute a dry run it wants to copy everything!\nAdditionally the user is the same for both machines with the same UID.\n*Edit\nAfter playing around a bit more, I've found that rsync does not like the whitespace in the subdirectory names; For instance if I use ' to escape local shell & \\ to escape remote shell\n\nsudo rsync -avz --ignore-existing -P '/media/Storage/OSs/Windows/Windows server 2011/' 'user@mydomain:/mnt/Storage/OSs/Windows/Windows\\ server\\ 2011/'\n\nThen all is well, my theory is then that rsync does not like the subdirectories with whitespaces. I have thousands of subdirectories; the only solution I can think of is to write a small python/shell script to run each sub directory separately but is undesirable.\n\nA: Turns out I should have bitten the bullet...\nThe dry run was just outputting the directories it explores but not the actual files.\nI ran rsync for real and all was ok it skipped everything apart from the one or two new additions.\nFor reference this worked;\nsudo rsync -avzs --ignore-existing --progress '/media/Storage/OSs/' 'User@MyDomain:/mnt/Storage/OSs/'\n\n", "Q: Is Disk Utility encryption the same as dm-crypt? I have found the following 2 minute video which shows how to encrypt a usb drive using ubuntu's disk utility app:\nhttp://www.youtube.com/watch?v=J_g-W6hrkNA\nMy question is, is that method using dm-crypt, or some other technique for encrypting the drive?\n\nA: Yes.\ngnome-disc-utility (or palimpsest as it was once named) uses Linux Unified Key Setup  which is a disk encryption specification. It is an enhanced version of cryptsetup, using dm-crypt as the disk encryption backend. From the 1st link:\n\nLinux Unified Key Setup (LUKS)\nCryptsetup is a utility used to conveniently setup disk encryption based on dm-crypt kernel module. These include plain dm-crypt volumes, LUKS volumes, loop-AES and TrueCrypt compatible format. Project also includes veritysetup utility used to conveniently setup dm-verity block integrity checking kernel module.\nLUKS Design\nLUKS is the standard for Linux hard disk encryption. By providing a standard on-disk-format, it does not only facilitate compatibility among distributions, but also provides secure management of multiple user passwords. In contrast to existing solution, LUKS stores all setup necessary setup information in the partition header, enabling the user to transport or migrate his data seamlessly.\nLUKS was designed according to TKS1, a template design developed in TKS1 for secure key setup. LUKS closely reassembles the structure recommended in the TKS1 paper, but also adds meta data for cipher setup management and LUKS also supports for multiple keys/passphrases.\n\n\n*\n\n*More detail in this topic on security stack exchange.\n\n", "Q: How do I use /etc/network/interfaces instead of network-manager I have 12.04 Desktop installed, how do I uninstall Network-Manager and set /etc/network/interfaces as the default file to resolve my network connections?\n\nA: In the file /etc/NetworkManager/NetworkManager.conf:\n[main]\nplugins=ifupdown,keyfile\ndns=dnsmasq\n\nno-auto-default=00:0C:29:90:24:0F,00:0C:29:2E:C8:2C,\n\n[ifupdown]\nmanaged=false\n\nwhere false means that network-manager doesn't manage the interfaces located in the file /etc/network/interfaces.\n\nA: If you manually manage your network card in /etc/network/interfaces , network manger will not manage it , it will state \"Not Managed\"\nSuppose your network card is eth0 :\nTo setup eth0 to static, enter:\nopen /etc/network/interfaces :\n\nauto eth0\niface eth0 inet static\naddress 192.168.1.15 #------> Your Ip Address\nnetmask 255.255.255.0 #------> Netmask\ngateway 192.168.1.254 #-------> Gateway\nbroadcast 192.168.0.255 \ndns-nameservers 192.168.1.3 #-----> Dns server\n\nTo setup eth0 to dhcp, enter:\nauto eth0\niface eth0 inet dhcp\n\nThe different keywords have the following meaning:\nauto: the interface should be configured during boot time.\niface : interface\ninet: interface uses TCP/IP networking. \nNow restart service :\nsudo service network-manager restart\n\n", "Q: How can I find the ProgID of a Windows program to use in Wine? You can open documents in particular programs in Wine from the terminal using \nwine start /ProgIDOpen <ProgID> <Document_to_open>\n\nThis format is necessary, since calling Wine programs in alternative ways will not open the document. e.g. the following launch the application, but do not open the document.\n/path/to/prog.exe <Document_to_open>\nwine /path/to/prog.exe <Document_to_open>\n\nHowever, it's not obvious how to find the <ProgID> associated with each program. How can I find this information?\n\nA: The ProgIDs are listed in $WINEPREFIX/system.reg, which by default is at ~/.wine/system.reg. They are of the format.\n[Software\\\\Classes\\\\FoxitReader.FDFDoc] 1382350649\n\nAlthough there are additional semi-duplicate lines such as\n[Software\\\\Classes\\\\FoxitReader.FDFDoc\\\\DefaultIcon] 1382350649\n\nTo list all ProgIDs, use the following command (in the terminal).\nsed -rn 's/^\\[Software\\\\\\\\Classes\\\\\\\\([^\\]*)\\].*/\\1/p' system.reg | less\n\nFor those unfamiliar with less: to search, press /, type a phrase then Enter ; to exit, press q.\n\nA: This might be fairly late but since you called for simpler ways (and for future readers), this is what I found. I didn't find it out myself, credits go to this post on the Ubuntu forums.\nSince Windows uses drive letters for it's partitions but Linux follows another concept, Wine links your local file system to $WINEPREFIX/dosdevices/z: so programs installed with Wine would find your file system under drive Z: and could thereby access your files. Instead of struggling through the depths of the windows registry you can simply prepend the file path in the argument with Z:. So in order to open a PDF file with Foxit Reader you would merely have to execute a command like\nwine /path/to/FoxitReader.exe Z:/path/to/whatever_file.pdf\n\nIf you want to put your program in the 'Open with' list in order to open files with a specific program by right clicking on them, you could create a custom desktop entry in your /home/user/.local/share/applications directory and append Z:%f to the Exec command. Sticking to the example, a desktop entry for Foxit Reader could look like this (given that WINEPREFIX is set to the path of your specific Wine environment):\n[Desktop Entry]\nName=Foxit Reader\nExec=wine \"$WINEPREFIX/drive_c/path/to/FoxitReader.exe\" Z:%f\nEncoding=UTF-8\nIcon=DBA8_FoxitReader.0\nVersion=1.0\nType=Application\nNoDisplay=true\n\nContrary to the above-mentioned post it wasn't necessary for me to add all those quotation marks. In case it doesn't work for you, try with adding them back in ('\"\"Z:%f\"\"').\n", "Q: xubuntu no workspaces I removed xubuntu top panel by mistake, and then restored it using this answer, but now I can't see workspaces, tried to add them from settings, didn't work. I'm  on xubuntu 13.10 64 bit xfce 4.11 \n\nA: I think you can add workspace form, panel > panel preference > items > then click the add button, from there you can search workspace switcher. \nWhen I mess up my default settings, I usually add everything like this.\n", "Q: 13.10 Onscreen Keyboard suddenly stopped working My Onscreen keyboard suddenly stopped working. I click with mouse but it's not writing any more. Not sure where is the problem.\n\nA: Try to reinstall your onboard application by running the below command on terminal,\nsudo apt-get install --reinstall onboard\n\nNow it will work.\n", "Q: changing windows c drive to create more partitions hi actually my problem is very specific.\ni have four primary partitions \n\n\n*\n\n*system 100mb - system which create while installing win 7\n\n*windows c drive -820 gb where my windows 7 is installed\n\n*ubuntu - 90 gb where ubuntu 13.10 is installed\n\n*swap partition - for ubuntu \n\n\nall above are primary \ni want to make one more partition in windows but this current situation doesn't allow me to do it.\ni do not want to delete any OS.\nplease help!!!\n\nA: Simply delete your swap partition.From that unallocated space create a new extended partition.There you will be able to create logical partitions(ext4,ntfs,etc).\nBoot Ubuntu live disk or Gparted live disk to do the above operations.\n", "Q: Ubuntu one password forgotten I was trying to activate Ubuntu-one on Ubuntu 12.04 LTS. After all entries were completed the system replied that e-mail has already been used. I remembered that some years back I tried Ubuntu on my system and may have created a Ubuntu-One account. I don't have password which i used at that time.\nHelp.\n\nA: Use this link: https://login.ubuntu.com/+forgot_password\nEnter your Email address on the box. (The Email address you used to register on Ubuntu One.) They will send you an Email.\nEither: 1) Ignore the Second step of the above page. Simply, open the link on the Email, and choose a new password. 2) If you had problem with openning the link, copy/paste the Code they send you on the Email, in the second step of the above page.\nMore information can be found on FAQ page.\n\nA: Assuming you still have access to that email address,\nhttps://one.ubuntu.com/help/faq/how-do-i-recover-or-change-my-password/\n", "Q: How to add \"open with custom command\" option in right click menu of Nautilus Sometimes while going to open a file from Nautilus I do not find the intended application in \"open with\" menu on right click. Or the desired application remains hidden in a long list of applications. It becomes difficult to find it quickly.\nPrior to Ubuntu 11.04 there was a nice feature \"Use a custom command\" under \"open with\" menu on right click on a file. One could able write a command in the box to open a file with a custom application. This option is no longer available in Nautilus after Ubuntu 10.10.\n\nQuestion:\n\nCan I have a similar \"Use a custom command\" dialogue box on Nautilus so that I can open a file writing any custom command in a box as shown in the above picture?\n\n\nA: Here is a small Nautilus script which gives you a \"Use a custom command\" dialogue box on Nautilus.\nThe Script\nSave the following script as Open with custom command in the following directory\n\n*\n\n*~/.local/share/nautilus/scripts/ (Ubuntu 13.04 or above)\n\n*~/.gnome2/nautilus-scripts/ (Ubuntu 12.10 and below)\n\n#!/bin/bash\nvar=$(zenity --entry \\\n--title=\"Add Application\" \\\n--text=\"Use a custom command\" \\\n--width=\"320\")\nif [ $? -eq 0 ] && [ \"$var\" ]; then\n    $var \"$1\"\nelse\n    exit 0\nfi\n\n\n*\n\n*Give the script execution permission. It is important, otherwise no change will take place. You can use in terminal,\n\nchmod +x ~/.local/share/nautilus/scripts/Open\\ with\\ custom\\ command\nOr you can do it from GUI. Right click on the script, then go to Properties >> Permissions and check the box corresponds to Execute to give the script execution permission.\nHow it looks like\nAfter that when you right click on a file you could see an option Scripts followed by another option under script Open with custom command.\n\nWhen you select the option Open with custom command, you will get a dialogue box like,\n\nYou can write a command in the box to open the file.\nUsage\nYou can open any file by entering corresponding application's command only in the dialogue box.\nFor example you can open a .txt file using gedit or a .pdf file writing evince in the dialogue box.\n\nSome Other Usage\nOpen file as root:\nIf you want to open a file as root, just use gksudo before your command. To open a .txt file as root you can use in the dialogue box,\ngksudo gedit\n\nOpening an unknown file:\nIf you are not sure which application to use to open an unknown file, you can use in the dialogue box,\nxdg-open\n\nOpening a file with a Terminal Application:\nIf you want to open a text file using vi, you can use in the dialogue box,\ngnome-terminal -x vi\n\nNote:\nTo use gksudo you need to have gksu installed. In Ubuntu 13.04 onwards it is not install by default. You can install it using,\nsudo apt-get install gksu\n\n", "Q: ecryptfs mounts as read only I did the following (http://haridas.in/how-to-put-encrypted-contents-on-cloud-storages.html), and after mounting, the mounted dir is read-only filesystem:\nI created two dirs: one to /home/user/dir1 and /home/user/Dropbox/dir2. Then:\nmount -t ecryptfs /home/user/Dropbox/dir2 /home/user/dir1\n\nSelected: aes/16 bytes/plaintext passthrough yes/filename encryption no\nCreated /root/.ecryptfsrc file with following content:\nkey=passphrase:passphrase_passwd_file=/home/user/.ecryptfs/passphrase.txt\necryptfs_sig=mysighere\necryptfs_cipher=aes\necryptfs_key_bytes=16\necryptfs_passthrough=y\necryptfs_enable_filename_crypto=n\n\nCreated file /home/user/.ecryptfs/passphrase.txt with content:\npassphrase_passwd=mypassphrase\n\nAdded line to /etc/fstab:\n/home/user/Dropbox/dir2 /home/user/dir1 ecryptfs defaults 0 0\n\nAnd now the dir2 and dir1 are read only filesystem. What should I do to change them to mount as read-write filesystem? When I add the line to fstab, the filesystem mounts as it should, but when system boots, it's mounted as a read-only filesystem.\n\nA: Check write permissions in your mounts :\n\n\n*\n\n*Type cat /etc/mtab and find your ecrypt device\n\n*Remount the partition with read/write permissions : sudo mount -i -o remount,rw /path/to/your/Device/or/.Private\n", "Q: Ubuntu on Acer E1-510 So I have an Acer E1-510-2821 Computer I recently purchased at Walmart. The computer came pre-installed with Windows 8.1. The system of course is UEFI, and unfortunately has no legacy Bios mode.\nI have tried Ubuntu 12.04, Ubuntu 13.10, and Kubuntu 13.10 and, each will show the grub bootloader and allows me to enter my boot parameters if I want. I have tried noapic, nolapic, and of course nomodeset, yet each time the computer only goes to a black screen.\nI have noticed however that in the case of Kubuntu, it actually showed the installer and allowed me to choose \"Try Ubuntu\" or \"Install Ubuntu\", however as soon as I click Try it only goes to a black screen like all the rest. This is the only environment however that I even seen an active mouse. I did not try clicking Install Kubuntu as I do not want to install if I cannot get it to run.\nI tried removing quiet splash and it showed the kernel booting, and each time after booting it would simply show the prompt rather than go to a desktop. If I run sudo service lightdm start then it just goes to the black screen again.\nThe system has an Intel Celeron Quad Core CPU N2920 with integrated graphics, so it's not a proprietary graphics card. Any help to get this running Ubuntu would be appreciated, as I hate Windows 8.\n\nA: Is this a laptop? Does it have screen brightness keys? If so, try using them; the screen might simply be dimmed.\nIf that fails, my next suggestion is much more painful: It's to boot to text mode and create an /etc/X11/xorg.conf file and try adjusting its options (particularly the X driver you're using). This is a very open-ended approach, though, and potentially rather complex. Try doing a Web search on xorg.conf to find tutorials on how to create and use this file.\nOf course, another option is to return the computer; if it's a recent purchase, you can probably do so and get your money back. You can then research what works painlessly with Linux and get something better.\n", "Q: Problem setting the default wired connection I have three wired connections setting saved. I would like to have connection_1 as my default setting whenever I log-in. How can i do that ?\nThanks\n\nA: You can check automatically connect on connection_1 and uncheck it from other connection :\n\n", "Q: Changing decimal separator in existing columns in LibreOffice Calc In LibreOffice Calc, if I have a column with a lot of numbers in this format 8,1 (comma), how  can I transfer all these numbers to the format 8.1 (dot)?\nWhen I say \"a lot\" I mean thousands of numbers, so it is just impossible to rewrite it again in the right format.\n\nA: Go to the Edit, and select Find & Replace.\nUnder Search for, put ,- and under Replace with, put .. Then press Replace All\n\nA: --For ubuntu system:\nGo to System Setting -> Language Support - Regional Format -> \"Display numbers, date and currency amounts in the used format for:\"\nand choose your local system.\n\n", "Q: Format USB stick using LVM? Is it possible to format a USB stick using LVM?  I am interested in LVM because apparently it allows you to create instantaneous snapshots for backup purposes.\n\nA: assume your usb is mounted as sdb1 :\nInstall lvm :\nsudo apt-get install lvm2\n\nCreate physical volume :\nsudo pvcreate /dev/sdb1\n\nCheck if your physical volume is created :\nsudo pvscan\n\nCreate volume group :\nsudo vgcreate \"Nameyouwant\" /dev/sdb1\n\nCheck volume groups :\nsudo vgscan\n\nCreate logical volume (suppose we will use ext3):\nsudo lvcreate -l 100%FREE -next3 \"Nameofvolumegroup\"\n\nCreate ext3 partition :\nsudo mkfs.ext3 /dev/nameyouchoose/ext3\n\nMount your logical volume :\nsudo mount /dev/seagate/ext3 /path you want\nYou can now store your backups .\n", "Q: Libre Office Calc - small sheet toolbar? is there any possible way to enlarge this toolbar where sheets are listed (Sheet 1, Sheet 2, Sheet 3, ...)? See the below screenshot: \n\nIn my case, these cards are so small that it's barely possible to click on it. Please help!\n\nA: Here is a solution without changing your theme :\ngksu gedit /usr/share/themes/Ambiance/gtk-2.0/gtkrc\n\nFind this line : GtkScrollbar::sider-width \nChange it to the number you want , i change it to 25 .\nHere my sheet font size : \n\n", "Q: Ubuntu in Israel? Is it possible to use Ubuntu in Israel? Someone in Israel would use the hebrew keyboard and probably the Hebrew calendar. Is it therefore possible to use the Hebrew calendar in Ubuntu? Is it possible to write hebrew from right to left?\n\nA: you can add hebrew keyboad layout just search keyboard and select keyboard layout\nthen in layouts tab select \"+\" button and add hebrew keyboard layout \n\nA: yes. it is very simple.\nIn the installation process choose the Hebrew as language, and Hebrew keyboard layout.\nabout Hebrew calender, there a lib called libhdate and program (Hdate) base on that. you can find it in ubuntu software center.\nit is very simple program, not something special. \ni'm working on something better, maybe it will be released soon \nAdditionally, you have the website of Ubuntu Israel \n", "Q: Lubuntu dual monitor doesn't save config I'm using Lubuntu and I have a external monitor (connected using HDMI) to my laptop.\nEverytime I enter on Lubuntu, both laptop and Monitor are turned on.\nWhat I do: I go to Menu > Preferences > Monitor Settings and I disable the laptop monitor, I click on Apply and I do the same process again but I click on Save his time, just to be sure.\nhttp://s7.postimg.org/s0fnce4cr/Display_Settings_001.jpg\nI want to use ONLY the external monitor, I don't want to use the laptop's screen.\nBut this process is not working, because when I restart or turn the laptopn on again, both screens are turned on again ... seems that it's not saving my config.\nIs there a way, maybe editing a file, to save this config? Thanks!\n\nA: My solution involves i3, it's not necessarily valid for other cases.\nI've been using ARandR to manage my screens.\nThough after the computer goes to sleep and I turn off the screens, it doesn't detect the dual screens anymore.\nARandR can save your config in a .sh file, by default in ~/.screenlayout/config.sh\nin my case with dual monitor, one vertical one horizontal, you get something like:\nxrandr --output DVI-I-0 --primary --mode 1920x1200 --pos 3840x0 --rotate left --output DVI-I-1 --off --output HDMI-0 --off --output DP-0 --off --output DP-1 --off --output DP-2 --mode 3840x2160 --pos 0x0 --rotate normal --output DP-3 --off --output DP-4 --off --output DP-5 --off\n\nIn i3 config file (~/.config/i3/config) you can insert:\nexec_always '.screenlayout/hv.sh'\n\nThis way, you just need to refresh i3 with mod+shift+R (by default) to update your xrandr config.\n\nA: Try this solution : \nIn terminal :\nType xrandr -----> see what your laptop monitor is called ( maybe LVDS1 )\nNow type xrandr --output LVDS1 --off\nIf its power on after reboot :\nadd : xrandr --output LVDS1 --offin /etc/rc.local and save .\n", "Q: Is it wise to run computing virtual machines on KVM? I have a physical server with 384GB memory. My main applications are to run CPU and I/O intensive programs. I could run everything on the physical server.\nBut I'm wondering if it is better to host a virtual machine on the physical server to simplify future system restoration issues. For example, if the physical server crashes, I can still grab the image of the virtual machine and run it somewhere else. If most of my applications are installed in the virtual machine, then few applications shall be installed on the physical machine. It sounds this strategy can make the system restoration much easier. Also, when I want to duplicate the system configuration, I just need to make a copy of the image of the virtual machine.\nOn the other hand, running processes on a virtual machine is slower than running on a physical machine. And since I have a large memory, the swap space for the virtual machine is also large (should it be 384GB) and is not based on a physical partition. I think that this can cause performance issues.\nCould any experienced users provide some recommendations on whether it is wise to run virtual machines for computing purposes? Thanks.\n\nA: Your server seems to be a good candidate for a \"computing node\" hosting several virtual machines. I would recommend reading about MAAS to manage it.\n", "Q: Broadcom Wireless for Compaq 615 on Ubuntu 12.04.4 LTS I have a problem where after recent updates my Wifi stopped working. I can detect my wireless network but when attempting to join it the wifi icon in the task bar just 'rolls' the wifi signal indicator up and down and never actually connects. It would often ask for the password a few times. I've tried changing the Wifi password, restarting the machine, disabling/enabling the wifi adapter, but nothing seems to be working. I can see the network but just can't connect.\nPlease help. How can I fix this.\nI am using: Broadcom Corporation BCM4312 802.11b/g LP-PHY [14e4:4315] (rev 01)\nThe 14e4 was Orange/red in the report, not sure if that means something?\nAnyone know I can can get my laptop to actually connect to the Wifi again? \n\nA: Please open a terminal and do:\nsudo apt-get purge bcmwl-kernel-source\n\nNow, with a temporary wired ethernet connection:\nsudo apt-get install firmware-b43-lpphy-installer\n\nDetach the ethernet, reboot and let us have your report.\n", "Q: Ubuntu Touch date picker HTML5 I'm working on an app for ubuntu touch in html5 but Im wondering what components I should use for a date or time picker. I've asked it a couple of times on IRC but never got an answer\ngreetz\nJustCarakas\n\nA: Currently the Ubuntu HTML5 UI toolkit (0.1.2) does not have a specific widget for date or time pickers.\nSo you need to create your own set of widgets, maybe using some text fields and an option selector.\n", "Q: How to unistall a program installed by a .sh installer? I downloaded a .sh program (in this case is a game) and then I installed using \"sh name.sh\" (or maybe it was \"bash name.sh\". I don't remember quite well, but I guess it has no importance in this case :P).\nEverything worked as planned. The .sh created a folder in /usr/local/games/ and from there I can run the game from a .bin (I created a \"link to application\" in my Desktop to run it faster).\nSo far so good, but now I want to remove/uninstall the game but I don't know how (I guess that neither apt-get or dpkg work in this particular case. Correct me if I'm wrong).\nSo my question is, how can I remove/unistall this game?\nTyvm in advance for any reply.\nEDIT\nI tried to open and read the .sh (actually, it was the first thing I did), but when I open it, the editor (kate in this case) warns me with the following message:\nThe file /home/user/Games/name/name.sh was opened with UTF-8 encoding but contained invalid characters.\nIt is set to read-only mode, as saving might destroy its content.\nEither reopen the file with the correct encoding chosen or enable the read-write mode again in the menu to be able to edit it.\nAnd when I try to do anything, such as find or select something, my computer gets numb and 'overloaded' and it doesn't let me do anything (almost as a freeze), and since the code is big I can't just read line by line until I find the part(s) I'm looking for.\nThe folder that was created when installed (in /usr/local/games/) has the following:\nname.bin.x86_64\nname.png\nREADME.linux\nxdg-utils (folder)\n  xdg-desktop-menu\nname.dat\nlib64 (folder)\n  libfreeimage.so.3\n  libminizip.so.1\n  libSDL2-2.0.so.0\nxdg-open\n\nI guess that xdg-desktop-menu is used in this case to uninstall the game since when I type in the terminal: \"xdg-desktop-menu --help\", one of the lines says:\nxdg-desktop-menu uninstall [--noupdate] [--mode mode] directory-file(s)\ndesktop-file(s)\n\nBut I'm not sure how to use it. Have someone used something like this? or based in the line above, in this case, what should I type?\n\nA: How do I uninstall?\nThe .sh file is an installer script. It does various actions to install the game. (like copying files to the /usr/local/games/)\nRemove using an remove script (recommended)\nMost applications that ship with a .sh installer also have a .sh remove script. Sometimes you can find the location of the remove script in the README of the application. Otherwise, you will have to search it yourself in the installation directory (/usr/local/games/<NAME_OF_GAME>). It's named uninstall.sh or something similar.\nIf you find the script, you can excecute it by typing ./<NAME_OF_SCRIPT>.sh in the terminal.\nRemove manually\nIf the application does not have an uninstaller script, you can remove the application manually by removing the complete directory /usr/local/games/<NAME_OF_GAME> and removing the launcher. However, it could be that the application also has some files in other directories.\nYou can use the command in Terdon's answer to find all the directories that the installer script changes.\nCan i uninstall using xdg-desktop-menu?\nNo. From the man-pages (man xdg-desktop-menu)\n\nThe xdg-desktop-menu program can be used to install new menu entries\nto the desktop's application menu.\n\nSo it is only used to install/remove the menu entry, not the complete program itself\n\nA: You can't do this automatically, you will have to read the script to see what directories and files it created. You could make that easier with something like:\ngrep -P '(\"|/)\\S+/\\S+' script.sh\n\nThe command above should print all paths found in the install script, assuming they don't contain spaces. You can then have a look at the result and delete them by hand.\n", "Q: Installing Tomcat 5.5 from source for PHP Java Bridge \n\nI want to install PHP/Java Bridge. I installed Tomcat 7 for it, but it failed:\nsudo dpkg -i /home/asif/jbridge/php-java-bridge-j2ee_5.4.4.2-3_all.deb\nSelecting previously unselected package php-java-bridge-j2ee.\n(Reading database ... 190386 files and directories currently installed.)\nUnpacking php-java-bridge-j2ee (from .../php-java-bridge-j2ee_5.4.4.2-3_all.deb) ...\ninvoke-rc.d: unknown initscript, /etc/init.d/tomcat5.5 not found.\ndpkg: error processing /home/asif/jbridge/php-java-bridge-j2ee_5.4.4.2-3_all.deb (--install):\n subprocess new pre-installation script returned error exit status 100\ninvoke-rc.d: unknown initscript, /etc/init.d/tomcat5.5 not found.\ndpkg: error while cleaning up:\n subprocess new post-removal script returned error exit status 100\nErrors were encountered while processing:\n /home/asif/jbridge/php-java-bridge-j2ee_5.4.4.2-3_all.deb\n\nSee it says: /etc/init.d/tomcat5.5 not found. So I want to install Tomcat5.5 but Jakarta is no longer active. So I got Tomcat5.5 from Apache archives. I have downloaded apache-tomcat-5.5.12-src.zip and now I don't know how to install it. How can I?\n\nA: I have tried installing as well. It worked on Tomcat7. You can try that...\n", "Q: Why bonding does not improve network speed? I have the following content in /etc/network/interfaces on one of my server (say server1). On another server (say server2). The content of /etc/network/interfaces is similar. Except that the mac addresses are changed accordingly and the ip address is changed to 192.168.2.2. Ubuntu 13.10 is installed on both servers.\nBut when I use iperf -s on server1 and iperf -c 192.168.2.1 to test the speed. I only get around 10Gbps speed (the speed of a single NIC). My switch is configured as a layer 2 switch. Does anybody know how to make the speed to be 20Gbps through bonding? Thanks.\nauto em1\niface em1 inet manual\nhwaddress ether c8:1f:66:e2:90:43\nbond-master bond0\n\nauto em2\niface em2 inet manual\nhwaddress ether c8:1f:66:e2:90:45  \nbond-master bond0\n\nauto bond0\niface bond0 inet static\naddress 192.168.2.1\nnetmask 255.255.255.0\nnetwork 192.168.2.0\nbond-mode 4\nbond-miimon 100\nbond-lacp-rate 1\nbond-slaves em1 em2\n\nThe output of iperf is the following.\nserver2:~$ iperf -s\n------------------------------------------------------------\nServer listening on TCP port 5001\nTCP window size: 85.3 KByte (default)\n------------------------------------------------------------\n[  4] local 192.168.2.2 port 5001 connected with 192.168.2.1 port 34014\n[ ID] Interval       Transfer     Bandwidth\n[  4]  0.0-10.0 sec  11.0 GBytes  9.41 Gbits/sec\n\nserver1:~$ iperf -c 192.168.2.2\n------------------------------------------------------------\nClient connecting to 192.168.2.2, TCP port 5001\nTCP window size: 22.9 KByte (default)\n------------------------------------------------------------\n[  4] local 192.168.2.1 port 34014 connected with 192.168.2.2 port 5001\n[ ID] Interval       Transfer     Bandwidth\n[  4]  0.0-10.0 sec  11.0 GBytes  9.41 Gbits/sec\n\nI also tried to change the mode to balance-alb and balance-rr. But they don't lead to improved performance as well. Does anybody know to debug the problem? Thanks.\nauto bond0\niface bond0 inet static\naddress 192.168.2.1\nnetmask 255.255.255.0\nnetwork 192.168.2.0\n#bond-mode balance-rr\nbond-mode balance-alb\nbond-miimon 100\nbond-slaves em1 em2\n\n\nA: To reach the ~20Gbps transfer bandwidth with LACP bonding (mode 4) one needs to connect the server to more than one client, The maximum transfer speed of one client is capped to the speed of an individual channel (10Gbps /client max. in the above case). LACP \"Does not increase the bandwidth for a single conversation\"; LACP \"Achieves high utilization only when carrying multiple simultaneous conversations\" as from the slide 7 from the presentation of the gurus:  http://www.ieee802.org/3/hssg/public/apr07/frazier_01_0407.pdf and the same question here: https://serverfault.com/questions/569060/link-aggregation-lacp-802-3ad-max-throughput/569125#569125\n\nA: ifenslave is used to attach and detach slave network interfaces to a bonding device. \nTo install it :\nFor Ubuntu 12.04 and earlier\nsudo apt-get install ifenslave\n\nTo configure it :\nThis link will help you : Link \nYou should be notice that some bonding modes need special switch support.\n", "Q: apt-get install vs pip install I am a bit confused about the cases in which the above commands must be used when downloading python packages. I was trying to download a package named pyudev in accordance with an answer with this question. I executed this command :\nsudo pip install python-pyudev\n\nbut received the following message :\nDownloading/unpacking python-pyudev\n\n  Could not find any downloads that satisfy the requirement python-pyudev\nCleaning up...\nNo distributions at all found for python-pyudev\nStoring complete log in /home/vineet/.pip/pip.log\n\nHowever the following worked fine :\nsudo apt-get install python-pyudev\n\nWhen is apt-get supposed to be used to install packages and when is python-pip used?\n\nA: My preferred way is to always use apt and only in case the module is not yet available in Debian/Ubuntu repository to use pip, but only in user context - --user flag. By using pip one anyway have to get all the build-dependencies installed from let's say Ubuntu's repository or provide them themselves which can be a tedious task. apt-get install binary packages while pip builds them after downloading. One shouldn't use pip to install modules into system locations. This is plain wrong. Always use --user flag to install a module to home location. Properly configured PYTHONPATH let python to pick up the modules from the HOME first and then system modules installed with apt-get.\n\nA: This is the advice given on a widely linked issue on the GitHub pip site on the subject of system installed pip vs local installed pip:\n\n\n*\n\n*Only ever use your system package manager to upgrade the system pip. The system installed pip is owned by the distribution, and if\nyou don't use distribution-supplied tools to manage it, you will hit\nproblems. Yes, we know pip says \"you should upgrade with pip install\n-U pip\" - that's true in a pip-managed installation, ideally distributions should patch this message to give appropriate\ninstructions in the system pip, but they don't. We're working with\nthem on this, but it's not going to happen soon (remember, we're\nlooking at cases where people are upgrading old versions of pip here,\nso patches to new versions won't help).\n\n\n*Never use sudo with pip. This follows on from the first point. If you think you need to use sudo, you're probably trying to modify a\ndistribution-owned file. See point 1.\n\n\n*Prefer to use --user. By doing this, you only ever install packages in your personal directories, and so you avoid interfering\nwith the system copy of pip. But there are PATH issues you need to be\naware of here. We'll cover these later. Put simply, it's possible to\nfollow this advice, and still hit problems, because you're not\nactually running the wrapper you installed as --user.\n\n\nA: As @AvinashRaj said in his comment, pip is used to install python packages only, but apt-get is used to install packages created in any programming language.\nYour main problem is to find the right package name in both cases:\npip search pyudev\n\nwill give you the right name for the package you want to install using pip install, as\napt-cache search pyudev\n\nwill give you the right name for the package you want to install using apt-get install:\nradu@Radu: ~ $ pip search pyudev\npyudev                    - A libudev binding\nradu@Radu: ~ $ apt-cache search pyudev\npython-pyudev - Python bindings for libudev\npython3-pyudev - Python3 bindings for libudev\n\nSo, in conlusion, the correspondent of sudo apt-get install python-pyudev is sudo pip install pyudev, not sudo pip install python-pyudev.\nNow depends on you what you want to choose when you want to install a python package: pip or apt-get. See for example this Q&A about difference in installing a package using pip and apt-get.\n\nA: PyPI is the Python Package index — repository of python modules.\npip is used to download and install packages directly from PyPI. PyPI is hosted by Python Software Foundation. It is a specialized package manager that only deals with python packages.\napt-get is used to download and install packages from Ubuntu repositories which are hosted by Canonical.\nSome of the differences between installing python packages from apt-get and pip are as follows:\n\n\n*\n\n*Canonical only provides packages for selected python modules. Whereas, PyPI hosts a much broader range of python modules. So, there are a lot of python modules which you won't be able to install using apt-get.\n\n*Canonical only hosts a single version of any package (generally the latest or the one released in recent past). So, with apt-get we cannot decide the version of python-package that we want. pip helps us in this situation. We can install any version of the package that has previously been uploaded on PyPI. This is extremely helpful in case of conflict in dependencies.\n\n*apt-get installs python modules in system-wide location. We cannot just install modules in our project virtualenv. pip solves this problem for us. If we are using pip after activating the virtualenv, it is intelligent enough to only install the modules in our project virtualenv. As mentioned in previous point, if there is a version of a particular python package already installed in system-wide location, and one of our project requires an older version of the same python package, in such situations we can use virtualenv and pip to install that older version of python package without any conflicts.\n\n*As @Radu Rădeanu pointed out in this answer, there would generally be difference in names of packages as well. Canonical usually names Python 2 packages as python-<package_name> and Python 3 packages as python3-<package_name>. Whereas for pip we generally just need to use <package_name> for both Python 2 as well as Python3 packages.\nWhich one should you use:\nBoth apt-get and pip are mature package managers which automatically install any other package dependency while installing. You may use anyone as you like. However, if you need to install a particular version of python-package, or install the package in a virtualenv, or install a package which is only hosted on PyPI; only pip would help you solve that issue. Otherwise, if you don't mind installing the packages in system-wide location it doesn't really matter whether you use apt-get or pip.\n", "Q: cant install \"additional driver\" I uninstalled the \"additional driver\" app from the ubuntu software center.\nAfter that ,when I tried reinstalling it ,I am getting this error- Package dependencies cannot be resolved\nHow can I reinstall it again?\n\nA: From the comments, the output of sudo apt-get install -f command shows,\n\nReading package lists... \nDone Building dependency tree Reading state information... \nDone The following package was automatically installed and is no longer required: \njockey-common \nUse 'apt-get autoremove' to remove them. \n0 upgraded, 0 newly installed, 0 to remove and 438 not upgraded\n\nThe above error report shows clearly that you have to run sudo apt-get autoremove command to automatically remove all the unused packages.In your case it's jockey-common. While running sudo apt-get autoremove command, it removes automatically jockey-common package.And also sudo apt-get install -f will solve dependency problems.\n", "Q: What is this GNUstep folder? I am using ubuntu 12.04 LTS and I opened the GUI and noticed this folder called GNUstep and Mail. Here is a screenshot of it: \nInside GNUstep is Library which is empty. And inside of Mail is Drafts and Outbox.\n\nA: First its GNUstep not GNUsetup , some one downloaded or installed it on your desktop .\nGNUstep provides an environment to easily develop advanced GUI desktop applications as well as server applications.\nGNUstep offers Development tools for command-line and GUI development, as well as the foundations for a Desktop environment, which other projects can complete. \nReference\n", "Q: How to set DLL to native (Wine) I'm currently trying to setup MathCad14 on 13.10 using Wine 1.7.\nHere are the instructions I'm using.\nIn there I'm told to:\n\nset all DLLs to Native (especially msvcm80.dll). \n\nI have no idea how to do this. Can anyone explain?\n\nA: *\n\n*Open Wine Configure or winecfg from command-line.\n\n\n*Select Libraries tab: Enter name of DLL or select it from dropbox\n\n\n\n*Click Add, it should be (native first then built-in) → Apply\n\nNotes:\n\n*\n\n*You may create new profile for MathCad from Applications tab if you don't want global settings.\n\n\n*DLL override modes: It's possible to force only native or builtin DLL. But I recommend using these to cover both cases:\nbuiltin, native wine will try its builtin DLL then Microsoft native DLL\nnative, builtin wine will try Microsoft native DLL then its own builtin DLL\nSee Chapter 4. Configuring Wine\n\n\n*Sometimes, it is needed to figure out which libs are loaded, this may help WINEDEBUG=+loaddll wine yourprogram.exe.\nSee General help on running applications under Wine\n", "Q: Remove Ubuntu 12.04.4 from secondary drive I am a novice and need help to solve the following.\n\n\n*\n\n*My computer.\n\n\n*\n\n*Intel i5-4440 processor,\n\n*Intel DB85FL motherboard,\n\n*Western Digital WDC WD5000AAKX-6 , 500 GB, primary disk with Ubuntu\n13.10,64bit, whole disk.\n\n*Seagate ST3500418AS , 500 GB, secondary with 12.04.4,64bit, whole\ndisk.\n\n*Samsung SyncMaster 943 and so on.\n\n\n*In BIOS, the boot priority is as follows. \n\n\n*\n\n*DVD drive \n\n*WD HDD\n\n*Seagate HDD \n\n*USB\n\n*Internet\n\n\n*On booting the system, Ubuntu displays the option to boot from \n\n\n*\n\n*Ubuntu, \n\n*Advanced options for Ubuntu 13.10,\n\n*Ubuntu 12.04.4,\n\n*Advanced options for Ubuntu 12.04.4,and System Setup\n\n\n\nI want to remove everything on the secondary Seagate ST3500418AS, 500 GB, with 12.04.4, to use it as my backup drive. But without affecting anything from Western Digital WDC WD5000AAKX-6 , 500 GB, primary disk with Ubuntu 13.10. I have nearly 208GB data on this. \nPlease advice me.\n\nA: *\n\n*In Ubuntu 13.10 (on the drive you want to keep), open up GParted.\n\n*Check to see which drive is listed as which. My guess is that the Western Digital drive will be listed as /dev/sda, and the Samsung drive will be listed as /dev/sdb. If it's the other way around (or if you have more drives listed), change the next step appropriately.\n\n*Switch to the /dev/sdb drive (the Samsung drive) using the drop-down in the top-right corner.\n\n*You should see your Ubuntu 12.04 partition. Right-click on the partition and remove the partition.\n\n*Apply the changes. GParted might see that the boot configuration might be affected, and so might automatically do the next step, but just in case (there's no harm in doing it twice)...\n\n*Open up Terminal and run sudo update-grub.\n\n*When you reboot, you should see that only Ubuntu 13.10 has the menu entries present. At this point, you can remove/repurpose the Samsung hard drive.\n", "Q: Ubuntu will not go to login screen I am a new user and i have been using Ubuntu for a couple of weeks now. I shut the computer down yesterday and when i opened it this morning it got stuck at the loading screen with the dots. I tried opening grub by pressing shift and nothing happened. I don't really know what else to do. If anybody could please help me solve this it would be greatly appreciated as i have some important files saved there. \n\nA: you can try below listed method On start press:\nCtrl + Alt + F1\nthen type 'startx' (without quotes)\n", "Q: Extreme difference in navigation speed between Win7 and Ubuntu 13.10 I have dual boot 13.10 and Windows 7. After the installation of the driver rtl8188ce in both Ubuntu and Windows, Ubuntu holds the connection, unlike before. But there is a very big difference in navigation speed.\nWhat could be the problem and how can I fix it?\n\nA: If you have administrative priveleges over the router, I suggest you change the WPA2 encryption method to AES. It is more secure. Also, if the router uses WPA and WPA2 mixed mode, change it to WPA2 only.\nSecond, if the connection is made as expected, but seems to drop for no apparent reason, there are a few things we can try:\nsudo modprobe -r rtl8188ee\nsudo modprobe rtl8188ee swenc=1\n\nAlso, find your country code here:\niw reg get\n\nIf it shows as 00, that's a one-size-fits-all...maybe code. Let's try setting your code explicitly. Find it here: http://en.wikipedia.org/wiki/ISO_3166-1_alpha-2 Set it with:\nsudo iw reg set IS \n\nOf course, substitute your actual country code, if not Iceland.\nFinally, tell your system you wish to always use your preferred network rather than roaming to another: Ubuntu connect drops. Worked for a while then started dropping again\nIn order to make some or all of these permanent, we'll need to amend a few files. First, tell us if the problem is resolved.\nIf none of these steps help, I suggest you compile a later version of the driver. Please obtain a temporary wired ethernet connection. Please download this file to your desktop: https://www.kernel.org/pub/linux/kernel/projects/backports/stable/v3.13.2/backports-3.13.2-1.tar.gz  Right-click it and select 'Extract Here.' Now open a terminal and do:\nsudo apt-get install linux-headers-generic build-essential\ncd ~/Desktop/backports-3.13.2-1\nmake defconfig-rtlwifi\nmake\nsudo make install\n\nYou will get a warning about signing that you may safely ignore. Detach the ethernet, reboot and let us hear your report.\n", "Q: Grub2 and Windows 7 & Vista I would like to triple boot... don't ask why ;-)...\nI have Ubuntu 13.10 and ghost copy of W7 and Vista installation. Would like to be able to boot all three OS from the same partition.\nThe problem is that it wont boot both the Vista and 7. I think the issue is related to the guid on the partition. And that systemreserved partition that both Windows versions have.\nI would like to end up with Grub2 managing all three OSes but I don't want Windows' own boot manager knowing and showing the other OS in its boot menu. If I would start Windows 7 then it will only boot it, same with Vista.\n\nA: In 1st step make 3 partitions for all your system, but (because u need disable partitions)  i think better would be when u get 2 'hdd' to install on 1st Ubuntu and to 2nd windows \nhttp://ubuntuforums.org/showthread.php?t=1664134\nsudo apt-get install grub2\n\n\nA: More of a Windows install issue than this forums Ubuntu with grub.\nThe Windows boot loader only knows one primary partition to boot from. In Linux we see that as the boot flag, in Windows it is the active partition. All installs of Windows will put boot files into that one active partition.\nIf you install each Windows in a separate primary NTFS partition with the boot flag at the time of install, it will keep its boot files. Or you may be abel to move boot flag and do repairs to restore boot files. If second install is in a logical partition it may not be possible.\nThen from grub you can direct boot each Windows install. But the Windows boot loader if restored to the MBR, would only boot one install or the other depending on which has boot flag.\nPictures here worth 1000+ words - Vista but all Windows with BIOS/MBR\nhttp://www.multibooters.co.uk/multiboot.html\n", "Q: 'mount: error while loading shared libraries: libudev.so.0 : no such file or directory' I got this error while booting\n'mount: error while loading shared libraries: libudev.so.0 : no such file or directory' \n\nThen i followed this\nI Booted into recovery mode and opened terminal and installed libudev0 using\n    apt-get install libudev0 \nIt says its already installed \nEven i linked libudev0 and libudev1 as mentioned here\nBut no gain :( \nEDIT: Output of locate -e libudev.so.0\n/lib/i386-linux-gnu/libudev.so.0\n/lib/i386-linux-gnu/libudev.so.0.13.0\n/lib/x86_64-linux-gnu/libudev.so.0.13.0\n\n\nA: I am guessing that you are running a 64bit system. If so, this dirty hack should work:\nsudo ln -s /lib/x86_64-linux-gnu/libudev.so.0.13.0 /lib/x86_64-linux-gnu/libudev.so.0\n\nThat will crate a link named libudev.so.0 that points to /lib/x86_64-linux-gnu/libudev.so.0.13.0.\n\nA: i had the same problem on ubuntu 12.04 x64, solved it fast \nfirst remounting  with \nsudo mount -o remount, rw /\n\nthen locating the libudev.so.0\nlocate -e libudev.so.0\n\nthen doin the \"dirty trick\"\nsudo ln -s /lib/x86_64-linux-gnu/libudev.so.0.13.0 /lib/x86_64-linux-gnu/libudev.so.0\n\nworked perfectly to me,\n  thanx Terdon!\n", "Q: Would someone plese tell what section this is that I have outlined in red I am attempting to edit this theme and have no idea what this section is. So I outlined it in red and would appreciate someone telling me what section it is. thanks\n\nThe name of the section, I want the name of the section.\n\nA: I am almost sure that is a menu bar:\n\nA menu bar is a region of a screen or application interface where drop down menus are displayed. The menu bar's purpose is to supply a common housing for window- or application-specific menus which provide access to such functions as opening files, interacting with an application, or displaying help documentation or manuals. Menu bars are typically present in graphical user interfaces that display documents and representations of files in windows and windowing systems but menus can be used as well in command line interface programs like text editors or filemanagers where drop-down menu is activated with shortcut key or combination.\n\nMore about: http://en.wikipedia.org/wiki/Menu_bar\n", "Q: How to upgrade from Ubuntu amd 64bit to intel 64bit? I've been using Ubuntu 12.10 for about a year and half now on my laptop with an intel processor. When I installed it I was dumb enough to commit the mistake of downloading a amd 64bit version of the OS instead of an  intel 64bit version. It actually works ok sometimes, but I think that I might be forcing my processor since it's using the wrong drivers, and Ubuntu sometimes randomly freezes when I have just few programs open and I end up having to force restart it. \nMy question is, is it possible to upgrade to a intel 64bit version of Ubuntu, without loosing most of the programs I have installed and personal files? Thanks in advance.\n\nA: AMD were first to produce a commercial 64bit CPU architecture aimed at normal users rather than the server market. As a result, amd64 has come to be used to mean any 64bit architecture. There is no such thing as intel64, the possible names are x86-64,x86_64,x64, and AMD64x86_64 but they all refer to the same architecture. \nYou can test this by running uname -m. On my system, for example, with an intel i7 CPU, I get:\nx86_64\n\nSo, any issues you are having are not because you installed the wrong version. I suggest you post a new question, explaining your issues and we'll see if we can figure it out.\n\nA: They are the same thing. From Ubuntu's help page:\n\nEach manufacturer has a different name for 64-bit, such as: AMD's AMD64 and Intel's IA-32e (later EM64T). We use AMD64 to refer to all implementations.\n\nHowever, there is another 64-bit Intel architecture named Itanium, also known as IA-64. Itanium desktop machines are very rare, and that architecture hasn't been supported since version 10.04 of Ubuntu. It was discontinued due to a lack of developer interest.\n", "Q: Calc always have to zoom in! Every time when I open new document in Libre Office Calc, the cells are too small so every time I have to zoom in with CTRL+scroll wheel UP;  (See the picture below)\n\nHow can I set the most acceptable view for me (but not only for one document, I want larger cells every time I open new blank document)?\n\nA: Go to Tools -> Options -> LibreOffice -> View and reset the Scaling option to 100%. Yours appears to be set at 22%.\nTo quickly reset the scaling for any open sheet, double-click on the display percentage at the bottom-right of the window (next to the scaling slider) to bring up the Zoom & View Layout dialog.\n\nA: What you describe makes me think of a broken template. I'd suggest to create a new one and set it as your default Calc template:\n\n\n*\n\n*Open a Calc document, adjust the zoom level to 100%\n\n*Save the document by choosing File - Save As Template and saving the document in the My Templates category.\n\n*Choose File - New - Templates.\n\n*Double-click My Templates in the list. You will see the user-defined templates in the user directory specified under Tools - Options - LibreOffice - Paths. Select the template you have just saved.\n\n*Choose Set as default. The next time you open a new Calc document, the new spreadsheet will be based on the new default template.\n\n\nA: *\n\n*Close all CALC windows\n\n*open a new one\n\n*Go to bottom right slider and move it to 100% (or whatever value you need)\n\n*Close CALC\n\n*open it again; cells are now in correct size :)\n\n\nyou can also do it from Menu > View > Zoom\n", "Q: Deja-dup cannot access Truecrypt volume when run from Cron I have a deja-dup set up to backup into a mounted Truecrypt volume. It works fine but now I would like to run deja-dup in my own intervals via Cron (set up for my account):\n* * * * *  env DISPLAY=:0 deja-dup --backup\n(the every-minute schedule is just for testing)\nThe job is started fine but deja-dup outputs that the destination is not available:\n\nIf I try to set up the Cron job through the \"Scheduled Tasks\" GUI and select it to be \"X application\", it's added to the Cron jobs as:\n* * * * * /usr/bin/python /usr/share/gnome-schedule/xwrapper.py c 2 # JOB_ID_2\nHowever, when the job is run, it fails in the same way as with my own Cron setting.\nAs the task starts just fine if I run it from terminal, my assumption is that for some reason the task started via cron doesn't have permission to access the mounted volume.\nQ1: As the task is started from my user's Cron settings and should therefore run as my user, why wouldn't it have access to a mounted volume?\nQ2: Could the reason of failure be something else than permissions?\nQ3: Can you suggest some solution for this problem?\n\nA: Based on answers for other question, I managed to find the solution myself. It consists of starting deja-dup with a script that adds some system variables. The cron job then obviously runs the script.\n#!/bin/bash\n\nexport DISPLAY=:0\n\nsessionfile=`find \"${HOME}/.dbus/session-bus/\" -type f`\nexport `grep \"DBUS_SESSION_BUS_ADDRESS\" \"${sessionfile}\" | sed '/^#/d'`\nexport `grep \"DBUS_SESSION_BUS_PID\" \"${sessionfile}\" | sed '/^#/d'`\nexport `grep \"DBUS_SESSION_BUS_WINDOWID\" \"${sessionfile}\" | sed '/^#/d'`\n\ndeja-dup --backup\nexit 0\n\nNOTE: If somebody comes up with a well-written answer that not only provides this or other working solution but that also explains the reason for the problem, what DBUS session is and what role it plays in this problem, I'll gladly accept your answer instead of this one.\n", "Q: How to select an already-made partition to install Ubuntu I have Windows 8 on my PC right now and I would like to install Ubuntu. On my HDD I have following partitions (I see the names form a partition software I use which is called \"MiniTool Partition Wizard\"):\n\n1) *:SYSTEM (FAT32)\n2) *: (Other)\n3) C:OS (NTFS)\n4) D: (NTFS)\n5) G: (NTFS)  <- this is the one I created for Ubuntu\n6) *:Recovery\n\n\nAll I want to do is to Install Ubuntu on G: partition.\nThe problem comes when I am in the Ubuntu installation page abd I select the option to manually partition the Hard Drive.\nNames shown in that window are not the same as the ones shown on windows, and I cant recognize and install.\nAnd I obviously want to have a dual-boot with Ubuntu and W8.\nCan someone help me? Thanks a lot in advance.\n\nA: As i can't comment yet, i'll post this as an answer.\nAgain someone correct me if i am wrong with my answer.\nThe G: partition you have is formatted as NTFS.\nIf you want to install Ubuntu it is best not to format the partition.\nThe problem however will be that you will be unable to access the partition from Windows.\nOn a side note, is the G: partition you made a seperate disc or another partition of a single disc?\nPart of Ubuntu prefers to be installed at the beginning of a disc. (could be wrong here)\n\nA: Linux has no concept of separate drives; everything is one file system, and other drives (partitions, actually) are mounted somewhere on the single filesystem.  Everything can be accessed from the root directory.\nSo the best way to handle your situation is to either delete that partition and let Ubuntu create one, or note the sizes of the partitions to make sure you get the right one - assuming they are not close to the same size.\nMost likely, your Windows partitions will be sda1, sda2, etc; this means the first drive, first partitions, and the sd is one of the labels for disk drives.  But the one for Ubuntu is probably the highest number, such as sda3, sda4 or sda5.  Still, it's best to confirm by checking the size.  Or, if you are installing from a live CD, you can run gparted to visually see the partitions, and also see how much data each partition has.\n\nA: To use an existing partition for your Ubuntu installation you must choose \"something else\", then click \"change\" for the partition you wish to use. While not required it is recommend to have a swap partition so you might want to trim a little off that NTFS one for swap before starting the installation process.\nScreenshot of selecting a partition for Ubuntu to install on (make sure to check the \"format the partition\" box, even though this photo shows it unchecked):\nhttps://www.copy.com/s/JQbwzdx6ishL/screen_shot_iuoedww7oid_18.PNG\nwww.copy.com/s/Hk0uRTzAB4Yo/screen_shot_iuoedww7oid_19.PNG\nwww.copy.com/s/NdCBTXh7UM2T/screen_shot_iuoedww7oid_20.PNG\nI strongly recommend you backup your UEFI partition before installing Ubuntu. You can do this by creating an archive (.zip .tar etc) or even just copying and pasting the files that are currently stored on your FAT32 system partition.\nSources:\nNeed advice installing Ubuntu on 2nd storage drive for windows 7 computer\n\nA: Yes it's different.It will be like dev/sda1 or dev/sda2 etc.It's not just like C,D,F partitions in windows.Indentify the correct partition by used and unused spaces.\nMy opinion is Go back into Windows and find the used, unused space on your G partition.Note it down on paper.It will helps you to easily identify your G partition during Ubuntu installation.Otherwise you gonna mess with partitions.\nAtlast format your G partion to ext4 filesystem during Ubuntu installation.So that only, you can be able to install Ubuntu on that partition.\n", "Q: How can I change the icon for a binary file on my desktop? I want to change icon of a binary file which is placed on my desktop. The binary file is related to unetbootin. I want to execute unetbootin from the desktop so I want to change the icon.\nHow can I achieve this?\n\nA: You must be talking about a .desktop file? open it with gedit, find the Icon= line and change the icon to what you want it to be. \nOr, the GUI way: right click on the .desktop file > properties > click on the icon and browse to another icon. \nBy the way, you need to make it executable to have it work from the desktop!\n\nA: How to change the icon of a Unity Launcher (12.04 or above):\nUnity Launchers are files stored in your computer, with a .desktop extension. These files are used to launch a specific application, but in Unity they are also used so as to create right-click menus for each application, which you can access from the Unity Launcher.\nSuch file looks something like this:\n[Desktop Entry]\nVersion=x.y\nName=ProgramName\nComment=This is my comment\nExec=/home/$USER/Documents/exec.sh\nIcon=/home/$USER/Pictures/icon.png\nTerminal=false\nType=Application\nCategories=Utility;Application;\n\nIcon field is the icon that should be used by the launcher and represents the application. All icons that are under the directory /usr/share/pixmaps don't need to have their full path specified, but their filename without the extension.\nFor example, if the icon file is /usr/share/pixmaps/wallch.png, then the Icon field should be just wallch. All other icons should have their full path specified. \n\nTherefore, in order to change the icon for a specific program, you need to:\n1. Find the related .desktop file, they are commonly under /usr/share/....\nYou can do so with:\nlocate program_name.desktop\n\nor if you can't seem to find it:\nlocate *.desktop\n\nand scroll through the list.\n2. Open the .desktop you want to modify:\ngedit /path/to/program_name.desktop\n\n3. Modify any of the fields you wish: \nJust to be save, make a backup first, which you can replace for the original file in case you screw up:\ncp /path/to/program_name.desktop /path/to/program_name_backup\n\n\nSource and further information:\nhttps://help.ubuntu.com/community/UnityLaunchersAndDesktopFiles\n", "Q: grub EFI bootup order I have two versions of Linux installed in different partitions on a 2013 iMac and I'm using rEFInd to perform the initial booting, which then starts up the grub EFI binary that lives on a dedicated MSDOS partition.\nIf I select grub, it seems to scan all my partitions and discovers a kernel at /dev/sda8 (latest release) and /dev/sda9 (long term support). It then gives me the option to boot into each kernel, but orders them in alphabetical order: meaning the old kernel is the default. But I want the new kernel to be the default.\nThere do not appear to be any config files for this /boot/efi/EFI/ version of grub... the /boot/grub/* files are specific to each installation.\nHow can I set the display order (or at least the default choice) for grub EFI?\n\nA: See the following question and answers:\nHow do I change the GRUB boot order?\nAn alternative is to ditch GRUB entirely; rEFInd can launch your kernels directly, assuming they're 3.3.0 or later. You may need to install an EFI filesystem driver. With that done, you can edit the refind.conf file to change the default_selection option to specify which kernel you want to boot by default.\n", "Q: How to root my Acer Tablet I'd like to know if there a chance to root my Acer tablet \nto install ubuntu on it. There is method under Windows but this \ndid not work on my tablet. \nI've still seached the internet but can't find a solution.\nCan some one help me?\n\nA: Here is the procedure for installing Ubuntu touch including unlocking your device and backing it up prior to doing anything.\n\n\n*\n\n*https://wiki.ubuntu.com/Touch/Install\nFor supported devices (The only Acer device is Iconia A700);\n\n\n*\n\n*https://wiki.ubuntu.com/Touch/Devices\n", "Q: 13.10: Can't log in So I've tried just about every fix I could find out there, but I still can't log in to my account. When I enter the correct password, the screen goes black for about a second, the cursor disappears, and after another second it brings me right back to the login screen. I can log in to the guest account without any issues, but not the one I normally use. For reference, I've tried all these possible solutions:\nsudo mv ~/.Xauthority ~/.Xauthority.backup\n\nNothing happens. Exact same issue.\nsudo apt-get remove --purge cinnamon*\nsudo apt-get autoremove\n\nTells me cinnamon is not installed. Issue continues.\nls -lah\nchown \"username:username\" .Xauthority\n\n\"username\" = my username. No errors, but the issue persists.\nls -ld /tmp\nsudo chmod a+wt /tmp\n\nStill no errors, but no sign of being able to log in.\nsudo dpkg-reconfigure lightdm\n\nWorks in the background for about a second and.... nothing. Issue persists.\nsudo add-apt-repository ppa:ubuntu-x-swat/x-updates\nsudo apt-get update\nsudo apt-get install nvidia-current\n\nUpdate of Nvidia drivers proceeds with no errors, but it does nothing to correct my issue.\nsudo service lightdm restart\n\nKicks me back to the login screen but the issue persists.\nsudo rm ~/.Xauthority\nsudo rm ~/.Xauthority\n\nNothing happens.\nReinstall Ubuntu (twice.)\nNothing changed either time.\nEDIT: Contents of /var/log/xorg.0.log available at http://paste.ubuntu.com/7063767/\nAnyone have some Ideas? \n\nA: This may sound silly but is the caps-lock on on your keyboard when you try to enter your password? also, perhaps your keyboard has malfunctioned. Try plugging in a different keyboard.\n\nA: Try switching into CLI by pushing ctrl + alt + f1 and see if you can log in that way.  From there try switching back to the GUI using startx or lightdm start\n", "Q: laptop display black noob here...  searching for a while for the answer to this but haven't had any luck.\nI am out of town and just fired up my laptop but got a black screen only.  Totally my fault because I usually have a monitor plugged in and (with the help of an few websites) wrote a script to keep my laptop display off, but I forgot to disable it before travelling now I am kinda screwed.\nI managed to get a terminal up and tried playing with xrandr but it just keeps telling me 'can't open display' whenever I try something.  I don't remember what the content of the script was but xrandr sounds farmiliar.\nSo I am a little frustrated and could use some help.\nI have an acer aspire 5315 running lubuntu (most recent stable, 13.04 I think?)  Nothing fancy or crazy...jus need to get it working so I can get some work done.\nAny help would be greatly appreciated!\n\nA: Does the Fn keys on your laptop do anything? If there are Fn keys there should be a combination that switches display, but since your script forces the display off I don't know if it would even do anything at all. If it doesn't:\n\nTry xrandr | grep disconnected to list the disconnected displays you have, then do:\nxrandr --output <monitor name (eg. LVDS-1, HDMI-1, etc)> --auto\n\nand see if it switches back on. Well if it does, remember to disable to script this time round.\n", "Q: Launch Steam games without a X Desktop running I'm using the first, accepted answer to this question to have Steam as an Environment on Login.\nSteam itself works fine, but when I attempt to start a game, the screen turns black and I have to restart LightDM service to be able to login again...\nHow do I launch a game when there's no Desktop Environment running, just LightDM and Steam in BigPicture mode?\nI've tried to start DotA2 and Super Hexagon, but both times the screen turns black.\n\nA: You need have a window manager running.\nIf you don't know how, there's a project for what you want to do:\nsteam big picture xsession\n\nA: Steam Login will launch you directly into BPM and also reduce overhead on your processor.\n", "Q: Terminal, how to quit --More-- list I use autocomplete a lot in the terminal, like for example for cp command. But sometimes, when I am putting in the directory for the cp command and I press Tab, the list of files is so long that Ubuntu spits out part of the list and then waits for key input before sequentially listing the rest of the files, one by one. This feature is near useless because you never know how many files are left, and almost always end up with an error. \nIs there some way to leave this list and go back to my cp command, or do I have to press Ctrl+C and start typing in my cp command again?\n\nA: This doesn't directly answer your question (@saiarco895 did that), but I hate the default behavior of tab-completion in bash for the same reason. Assuming you're using Bash, you can change the behavior of the readline library it uses by editing the ~/.inputrc file. I put the following in it:\nset menu-complete-display-prefix On\n\"\\CTAB\": possible-completions\nTAB: menu-complete\n\"\\x1b[Z\": menu-complete-backward\n\nwhich allows me to cycle through completion options without printing them out using tab and shift-tab. If I need to see a print-out of all options, I use alt-shift-?\n\nA: You can type in the Q key. ...   \n", "Q: Upgrade from 13.04 to 13.10, update-manager crashed, and now hangs I started update-manager in order to do the 13.04 to 13.10 upgrade. At some point not far into the process, it died with some sort of unexplained error. (There was a message in the console about a Unicode decode failure, but I don't know whether to pay attention to that; Linux GUI programs spew out continual errors and warnings under apparently normal operation.)\nWhen I start it back up now, it just sits there burning CPU, showing the initial \"Checking for updates\" progress screen. The \"Stop\" button is greyed-out.\nI think that before the thing died the first time, it had gotten part-way, or maybe all the way, through the process of updating my apt files to point to the new release.\nAt this point, should I just kill the update-manager process and do a manual apt-get dist-upgrade from the command line? Is there something I should check first to make sure that won't be a disaster?\n\nA: Yes, you're going to want to do the dist-upgrade command from Terminal. First, you should run auto-remove, just to make sure all goes smoothly.\n", "Q: Terminal with output scrolling down I have currently decided to test my double monitors in the vertical configuration, and I came across a problem that I had never had before:  the input line on my terminal is too far down the screen!\nI was wondering if there is a way to make the output scroll downwards, so that the input line stays at the top.\ne.g., a normal terminal view looks like this:\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n64 bytes from 8.8.8.8: icmp_req=1 ttl=46 time=28.3 ms\n64 bytes from 8.8.8.8: icmp_req=2 ttl=46 time=13.7 ms\n64 bytes from 8.8.8.8: icmp_req=3 ttl=46 time=19.1 ms\n64 bytes from 8.8.8.8: icmp_req=4 ttl=45 time=20.8 ms\n64 bytes from 8.8.8.8: icmp_req=5 ttl=45 time=15.6 ms\n64 bytes from 8.8.8.8: icmp_req=6 ttl=46 time=15.3 ms\n64 bytes from 8.8.8.8: icmp_req=7 ttl=46 time=15.3 ms\n64 bytes from 8.8.8.8: icmp_req=8 ttl=45 time=14.3 ms\n64 bytes from 8.8.8.8: icmp_req=9 ttl=45 time=14.3 ms\n64 bytes from 8.8.8.8: icmp_req=10 ttl=45 time=15.5 ms\n64 bytes from 8.8.8.8: icmp_req=11 ttl=45 time=16.9 ms\n64 bytes from 8.8.8.8: icmp_req=12 ttl=45 time=16.3 ms\n64 bytes from 8.8.8.8: icmp_req=13 ttl=45 time=20.0 ms\n^C\n--- 8.8.8.8 ping statistics ---\n13 packets transmitted, 13 received, 0% packet loss, time 12017ms\nrtt min/avg/max/mdev = 13.773/17.391/28.343/3.812 ms\nme@my_computer:~$ \n\nand instead I would like to have something like this:\nme@my_computer:~$ \nrtt min/avg/max/mdev = 13.773/17.391/28.343/3.812 ms\n13 packets transmitted, 13 received, 0% packet loss, time 12017ms\n--- 8.8.8.8 ping statistics ---\n^C\n64 bytes from 8.8.8.8: icmp_req=13 ttl=45 time=20.0 ms\n64 bytes from 8.8.8.8: icmp_req=12 ttl=45 time=16.3 ms\n64 bytes from 8.8.8.8: icmp_req=11 ttl=45 time=16.9 ms\n64 bytes from 8.8.8.8: icmp_req=10 ttl=45 time=15.5 ms\n64 bytes from 8.8.8.8: icmp_req=9 ttl=45 time=14.3 ms\n64 bytes from 8.8.8.8: icmp_req=8 ttl=45 time=14.3 ms\n64 bytes from 8.8.8.8: icmp_req=7 ttl=46 time=15.3 ms\n64 bytes from 8.8.8.8: icmp_req=6 ttl=46 time=15.3 ms\n64 bytes from 8.8.8.8: icmp_req=5 ttl=45 time=15.6 ms\n64 bytes from 8.8.8.8: icmp_req=4 ttl=45 time=20.8 ms\n64 bytes from 8.8.8.8: icmp_req=3 ttl=46 time=19.1 ms\n64 bytes from 8.8.8.8: icmp_req=2 ttl=46 time=13.7 ms\n64 bytes from 8.8.8.8: icmp_req=1 ttl=46 time=28.3 ms\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n\nI could not find any such documentation or question on the forums. If anyone has an idea, please let me know! (also if you think it's not possible)\nThanks!\nPS: I'm using Ubuntu 12.04\n\nA: I found one nice tip from which you can start. You must to play with bash:\n\nTo set it up:\n$ bash    # try this in a subshell since ^C seems to cause it to exit\n$ f () { sed \"1s/^/$(tput cup 0 0)/;s/^/$(tput il1)/\"; }\n$ PROMPT_COMMAND='tput cup 0 0;tput il1; echo'\n$ exec > >(f)\n\nPress enter one extra time and it's ready to try. Sometimes the output\n  and the prompt are out of order and there may be other weirdness, but\n  it's kind of an interesting thing to try.\n\nSource: Reversed Terminal / Command line window.\nSee also:\n\n\n*\n\n*Reverse bash console text flow\n\n*Pushdown Terminal Output\n\nA: After searching for this good question , i found this commands and hope it can help you , so it can help you focusing on the top of the terminal when writing a command .\nIn terminal try :\n f () { sed \"1s/^/$(tput cup 0 0)/;s/^/$(tput il1)/\"; }\n PROMPT_COMMAND='tput cup 0 0;tput il1; echo'\n exec > >(f)\n\nReference Site\n\nA: Another trick would be to pass your command's output through tac which is like cat but prints in reverse order:\nterdon@oregano ~ $ ping -c 5 8.8.8.8 | tac\nrtt min/avg/max/mdev = 88.906/91.678/94.948/2.129 ms\n5 packets transmitted, 5 received, 0% packet loss, time 4005ms\n--- 8.8.8.8 ping statistics ---\n\n64 bytes from 8.8.8.8: icmp_seq=5 ttl=42 time=88.9 ms\n64 bytes from 8.8.8.8: icmp_seq=4 ttl=42 time=92.8 ms\n64 bytes from 8.8.8.8: icmp_seq=3 ttl=42 time=90.0 ms\n64 bytes from 8.8.8.8: icmp_seq=2 ttl=42 time=91.5 ms\n64 bytes from 8.8.8.8: icmp_seq=1 ttl=42 time=94.9 ms\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n\nNote that I had to specify a maximum ping number (-c 5) because otherwise the ping command won't exit and the pipe will break. Anyway, tac is very useful for this type of thing.\n", "Q: Nvidia Drivers and Ubuntu 12.04 x64 I had Linux Mint installed on my desktop. I was using xserver to configure the cards and I could not for the life of me get my monitors to display properly. Here is some information on my setup:\nI have a BFGTech GTS250 pushing to two 25\" monitors. \nI have another card GeForce GT 520 pushing to a 60\" TV. \nOut of the box ubuntu is doing quite well with both cards. Every now and then the mouse will freeze and the computer become unresponsive. It will suddenly catch up with all my mouse movement and I am ready to rock. \nI have attempted the following:\nsudo apt-get --purge remove nvidia-current\n\nreboot.\nsudo apt-add-repository ppa:ubuntu-x-swat/x-updates\nsudo apt-get update\nsudo apt-get install nvidia-current nvidia-settings\n\nreboot.\nNow, my large TV is displaying a blank screen and the mouse is a large \"X\". Any advice? Thanks in advance for any help.\nAfter removing the nvidia install and installing from nvidia-331 I get the same results. Here is my xorg.conf:\nhttp://pastebin.com/93JtX5Ge\n\nA: sudo apt-get install ppa-purge\n\nsudo ppa-purge ppa:bumblebee/stable\n\nYour solution.\n", "Q: Error when installing ubuntu-zfs I'm switching from FreeNAS to Ubuntu 12.04 LTS.  After a vanilla install of Ubuntu has been completed I run the following commands in the order shown to install ZFS:\n\n\n*\n\n*apt-get install python-software-properties\n\n*add-apt-repository ppa:zfs-native/stable\n\n*apt-get -y -q update && apt-get -y -q upgrade\n\n*apt-get install ubuntu-zfs\nWhen the last command is run ZFS is installed and seems to be working correctly... mostly (more on that later).  However, when the last command is run I get this error (full log here):\nconfigure: error:\n        *** Please make sure the kmod spl devel <kernel> package for your\n        *** distribution is installed then try again.  If that fails you\n        *** can specify the location of the spl objects with the\n        *** '--with-spl-obj=PATH' option.\n\nWhat is this error and how do I fix it?\nNow I said mostly earlier because my pool's don't auto mount when the server restarts the way they should.   All my reading (mostly from this page) indicates that mountall should just take care of the mounting.  I have followed the instructions on that page and I cannot get mountall to work correctly.  My pools will only auto mount on restart if I edit /etc/fstab or change the ZFS_MOUNT and ZFS_UNMOUNT options in /etc/default/zfs.\n\nA: The following helped me on 14.04:\nsudo apt-get remove spl-dkms zfs-dkms ubuntu-zfs\nsudo apt-get install spl-dkms\nsudo apt-get install zfs-dkms\nsudo apt-get install ubuntu-zfs\n\nI didn't realize that spl needs to be installed before zfs can be compiled successfully and I think I kept getting compile errors based on that fact. The gist, as I understand it, is that the zfs source depends on the spl source.\nI found this information on a mailing list.\n\nA: You need to re-initialise your kernel stuff.. Just found the same issue on a fresh install here..\nThe following assumes you have the repo ppa:zfs-native/stable installed:\nFirstly before attempting to install the stuff needed to compile::\napt-get install linux-headers-generic build-essential -y\n\nInstall zfs\napt-get install ubuntu-zfs -y\n\nRebuild the dkms drivers (SPL first)\ndpkg-reconfigure spl-dkms\ndpkg-reconfigure zfs-dkms\n\nIf all went well you should be able to load the module and see them loaded:\n# modprobe zfs\n# lsmod | grep zfs\nzfs                  1144227  0 \nzunicode              331251  1 zfs\nzavl                   15010  1 zfs\nzcommon                47181  1 zfs\nznvpair                88812  2 zfs,zcommon\nspl                   168728  5 zfs,zavl,zunicode,zcommon,znvpair\n\nThis is all the \"simple\" version of what I found here: https://groups.google.com/a/zfsonlinux.org/d/msg/zfs-discuss/sSTbgwerXi4/txQ9EK2yqMMJ\nI used this on my workstation for what its worth, about the same as the two dpkg rebuilds above:\nKERNEL_VER=`uname -r`\nZFS_VER=0.6.2\n\ndkms remove -m spl -v $ZFS_VER --all \ndkms remove -m zfs -v $ZFS_VER --all\n\nls -l /var/lib/dkms/spl /var/lib/dkms/zfs   # (should be nothing there)\n\ndkms add -m sqpl -v $ZFS_VER -k KERNEL_VER\ndkms install -m spl -v $ZFS_VER -k $KERNEL_VER\n\ndkms add -m zfs -v $ZFS_VER -k KERNEL_VER\ndkms install -m zfs -v $ZFS_VER -k $KERNEL_VER\n\n\nA: With a bit of trial and error I found that calling apt-get install linux-headers-generic build-essential before any of the other commands resulted in the later call to apt-get install ubuntu-zfs executing without error.  That still didn't fix the mountall problem though :(\n", "Q: GRUB does not load, only shows a blinking cursor I may mix things up here because I don't know extensively about a computer's architecture.\nSo I bought an ASUS EEE PC 1025E and wanted to replace Windows 7 Starter by a GNU/Linux distribution, so I chose Debian. However I wanted something else so I put Ubuntu 13.10 on an USB stick and started the installation from the stick.\nHere's where I did something really dumb. While navigating through the installation menus I noticed the computer was getting slow (it didn't surprise me because c'mon, it's a tiny computer), so I shut down the computer. What I didn't notice was that although it didn't seem like it, Ubuntu was actually being installed while I was in the menus (The program didn't tell me it). Since I ordered Ubuntu to write itself over all of my HDD, I ended with a messed up hard drive because I interrupted the installation process.\nSymptoms:\nWhen I boot up the computer, the ASUS screen shows for a second, then a blinking cursor appears which I assume is from GRUB. From here it seems I can't do anything except press Ctrl+Alt+Del which restarts my computer and does the same process.\nHere's the tricky part: due to my computer being a netbook it doesn't have anything to read disks, so any solution involving a disk doesn't work.\nAny advice would be greatly appreciated because I basically put my computer out of service at that point.\n\nA: Use your usb to reinstall. You are not going to salvage the interrupted installation.\n", "Q: Got this error when trying to install avast help a newbie!\nTryed to download Avast and this message shows up?\nSome one who care to explain slowly and in a kind way, what the message means, and if I can fix it myself?\nArchive:  /home/lars/Hentede filer/avast_internet_security_setup_online.exe\n[/home/lars/Hentede filer/avast_internet_security_setup_online.exe]\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nzipinfo:  cannot find zipfile directory in one of /home/lars/Hentede filer/avast_internet_security_setup_online.exe or\n          /home/lars/Hentede filer/avast_internet_security_setup_online.exe.zip, and cannot find /home/lars/Hentede filer/avast_internet_security_setup_online.exe.ZIP, period.\n\n\nA: You are trying to download a Windows executable (.exe), those don't work on Linux unless you use a wrapper like wine. More importantly, you don't need an antivirus on Linux. While there are actually a few viruses around, they are either harmless, or very old and in any case you can safely ignore them. \nI have been using Linux at home and professionally for more than 15 years and have never, ever, needed to install an antivirus. If you really want to, just install one that has a Linux version. \n", "Q: Integrity Check after an update fail in Xubuntu I have done an update (61mb ~ total) in Xubuntu 12.04 this morning but the progress bar was blocked at the start so i decided to cancel the update's installation. During the second update check the update manager that there were only 10mb ~ of updates and an error that said to run the following command: sudo apt-get install -f.\nThis command showed another error that said to run this command: sudo dpkg --configure -a. After this command and a system reboot i think i have installed all the update but im not sure of the integrity of the system. Is there any method to see if all in my os is fine ?\n\nA: Well, the fact that you can already boot is a good sign. I went once through a botched LTS upgrade and the system wouldn't boot; I clearly stumbled onto an update bug, but managed to find a workaround and in the end it worked. \nIn your place I would (to make sure that all packages are up-to-date): \nsudo apt-get update\nsudo apt-get upgrade\n\nThen I would check which distribution the system is running (see upgrade from lucid to precise): \nlsb_release -a\n\nIf all checks out, and the system boots, I wouldn't worry too much about it.\n", "Q: an Arch-linux-esque way to remove package and dependencies? I have within the last year started to experiment with Linux in an effort to learn the technical underpinnings as well as the fact that I strongly support the whole idea of open source software. Anyways, two of the distributions that I have spent the most time messing around with are Arch Linux and Ubuntu. I realize they are extremely different but my question today has to do with the package management system.\nIn Arch Linux if you would like to remove a package and all of its dependencies you can run a command pacman -Rs [packagename]. To see packages installed as dependencies and no longer needed by any other program you can run pacman -Qdt.\nNow in Ubuntu or for that matter any other APT-based package system you remove packages with something like apt-get remove [packagename] followed by apt-get autoremove to take away dependencies that are no longer needed.\nThe problem that I seem to be having is that while in Arch Linux running something like pacman -Rs gnome will remove gnome and all of the dependencies installed with it and an pacman -Qdt will allow me to make sure nothing is left over, but in Ubuntu apt-get remove gnome will only remove the meta package, and then running apt-get autoremove returns nothing.\nI was wondering how I could achieve a pacman -Rs type removal on an APT-based package system.\n\nA: The reason why you don't remove what you expect is because gnome metapackage isn't the only one depending on all the gnome desktop (in case you use Ubuntu GNOME Remix) but ubuntu-desktop or its variant ubuntu-gnome-desktop. What you are looking at is something offered by aptitude and advanced package managers. apt-get is simple, it needs most of things done manually. You can't expect it to do every function of pacman, specially in Ubuntu where there are metapackages created just to install flavors.\nWhat you need is:\naptitude search ~i~sgnome\n\nThis looks for packages that are installed from the gnome section. You may want the packages that are dependencies and installed of some installed package:\naptitude search '~R(?and(?name(gnome), ~i))'\n\n", "Q: how do i get remote desktop or other services running on ubuntu 12.04 I have just installed ubuntu 12.04 on a computer and would like to have it act as a server for remote desktop sessions and other services on my network.  How can I accomplish this.  I am also new to using ubuntu.  Formerly all windows user.\n\nA: You can use xrdp . \nxrdp: An open source remote desktop protocol(rdp) server. \nOpen your terminal :\napt-get install xrdp\n\nAfter you download , you can connect from any computer to your server , by remmina if you are using ubuntu or remote desktop for windows by typing the ip and the password of your account.\nOfficial site Here\n", "Q: Software Updater Not Automatically Launching Any More I run Ubuntu 12.10 32-bit and (if this is relevant) use the Cinnamon desktop. When I first installed Ubuntu about a year and a half ago, the software updater would pop up automatically whenever updates are available and prompt me to confirm that I wanted to install the updates. Now, however, it never pops up and I have to launch the updater manually to check for and install updates. I have not changed any settings for the updater and, in fact,it appears to be set to automatically notify when updates are available. Any insights on why it's not doing so and how I may be able to configure it to do so, as it did when I first installed Ubuntu? Thanks!\n\nA: Open Software & Updates, go to Updates tab and be sure that you select automatically check for updates and when these to be displayed as in the following image:\n\n", "Q: How does update work with programs installed from .deb file I'm having some difficulties exactly understanding how the the whole update thing work in Ubuntu and good practice for installing software.\nI understand I have a  /etc/apt/sources.list file where all my repositories are listed, and that these repositories are queried when I use apt-get update - to later be used with e.g.\napt-get upgrade.  This makes perfect sense and I recently installed spotify by adding\ndeb http://repository.spotify.com stable non-free to this \"sources\" list.  \nBut then I got confused...\nWhen I went to download Google Chrome I merely had to download and grab a .deb file, and Chrome installed with no problem... but I don't see any new entry in /etc/apt/sources.list...\nSo how does apt-get update know where to query concerning Chrome updates?  Has it somehow been added to one of the already listed repositories in the sources file?\nI would like all my installed software to be encompassed by the update function.\n\nA: apt searches in the sources listed in /etc/apt/sources.list and also all files in /etc/apt/source.list.d. You will have a file such as google-chrome.list in /etc/apt/sources.list.d which will have the following line:\ndeb http://dl.google.com/linux/chrome/deb/ stable main\n\nThis is used as the source for updating google-chrome.\nWhen you downloaded the deb file for google-chrome manually and installed it, a script in the deb file created this file, so that you don't have to manually search for updates.\n\nA: This is indeed kind of complicated. First, apt is a front-end to dkpg which actually handles installing/removing packages. So, /etc/apt/sources.list (and any files in /etc/apt/sources.list.d/) are read by apt, not dpkg.\nNow, when you download a .deb file manually, you are bypassing apt and will use dpkg -i packagename.deb to install it instead. This means that apt's database will not be updated and that the apt system will have no knowledge of the package you installed. In other words, apt-get upgrade will never update any manually installed packages.\nHaving said that, chrome is actually an exception to the rule. When you go to its download page, you will see this message:\n \nAt the bottom is this note:\n\nNote: Installing Google Chrome will add the Google repository so your system will automatically keep Google Chrome up to date. If you don’t want Google's repository, do “sudo touch /etc/default/google-chrome” before installing the package.\n\nThis means that the .deb package includes a script that will add Google's repository to your system (specifically, it will create a file at /etc/apt/sources.list.d/) thereby ensuring that chrome will be updated when you use apt-get.\n", "Q: How can I verify the speed of my NIC in ubuntu? Is there a command that I can verify by its output the speed of my NIC and some information about its characteristics such as duplex full or half .\n\nA: Suppose your NIC name eth0 :\nYou can verify the speed and some informations by three Commands :\nFirst Command :\ndmesg |grep eth0\n\nOutput :\n\nSecond Command :\nmii-tool -v  eth0\n\nOutput :\n\nFD : full duplex ,  Logic that enables concurrent sending and receiving. This is usually desirable and enabled when your computer is connected to a switch.\nHD : half duplex , his logic requires a card to only send or receive at a single point of time. When your machine is connected to a Hub, it auto-negotiates itself and uses half duplex to avoid collisions.\nThird command :\nethtool eth0\n\nethtool - Display or change ethernet card settings\n\nInstall ethtool :\nsudo apt-get install ethtool\n\nOutput :\nSettings for eth0:\n    Supported ports: [ TP ]\n    Supported link modes:   10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Full \n    Supported pause frame use: No\n    Supports auto-negotiation: Yes\n    Advertised link modes:  10baseT/Half 10baseT/Full \n                            100baseT/Half 100baseT/Full \n                            1000baseT/Full \n    Advertised pause frame use: No\n    Advertised auto-negotiation: Yes\n    Speed: 1000Mb/s\n    Duplex: Full\n    Port: Twisted Pair\n    PHYAD: 0\n    Transceiver: internal\n    Auto-negotiation: on\n    MDI-X: Unknown\n    Supports Wake-on: d\n    Wake-on: d\n    Current message level: 0x00000007 (7)\n                   drv probe link\n    Link detected: yes\n\nHope it helps .\n\nA: To obtain the link speed of an interface without parsing logs or installing additional tools, simply read its corresponding speed sysfs node, as follows:\ncat /sys/class/net/<interface>/speed\n\nwhere  is the name of your NIC, e.g. eth0\n\nA: \nYou can use NetSpeed Extension\nNetSpeed is a GNOME shell extension that displays the sum of your download and upload speed in your gnome panel. Clicking on it displays the separate values in a drop-down.\nYou can download it from Ubuntu Software Store.\nIt is applicable only if you use the GNOME desktop environment.\nReference: https://itsfoss.com/network-speed-monitor-linux/\n", "Q: Ubuntu 12.04 ATI Driver Good day,\nSo i just installed Ubuntu 12.04 LTS (i'm now to Ubuntu and even Linux systems, but i've bored of the lot of brainfuck with Windows systems)\nSo, i installed Steam and then 2 games (Left 4 Dead 2 and Killing Floor)\nBut then i realized both of them runs slow as hell... I searched on google for what can cause this, and i found that it must be the Graphics Driver... The system settings says it is \"Unknown\" but according to 13.10 it might be the Gallion 4.0 (or something like this)\nSo, i want to install the official AMD Catalyst Drivers...\nBut the problem is, every time i'd like to install it push a sexy error to my face: \"Some of the tools are missing\"\nI checked the .log file and it can't find the \"version.h\" for the kernel 3.11.0-18-generic\n(Before i pudated the system programs it said 3.11.0-15-generic)\nSo, i checked it, the 3.11.0-15 have the version.h inside, but the 18 does not...\nI could not find any solution in google, somebody maybe can help me how to fix this...\n\nA: What you need to do from a fresh install is to update and then install additional hardware. You'll have the options to install a stable driver that works with Steam without throwing up out of date driver messages at you. They may not be the fastest drivers but they are faster than the Gallion drivers at the moment. \n", "Q: How many partitions can I create on my hard disk? How many partitions can I create in my hard disk? I have now 4 partitions, and the 5th partition is not allowed.\nI currently have:\n\n\n*\n\n*104 MB for Windows system\n\n*20.98 GB for ubuntu, \n\n*C for Windows\n\n*D for Windows\n\n\nBut I also now have the fifth partition (38 GB) which is not formatted. Can I add that place for my Ubuntu (33GB), and swap place (5GB)? \nNow I am using both Windows and Ubuntu without problems but I have this free space doing nothing, and it is shown black in Windows partition window.\n\nA: This depends on what partition scheme you are using. The traditional approach (MBR partitioning) only allows 4 primary partitions. The trick is to create one of the four as an extended partition and then create further logical partitions within that.\nThe more modern GPT partitioning scheme allows as many partitions as you like. To test which of the two you have, run \nsudo parted -l\n\nLook in the output for a line like this:\nPartition Table: msdos\n\nThe line above means the disk is using an MBR scheme. If you are using GPT instead, you'll see:\nPartition Table: gpt\n\nYou can read more about the differences here. \n\nA: Based on the description (namely, the fact that it's a Windows boot disk that has no EFI System Partition), the disk is almost certainly MBR (aka MS-DOS, BIOS, or various other terms), which has the 4-partition limit that terdon describes.\nYou can convert a partition from primary to logical form using various programs. My FixParts, which is part of the gdisk package in Ubuntu, can do this, albeit with some caveats -- see the FixParts documentation for details. Some commercial Windows programs can also do this, but I don't know the details.\nIncidentally, I believe that you do not \"have the fifth part(38 GB) which is not formatted to anything.\" You've got 38 GB of unpartitioned space -- that is, space that's not claimed by any partition in the partition table. The partition table describes partitions, and it's possible for the partition table to become full before the disk does, in which case you'll have unpartitioned space that you can't use except by resizing partitions or jumping through hoops like a primary-to-logical conversion.\n", "Q: How to restart apache2 when I get a pid conflict? I receive the same message than explained in this thread when I'm trying to restart apache2 :\n * Restarting web server apache2 [fail]\n * There are processes named 'apache2' running which do not match your pid file which are left untouched in the name of safety, Please review the situation by hand.\n\nBut the problem is that I don't have any file inside /var/run/apache2.\nThe command pidof apache2 returns :\n1274\n\nI don't know if it will help but here is the line in apache2.conf :\nPidFile ${APACHE_PID_FILE}\n\nAnd the one in envvars :\nexport APACHE_PID_FILE=/var/run/apache2/apache2$SUFFIX.pid\n\nShould I manually create a .pid file inside /var/run/apache2 ?\nThank you very much !\n\nA: Thanks to @douggro who found the answer.\nFind the processus id of Apache2 with :\npidof apache2 \n\nKill the process(es) :\nsudo kill -9 <pid>\n\nThen you can start Apache2 as usually :\nsudo service apache2 start\n\nUPDATE\nIf sudo kill -9 <pid> doesn't work, just try sudo kill <pid> !\n\nA: After trying various one liners that did not work I found this\nkill -9 $(pidof apache2)\n\nthat seems to work just fine\n", "Q: Installing Ubuntu GNOME dual boot on Sony VAIO Pro, EFI problems I recently bought a Sony VAIO Pro 13 and after witnessing the horror that in Windows 8, I decided to attempt to install Ubuntu GNOME 13.10 as a dual boot option.\nDuring the install process I partitioned 2 drives: for the Ubuntu root mount and the swap area. The installation went fine and I restarted without the LiveUSB, however tHe laptop booted directly into Win 8. The install guide said I should see a GRUB menu but I didn't. After restarting back into the LiveUSB I ran the boot-repair utility using the recommended settings and then restarted. Now the laptop will not even boot into Windows, I get an \"Operating system not found error\" in both UEFI and Legacy modes.\nHere is my boot-repair log:\nhttp://paste.ubuntu.com/7064164/\nI know there are some issues with the SSD and I have found info on how to fix this, providing you can at least boot to Grub, which I can't?! \nAny help is appreciated, I am worried I have bricked this brand new laptop.\nThanks!\n\nA: Here's what I recommend you do, but I can make no guarantees that it will work:\n\n\n*\n\n*Boot a Linux live CD.\n\n*Run Boot Repair again, but enter the Advanced setup area and select the option to restore backed-up files. When you tell it to complete this action, you should be back to where you were before (Windows should boot, but GRUB won't appear). Even if you can't boot Windows at this point, you can proceed at least through step #6 without risking anything.\n\n*Disable Secure Boot in your firmware.\n\n*Download the USB flash drive or CD-R version of my rEFInd boot manager and prepare a boot medium with it.\n\n*Boot to the rEFInd medium.\n\n*rEFInd should detect both Windows and Ubuntu, and both should boot. (There will probably be more than one Ubuntu entry. As long as one boots, you're fine, but it's possible that the GRUB option will fail.)\n\n*If both Windows and Ubuntu boot, download and install the Debian-package version of rEFInd.\n\n\nAt this point, rEFInd should appear when you reboot the computer. If not, then your firmware is broken, and you'll need to experiment with workarounds, as described here. You can also post back with more details if you run into such problems.\n\nA: Actually, the firmware boots only the EFI boot entry named Windows Boot Manager, so renaming your Linux boot entry to that will make it work in SecureBoot mode. It works for me.\n", "Q: Why 'sudo service networking restart\" do not work? Normally, if I run sudo service networking restart, it will take some time before it finishes.\nBut, on one machine, it returns immediately, and the results in ifconfig does not change even when /etc/network/interfaces is changed. Then I have to restart the machine in order to load any changes in the interfaces file.\nI'm wondering how to debug this problem.\nMy OS is ubuntu server 13.10.\n\nA: Many thanks for user douggro (comment from Mar 9 '14 at 22:05)!\nAnswer for me was:\nsudo service network-manager restart\n\n", "Q: how do I mount a second hard drive? My laptop has a 32GB SSD on which I've installed Ubuntu, and a 500GB HDD where I plan to store my files. When I try to download big files (like blu ray movies) it says it can't because my HDD is not big enough. How do I tell the OS that it can use the free 500GB on the other drive?\n\nA: you need to switch download folder to the external hard driver. The default place for all downloads is the folder called Downloads but this can be changed in the program.\nso go to settings in the program you are using and select your hard drive instead of your downloads folder. It's really easy, comment the program if you have any problems and I'll guide you better. \n", "Q: What software can I use to make a mirror image of Ubuntu? I used to use Easeus Todo for Windows, or Norton Ghost. What options do I have for linux? \n\nA: Clonezilla is great for cloning Windows and Linux. You can boot it from USB/CD/PXE and image to files on an external drive, samba, nfs,  & ssh. You can also disk to disk.\n\nA: To make a backup of linux, you can use the tar or dd command.  \nIn order to answer this question it may be useful to know if you want a regular backup that runs automatically (e.g. create a copy of the system and store it in the cloud (e.g. Amazon Glacier), or just do a quick once off backup to a local hard drive.  \nThe beauty of linux is that there are many ways to do it, from manual to fully automated. \nTar See: [Techrepublic](http://b2b.cbsimg.net/downloads/PDF/SolutionBase_Backup_Linux_reliably_with_rsync_and_tar.pdf for some additional details.)\ndd: See dd\nOh, and do take care and read the instructions thoroughly and run a test on a spare machine first, as these commands are powerful, but once you have mastered it you can save the command as your own software to run when you need to.\n\nA: Just cloned my hdd, easily and quickly with no errors, i used clonzilla, a brilliant bit of software.\nIt allows you to clone HDD to HDD, or HDD to image, plus other options.\nI can't stress how easy it is to use...\nSome info here:\nTop 6 Open Source Disk Cloning and Imaging Software\n", "Q: If i Install Ubuntu on an External Drive using Wubi, does it do anything to my C: Drive? I have installed ubuntu using wubi on my old computer and Broke Windows (I had to re-install it). So excuse me If I am acting paranoid.\nI was all ready to install ubuntu using Wubi then it hit me. Would WUBI Install GRUB on my C: or my Installation Drive (F:).\nI will take any form of answer. I really need help!\n\nA: That's your solution. You must install Ubuntu with Windows. Before you installed Ubuntu instead Windows.\nhttp://www.ubuntu.com/download/desktop/install-ubuntu-with-windows\n", "Q: Headphone noise when no sound is played I have an Asus K50IJ laptop with ubuntu 12.04 on it, and with the following hardware:\nafter typing:  sudo aplay -l\n**** List of PLAYBACK Hardware Devices ****\ncard 0: Intel [HDA Intel], device 0: VT1708S Analog [VT1708S Analog]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\ncard 0: Intel [HDA Intel], device 2: VT1708S Alt Analog [VT1708S Alt Analog]\n  Subdevices: 1/1\n  Subdevice #0: subdevice #0\n\nMy codec called: VIA VT1708S\nEvery time when a sound is played, I hear an annoying noise, similar to white noise. The worst part is that it doesn't stop after the sound is over. I googled for it thousands of times, tried every setup of alsamixer, but nothing works. I found on a forum, that because of the integrated soundcard on the motherboard, it may be the static earth noise from the electric network. I removed my laptop charger (from the laptop) and after 2-3 seconds the sound just stopped. When I plugged it back, it doesn't come back until I play another sound.\n\nA: I have exactly the same issue and it seems to be known. I've found this during my researches: https://bugs.launchpad.net/ubuntu/+source/alsa-driver/+bug/1252733 . \nApparently a fix has been made but don't know when it will be available and how we can apply it for testing. (the fix: https://git.kernel.org/cgit/linux/kernel/git/tiwai/sound.git/commit/?id=493a52a9b6645f61954580c7d4bd52fa62110934)\n", "Q: \"Sudo: Must Be Setuid Root\" error after login to diskless client I'm working on diskless linux clusters. I followed instructions as described here. I did these steps:\n1- Installed a pxe server on server pc.\n2- Installed ubuntu to a client pc.\n3- Configured and installed all programs I need on client pc.\n4- Copied all OS files(on client pc) to NFS share point.\n5- Booted diskless pc via pxe server.\n\nIt works. But after login to my account, I got this error message : \"Sudo: Must Be Setuid Root\". So I can't use /usr/bin/sudo. How can I fix this? Do I need to change some files on OS files which I copied to PXE server?\n\nA: This error indicated that the /usr/bin/sudo file doesn't have the setuid attribute set. The setuid attribute means that when you execute as if you were the user that owns the file. So, sudo must be owned by root and have this set or it is not able to allow you gain root privileges. You can set this attribute by running chmod u+s /usr/bin/sudo while running as root. You may also need to change the owner to root (chown root:root /usr/bin/sudo).\n\nA: I found the problem. I have copied the OS files from client pc to server pc. I changed the permissions (chmod 777 -R /pathToOsFiles) on these files on server. Then I got this  error message (Sudo: Must Be Setuid Root) on diskless pc. I couldn't fix it. I used every options (755, 744 ...) but nothing changed. \nEverything works correctly after copied OS files from client pc to server pc again. But this time I didn't change permissions. If someone faces same problem, I can say that don't touch permissions on server after copy the OS files. \nOne more thing: User names can be different on client pc and server pc but SUID must be same on both. Otherwise you will see same error message.     \n", "Q: serial-port thermal printer communication I am trying to establish low level communication with an Epson tm-t88iv thermal printer via shell but I can't figure it out. I'm working on ubuntu 13.10 64 bit with a Dell vostro 1510.\nI have it connected through a prolific serial-usb pl2303 cable.\nlsusb shows:\nben@ben-Vostro1510:~$ lsusb\nBus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 007 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 006 Device 003: ID 046d:c52b Logitech, Inc. Unifying Receiver\nBus 006 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 005 Device 005: ID 067b:2303 Prolific Technology, Inc. PL2303 Serial Port\nBus 005 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 001 Device 002: ID 0c45:63e0 Microdia Sonix Integrated Webcam\nBus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub\nBus 004 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\nBus 003 Device 001: ID 1d6b:0001 Linux Foundation 1.1 root hub\n\ndmesg | grep tty shows:\nben@ben-Vostro1510:~$ dmesg | grep tty\n[    0.000000] console [tty0] enabled\n[    1.488664] tty tty28: hash matches\n[  225.882444] cdc_acm 2-4:1.0: ttyACM0: USB ACM device\n[ 1478.741395] usb 5-1: pl2303 converter now attached to ttyUSB0\n[ 3672.537405] pl2303 ttyUSB0: pl2303 converter now disconnected from ttyUSB0\n[ 3679.219805] usb 5-1: pl2303 converter now attached to ttyUSB0\n[ 4657.704772] pl2303 ttyUSB0: pl2303 converter now disconnected from ttyUSB0\n[ 4699.905633] usb 5-1: pl2303 converter now attached to ttyUSB0\n[ 4798.952739] pl2303 ttyUSB0: pl2303 converter now disconnected from ttyUSB0\n[ 9930.266470] usb 5-1: pl2303 converter now attached to ttyUSB0\n\nI have tried using cutecom to send a specific hexadecimal code to it, but i get no answer. I also tried echoing to /dev/ttyUSB0 but i don't know where to read the response from. i also tried \"sudo cat /dev/ttyUSB0\" but get nothing.\nplease help me solve this! thanks!\nSolution:\nI had to run\nsudo chmod 777 /dev/ttyUSB0\n\nand then run jpnevulator as root\nsudo jpnevulator --tty /dev/ttyUSB0 --read\n\nand then using another in write mode I wrote the status check sequence\n02 AC 00 01 1C 00 00 03 30 30 43 45\nand got the printer's response on screen. I now have a different problem with the checksum, but that's for the next episode of my odyssey into low-level programming. \n\nA: I have no idea about thermal printers, but this the way I used to test Arduino or cell phone modem.\nAs example, with an Android phone as modem:\n\n\n*\n\n*Reading serial port (need to be root):\nsudo su\ncat /dev/ttyACM0\n\nAs you can read just few lines as needed:\nhead -n2 /dev/ttyACM0\n\n\n*Writing serial, Open other terminal tab or window:\nsudo su\necho -e \"AT\" > /dev/ttyACM0\n\nIt shows OK on reading port window, Also you can sent hexadecimal data (use -n option to avoid sending new line at the end)\necho -e -n \"\\x41\\x54\\x0a\" > /dev/ttyACM0\n\nsame as:\necho -e \"\\x41\\x54\" > /dev/ttyACM0\n\nShell will show undisplayed hex as small square with its value written inside it. Try this.\necho -e \"\\x13\"\n\n", "Q: Problems loging in after dealing with video drivers and black screen I recently installed Ubuntu 13.10 on my laptop alongside windows 8.1. I have a Nvidia GeForce GT 645M video card on it and was having black screen on boot issues. so I installed the  xorg-edgers Nvidia drivers. After this fix I could get to the login screen, however whenever I would try to log in I get blank desktop screen with no interface and a warning saying \"System program problem detected Do you want to report the problem now?\"  and  If I log in as a guest I get a desktop screen with no interface.\n\nA: If you can get to a Terminal prompt or Recovery Console,\nsudo apt-get remove --purge nvidia-*\n\nwill remove the Nvidia drivers;\nsudo rm /etc/X11/xorg.conf\n\nwill reset the X session settings; and\necho 'nouveau' | sudo tee -a /etc/modules\n\nwill load the default nouveau drivers to let you have a working GUI. A reboot may be required, or try service lightdm start to get to the login screen.\n", "Q: build libav from GIT using --enable-* I need to get a newer version of libav-tools (containing avconv) to get the AAC-encoder to resample an input 6-channel audio stream into an output 2-channel one.\nI successfully built the package, but I realized after that I needed to ./configure --enable-libvo-aacenc to get avconvto use AAC as an encoder. Here's what I'm trying to do :\ngit clone git://git.libav.org/libav.git\nsudo apt-get build-dep libav-tools\ncd libav\n./configure --enable-libvo-aacenc --enable-gpl --enable-nonfree --enable-version3\nmake\nsudo make install\n\nBut I have this instead :\n\nI don't understand what I'm doing wrong here... I can't seem to use the libraries that are installed on my Ubuntu.\n\nA: You need to install the VisualOn AAC encoder library (development files):\nsudo apt-get install libvo-aacenc-dev\n\n", "Q: Is there a good OCR-readable font As part of my backups, I would like to be able to print and later re-scan a Base64-encoded copy of my private key. Unfortunately, neither gocr nor tesseract seems to be able to properly read any font that I throw at them. I have tried Times New Roman, Courier New, and OCR-A. Are there any other fonts I should try?\n\nA: This only partly answers you question: I will not provide a solution for OCRing your backup, but for an paper alternative I recommend using QR codes. I \"stored\" my revocation certificates as QR codes on paper myself and created them by applying qrencode on the ASCII-armored version of the key (thus the one you'd print anyway).\nThere's also Paperkey and some other small scripts for doing so, but just piping it through qrencode worked very well for me. Make sure to try reading the code after printing, so you definitely know everything's fine!\nI also printed the command to create the code below, and added the ASCII-armored version in plain text on the backside of the page.\n\nA: Here are some suggestions:\n\n\n*\n\n*Using Arial with font size 16 or bigger;\n\n*When you scan, make sure you scan at DPI 200 or 300\n\n\nand most OCR engines should be able to read correctly.\n\nA: It really depends on the OCR engine considered.\nFor gocr, FreeMono is the best, see gocr documentation.\nFor tesseract, DejaVu-Serif works well, see https://superuser.com/a/1543382/280936\nFor abbyocr, verdana is good, see this comparison\nSee also this wrap-up: https://www.monperrus.net/martin/perfect-ocr-digital-data\n", "Q: How do I install amd legacy drivers in Ubuntu 13.10? I am new to Ubuntu and would like to know how I can install amd graphic drivers?\nAlso do I need to manually uninstall the open-source drivers in use right now?\n\nA: There is actually a pretty straight forward graphical way to do this.\nOpen your system settings and click on Software & Updates\nThere it should list some available drivers that have been detected for your System.\nJust select the one you want, install it and reboot your system.\nEDIT\nAccording to AMD and this bug report: https://bugs.launchpad.net/ubuntu/+source/fglrx-installer/+bug/1058040\nyour card is not supported by the regular amd drivers anymore. It is, according to AMDs download page, not possible to use the legacy drivers with linux kernel verisons higher than 3.4 (as of Ubuntu 12.04.2 kernel > 3.5.x is in use). See description section on the official AMD download site: http://support.amd.com/en-us/download/desktop/legacy?product=Legacy2&os=Linux%20x86_64\nIn other words: You can not use an official AMD driver for your card.Your options are:\n\n\n*\n\n*Leave your system as it is and use the default radeon drivers already in use on your system (recommended!)\n\n*Get a newer card (HD 5xxx and above) and install the official drivers via terminal sudo apt-get install fglrx-amdcccle\n\n*Reinstall your system to a version prior to Ubuntu 12.04.2 and install the amd legacy drivers from the link provided above (SERIOUSLY NOT RECOMMENDED! ..just to be complete)\n\n", "Q: I installed Ubuntu updates and wifi doesnt work anymore I am working on a dell machine and wifi didnt work out of the box but I was able to get it to work. After doing updates the network appears in the place where you can edit connections but there is no way to connect.\nWhen I first installed ubuntu I successfully tried this to get the wifi to work: Installing Broadcom Wireless Drivers.\n.\nToday I updated my system using the software updater. Now when I click on the network indicator in the top panel it just shows wired network disconnected and no wireless networks at all, like it used to.\nWhen I click edit connections I can find \"A Network\" but I cannot connect just edit it.\nI did what was in the link again and still no wifi.\nWhat do I do? Please be as specific as possible, I am new to ubuntu.\nEdit -  I answered the post with 59^ and it is a Dell Latitude D620 and I am using ubuntu 12.04 LTS and nothing happens when I type those codes. I tried putting sudo in front of them also and still, nothing happened...\n\nA: Try this in the terminal\nsudo /etc/init.d/networking restart\n\nthis shuld solve the problem\nif the above is not working this will fix the problem for sure\nsudo service network-manager restart\n\nplease let me know if it helped and what so i can edit the post thank you\n\nA: Please do:\nsudo apt-get purge --remove bcmwl-kernel-source\nsudo apt-get install linux-firmware-nonfree\nsudo modprobe -rv wl\nsudo modprobe -v b43 \n\nwatch for error if any occur in the last two commands please continue.\n", "Q: Slow file transfer on a local network NETWORK TOPOLOGY\n\nWhenever I try to transfer files within the local network with scp I can't reach speeds above 2Mb/s, in both direction (server--->laptop or laptop--->server). Same with FTP.\nI noticed that the data transfer starts at 2.5[Mb/s] and then quickly drops down to 500[Kb/s] after a few seconds.\nThe transfer from the server to the laptop is slightly faster (3Mb/s instead of 2Mb/s).\nI would expect the speed to be at least 25Mb/s since it is a pure local data transfer.\nFYI, some meaningful outputs :\nON THE SERVER\n:~$ ifconfig\neth0  Link encap:Ethernet  HWaddr 00:13:d3:cd:8a:7b  \n      inet adr:192.168.1.246  Bcast:192.168.1.255  Masque:255.255.255.0\n      adr inet6: fe80::213:d3ff:fecd:8a7b/64 Scope:Lien\n      UP BROADCAST RUNNING MULTICAST  MTU:1492  Metric:1\n      Packets reçus:34893 erreurs:0 :2 overruns:0 frame:0\n      TX packets:45145 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 lg file transmission:1000 \n      Octets reçus:19810274 (19.8 MB) Octets transmis:57877746 (57.8 MB)\n\nlo    Link encap:Boucle locale  \n      inet adr:127.0.0.1  Masque:255.0.0.0\n      adr inet6: ::1/128 Scope:Hôte\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      Packets reçus:36 erreurs:0 :0 overruns:0 frame:0\n      TX packets:36 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 lg file transmission:0 \n      Octets reçus:2160 (2.1 KB) Octets transmis:2160 (2.1 KB)\n\n:~$ sudo ethtool eth0\nSettings for eth0:\nSupported ports: [ TP MII ]\nSupported link modes:   10baseT/Half 10baseT/Full \n                        100baseT/Half 100baseT/Full \nSupported pause frame use: No\nSupports auto-negotiation: Yes\nAdvertised link modes:  10baseT/Half 10baseT/Full \n                        100baseT/Half 100baseT/Full \nAdvertised pause frame use: No\nAdvertised auto-negotiation: Yes\nLink partner advertised link modes:  10baseT/Half 10baseT/Full \n                                     100baseT/Half 100baseT/Full \nLink partner advertised pause frame use: No\nLink partner advertised auto-negotiation: Yes\nSpeed: 100Mb/s\nDuplex: Full\nPort: MII\nPHYAD: 1\nTransceiver: internal\nAuto-negotiation: on\nSupports Wake-on: pumbg\nWake-on: d\nCurrent message level: 0x00000000 (0)\n\nLink detected: yes\n\nON THE LAPTOP\n$ ifconfig \neth0      Link encap:Ethernet  HWaddr 00:21:cc:d3:8d:67  \n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          Packets reçus:0 erreurs:0 :0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 lg file transmission:1000 \n          Octets reçus:0 (0.0 B) Octets transmis:0 (0.0 B)\n          Interruption:20 Mémoire:f2500000-f2520000 \n\nlo        Link encap:Boucle locale  \n          inet adr:127.0.0.1  Masque:255.0.0.0\n          adr inet6: ::1/128 Scope:Hôte\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          Packets reçus:1562 erreurs:0 :0 overruns:0 frame:0\n          TX packets:1562 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 lg file transmission:0 \n          Octets reçus:478231 (478.2 KB) Octets transmis:478231 (478.2 KB)\n\nwlan0     Link encap:Ethernet  HWaddr 60:67:20:bd:5e:4c  \n          inet adr:192.168.1.12  Bcast:192.168.1.255  Masque:255.255.255.0\n          adr inet6: fe80::6267:20ff:febd:5e4c/64 Scope:Lien\n          UP BROADCAST RUNNING MULTICAST  MTU:1492  Metric:1\n          Packets reçus:161831 erreurs:0 :0 overruns:0 frame:0\n          TX packets:101552 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 lg file transmission:1000 \n          Octets reçus:195684887 (195.6 MB) Octets transmis:29360206 (29.3 MB)\n\nsudo iwconfig wlan0\nwlan0     IEEE 802.11abgn  \n          Mode:Managed  Frequency:2.437 GHz  Access Point: 00:26:4D:26:A1:2D   \n          Bit Rate=54 Mb/s   Tx-Power=15 dBm   \n          Retry  long limit:7   RTS thr:off   Fragment thr:off\n          Encryption key:off\n          Power Management:off\n          Link Quality=52/70  Signal level=-58 dBm  \n          Rx invalid nwid:0  Rx invalid crypt:0  Rx invalid frag:0\n          Tx excessive retries:0  Invalid misc:3791   Missed beacon:0\n\nDo you know what could be the root cause of this crazy slowness ?\n\nA: Try this in Terminal\nsudo iwconfig wlan0 rate 54M\n\nIf you are trying to transfer from laptop on the wireless network\n\n\n*\n\n*you can change wlan0 to what ever the network you need to get edited i think its the wireless :)\n\n\nplease let me know if this helps\n", "Q: How to start games in Steam running on Wine? I understand that not all games will be compatible with Wine, but how do I start a game in Steam while running Steam on wine? Do i just press play?\n\nA: If a Steam game is able to run with Wine, and you're running the Windows version of Steam with Wine, then yes, double-clicking on the game in your game library or pressing Play will (attempt to) run the game with Wine.\nThis is really an instance of a more general question: What happens when a Windows program running with Wine tries to launch another Windows program; does Wine try to run that, too?\nThe answer is yes. Wine supports the parts of the Windows API that Windows programs use to launch new processes.\nWith that said, it is possible that you could have some Windows Steam game that only sort of works with Wine on Ubuntu and requires special steps to launch. In that case, you might have to do something different from just launching the game in your Steam games library. But what you'd have to do would be particular to the specific problems running the game. In general, to run a Windows Steam game from the Windows version of Steam in Wine, clicking Play is the way to do it.\n", "Q: How to fix backlight for Dell inspiron on ubuntu 12.0.4 LTS? I work on a Dell Inspiron laptop.\nThe backlight is not working on Ubuntu. Is there any known issues like this with Ubuntu on Dell machines?\nI've tried some solutions such as changing grub like the following sample but still it's not working.\nsudo gedit /etc/default/grub\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi_backlight=vendor\"\nsudo update-grub\n\nAlso, I installed xbacklight, but I can only set a value for it once and then I have to restart if I want to decrease the backlight.\nCan someone tell me how can I fix it, or what else I can try?\n\nA: Click Here >> Ubuntu Wiki >> Debugging >> Backlight\nPlease let me know if this helps\n\nA: I have a Dell Inspiron 1520 running Ubuntu 14.04. For quite a long time I've been looking for a fix on how to control the screen brightness using the Fn+F5/F6 key.\nI've tried including some arguments at boot, some packages, nothing worked. Anyway, I stumbled upon this guide , update the kernel successfully and, woot!, screen brightness is now available!\nPSA: Use this guide on your own. One thing I had to do was downgrade the AMD Drivers to the Ubuntu packages default (fglrx package).\n", "Q: rsync isn't creating files or folders I'm still relatively new to Ubuntu and Linux.  I've got a windows machine with a DAS.  I've got about 5TB of data on it, and I want to use my server running 12.04 to back it up daily / weekly.  I've got a Drobo attached to my server.  I'm mounting the network drive using:\nsudo mount -o username=username,password=******** //192.168.1.100/Storage /mnt/Storage\nEverything mounts correctly and I can read and write files.  The Drobo mounts automatically at startup, and I can read and write files to it just fine.  I've used the cp command to copy files from the network drive to the Drobo and everything works correctly.  Then I try rsync, and while rsync looks like it's running correctly, nothing gets copied over.  Here's the command I'm using.\nsudo rsync -av --delete /mnt/Storage /media/Drobo\nSo after about 2-3 days of running (like it's actually copying), it says complete and yet no files were copied.  I've ran it on smaller folders with just a few files and nothing copies over.  No folders, no files.  Is there something I'm doing wrong here?\nEDIT: As requested, the Drobo is a 5D attached via USB 3.0 formatted as NTFS.  Here are the results of df -h.\n\nFilesystem               Size  Used Avail Use% Mounted on\n/dev/sda6                184G  6.8G  168G   4% /\nudev                     7.7G  4.0K  7.7G   1% /dev\ntmpfs                    3.1G  1.1M  3.1G   1% /run\nnone                     5.0M     0  5.0M   0% /run/lock\nnone                     7.8G  160K  7.8G   1% /run/shm\n/dev/sdb2                 16T  5.4T   11T  34% /media/Drobo\n//192.168.1.101/Storage  7.3T  5.2T  2.2T  71% /mnt/Storage\n\nBrent\n\nA: Thank you guys for the help, this appears to be a dumb user error.  I didn't realize when copying files like so:\nsudo rsync -av --delete /mnt/Storage /media/Drobo\n\nIt would be making a folder inside Drobo called Storage.  Apparently I needed / after Storage and Drobo.  Interesting that the cp command doesn't, yet rsync does.  Anyways, I noticed when testing another folder double nested names and realized my error.\nThanks community!\n", "Q: Editor with live preview for AsciiDoc I'm looking for something like ReText, but for AsciiDoc.\nThe closest I have found is this relatively complex solution (or here) involving Ruby, guard, guard-shell, rb-inotify, asciidoctor, Epiphany (or another browser with LiveReload).\nI'll do all that if it is the best option. But I was looking for just a simple solution, along the lines of a ReText for AsciiDoc. \nI also heard that O'Reilly has some tools (e.g., the Atlas wiki interface), but I'm not submitting my documents to O'Reilly. (Atlas looks cool and I'd consider using it if I could do so privately.) \nAnyone have another suggestion?\n\nA: You can use AsciidocFX on any platform.\nThere are many features:\n\n\n*\n\n*Real-Time Preview\n\n*Multi-platform (Windows, Mac, Linux ..)\n\n*Creating Asciidoc Books\n\n*Creating Markdown Books\n\n*Creating PDF, HTML, Epub, Mobi, Docbook\n\n*Epub Viewer\n\n*External Browser Support\n\n*Table Generator\n\n*MathJax Extension\n\n*PlantUML Extension\n\n*Filesystem Tree Extension\n\n*JavaFX Charts Extension\n\n\nA: You can also use atom.io with the plugin asciidoc-preview :\nhttp://www.youtube.com/watch?v=R9o-0J2YKZ4\n\nA: You can use the Asciidoctor.js Live Preview browser extension to render AsciiDoc (.ad, .adoc, .asc, .asciidoc) as HTML.\n\n\n*\n\n*Install it for either Chrome or Firefox.\n\n*For Firefox, you'll need to download the latest xpi file (link on the README).\n\n*For Chrome, you'll likely want to enable Allow access to local file URLs under the extension options.\n\n*Then either point your browser at a remote AsciiDoc URL or create a new file locally (e.g. helloworld.adoc), enter some text in it with your favorite editor, and then point your browser to it (e.g. file:///home/ggrossetie/helloworld.adoc).\n\nA: Visual Studio Code also comes with a nice AsciiDoc plugin:\n\n\n\n\nA: Brackets Editor has a AsciiDoc Preview Extension that I am using right now. Works well.\n\nA: AsciiDoctor provides a nice Overview of Editing AsciiDoc with Live Preview.\nIt includes details on how to setup many of the tools mentioned here, e.g. AsciidocFX, Atom, Brackets and IntelliJ.\n", "Q: Software & Updates; should I turn on Canonical Partners source? Source code? In Software Sources under the Other Software tab, there is an option of enabling \"Canonical Partners\" repository: software packaged by Canonical for their partners. Should I check \"Source Code\" as well? What does that mean when that's checked?\n\nA: The Canonical Partner repository contains closed source third party software that don't cost any money. Canonical doesn't have access to the source code, they just package and test it and may provide feedback and help to the author if there are issues.\nFor the sources, you can leave them unticked if you don't plan to do anything with the source code of software in the repositories.\n\nA: This is to activate the proprietary software that has reached an agreement with Canonical for use.\nYes you can activate it, no problem.\n", "Q: Ubuntu starting in low resolution and keyboard and mouse not working I just installed Ubuntu on my 2010 Mac mini, (2.1GHz Intel Core 2 Duo, 4GB RAM) and at first it worked fine. Then, after turning off the computer, when I powered it on again it logged in and displayed my desktop, but the resolution is really low and the mouse and keyboard stopped doing anything.\nHow do I fix this?\n\nA: Try including nomodeset as a boot option in grub. From the main grub bootloader press 'e' to edit the boot parameters. Find where it reads:\nquiet splash\n\nEdit to look like this:\nquiet splash nomodeset\n\nHopefully this will solve your resolution issue and prevent the crash. If so, try changing your graphics driver from the 'Additional Software' app and reboot.\n", "Q: Guake disappears randomly on Ubuntu 13.10 I use dual monitors with a static Guake terminal on one while doing everything else on the other. Guake will work for a seemingly random amount of time, and eventually disappear until I reboot or kill the process (which loses any open tabs).\nI found a similar question, but it seems to be completely unrelated.\n\nA: There's an even better workaround in that thread that lets you get the running guake back without restarting it, by mbondfusion:\n1) Use xwininfo to find your root window ID\nxwininfo -name 'Guake!' -int -tree\n\nxwininfo: Window id: 60817461 \"Guake!\"\n\nRoot window id: 143 (the root window) (has no name)\nParent window id: 143 (the root window) (has no name)\n1 child:\n60817462 (has no name): () 1x1+-1+-1 +64+23\n\n2) Use xdotool to reparent the Guake window:\nxdotool search --name 'Guake!' windowreparent 143\n\n\nA: The problem comes from the show desktop button which is a confirmed Guake bug. I never use the show desktop button from the sidebar, but realized later on that accidentally selecting show desktop while alt-tabbing is very easy to do (more so if you're unaccustomed to the alt-tab behavior brought about in 12.04).\nI found a temporary fix as outlined by Stibbons by using \"Hide on lose focus\" in preferences. Keep in mind this will only prevent the alt-tabbing show desktop bug, and isn't ideal if you require a static terminal on a separate monitor. (I've disabled the sidebar button in settings > appearance > behavior - just in case!)\nStibbons said 19 days ago \"I'll try to fix it asap,\" and as I was losing current tabs every few hours this temporary fix is HUGE timesaver.\n\nA: My workaround for this problem is to disable the \"Show Desktop\" in the switcher with the unity tweak tool. It is easily installed with sudo apt-get install unity-tweak-tool\nas explained in How can I remove \"Show Desktop\" from the Alt-Tab (application) switcher?.\n", "Q: USB/Keyboard/Mouse not recognized after update to 13.10 from 12.10 I just updated to 13.10 from 12.10. On restarting, I was completely unable to use my keyboard or mouse through USB. I have no PS/2 devices to use. Also, it said that I had been disconnected from my network even though I did not do anything to disconnect it myself. My network card is connected through PCIe x1.\nThe USB worked in 12.10 and 12.04 and also works in the BIOS and before loading into the kernel, working when you hold shift to test RAM or go into recovery mode. \nThe kernel is by default 3.11.0-18. Reverting to 3.11.0-15 gives the same issue. Booting into either recovery modes lets you load up the kernel but when the menu appears to start dpkg or other options such as networking the keyboard again fails to work. \nTested with Tesoro Durandal G1NL, Cooler Master Storm Spawn, and a Dell keyboard and Targus mouse of which I am unsure of the exact models, although they were not recently made. \nAlso of note is that it is not simply a problem with not being able to move the cursor. There is no cursor at all. Ubuntu boots into a black screen, on which a cursor appears. The cursor flickers and then disappears. It then boots into the Unity desktop, with no cursor. \nPlease help.\n\nA: @Konveyorbelt - I have just found a solution that worked for me here:\nhttps://unix.stackexchange.com/questions/72625/why-is-usb-not-working-in-linux-when-it-works-in-uefi-bios\nCheck the BIOS settings - there should be something called IOMMU controller which is disabled by default - When I clicked enable, saved settings and restarted the computer the USB and network functionality were completely restored. Hope it works for you.\n", "Q: All themes are not appearing in Ubuntu 13.10 I a using ubuntu 13.10 and I can not see all available themes in either 'Appearance' or 'unity-tweak tool' Though I have many theme in /usr/share/themes' directory. I do not have~/.themes` folder. Do I need to create that folder and link something.  \n\n\n\n\nA: All of those themes listed are not full environment themes. They only theme a small part of the system. Atlanta, Bright, Crux, and Esco, for example, are only Metacity themes. They do not have icons or GTK+ themes.\nAmbiance, Radiance, and I think HighContrast in that list, are the only ones that would be full system themes, and thus, the only ones that would be displayed in the list in the Display properties.\n", "Q: How do I run install Ubuntu 13.10 and keep windows at the same time? I burned the iso onto the disk and ran it. Which option do I choose?\nThese are the only options I have:\n-Erase disk and install Ubuntu\n-Encrypt the new Ubuntu installation for installation. \n-Use LVM with the new Ubuntu installation. \n-Something else. \n\nA: Try with this:\nOfficial Ubuntu Documentation\nInstall Ubuntu with the Windows installer (Wubi)\nOr go to answered question: Here\n\nA: Choose something else, and then manually select the partition you wish to install on. \nNeed advice installing Ubuntu on 2nd storage drive for windows 7 computer\n", "Q: Acer wireless is not working I have Ubuntu 12.04 on my Acer Travelmate 2300, and I can't enable wireless or use the wireless switch. Does anyone know how to turn on wifi on an Acer Travelmate 2300 using Ubuntu 12.04?\nThis is the first time I've tried to use Linux. I've always used Windows.\n\nA: Can you connect to Internet via ethernet?\nIf yes, do so and go to dash and type Additional Drivers\nThis should open a window and hopefully you will find your Wireless card drivers listed\nClick Activate and you are good to go\nThe window should look like this \n\nA: You have to use ndiwrapper to get your device to work there is no native support for your wifi card in linux.\nDownload the windows driver to your desktop:\nwinxp.zip\nThen:\nRight click on the driver and select extract here. Open a terminal and do:\nsudo apt-get install ndisgtk\nsudo ndisgtk\n\nA window will open, point to Desktop > Winxp > neti2220.inf. Your wireless should turn on. \n", "Q: Disable GNOME (Compiz) task switcher grouping I'm currently running GNOME (GNOME Shell 3.10.4; Compiz) on ubuntu.\nAlt+Tab does the expected (and \"correct\") behavior of showing the task switcher, enabling to switch between current open applications.\nHowever, it groups multiple \"instances\" of the same application (example, gnome-terminal) and requires extra key presses to be able to switch between the instances.\n\nIs there a way to disable the grouping behavior? I've looked around in ccsm and was unable to find anything of relevance.\n\nAny hints you share would be highly appreciated!\n\nA: In my case, I disabled \"Application Switcher\" and enabled \"Shift Switcher\" and retained the default options. The windows are not grouped anymore and you get a 'fancy' switcher.\nIn the screenshot below, the multiple Firefox windows are not grouped together.\n\n\nFor this to work, you will have to install compiz-config settings manager and its plugins. Run this command on the terminal.\nsudo apt install compizconfig-settings-manager compiz-plugins compiz-plugins-extra\n\nOnce they are installed, launch compiz config settings manager and go the section 'Window Management'. Thst's where you find both the \"Application Switcher\" and \"Shift Switcher\" options.\nSee screenshot:\n\n\nA: I hate the grouping windows function. Anti-programmer. I don't want to remember which window should I press Alt+Tab and which window should I press Alt+`.\nJust one combo-key:  Alt+Tab for all the windows, all the time!! \nSo here is the solution for Ubuntu GNOME: \n\n\n*\n\n*Open dconf-editor.\n\n*Go to org/gnome/desktop/wm/keybindings.\n\n*Move the value 'Tab' from switch-applications to switch-windows.\n\n\nDone. \nRefer to: Mad Physicist's answer to the same question on Super User\n\nA: The normal behavior doesn't require extra key presses to be able to to switch between the instances. When you get to an application that has multiple instances just keep a while the Alt key pressed (maximum 2 seconds) and you will see that after you can switch between instances also using the same shortcut: Alt+Tab. Just don't take your finger from the Alt key.\nAnyway, if you want more, the behavior about you asked can be obtained using CompizConfig Settings Manager (you said that you have it installed). After you open it, first enable Application Switcher:\n\nSecond, go inside to Application Switcher, select General tab and play a little with those options until you get what you wish. Personally, I made the following selections:\n\nAnd the result is:\n\n", "Q: How to change a drive's permissions if it's owned by root? Earlier I was trying to install steam on my 32 Gb Flash Drive, because my hard drive is very small, but I couldn't because it was FAT formatted. So then I formatted it to EXT 4 using GParted, and when I did that and went to install steam again, the drive was read only, and upon going to change it, it was owned by root. \nThere is already a question like this here- \nChanging permissions on a drive owned by root\nbut the solution there is to create a root user, however that involves logging out which I cannot do since my version of Ubuntu (xfce precise) is running side by side (dual booted) on a Chromebook (hence the low hard drive space), which means that If I log out, It closes the Ubuntu interface. So my question is this, how do I turn off read only if it is owned by root, without creating a new user?\n\nA: \nhowever that involves logging out\n\nIt doesn't necessarily involve a logout. You can create a nested terminal session as the root user that you create (or any other user, for that).\nsu - username\nWill log you in as username. In fact, to login as root, you don't need to specify the username:\nsu -\n\nHope that helps.\n", "Q: 13.10 - Samba mount error: Could not resolve address Basically, in Ubuntu 13.10 I can't mount a shared folder via the terminal nor fstabs, yet can access the shared folder via Nautilus and smbclient\nI recently upgraded from Linux Mint 15 to Ubuntu 13.10.\nI have a PC with a shared folder created via Windows Groups, that I could samba via a samba client from my old Mint laptop.\nBut now that I upgraded to Ubuntu 13.10, I can't seem to mount it.\nWhat seems weird to me, is that when using Nautilus, I can access the shared folder just fine (via \"Browse Network\"), and can also access it directly with smbclient , but I can't mount it with sudo mount , nor can set it to be automatically mounted at boot by adding the corresponding entry to fstab\nI'll add more info. In my PC, I have Windows 7. The folder I'm sharing is a specific drive (\"D:\" in my case).\nLike I said, when using Nautilus I can open it and access it just fine.\nAlso, when I try using the samba client, I can also access it fine:\nsmbclient \"//gonzalo-pc/Disco D\" -U [Win7 user]\n[Win7 user] being my user from Windows 7 in my PC\nBy executing this command (after introducing the password when it prompts me), I get the smb: > prompt, and by doing dir I can see every folder in my Win7 \"D:\" Drive, so it works.\nHowever, when I use the following command to try and mount it, it doesn't work:\nsudo mount -t cifs \"//gonzalo-pc/Disco D\"  /mnt/share\n/mnt/share being a directory I created to set up the mount.\nWhen I execute the above command, I get the following error:\nmount error: could not resolve address for gonzalo-pc: Unknown error\nI don't know what is causing this, since I don't see how the address \"gonzalo-pc\" can not be resolved, since it is resolved fine when accessing it via Nautilus or smbclient\nMoreover, I can't mount it by adding an entry to fstab either.\nThe entry is the following one:\n//GONZALO-PC/Disco\\040D /mnt/share cifs username=[Win7 User],credentials=/home/gonzalo\n/.smbcredentials,uid=[Ubuntu user],nbrl 0 0\n\nI have a file at ~/.smbcredentials with the following format:\nusername=[Win7 user]\npassword=[Win7 password]\n\nI am not sure exactly what is going wrong. In my previous Linux Mint installation, I followed similar steps and could mount it (the exact same shared folder) fine.\n\nA: the CIFS module only supports DNS names, not NetBIOS names (which I suspect gonzalo-pc is). Try replacing 'gonzalo-pc' in the CIFS mount command with the IP address of the machine.\n", "Q: Why does gnome-control-center have png images for a fingerprint reader? Does it have one and can I use it? So I was randomly looking at images on my computer and I found these in /usr/share/gnome-control-center/pixmaps:  \n \nI didn't think Ubuntu had any built in fingerprint reader support. So why are these here and did I miss something? I haven't installed any fingerprint reader related packages that I know of.\n\nA: Those are there when you need them. You don't need a fingerprint reader for those images being there at all, when you get a fingerprint reader the images don't need to be downloaded and installed.\nThose images are provided by the gnome-control-center-data which provides non-architecture dependant files needed for Gnome Control Center to work. The fact that the images are there doesn't mean that you have a fingerprint reader, but that your system will be ready the very moment you install one.\n\nA: GNOME does, in fact, have \"built-in\" fingerprint reader support.\nSee this help thread from gnome.org.\n", "Q: How do I increase the size of Ubuntu which was installed through Wubi? First, this is question is not same as this or this. It is similar but its somewhat different in a way. Particularly,  I want to change the path of where my disk copy is generated. The problem is: I know I have another drive where I have a lot of space and I want a new (resized) copy of my Ubuntu to be generated at that path and then remove the older copy after verifying that my new copy boots correctly. Currently my Ubuntu is of 30 gigs and is at drive H:\\, I want to increase it to 40 gigs (actually 50 gigs would be great but my H:\\ partition is of 50 gigs and would be requiring to have some free space for swap). I want to store the intermediate copy in drive E:. I want to do this because my H:\\ drive is 50 gigs (26 gigs filled) and so I can't create a copy in the same drive. Is it possible to do that by, say, modifying the script given here? Or is there any other way to do that? \nAny help would be appreciated. Thanks!\n\nA: Even if you found the steps to migrate and resize your WUBI installation, the maximum size is 30GB -by design limitation; which you are already configuring.\nIf you need a bigger size for your Ubuntu installation, then The answer will be backing up your system\\data > perform another installation on a dedicated partition or perhaps a virtual machine > restore your data to.\nYou can also migrate your WUBI installation to a partition by following this article http://help.ubuntu.com/community/MigrateWubi\nBut I'm afraid I didn't try it before\n", "Q: Does Software Updater update apps installed by Software Center I just want to know if I could install a bunch of apps through the Software Center and not have to add individual repositories to update every single app.\n\nA: *\n\n*If the application was installed originally from Software Center, then yes you have it in repositories already (although some apps might have other updated version outside ubuntu official repositories).\n\n*If an application was installed by a method other than Software Center, then maybe or maybe not you have its repository automatically added during installation (you need to check software sources or sources.list file for that).\n\n*Other application - MySQL workbench for example, have an in app tool to check for an update, and might direct you directly to update process.\n\nA: If the repositories contains the update for a particular package then software updater updates that package.\nInstalling package via software-center does the same function as installing package via apt-get.\nYes, software updater updates packages installed via software-center only if the corresponding package had an update in enabled repositories.\n", "Q: After installing Ubuntu 13.10 I get this message \"the disk drive for /dev/mapper/cryptswap1 is not ready yet or not present\" I've just finished installing Ubuntu 13.10 on my computer.\nWhen I start the computer, after the Ubuntu logo fades away, I see this message: \n\nthe disk drive for /dev/mapper/cryptswap1 is not ready yet or not present\n\nThen the login screen appears and when I enter my password I go to my desktop.\nIs this normal? Do I need to do something about it?\n\nA: This error comes up when your swap partition cannot be mounted for some reason.\nTo solve the error:\nTurns off swap:\nsudo swapoff -a \n\ncomment existing swap configuration in /etc/crypttab\ncryptswap1 /dev/sdXX /dev/urandom swap,cipher=aes-cbc-essiv:sha256\n\ncomment existing swap configuration in /etc/fstab\n/dev/mapper/cryptswap1 none swap sw 0 0\n\nre-format swap partition with gparted as linux-swap\nsudo mkswap /dev/sdXX \n\nmark somewhere the UUID value that the previous command returns\nSetting up swapspace version 1, size = 4208636 KiB\nno label, UUID=06a9be15-d05b-466d-bfe3-a086bb9cdba0\nupdate /etc/initramfs-tools/conf.d/resume with the new UUID\nCheck your new UUID\nRESUME=UUID=06a9be15-d05b-466d-bfe3-a086bb9cdba0\nsudo update-initramfs -u (update initramfs)\nsudo swapon /dev/sdXX (enable swap, XX depends on your setup)\nsudo ecryptfs-setup-swap (encrypt swap)\n\nsource and more information\n", "Q: Using grep to search texts with single quote? I am using gedit text editor with embedded terminal in ubuntu 12.04. I'm trying to search for some text using grep. I want to search for this line of code \n'type' => 'select'\n\nI tried:\ngrep -r '\\'type\\' => \\'select\\''\nBut grep didn't return any results.\nSo can someone kindly tell me how to search for the code above?\n\nA: Surround your search string with double quotes:\ngrep \"'type' => 'select'\"\n\n\nA: You cannot escape single quotes that appear within single quotes. As explained in the bash manual:\n\nEnclosing characters in single quotes (‘'’) preserves the literal value of each character within the quotes. A single quote may not occur between single quotes, even when preceded by a backslash.\n\nSo, you have to use different approaches:\n\n*\n\n*Use double quotes:\n grep  \"'type' => 'select'\" file \n\n\n\n*If you prefer needlessly complex solutions:\n grep  \"'\"type\"'\"\\ =\\>\\ \"'\"select\"'\" file \n\n\n\n*You can always search for any single character instead of specifying the single quotes:\n grep  '.type. => .select.' file \n\nBut just use \", it makes things much more straightforward.\n\nA: cd to the directory that contains your .txt file \ncd /path \n\nThen :\nyou can use grep \"'type' => 'select'\" name.txt \nor :\n`grep \"'type' => 'select'\" /path/file.txt\n\nOutput :\n\n", "Q: Why is \"*\" appended to apt-get purge package_name? When I run\nsudo apt-get purge -s clipit\n\nI see:\n$ sudo apt-get purge -s clipit\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following package was automatically installed and is no longer required:\n  libappindicator1\nUse 'apt-get autoremove' to remove it.\nThe following packages will be REMOVED:\n  clipit*\n0 upgraded, 0 newly installed, 1 to remove and 0 not upgraded.\nPurg clipit [1.4.1-1.1ubuntu1]\n$ \n\nI see clipit* instead of just clipit. What does * mean here?\n(It's not just clipit but with other packages as well.)\n\nA: According to the manual page for apt-get it indicates;\nAPT-GET(8)                            APT                           APT-GET(8)\n\nNAME\n       apt-get - APT package handling utility -- command-line interface\n\n       remove\n           remove is identical to install except that packages are removed\n           instead of installed. Note the removing a package leaves its\n           configuration files in system. If a plus sign is appended to the\n           package name (with no intervening space), the identified package\n           will be installed instead of removed.\n\n       purge\n           purge is identical to remove except that packages are removed and\n           purged (any configuration files are deleted too).\nThat explains the difference between remove and purge. Basically remove will only remove the package whilst not touching nor changing the config files where purge will remove everything relating to the package including the configuration files.\nHaving said that; clipit* with a * indicates that it will remove the said package & all its includes (config files.. etc) accordingly.\nExamples;\nremove - If you're removing skype, chrome.. etc or any other package that holds configuration files inside your /home/user directory. Those will not be removed.\npurge - Further, if you use this on bind, mysql, squid.. etc or any packages that stores configuration files in their respective location such as /etc.. well, those will be deleted.\n\nA: * appended to package name while purging because purging will remove config files,dependencies along with the original package.\npurge - Remove packages and config files\n\n", "Q: Install ATI Radeon HD 3450 (RV620 LE) in Ubuntu 13.10 (64bits) \nI failed to install the driver for my ATI Radeon HD 3450 (RV620 LE) card in Ubuntu 13.10 (64bit)\nsomeone could help me with this, to know if they can or not. \nI have tried several ways to install the driver but always I have to reinstall the xorg again, because after not let me sign in ubuntu. \nI hope someone help me with this problem\n\nA: For that card the only proprietary driver you could use is the legacy driver...however that one only works with linux kernel up to 3.4.x which was in use back in Ubuntu 12.04.2.So you can only use the default open-source radeon driver that is already installed.\nPerformance wise you'd be unlikely to see a big difference anyways, as the older cards are from my experience pretty well supported by the open-source driver. \n", "Q: Its virtual box legal? I had this question\nI install virtualbox in order to learn about this program, and i found that had the oportunity to run windows, even windows 3.1 to windows 8, my corcern is about the copyright, one of the reasons why, currently im an ubuntu user is because is opensource, and im against breaking the law (i dont like that microsoft has privative code, but i respect his desicion)\nThe official site says that is opensource, but, how this can be opensource and at the same time offer windows? (windows allow this company to offer his program?)\n\nA: I don't have experience with Virtualbox, but if it is like the other virtualization programs I have used, when it comes to installing any version of Windows it may offer to download an .iso of it for installing. However, you will need a valid activation code in order to continue using it beyond the default activation time period.\nFor other non-opensource or EOL'd OS's (re: Windows XP and earlier), you will probably need to have an installer disc and activation/license code to install and use them.\n", "Q: Will pure Java written software be accepted in Ubuntu Software Center I just came across an article regarding submitting app to Ubuntu Software Center\nhttp://developer.ubuntu.com/publish/apps/other-forms-of-submitting-apps/commercial-software-faqs/\nI'm currently maintaining a open source stock market software. I would say around 80% are Windows users, although the software itself can be executed in Linux too.\nI would like to increase adoption of Linux users. Hence, distributing the software in most popular Linux distro will definitely help.\nI was wondering, whether a pure Java written software will be accepted in Ubuntu Software Center? It requires JRE6 and above.\n\nA: Yep, there's no reason why not. Your package will just depend on JRE, so when installing your software, the USC will automatically install Java as well should it be missing.\n", "Q: Function keys not working after update I installed an update on the 7th and now have some strange keyboard behaviour. After first installing the update and rebooting the keyboard layout changed to US but only for Chromium - when I checked what keyboard layout was actually in use by the system it was still UK extended winkeys and the rest of the system was using that correct layout as far as I could tell from the limited testing I did. This morning the keyboard layout is fine but I'm still having an issue where the F5 key is putting my laptop into standby rather than what it's meant to be doing which is refreshing a page. The other function keys for volume, brightness, etc. aren't working either. The F*x* keys normally make the extended function work by default and you have to hold the Fn button to make them work as traditional F*x* buttons with the exception of F5 which has no extended function but which is now putting my laptop into standby.\nThe laptop is a HP E2 Vision and I'm running Ubuntu 13.10 64-bit. The log in var/log/apt/history.log contains no entries for the update on the 7th but does for this morning when I ran the software updater so logging is working. I therefore don't know what was actually installed by the updater.\n\nA: I know it's stupid, but check to see if your keyboard has an F-Lock key. I just wasted several minutes trying to debug the \"problem\", and it turned out that I had hit the F-Lock key. It replaces all the function keys with alternative operations.\n", "Q: Unable to play songs/videos from mounted android phone I have successfully mounted my android(JB) phone with ubuntu 12.04 lts. Everything is fine, when i connect my phone to laptop a window appears with memory card and phone memory. I can copy/paste files from system to phone and phone to system.\nNow my problem is that I can't play songs/videos from memory card or phone memory.\nI am new to Ubuntu. Now only started to understand this platform.\n Can anyone help me???\n\nA: Dude, there is some problem with mounting android phones in the Ubuntu 12.04.\nand  you didn't specified the phone type of yours. so i'll prefer to copy the contents first before using them. my nexus can't mount its internal storage(i think the mounting issue is only for internal storage) .so i use adb push/pull to copy files.\n\nA: Firstly, you need to understand that Android presents its internal and external storage to PC using MTP. It is not the same as USB mass storage where you mount a FAT filesystem.\nMTP has certain limitations. I'm not sure of the exact limitation here, may be the because MTP limits one operation at a time, which makes you cannot directly play a file in an MTP device. First you have to copy the file to your computer. Even in Windows OS (which originally introduced it), this is it\nWhen you connect a MTP device to a computer, do not expect the comfort you had with mass storage devices.\nSecondly, Ubuntu 12.04 has poor MTP support. I understand that you are on a LTS release. But no choice, you will have to upgrade if you need proper MTP support. In Ubuntu 13.04+, MTP works well.\n", "Q: How to turn off proprietary ATI drivers using Recovery Mode? I have setup just like in this question - AMD A10-7850K APU and an Asus A88XM-PLUS motherboard. Instruction by Ruben Bakker tells me how to install what I need, but it does not tell me how to clean up my system after a failed attempt made on my own.\nI installed drivers using Additional Drivers manager. Restarted, and now every time I boot all I can get is a black screen. Keyboard and mouse are trapped and I can't switch to text console, and so on. I can boot to recovery mode but what do I do there? In the old times when I was using Gentoo I would just edit xorg.conf to switch to an open driver, but I can't find anything like that in my Ubuntu. And I'm sure there is no text-based version of Additional Drivers manager.\n\nA: I'm not sure this is the correct answer, but I'll have a go. Try this page. Extracted instructions:\nsudo sh /usr/share/ati/fglrx-uninstall.sh\nsudo apt-get remove --purge fglrx*\n\nfollowed by the following for the sake of making sure all is clean:\nsudo apt-get remove --purge xserver-xorg-video-ati xserver-xorg-video-radeon\nsudo apt-get install xserver-xorg-video-ati\nsudo apt-get install --reinstall libgl1-mesa-glx libgl1-mesa-dri xserver-xorg-core\nsudo mv /etc/X11/xorg.conf /etc/X11/xorg.conf.backup\nsudo rm -f /etc/ati\n\nThat should remove all previous FGLRX drivers you had. Now you're back to the fresh Ubuntu graphics setup. This question provides an answer on how to get FGLRX working with Kaveri, but you had already seen that question.\n\nA: If you installed the proprietary drivers from the official repositories run\nsudo apt-get purge fglrx\\*\n\nin recovery mode and then reboot. This helped me revert a problematic fglrx installation in Ubuntu 12.04 on a PC with an AMD Radeon HD 7770 graphics card.\n", "Q: Ehterpad configure script not finding the existing dir given via prefix option I am following the official ubuntu guide to install etherpad from here.\nWhen it asks to download and extract the latest version of etherpad, I do so. The version I downloaded is node-v0.10.26.tar.gz.\nSince I am following the guide, the path of extracted directory is /opt/etherpad/local/node-v0.10.26\nThe guide then asks me to run configure script: \" ./configure –-prefix=$HOME/local/node\"\nOn doing so I get the following error:\ngyp: –-prefix=/opt/etherpad/local/node not found (cwd: /opt/etherpad/local/node) while trying to load –-prefix=/opt/etherpad/local/node\nError running GYP\n\nSo I then rename the node-v0.10.26 directory to simply \"node\" and then run the command again and I again get the same error:\ngyp: –-prefix=/opt/etherpad/local/node not found (cwd: /opt/etherpad/local/node) while trying to load –-prefix=/opt/etherpad/local/node\nError running GYP\n\nIf instead of $HOME I use /opt/etherpad, as in \" ./configure –-prefix=/opt/etherpad/local/node\" I still get the same error.\nAny clues why is it giving the error?\nOS is Ubuntu 12.04.4 LTS.\n\nA: Try to type the two dashes in front of \"prefix\" manually.\nIt was a copy and paste error for me.\n", "Q: Ubuntu 12.04 lts fails to load unity. Nvidia persistence daemon [fail] Ubuntu 12.04 fails to start when my drivers are installed for nvidia.\nWhen I’ve a ubuntu 12.04 LTS on my laptop without the drivers installed, everything works just fine . But when I install my nvidia drivers and bumblebbee it start to the terminal. What do I’ve to do? These are the errors I’ve when booting Ubuntu through recovery mode. Because I get on low graphic mode when I don't enter GRUB.\ncould not write bytes: broken pipe\ncould not write bytes: bad file descriptor\nNvidia Persistence daemon [fail]\nI’ve a asus ux32vd with i7 and NVIDIA [GeForce GT 620M]\n\nI have spent one week googling around. None of the solutions I found helps. Help please :)\n\nA: Ok. Here is the update. I was able to load my system with graphics enabled.\nAfter I've posted this question I have re-installed my Ubuntu. I have installed Ubuntu 12.04 LTS 64-bit. Then I have installed bumblebee following this post.\nEverything worked until I have installed freeglut3 using thise command:\n sudo apt-get install freeglut3 freeglut3-dev\n\nI have noticed that it asks to delete a lot of files, libraries which are related to x-server. (I only deduced this from the names of files it asked to delete). \nI confirmed. After freglut3 was installed, I rebooted my system and had the same problem again.\ncould not write bytes: broken pipe\ncould not write bytes: bad file descriptor\nNvidia Persistence daemon [fail]\n\nI decided to try to purge nvidia and bumblebee and re-install them, hoping that it will reload the files which freeglut3 deleted.\nsudo apt-get remove --purge nvidia*\nsudo apt-get --purge remove bumblebee\n\nAfter thatб I have added repositories containing latest nvidia drivers and installed them.\nsudo add-apt-repository ppa:xorg-edgers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-331\n\nAfter the installation was complete without rebooting I have installed bumblebee\nsudo apt-get install bumblebee\n\nI have rebooted, and my system started working again!\nUnfortunately I will have to do this each and every time some updates or new installations touch \"X\" files.\nHope this post helps somebody. Regards.\n", "Q: where do i get drivers for my Lenovo Ideatab a3000-h? I need to back-up my tablet...where do i get the drivers for it?\nIts a Lenovo Ideatab A3000-H \nI'm using Ubuntu 12.04\nWhen i plug my tablet into my laptop, I can't see it, so i assume i need the drivers for it?\nthanks\n\nA: Dude, Just plug it in as a media device and you can easily explore the whole SD card of your tab on PC. I faced the same prob with tab, but it works when i used it as media device(MTP)\n\nA: You shouldn't need drivers to access the files on it. What happens when you plug it in? It should show up on your desktop or in your file browser.\n", "Q: How to extract audio from video ?? (Not converting video into audio file ???) It sounds strange to ask this question as it has been asked before. However the answers only refer to converting video files into audio files.\nI would like to get into the container and separate the video file from the audio file and only keep the audio file. Simple conversion of the container to the audio file, makes the file way to big, and containing more info than I need.\nConverting the whole container file (avi, mpg, wav.....) etc is easy enough but that does not do the trick. \nPreferably I would like to do this without using the terminal. Working with the latest version of Ubuntu at this moment (march 2014). Also please do not suggest any cross platform ideas. I run my computer on only Ubuntu, there is nothing left of any other OS.\nH.W. Roos\n\nA: You can use avidemux.\nInstall it command line with:\nsudo apt-get install avidemux\n\nYou can rip the audio from the video file.\nIn the toolbar, click on the top left folder icon and load the video file from your computer.\n\nClick on the Audio option on the left side panel and choose the audio codec you want to use \nNow, click on the “Audio” option in the menu bar and select “Save” to save the audio\n\n\nIf you prefer a CLI give ffmpeg a try\nffmpeg -i input_file -vn -acodec CODEC output_file\n\nCODEC= libmp3lame if output .mp3\nCODEC= libvorbis if output .ogg\nexample:\nffmpeg -i ~/Desktop/video.mp4 -vn -acodec libmp3lame audio.mp3\n\nIn case you don't have ffmpeg installed:\nsudo apt-get install ffmpeg\n\n", "Q: Unable to connect to running ssh-agent I connect to a long-running screen session on Ubuntu 12.04 server, and use that as a jump box for other things I connect to. As a result, I want a long-running ssh-agent on that machine. To that end, I have the following in my .bashrc:\npgrep -u pdickey ssh-agent > /dev/null || ssh-agent -a $HOME/.ssh-auth-sock\nSSH_AUTH_SOCK=$HOME/.ssh-auth-sock\nexport SSH_AUTH_SOCK\n\nAs long as my screen session never disconnects, this works perfectly. I can spawn new screens, and they all get the same agent. Trouble arises when I disconnect from the machine that has the original ssh session. On a reconnect, I get the following:\n$ ssh-add -l\nCould not open a connection to your authentication agent.\n\nEverything I've found about this seems to indicate that this happens when the agent isn't running, but I can verify that it is running, and the $SSH_AUTH_SOCK variable is set:\n$ ps -fu pdickey | grep ssh-agent\npdickey    435     1  0 04:11 ?        00:00:00 ssh-agent -a /home/pdickey/.ssh-auth-sock\n$ echo $SSH_AUTH_SOCK\n/home/pdickey/.ssh-auth-sock\n\nSo why the heck isn't it connecting? I own the socket:\n$ ls -la .ssh-auth-sock \nsrw------- 1 pdickey pdickey 0 Mar 10 04:33 .ssh-auth-sock=\n\nI've even gone so far as to strace the process, which after sifting through all the library loads, provides the mostly-unhelpful bit of information:\n64962 connect(3, {sa_family=AF_FILE, path=\"/home/pdickey/.ssh-auth-sock\"}, 110) = -1 ECONNREFUSED (Connection refused)\n\nThis is now the limit of my linux / ubuntu / ssh knowledge. Why would a socket that I own, created by a process I own, refuse connection from another process I own?\n\nA: So turns out this is a result of deciding to encrypt my home directories, and placing the auth-sock there... This means when I fully detach from screen, my running programs lose access to my home directory, which breaks ssh-agent. It doesn't kill the ssh-agent process like deleting the socket normally does, and it doesn't remove the socket because it's in an encrypted directory that the machine can no longer access. This also manifests other oddities like my cron daemon not being able to run scripts in my home directory if I'm not logged in.\n", "Q: Automatic mount ext4 hard disk on boot problem I used blkid and its output:\n/dev/sda1: UUID=\"54221CEE221CD6B8\" TYPE=\"ntfs\" \n/dev/sda2: LABEL=\"Data\" UUID=\"FE10555E10551EC9\" TYPE=\"ntfs\" \n/dev/sda5: UUID=\"fc63b7f3-9b03-4e85-a0ce-fa638eeff40b\" TYPE=\"ext4\" \n/dev/sda6: UUID=\"f498cfb8-519f-462d-ae26-2fabb709ad8b\" TYPE=\"swap\" \n/dev/sdb5: LABEL=\"backup\" UUID=\"e8572aae-27e7-4d16-84fa-81c437529373\" TYPE=\"ext4\" \n\nI want to mount sdb5 automatically so I edited  the fstab like this \nUUID=fc63b7f3-9b03-4e85-a0ce-fa638eeff40b /               ext4    errors=remount-ro 0       1\nUUID=f498cfb8-519f-462d-ae26-2fabb709ad8b none            swap    sw              0       0\nUUID=e8572aae-27e7-4d16-84fa-81c437529373 /media/dongchirua/ ext4 uid=1000,gid=1000,umask=0022,sync,auto,rw 0 0\n\n(/media/dongchirua/ is place where I want to mount to)\nbut when system start, a message shows an error on sdb5 and press S to skip it? Could you please help?\n\nA: according to this thread, when mounting an ext4 partition via fstab, you cannot use uid=1000,gid=1000, but permissions should be set in the partition's root directory\n\nA: Just look at the dmesg output\nEXT4-fs (sdb5): Unrecognized mount option \"uid=1000\" or missing value\n\ngood starting options are defaults\nIf you want to tune the drive then you could also add barrier=0\n", "Q: Custom USB distro problem: cannot connect to the Internet This is my first thread and I would like to apologize for my lack of knowledge regarding forum-based rules.\nI intend to make a Custom USB Ubuntu 13.10 Distribution with the applications i need. I did everything i needed, but there is one problem: I cannot connect to the Internet.\nI created the distribution after installing the programs I needed (like GIMP and Google Earth) using \"remastersys\" and \"Ubuntu Startup Disk Creator\". Whenever i wish to acces the Internet while booted from USB it says there is a connection problem. I can connect to my router and the router gives me a DHCP address. I tried connecting using wired, wireless and USB wireless dongle. However, I pinged Google using terminal and i had 100% responses with no delay.\nI am really out of solutions and really need this USB Ubuntu to work on the internet. Thank you for any advice you can give me!\n\nA: I saw this off the remastersys forum, as I'm trying to figure this out on 14.04 as well\nhttp://www.remastersys.com/forums/index.php?topic=2729.0\n\"Network Manager has been changed.  You will have to remove the part in /usr/bin/remastersys that removes $WORKDIR/dummysys/etc/resolv.conf and remaster again.\nThis is caused by a change to the way they are populating resolv.conf since it is now just a link.  I have to update remastersys for 12.10 which I haven't had a chance to do yet.\"\nI say give that a shot and see - I'm re-making my image right now. \n", "Q: How can I confirm my name on a local network? My local network name is usually myhostname.local, but sometimes other people on the network can't access me at that address and I have to give them my network IP address (which changes).\nHow can I confirm my name on the network I am currently logged in to?\n\nA: After some digging around...\n\n\n*\n\n*Run ifconfig and identify which device is connected to the network you're interested in. For example, if you are connected to a WLAN it would be wlan0. Get your IP address on that device.\n\n*Run avahi-resolve-host-name -a 123.45.678.900 (where the numbers are your IP address). This should display:\n    123.45.678.900    yourhostname.local\n\n\nA: All this mDNS/Ahavi stuff is very platform dependent. Your computer will advertise its hostname but it's the other computers that set its DNS name on themselves.\n\n\n*\n\n*Avahi sticks .local on the end,\n\n*Bonjour (the Apple implementation) doesn't bother with the .local, and\n\n*NetBIOS isn't really mDNS but it's how Windows and Samba spreads its name. Again, no .local\nIf you're sitting in a network of a single, controlled platform, the answer is fairly simple... If you aren't, it's not.\nIf this is a common issue, and it's a network you control, it might be worth setting real DNS for your computers through a centralised DNS server and having that add DHCP leases to that. pdnsd is something I've looked at before but there are others.\nNote: If the router isn't industrial, you'll need to check you can set the DNS server to an internal IP. I had issues with that very issue on a Netgear router and never managed to work around it.\nFailing that, external services (Dyndns et al) could let you set local, illegal IPs to real domain names. Eg you could be resolved through d3vid-internal.d3vidsdomain.etx.\n", "Q: Avoid Hidden files while calculating disk usage? I am using ubuntu LTSP ,\nI want to find tje size of my home folder using ,\ndu command,\nI try du -hs /home/students/cs2011/cs1105 ,\nbut it shows more size than what i get by taking the properties \n\nA: The ambiguity you are getting is because when you right click on a folder and check its properties, it shows you much size the file/folder has occupied on disk, i.e. its disk usage and not because of hidden files.\nHowever, du shows the file size, i.e, the number of bytes the file/folder has. This is different from the size occupied by the file/folder because of spare blocks, internal fragmentation and other parameter which are filesystem-dependent.\nTo remove this ambiguity, use du as follows:\ndu --apparent-size -hs\n\nFrom du's manual page:\n\n  --apparent-size\n          print apparent sizes, rather than disk usage;\n          although the apparent size is usually smaller, \n          it may be larger due to holes in (`sparse') files, \n          internal fragmentation, indirect blocks, and the like\n\n\n", "Q: After mounting the ntfs partition, all files are readonly I made the following changes in /etc/fstab, after doing this i cant create any files in any of the partitions and the existing files are readonly. \nPls help me out.\nThis is my /etc/fstab\n# /etc/fstab: static file system information.\n#\n# Use 'blkid' to print the universally unique identifier for a\n# device; this may be used with UUID= as a more robust way to name devices  \n# that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\nproc                                       /proc        proc  nodev,noexec,nosuid                0  0  \n# / was on /dev/sda10 during installation\nUUID=89e6ce75-1460-4c7e-ab26-ada11484cf4e  /            ext4  errors=remount-ro                   0  1  \n# swap was on /dev/sda11 during installation\nUUID=fb568186-5d39-4a60-9412-c254a0489490  none         swap  sw                                 0  0  \n/dev/sda5                                  /media/EDUCATIONAL ntfs  nls=iso8859-1,umask=002  0  0 \n/dev/sda6                                  /media/ENTERTAINMENT  ntfs  nls=iso8859-1,umask=002  0  0  \n/dev/sda7                                  /media/PROJECTS  ntfs  nls=iso8859-1,umask=002 0  0  \n/dev/sda9                                  /media/sda9  swap  noauto,sw                          0  0  \n/dev/sda8                                  /media/sda8  ntfs  nls=iso8859-1,noauto,umask=000  0  0  \n\nAm trying to mount EDUCATIONAL, ENTERTAINMENT and PROJECT partitions.\nIf i go into PROJECT partition,cd /media/PROJECT\nand when i do ls -l\nmanu@manu-Ideapad-Z570:/media/PROJECTS/Programs$ ls -l\ntotal 20 \ndrwxrwxr-x 1 root root 4096 Oct 22 15:02 Beagle\n-rwxrwxr-x 1 root root 2943 Feb 28 21:37 checksum.c\ndrwxrwxr-x 1 root root    0 Sep  5  2013 GIT\ndrwxrwxr-x 1 root root 4096 Apr  2  2013 OOPs_programs\ndrwxrwxr-x 1 root root 4096 Mar  3 10:22 OS\ndrwxrwxr-x 1 root root    0 Jan 28 18:06 Python\ndrwxrwxr-x 1 root root    0 Mar  1 00:34 Software_House\ndrwxrwxr-x 1 root root 4096 Feb 17 10:09 test\ndrwxrwxr-x 1 root root    0 Feb  5 13:37 Uttara\nmanu@manu-Ideapad-Z570:/media/PROJECTS/Programs$ \n\nBut when i open the file checksum.c using vim it says readonly file. I tried doing chown and chmod, but also its always readonly.\nWhat should i do i want to access these files make changed and even create new files in there, can anyone please help me out ?? \n\nA: It seems that you must be using mount.ntfs instead of mount.ntfs-3g.\n\n\n*\n\n*Make sure you have the ntfs-3g package installed. sudo apt-get install ntfs-3g.\n\n*In the fstab replace ntfs with ntfs-3g.\n\n*Run sudo mount -a (or reboot) and you should be good to go.\n\n", "Q: How to start git-gui? I've installed git-gui tool via sudo apt-get install git-gui. But how do I start it? Trying with search or git-gui command did not find and UI tool for Git. \n\nA: Type git citool to start git-gui.\nIf it gives the error: git: 'citool' is not a git command, just install the following package: git-gui\nsudo apt-get install git-gui\n\n\nA: In terminal type :\ngit gui citool\n\nMake one commit and return to the shell when it is complete. This command returns a non-zero exit code if the window was closed in any way other than by making a commit. \n git gui citool --amend\n\nAutomatically enter the Amend Last Commit mode of the interface.\ngit gui citool --nocommit\n\nBehave as normal citool, but instead of making a commit simply terminate with a zero exit code. It still checks that the index does not contain any unmerged entries, so you can use it as a GUI version of git-mergetool.\nReference Site\n\nA: Typing it without the dash/hyphen should work:\ngit gui\n\ninstead of git-gui.\n", "Q: Grey screen background during logon Earlier during log on my screen's background used to be purple,but now it has become grey in colour,is it OK?But can anyone tell me why does did it happen.And,how can I switch from Lubuntu to Ubuntu?Which is better Lubuntu or Ubuntu?And how can I use the Remote login feature of Ubuntu 13.10?\n\nA: *\n\n*Don't worry saisanjeev, if you can still login there isn't any problem: read this askUbuntu article to know why you background is now dynamic and not static.\n\n*For the other questions: Lubuntu is made for low end machines (like Asus EeePc) and uses less memory and less CPU than Ubuntu, but uses lxde Desktop Enviroment as Graphical User Interface and has different software & updates than Ubuntu. Pass to Lubuntu if you notice lag in your current Ubuntu installation, I also suggest to try Lubuntu in Live before using it.\n\n*Last, for the Remote Desktop feature follow this unofficial guide.\nPlease, if you have more questions comment under here and don't forget to press the UP arrow. :-)\nHave a nice experience and Don't Panic, Linux is made for tweaking.\n", "Q: Lenovo Y580 reinstall network drivers I had some issues with WiFi with my Lenovo y580, I could connect my home WiFi but it would disonnect me after few minutes and I wasn't able to reconnect\nI have Ubuntu 12.04 and I believe my network card is \"AR8161 Gigabit Ethernet\"\nChanges I have been doing before it stopped working at all:\n191  lspci -vv | grep Atheros\n192  sudo apt-get install build-essential linux-headers-generic linux-headers-`uname -r`\n193  wget -O- http://linuxwireless.org/download/compat-wireless-2.6/compat-wireless-2012-07-03-pc.tar.bz2 | tar -xj\n194  cd compat-wireless-2012-07-03-pc\n195  ./scripts/driver-select alx\n196  make\n197  sudo make install\n198  sudo modprobe alx\n\nIt would be great if I could revert this change so ubuntu would use the previous standard driver.\nThen I could at least connect to some WiFi and maybe this problem was router's issue and not my network driver one\nThanks for any help\n\nA: Ok, after going 4 hours without being disconnected I can say, that I have solved the issue\nThe solution is to go to Network -> Edit Connections -> Wireless -> Click on WiFi -> Edit -> IPv6 Settings\nThere, you have to select Method: Ignore\nSo it is IPv6 related issue. Somehow.\n", "Q: Snapshot of a LXC container Please, is it possible to migrate a container to a new node and restart it there ? \nAnd How? should i take a snapshot of the container or i transfer the repository to the new node ?\n(Beginner with LXC container)\nThank you so much.\n\nA: If you have a standard container under /var/lib/lxc, i.e. /var/lib/lxc/container1, then it suffices to stop the container, make sure lxc is set up on the new node (call it 'desthost') and\nrsync -va /var/lib/lxc/container1 desthost:/var/lib/lxc/\n\n(You can't yet migrate a running container;  hopefully that'll work \"soon\" using criu)\n", "Q: I want to reinstall Ubuntu but I do not know which partitions to delete \nSo, I went to GParted and I know that I must delete the ext4 partition and the Linux Swap partition. My question is, does that unknown partition have anything to do with Linux? Should I delete that one too?\n\nA: msftres is the \"Microsoft Reserved\" Partition. It's used by some Windows tools, so if you are not going to delete Windows, you shouldn't delete this partition.\nmsftres is needed only for conversion from a basic disk to dynamic disk in Windows; it has nothing to do with Linux.\nReference: Microsoft Support\nSee also this Launchpad bug report which has some explanation of msftres oriented towards using Linux partitioning tools.\n\nA: Ubuntu is already installed on the /dev/sdb8 partition.\nBoot from Ubuntu live USB ..., when the partition manager (Gparted) prompt mark the /dev/sdb8 as / root with ext4 file system , select /dev/sdb9 partition as swap, then confirm to install the system.\n", "Q: Error mounting SD card when returning from suspend I have a 128 GB SD card that I use for permanent storage in my Lenovo Thinkpad X1. I've mounted it in /etc/fstab with this line:\nUUID=37733366-e936-41df-983a-f084352b3a5b   /home/kristian/sd128gb  auto    defaults 0  0\n\nwhich works just fine. Until I put my machine to suspend, upon returning I get the error:\nError mounting system-managed device /dev/mmcblk0p1: Command-line\n`mount \"/home/kristian/sd128gb\"' exited with non-zero exit status 32:\nmount: File exists\n\nThe mount point directory is empty, but attempting to mount it gives\n$ mount sd128gb/\nmount: according to mtab, /dev/mmcblk0p1 is already mounted on /home/kristian/sd128gb\n\nSyslog gives\nkernel: [271462.070388] EXT4-fs warning (device mmcblk0p1): __ext4_read_dirblock:908: error reading directory block (ino 2, block 0)\nkernel: [271462.070410] EXT4-fs warning (device mmcblk0p1): __ext4_read_dirblock:908: error reading directory block (ino 2, block 0)\nkernel: [271462.091100] EXT4-fs warning (device mmcblk0p1): __ext4_read_dirblock:908: error reading directory block (ino 2, block 0)\nkernel: [271462.091130] EXT4-fs warning (device mmcblk0p1): __ext4_read_dirblock:908: error reading directory block (ino 2, block 0)\n\nUnmounting and mounting it again works, but this is a hassle to do every time I return from suspend -- especially as I use it for permanent storage, it doesn't feel very reliable to work with data on a partition that frequently unmounts.\nThe \"file exists\" message seems obscure, and googling it, it seems like not many people get the same error message. \nCan I fix this permanently? Or, alternatively: How could I make an ugly fix with a remount command that runs every time I return from suspend? \n\nA: In case you're looking for an answer to this remount read-only issue, an unRaid valuable article showed me the solution yesterday, after I had a very similar issue on my biggest hard drive (while already recovering the files of an silly USB key...)\nMy logs:\n[40860.074298] blk_update_request: I/O error, dev sdc, sector 104869128\n[40860.074306] EXT4-fs warning (device sdc2): __ext4_read_dirblock:884: error -5 reading directory block (ino 2, block 0)\n[40860.661232] sd 7:0:0:0: [sdc] UNKNOWN Result: hostbyte=0x04 driverbyte=0x00\n[40860.661237] sd 7:0:0:0: [sdc] CDB:\n[40860.661239] cdb[0]=0x28: 28 00 06 40 2d 08 00 00 08 00\n\nHowever, the most interesting error was before these, ie the first or second line related to this issue:\nmars 27 22:27:55 llewellyn kernel: ata8: SError: { PHYRdyChg CommWake 10B8B LinkSeq }\n\nHeading\nLooking for PHYRdyChg on mentionned article, guided me to the « Drive interface issue #4 », ruling out any hard drive failure or driver issue :) Quoting their explanation:\n« This is an example of what is probably a loose backplane or cable connection issue: (could be either the SATA connection or the power connection or both)\nata7.00: exception Emask 0x10 SAct 0x7 SErr 0x990000 action 0xa frozen\nata7.00: irq_stat 0x00400000, PHY RDY changed\nata7: SError: { PHYRdyChg 10B8B Dispar LinkSeq }\nata7.00: cmd 60/48:00:af:1b:97/00:00:10:00:00/40 tag 0 ncq 36864 in\n           res 40/00:10:87:5f:96/00:00:10:00:00/40 Emask 0x10 (ATA bus error)\nata7.00: status: { DRDY }\n\nNote: There are no CRC errors here, which normally implicate a bad cable or two. »\nI checked any Sata / Power cables, rebooted and all was fine. A smartctl -a -A /dev/sdc confirmed this.\nPS: The unRAID article is invaluable to understand various Hard Drive errors and messages (eg BadCRC, failed to recover).\n", "Q: How can I deploy my local Juju Charm with Amulet framework? I use amulet as testing framework for charms which we developing. I've already tried to reproduce an example, provided on https://jujucharms.com/docs/stable/tools-amulet and it's work fine. But now I'm trying to do the same basic setup for charm, which was developed and stored on hard drive ('cf-nats' charm was cloned from github). Here the list of my actions (I use local environment for deploying):\nPython 3.2.3 (default, Feb 27 2014, 21:31:18) \n[GCC 4.6.3] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import os\n>>> import amulet\n>>> import requests\n>>> d = amulet.Deployment(series='trusty')\n>>> d.add('cf-nats', charm = '/home/ubuntu/cf-charms/charms/trusty/cf-nats')\n>>> d.setup()\n\nAnd I got the next output:\n2014-03-10 10:56:09 Starting deployment of local\nTraceback (most recent call last):\n  File \"/usr/bin/juju-deployer\", line 9, in <module>\n    load_entry_point('juju-deployer==0.2.5', 'console_scripts', 'juju-deployer')()\n  File \"/usr/lib/python2.7/dist-packages/deployer/cli.py\", line 118, in main\n    run()\n  File \"/usr/lib/python2.7/dist-packages/deployer/cli.py\", line 204, in run\n    importer.Importer(env, deployment, options).run()\n  File \"/usr/lib/python2.7/dist-packages/deployer/action/importer.py\", line 142, in run\n    self.get_charms()\n  File \"/usr/lib/python2.7/dist-packages/deployer/action/importer.py\", line 47, in get_charms\n    no_local_mods=self.options.no_local_mods)\n  File \"/usr/lib/python2.7/dist-packages/deployer/deployment.py\", line 112, in fetch_charms\n    charm.fetch()\n  File \"/usr/lib/python2.7/dist-packages/deployer/charm.py\", line 98, in fetch\n    self.vcs.branch()\nAttributeError: 'NoneType' object has no attribute 'branch'\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/lib/python3/dist-packages/amulet/deployer.py\", line 175, in setup\n    self.juju_env], cwd=self.deployer_dir)\n  File \"/usr/lib/python3.2/subprocess.py\", line 489, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '['juju-deployer', '-W', '-c', '/tmp/amulet-juju-deployer-myb41r.json', '-e', 'local', 'local']' returned non-zero exit status 1\n\nI've also tried to deploy the same charm manualy with juju command line interface and it's work. \nHere is the output from d.schema()\n>>> d.schema()\n{'local': {'services': {'cf-nats-sentry': {'_has_sentry': True, 'expose': True, 'branch': '/tmp/sentry-sub_16ocg4/cf-nats-sentry'}, 'cf-nats': {'_has_sentry': True, 'branch': '/home/ubuntu/cf-charms/charms/trusty/cf-nats'}, 'relation-sentry': {'expose': True, 'branch': '/tmp/sentry_5cdg4t/relation-sentry'}}, 'series': 'trusty', 'relations': [['cf-nats:juju-info', 'cf-nats-sentry:juju-info']]}}\n\nWhat is wrong in my code? How can I deploy my local charm with amulet framework? What kind of python packages should be installed?\nThank you in advance.\n\nA: I believe I see your problem. So, you pulled this charm from github which is fine. However, tests are usually written and run from within the tests directory. So, amulet applies a little bit of magic to deploy using the charm on disk so you don't have to explicitly put charm= in the d.add line. However, since you're running from interactive shell it makes sense for you to do this. The problem is, it's not a Bazaar branch which is what Juju Deployer is expecting.\nTypically, what happens, when you just do d.add('cf-nats') in a charm test, the charm tree gets copied to a temporary location, and a bzr repo is created (if one doesn't exist already). Then that new temp location is fed to deployer. However, since you've given it a firm file path that part isn't happening (by design) and it assumes you have a charm that has a bzr repo and it's just going to use that.\nThe way around this is to either run export JUJU_TEST_CHARM=\"cf-nats\" (and environment variable the juju test plugin sets) prior to launching your Python3 shell from the $CHARM_DIR (/home/ubuntu/cf-charms/charms/trusty/cf-nats)  or after creating d = amulet.Deployment() set d.charm_name = 'cf-nats'. Then just do d.add('cf-nats'), amulet will see that the basename of getcwd is the same as the charm name and transparently perform it's little bit of magic.\nThat should do it. Ideally, adding support for git based charms to juju deployer will resolve all of this, but try that and let me know if it doesn't work for you.\n", "Q: Xorg 1.15 and AMD 13.1 legacy I have a question: Will my ati Radeon 5145(4570) work with ubuntu 14.04? I need proprietary driver for good energy control. I have Laptop.\nOr I need to downgrade Xorg?\n\nA: I have the same type of graphics card, but I don't have a driver. use s3tc. its a compression tool. start by adding ppa:xorg-edgers/ppa to your ppa list, sudo apt-get update, then go to the software center and look up s3tc and there are 2 packages. install them both, and make sure you run the update manager. I did this, and my computer runs faster and better than ever when playing steam games.\nyou do not necessarily need one, but if you are a gamer, I recommend this\n\nA: Your solution is right here : http://www.thefanclub.co.za/how-to/ubuntu-amd-catalyst-install\n", "Q: how to run software on client machine installed on server machine? I have two machine one with ubuntu 12.04 server and another with ubuntu 12.04 client.\ni am having some software installed on ubuntu server machine. I need to use this software on client machine wihtout installing.\n\nA: The best way to access your server resources is by using ssh from your client.\nFirst login into your server and sudo apt-get install openssh-server\nYou can easily identify your server ip address using ifconfig, just look for inet addr:xxxxxxxx\nThen from you client type ssh my_login@server_ip_address\n", "Q: Running an executable with fixed execution-time and memory limit and getting exit-code What is the best way to run an executable with execution-time  and memory(RAM) limit (e.g. 2.5 seconds and 32768 kB)? \nI need to get the exit-code if it exits without violating time and memory limits. Otherwise it should be killed and I need to know which limit it violated (e.g. MEMORY_LIMIT_EXCEEDED, TIME_LIMIT_EXCEEDED).\n\nA: I'd recommend this nice tool, it'll limit CPU time or memory consumption:\nhttps://github.com/pshved/timeout\n", "Q: m4 preprocessor \"ERROR: end of file in string\" I'm getting this error msg:\nm4:myPerlScript.pl:77: ERROR: end of file in string\n\nwhen trying to use m4 to replace a string in some perl scripts. I'm making the call inside a makefile.\n$(OUTDIR)/%:    %.pl\n        m4 blah/thing.m4 $< > $@\n        chmod +x $@\n\ni made sure that thing.m4 exists and is in the right place. \n\nA: To others who have made it here, OP's error may also present as the result of a missing closing square bracket (likely, any unpaired bracketing character).\n\nA: It turned out that m4 was erring because of its sensitivity to quotes. I added changequote() to the replacing .m4 file. \nIt was also necessary to use the -P switch to avoid matching m4 key words, and add m4_dnl to each line.\n", "Q: Protecting Live USB from Windows Viruses Ever since I started using linux, I said good bye to windows forever.  I always carry live usb linux alongwith me (these days, I am trying LXLE for instance).\nI use the same pen drive to copy data.  Though, windows viruses do not affect the linux OS but when I connect the pen drive to windows OS they infect the other data files.\nIs there anyway to protect the pen drive itself from windows viruses?  I was thinking of creating two partitions:\n\n\n*\n\n*ext4\n\n*fat32\n\n\nthe second partition can contain some sort of software using which I can transfer data to ext4 partition as I understand ext4 partitions are secure from windows viruses.\ndoes this appear feasible?\n\nA: The solution you proposed is complex and not portable (Windows will need special extra drivers to read ext, and they are not stable).\nThere is no trouble, use the freeware Windows software Ninja Pendisk.\nNinja Pendisk is fully portable, self-contained, requires no installation and protects your Windows machine from any virus or malware trasmitted via USB: (from the website) \n\nbesides removing known virulent files, this tool will also immunize\n  your pendisk and create a folder called autorun.inf with special\n  protection permissions to protect your pendisk from being infected\n  again when plugged on contaminated computers\n\nI always used it and it's very handy!\nComment under here if you have other questions and press the UP arrow if I'm of any help.\nHave a safe day.\n\nA: You can install some Linux antivirus to scan the windows files.\nThere are many antivirus than you can use\nTo Install Clamav \nsudo apt-get install clamav \n\nTo update pattern files\nsudo freshclam\n\nTo scan all your filesystem and remove infected files\nsudo clamscan --infected --remove --recursive /\n\nTo download test virus\nwget http://www.eicar.org/download/eicar.com \n\nTo uninstall\nsudo apt-get remove clamav\n\nBut you can use a frontend GUI that works with calmav called AntiVirus Scanner(avscan). you can download from here.\nMoreover there are many GUI frontends for calmav. you can check this menu here and choose one of them but i advise you by the one above(avscan)\nIf you want to use other GUI i advise to use comodo.Comodo has a free, modern, easy to use anti-virus program for various GNU/Linux distributions including Ubuntu 12.04.x.y 32 and 64 bit LTS. The graphical user interface is easy to learn how to use. \n", "Q: prevent duplicate entries in $PATH In regular way to add a directory to PATH:\nPATH=$PATH:/new-directory\n\nNow the problem is if you add a new directory to the PATH then it will be added without checking if it's already in the PATH or not.\nFor example:\necho $PATH\n\ngives:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\n\nNow if I add /usr/bin:\nPATH=$PATH:/usr/bin\n\nThen PATH becomes:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/bin\n\nSo, if you can notice, now /usr/bin is repeated.\nSo, how can I add a new directory to the PATH without repeating?\n\nA: A short way is to use:\n[[ \":$PATH:\" =~ \":/new-directory:\" ]] || PATH=\"/new-directory:$PATH\"\n\nExplanations:\n\n\n*\n\n*First command, the [[ conditional command, is for test.\n\n*The =~ binary operator return 0 if the string from the right which is considered  an  extended  regular  expression matches the string from the left, and 1 otherwise.\n\n*If the test is not passed (/new-directory was not found in PATH), thanks to the || logical OR control operator, the second command is executed: PATH=\"/new-directory:$PATH\".\n\n\nObservations:\n\n\n*\n\n*You should always use quotes when you assign a string to a variable, even if the string is another variable: PATH=\"/new-directory:$PATH\".\n\n*In general is better to add a new directory to the PATH environment variable in front to others directories, not after:  PATH=\"/new-directory:$PATH\". This because directories at the beginning of PATH take precedence over those that come later.\n\n\nA: I use Stephen Collyer's bash_path_funcs, described in Linux Journal way back in 2000:\nhttps://www.linuxjournal.com/article/3645\nhttps://www.linuxjournal.com/article/3768\nhttps://www.linuxjournal.com/article/3935\nThe addpath function adds an entry to a path only if it is not there in the first place. delpath -n deletes all non-existent directories from a path.\nYou can get the pathfunc.tgz file from  https://web.archive.org/web/20061210054813/http://www.netspinner.co.uk:80/Downloads/pathfunc.tgz\n\nA: You can use this command:\nif [[ \":$PATH:\" != *\":/new-directory:\"* ]]; then PATH=${PATH}:/new-directory; fi\n\nNow for the example above:\necho $PATH\n\ngives:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\n\nNow if I want to add /usr/bin:\nif [[ \":$PATH:\" != *\":/usr/bin:\"* ]]; then PATH=${PATH}:/usr/bin; fi\n\nYou can notice that PATH doesn't change:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games\n\nnow to add other directory example /var/www\nif [[ \":$PATH:\" != *\":/var/www:\"* ]]; then PATH=${PATH}:/var/www; fi\n\nThen output of echo $PATH gives:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/var/www\n\n", "Q: Where to find the images for old Ubuntu Beta Releases? As a developer and a power user, I'd like to know from where can I download the images for old Betas like, Saucy Beta, Quantal Beta, and some EOL Beta releases.\n\nA: Not all Beta releases are available, I've found this one though:\nhttp://old-releases.ubuntu.com/releases/10.10/\n11.10 beta2 iso can be found here:\nhttp://kambing.ui.ac.id/iso/ubuntu/cdimage/releases/11.10/beta-2/ \n", "Q: Remap the middle click action of Logitech T400 wireless mouse I want to remap the functionality of the front part of middle click and back part of middle click on the Logitech Zone Touch Mouse T400 model.\nAccording to the answer in this question, I tried the commands but I don't understand what to exactly swap.\nHere is the output for the command xinput list-props id# (10 being the device id)\n nirmik@nirmik:~$ xinput list-props 10\nDevice 'Logitech Unifying Device. Wireless PID:4026':\n    Device Enabled (134):   1\n    Coordinate Transformation Matrix (136): 1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 1.000000\n    Device Accel Profile (256): 0\n    Device Accel Constant Deceleration (257):   1.000000\n    Device Accel Adaptive Deceleration (258):   1.000000\n    Device Accel Velocity Scaling (259):    10.000000\n    Device Product ID (251):    1133, 50475\n    Device Node (252):  \"/dev/input/event6\"\n    Evdev Axis Inversion (653): 0, 0\n    Evdev Axes Swap (655):  0\n    Axis Labels (656):  \"Rel X\" (144), \"Rel Y\" (145), \"Rel Horiz Wheel\" (650), \"Rel Dial\" (651), \"Rel Vert Wheel\" (652)\n    Button Labels (657):    \"Button Left\" (137), \"Button Middle\" (138), \"Button Right\" (139), \"Button Wheel Up\" (140), \"Button Wheel Down\" (141), \"Button Horiz Wheel Left\" (142), \"Button Horiz Wheel Right\" (143), \"Button Side\" (645), \"Button Extra\" (646), \"Button Forward\" (647), \"Button Back\" (648), \"Button Task\" (649), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643), \"Button Unknown\" (643)\n    Evdev Middle Button Emulation (658):    0\n    Evdev Middle Button Timeout (659):  50\n    Evdev Third Button Emulation (660): 0\n    Evdev Third Button Emulation Timeout (661): 1000\n    Evdev Third Button Emulation Button (662):  3\n    Evdev Third Button Emulation Threshold (663):   20\n    Evdev Wheel Emulation (664):    0\n    Evdev Wheel Emulation Axes (665):   0, 0, 4, 5\n    Evdev Wheel Emulation Inertia (666):    10\n    Evdev Wheel Emulation Timeout (667):    200\n    Evdev Wheel Emulation Button (668): 4\n    Evdev Drag Lock Buttons (669):  0\n\nAnd the output of the next command xinput get-button-map 10 is\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \n\nNow what do I exactly swap to change the middle click to front part of middle click = middle click action. From/instead of front part of middle click = super button\n\nA: Try imwheel.\nsudo apt-get install imwheel\n\nYou can configure your buttons using imwheel and it's recommended by the Ubuntu wiki. \n\nA: I used this way:\n\n\n*\n\n*Install xbindkeys and xdotool\nsudo apt-get install xbindkeys xdotool\n\n\n*Rebind the Super key to middle mouse button by xbindkeys config\n$ cat ~/.xbindkeysrc\n\"xdotool click 2\"\n  c:133\n\n\n*Add xbindkeys to start with X\n$ echo xbindkeys > ~/.xinitrc\n\n\n*Disable opening Dash on Super key\n$ sudo apt-get install compizconfig-settings-manager\n\nThen press Alt + F2 and type about:config\nOn tab \"Launcher\" you can disable or change \"Key to show the Dash...\"\n\n*Start xbindkeys for this session or reboot.\n\nA: I don't know if this will really help, since I can't try it.  If it works, let me know.\nIf you're running 12.04, you can use btnx.  It will ask for the btnx-config, which you can get here\nYou can also change the button mapping with xmodmap. For instance, to swap the left with the right mouse button:\nxmodmap -e 'pointer = 3 2 1'\n\nTo revert it, simply set 1 2 3 or use 'default' according to the manpage.\nYou may also take a look at How to configure extra mouse buttons in Ubuntu 13.10 for more info.\n", "Q: What do I need to do to connect to public wifi in a local shop? I go into a local coffee shop with public wifi and try to connect.  The connection shows up in network manager so I click on it and it says it is connected.  Apparently the next thing I should do is open a browser and accept the acceptable use policy.  However when I open Firefox it just shows the start page which I'm assuming is local and if I try to go anyplace on the internet says \"connecting\" and never goes anyplace.  How am I supposed to get to the \"Acceptable Use\" page?    \nThe network manager is set to Automatic for everthing and when I sit down and click connect on the indicator icon, after it says connected, it appears to be ready to go.  If I edit things in the connection properties that I know will cause it to fail the browser shows the \"server not found\" page when I try to access the internet, but if I leave everthing set to automatic and get the connection shown below it just freezes at \"connecting\".    \nI have tried firefox and chromium and they both act the same, but could there be something in the way I have my browsers configured that aren't allowing them to re-direct to the \"acceptable use\" page?  Are there other tools that might help diagnose what is going on?\nState: connected (global)\n\n- Device: wlan0  [TimHortons-US-Staging] ---------------------------------------\n  Type:              802.11 WiFi\n  Driver:            iwl3945\n  State:             connected\n  Default:           yes\n  HW Address:        <MAC address removed>\n\n  Capabilities:\n    Speed:           54 Mb/s\n\n  Wireless Properties\n    WEP Encryption:  yes\n    WPA Encryption:  yes\n    WPA2 Encryption: yes\n\n  Wireless Access Points (* = current AP)\n    *TimHortons-US-Staging: Infra, <MAC address removed>, Freq 2437 MHz, Rate 54 Mb/s, Strength 67\n\n  IPv4 Settings:\n    Address:         10.2.242.244\n    Prefix:          16 (255.255.0.0)\n    Gateway:         10.2.1.1\n\n    DNS:             208.67.222.222\n    DNS:             208.67.220.220\n\n\nA: I had a similar problem, and found that I could make a curl request just fine:\n$ curl -vL \"https://www.google.com\"\n* Rebuilt URL to: https://www.google.com/\n*   Trying 172.217.19.196...\n\nWhen I connected directly to that IP in chrome(ium), I got shown the guard page, and could tick the necessary box. YMMV.\n", "Q: postfix doesn't authenticate through /var/spool/postfix/var/run/saslauthd I have a problem with postfix.\nI followed all description from https://help.ubuntu.com/community/Postfix.\nAnd it worked perfect except smtp authentication.\nI've suffered that mail.log always told \"password verification fail\" when email sending through my server for a while. Finally I reached that it all happened due to postfix chroot.\nMy master.cf file is following.\n ==========================================================================\n smtp      inet  n       -       -       -       -       smtpd\n #smtp      inet  n       -       -       -       1       postscreen\n #smtpd     pass  -       -       -       -       -       smtpd\n #dnsblog   unix  -       -       -       -       0       dnsblog\n #tlsproxy  unix  -       -       -       -       0       tlsproxy\n submission inet n       -       n       -       -       smtpd\n\nWhen I once made symbol link of /var/spool/postfix/var/run/saslauthd at /var/run, it smtp worked well.\nbut, this /var/run folder is volatile so this symbol link just gone after rebooting.\nMoreover, I don't see any this manual symbol link trick in official ubuntu documentation, which I want to avoid.\nAny suggestion and advice for me?\n\nA: creating a permanent mount point using /etc/fstab should help.  This method is explained in section Add binding for saslauthd in Postfix of https://github.com/webmin/webmin/issues/58 \n", "Q: Installing Ubuntu alongside an existing Windows system without creating a CD? This Ubuntu help wiki page says that, in order to add Ubuntu on an existing Windows system, I must burn Ubuntu on a CD first. But CDs are becoming less common these days, so I wonder if there is a way to install Ubuntu without burning it on a CD (or a DVD, or a USB stick) - just download the ISO to my Windows machine and then somehow install it as dual boot.\nIn the past I have tried to use Wubi for that purpose, but this was not stable, and got stuck too many times. So now I want to create a dual-boot system.\n\nA: To install Ubuntu without a CD or DVD or USB, you need to install Ubuntu as WUBI first, then migrate it to a hard drive partition using 'migrate-wubi'. This will work like a normal installation and won't be slow like WUBI. How to do this is written on this page\n\nA: If you don't want to use a CD you can check how to boot from a flash drive here. Just follow the instructions, then plug in your usb stick, reboot and set the boot sequence to your USB port in the BIOS menu. The rest is really straightforward.\n\nA: From Ubuntu\nUSB installation Guide from Ubuntu\nThere's a package called usb-creator-gtk (and usb-creator-kde for KDE-desktop).\nIt can be found in the Unity Dash\nThis application has a GUI to copy an iso/or from cd to a USB-drive and make it bootable.\nFrom Windows\nYou can use the software LinuxLive to create a Bootable USB in Windows.\n\n\nA: Using a USB stick works Great!\nuse LILI or Universal USB Installer.\nBoth methods are very fast.\n\nA: Yes, you can create bootable Ubuntu USB on Windows through Unetbootin software.\nThis link explains various methods of creating Ubuntu live USB on Windows.\n", "Q: Is it necessary to install AMD graphics driver for ubuntu? Currently I'm using ubuntu 12.04. Previously I've used dual boot (Ubuntu 13.04 / Windows 7), both OS configured with ATI Catalyst Center. But few days back both OS started to crash. Ubuntu 13.04 freezes to death, I can't even switch to CLI. Other OS error log indicated that it was due to Graphics driver. Now I can't re-install Ubuntu 13.04-amd64.\nTill now 12.04 working fine without additional graphics driver. Is it necessary to install ATI CC, If I continue without ATI Driver does it harm my system.\nI've 1GB ATI Radeon HD 5470, Please ask if you need any additional info.\n\nA: I'm running 12.04 with ATI AIW, and I never loaded ATI CC, and everything works fine.  Its been running like that since 12.04 came out, and Its updated as of yesterday.  So it won't harm the system.  I don't run any games.\n\nA: Most distros including Ubuntu comes with a \"free\" version of driver that is enough to display the desktop and make a smooth experience. However, if you run games and other graphics intensive stuff, its recommended to install a non-free driver provided by your vendor\n\nA: The OSS driver (radeon) is coming on in leaps and bounds though. 3D performance in Mesa 10.2 and post-3.12 kernels is pretty good. Not quite as good as the closed driver, admittedly, but if you're stuck with a card that's only supported by the legacy catalyst driver then the OSS driver is a bad consolation prize.\n\nA: No, it is not necessary to run the proprietary drivers. They are not installed by default. Also, once you do install them, it is not straightforward to remove them. \nHowever, if both windows and ubuntu are crashing, perhaps it is not your drivers at fault but some hardware issue with your graphics card i.e. it is worn out.\n\nA: I have the same type of graphics card, but I don't have a driver. use s3tc. its a compression tool. start by adding ppa:xorg-edgers/ppa to your ppa list, sudo apt-get update, then go to the software center and look up s3tc and there are 2 packages. install them both, and make sure you run the update manager. I did this, and my computer runs faster and better than ever when playing steam games.\n", "Q: What is the $DISPLAY environment variable? I am new to shell scripting. I don't understand what the $DISPLAY environmental variable is.\nI have Ubuntu 13.10 and I use /bin/bash shell. I have two monitors.\nQuestions:\n\n\n*\n\n*Command echo $DISPLAY will print :0.0 on my machine (on both monitors). What does this mean?\n\n*In which cases will the $DISPLAY variable be blank or NULL?\n\n*Are there any articles or tutorials on this?\n\nA: \necho $DISPLAY will print :0.0 on my machine(on Both monitors). What\nthis means?\n\n:0.0 means display number 0 and screen number 0\n\nIn which case $DISPLAY will be blank or NULL?\n\nIn case of error in your $DISPLAY and this doesn't happen normally\n\nAre there any articles or tutorials on this?\n\nSome tutorials and resource can be found here:\n\n*\n\n*1 pic.dhe.ibm.com\n\n*2 unix.com/unix-dummies-questions-answers\n\n*3 superuser.com/questions/368530\n\nA: From https://help.ubuntu.com/community/EnvironmentVariables:\nVariable- DISPLAY\nValues Example:\n:0.0\nlocalhost:10.0\nterminal01:0.0\n\nWhat it's for?\n\nThis variable is used to indicate to graphical applications where to display the actual graphical user interface, the value consists of 3 parts: A host-name followed by a colon (:), a display number followed by a dot (.) and a screen number.\nThe host-name part can be used to have the graphical output sent to a remote machine over the network. It can be omitted when the output is meant for an X server running on the local machine. The display number allows selecting among multiple X servers running on the same machine (Ubuntu uses multiple X servers to enable multiple graphical desktop sessions).\nAlthough the screen number is used to select among multiple physical screen that are managed by the same X server, it is rarely set to anything other than \"0\" nowadays. Manually setting the \"DISPLAY\" environment variable's value is rarely needed nowadays since it can be automatically and intelligently adjusted by many applications such as \"GDM\" and \"SSH\" when needed.\n\n\nA: The existing answers fail to address the broader picture.\nIf you are not using a graphical environment (i.e. you are logging in on the system console with no windows etc; or you are logging in remotely from a text-only terminal over SSH or similar, such as from a Windows computer running PuTTY) then no GUI is involved, and DISPLAY will typically be unset.  Your only means of communicating with the computer is the command line (though there may be ways to pivot into a GUI session if you know how).\nIf you are logging in on the console with a graphical interface (on Ubuntu, typically the GDM greeter is used) or using a graphical terminal (such as from a Windows computer running eXceed or mobaX, or remote desktop software like a VNC client) the DISPLAY variable is set up by the program which manages your graphical session to indicate to graphical clients which I/O devices to connect to.\nTraditionally, the GUI on an Ubuntu computer was running X.org, an X11 implementation, though more recently, a modernized replacement called Mir was introduced by Canonical; and even more recently, I believe Mir will be abandoned in favor of another project with broadly similar goals called Wayland.  These replacements are intended to reduce the complexity of a full X11 stack, which we will not be going into here -- they adhere to the same DISPLAY convention, which is after all what we are discussing here.\nOn X11, the host part of DISPLAY could be a remote server, and you would use your Ubuntu computer as a \"graphical terminal\" to access files and programs on that remote server (in which case your computer is the \"server\" which serves a keyboard, a mouse, and one or more display devices to \"client\" programs running on the remote ... server).  More commonly, the X11 (or Mir, or Wayland) server and the client programs (a desktop manager and various graphical clients such as a web browser, an email client, a calendar program, etc) all run on your computer.  This is indicated by the \"server\" part of the DISPLAY value, which in the latter case is typically empty (which implies the default value, localhost).\nAn X11 server may run one or more graphical sessions -- for example, your console login and a remote VNC session could be running at the same time.  In this case (if they are managed by the same X11 server instance) you have more than one \"display\" in X11 terms.  In practice, one session (one login event and the desktop instance spawned from this) is one display in X11.\nOne such display can have one or more screens.  Traditionally, this meant one monitor, though the original architecture had some unfortunate traits such as the inability to move a window from one screen to another.  Add-ons like Xinerama and Xrandr further muddied the situation to the point where one screen often connects multiple monitors in various ways.\nIf you have played with multiple-monitor systems, you have probably discovered that you can arrange monitors in various ways and end up with a rectangular area where your monitors display some parts of it and other parts are not assigned to any monitor.  This is the \"screen\" that X11 creates, and if you have more than one display card, you can have multiple of these screens, each assigned to one or more monitors (or in theory, running without a monitor; Xvfb exploits this to allow you to run X11 without any monitors, simply mapping the GUI to a memory region for whatever purpose).\n\nA: Recently I have been doing some scripting for some automatic launching of Firefox at a specific time for reminding me to clock in and out since I have been working from home.  I found out that the DISPLAY variable is determined by the Display Manager, i.e. GDM3, LightDM, etc.  I also made the discovery that the :0 or :1 is determined by AutomaticLogin.  In GDM3 if I have the AutomaticLogin disabled, then my DISPLAY variable is :1.  If I have AutomaticLogin enabled, DISPLAY is now :0.  These numbers do not change regardless of number of monitors I have connected to my system.\nThe reason why this is important is that I use cron to launch a script for me at certain times to launch Firefox.  cron does not have the variables set, in fact they are very limited, so at the top of my script after my SheBang line I have this line to export my DISPLAY type.  Without exporting the DISPLAY in the script that is being called by crontab, Firefox will not launch and instead will give an error since no DISPLAY is set.\n#This line checks if automatic login is disabled in gdm3 and sets DISPLAY.\ngrep \"# AutomaticLogin\" /etc/gdm3/custom.conf >/dev/null && export DISPLAY=\":1\" || export DISPLAY=\":0\"\n\n\nA: The magic word in the X window system is DISPLAY. A display consists (simplified) of:\n\n*\n\n*a keyboard,\n\n*a mouse\n\n*and a screen.\n\nA display is managed by a server program, known as an X server. The server serves displaying capabilities to other programs that connect to it.\nThe remote server knows where it has to redirect the X network traffic via the definition of the DISPLAY environment variable which generally points to an X Display server located on your local computer.\nThe value of the display environment variable is:\nhostname:D.S\n\nwhere:\nhostname is the name of the computer where the X server runs. An omitted hostname means the localhost.\nD is a sequence number (usually 0). It can be varied if there are multiple displays connected to one computer.\nS is the screen number. A display can actually have multiple screens. Usually, there's only one screen though where 0 is the default.\nExample of values\nlocalhost:4\ngoogle.com:0\n:0.0\n\nhostname:D.S means screen S on display D of host hostname; the X server for this display is listening at TCP port 6000+D.\nhost/unix:D.S means screen S on display D of host host; the X server for this display is listening at UNIX domain socket /tmp/.X11-unix/XD (so it's only reachable from host).\n:D.S is equivalent to host/unix:D.S, where host is the local hostname.\n:0.0 means that we are talking about the first screen attached to your first display in your local host\nRead more here: support.objectplanet.com and here: superuser.com and here: docstore.mik.ua.\nFrom a X(7) man page:\n\nFrom the user's perspective, every X server has a display name\nof the form:\nhostname:displaynumber.screennumber\nThis information is used by the application to determine how it should\nconnect to the server and which screen it should use by default (on\ndisplays with multiple monitors):\nhostname The hostname specifies the name of the machine to which the\ndisplay is physically connected. If the hostname is not given, the\nmost efficient way of communicating to a server on the same machine\nwill be used.  displaynumber The phrase \"display\" is usually used to\nrefer to a collection of monitors that share a common keyboard and\npointer (mouse, tablet, etc.). Most workstations tend to only have one\nkeyboard, and therefore, only one display. Larger, multi-user systems,\nhowever, frequently have several displays so that more than one person\ncan be doing graphics work at once. To avoid confusion, each display\non a machine is assigned a display number (beginning at 0) when the X\nserver for that display is started. The display number must always be\ngiven in a display name.  screennumber Some displays share a single\nkeyboard and pointer among two or more monitors. Since each monitor\nhas its own set of windows, each screen is assigned a screen number\n(beginning at 0) when the X server for that display is started. If the\nscreen number is not given, screen 0 will be used.\n\n", "Q: Transfer sound with my powerpoint? So we have a PowerPoint to present. I made the PowerPoint on one computer and it had different sounds. Well we emailed the PowerPoint to others and they got it but it did not transfer the sounds. We need the PowerPoint on another computer to present it but we need the sound too. What should we do?? \n\nA: Zip the sound and powerpoint files and send the zipped file as a whole\n", "Q: Updating an old Ubuntu USB installer I found an old USB stick that contains an Ubuntu 10.04 installer. I want to install Ubuntu on my Windows machine, but I want 12.04, not 10.04. \nCan I update the USB stick to install 12.04, without wiping it out first?\n\nA: No, you cannot. Writing a new Ubuntu ISO to the flash drive will replace all content on the drive with the installer ISO data.\n", "Q: How to prevent users from deleting files that are already in use? Consider this scenario:\nUser is executing a command on a file. This file becomes 'in-use' now.\n$ tail -f somefile.log\n\nIn another shell, user deletes the file.\n$ rm somefile.log\n\nNow, this file is 'removed'. Meaning the only hardlink to the file inode is gone. If you execute the following command, you can still see the file, indicated as 'deleted'.\n$ lsof | grep somefile.log\n\nDisk space used by somefile.log is not released until user interrupts tail command in this case.\nMy question is, is it possible to prevent users from deleting files that are in-use at the moment of deletion attempt (similar to Windows)?\nIs it possible to use PAM for this?\n\nA: There is no way to 'lock' files or to prevent them from modification from users that have permissions to do so.\nAs long as the user has file system permissions (write permissions, to be exact) to delete a file, then they will be able to delete it. You will need to utilize users and file permissions in order to prevent someone from deleting files. \nSpecifically, I would look at the following commands:\nchmod\nchown\nchgrp\nadduser\npasswd\n\n\nA: In windows when you open a file  , it will be locked by a process and cannot be delete or edit it until the process release it , that a primary reason for the need of restart after every update in windows .\nLinux has another mechanism which permit deletion of a file while its executing , and you can still use it until all process using it terminates. So here is the advantage when you upgrade there is no need to reboot.\nWhen you delete the file in Linux , it will be deleted when all references to this file is deleted , so if you want to solve deletion you should create hard-links for this file , or work with permissions of the user on this file .\n", "Q: Autoclicker for Ubuntu I've tried to search many places for an autoclicker\nI need one to use it in a game.\nAnd I found one here:\nFrom Murguu \nI downloaded it, but I have no idea how to install\nIt states that it is for Ubuntu, but I'm new to this and don't know what to do.\nAlso, I tried some forum answers and got to know that by changing the permission of the AutoMouseClick.sh to \"Allow executing file as Program\" but it always unchecks itself every time i check it. It doesn't let me change anything from the \"Permission\" Tab\nPlease help - \nThanks\nEdit\nMy Ubuntu Version is 12.04 Linux SUPERFAST 3.8.0-35-generic #52~precise1-Ubuntu SMP Thu Jan 30 17:24:40 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n\nYeah! Got it!\nI don't know how it worked but it's working now.\nI had extracted it in a Drive called \"Storage\" and used to launch.\nNow, instead of putting it anywhere, i just extracted it on Desktop and Launched\nIt's not working\nThank you all for your support!\nThanks a lot :D\n-Jack\n\nA: Are you sure you have correctly downloaded the package at \nhttp://www.murguu.com/linux-auto-mouse-click/download/32-bit/LinuxAutoMouseClick.zip (32-bit) or \nhttp://www.murguu.com/linux-auto-mouse-click/download/64-bit/LinuxAutoMouseClick64Bit.zip (64-bit) ?\nExtract the package once you downloaded it by right clicking on the package and selecting extract here \nThe folder after extraction should look like this:\n\nNow all you have to do is double-click the AutoMouseClick file and the program should start.\n\n(Tested just now)  \nIf these steps don't work please edit your post to tell us which version of ubuntu you are using and also append the output of the command uname -a\n", "Q: How to find all dependent (dependency walker) packages before installing a .deb file? When installing Ubuntu Core 13.10 according to the instructions at wiki.ubuntu.com/Core/InstallationExample, step 5 says that Ubuntu 12.04 \"Precise Pangolin\" development kernel requires the 'wireless-crda' package. This wiki suggest to have a look at packages.ubuntu.com. However the precise/linux-image-3.8.0-37-generic page  doesn't even mention the 'wireless-crda' package at all. \nAfter reading the Ask Ubuntu articles for 'download +kernel +packages +deb', '\"depends on\" +kernel +packages', 'wireless-crda' and \"How to automatically fetch missing dependencies when installing software from .deb?\" I still don't know how to figure out all dependent packages.\nUpdate#1\nThe answers from How can I check dependency list for a deb package \n1. apt-cache showpkg linux-image-3.11.0-18-generic\ndoesn't output a 'wireless-crda' dependency:\nReverse Depends: \n  linux-image-3.11.0-18-generic:i386,linux-image-3.11.0-18-generic\n  linux-signed-image-3.11.0-18-generic,linux-image-3.11.0-18-generic 3.11.0-18.32\n  linux-image-virtual,linux-image-3.11.0-18-generic\n  linux-image-generic,linux-image-3.11.0-18-generic\n  linux-image-extra-3.11.0-18-generic,linux-image-3.11.0-18-generic\nDependencies: \n3.11.0-18.32 - initramfs-tools (2 0.36ubuntu6) module-init-tools (2 3.3-pre11-4ubuntu3) dpkg (2 1.10.24) fdutils (0 (null)) linux-doc-3.11.0 (16 (null)) linux-source-3.11.0 (0 (null)) linux-tools (0 (null)) linux-headers-3.11.0-18-generic (0 (null)) grub-pc (16 (null)) grub-efi-amd64 (16 (null)) grub-efi-ia32 (16 (null)) grub (16 (null)) lilo (2 19.1) hotplug (3 0.0.20040105-1) hotplug:i386 (3 0.0.20040105-1) linux-image-3.11.0-18-generic:i386 (0 (null)) \nProvides: \n3.11.0-18.32 - redhat-cluster-modules linux-image-3.0 linux-image kvm-api-4 ivtv-modules fuse-module \nReverse Provides:\n\n2. dpkg -I linux-image-3.11.0-18-generic_3.11.0-18.32_amd64.deb\nalso doesn't output a 'wireless-crda' dependency:\nDepends: initramfs-tools (>= 0.36ubuntu6), module-init-tools (>= 3.3-pre11-4ubuntu3)\n Recommends: grub-pc | grub-efi-amd64 | grub-efi-ia32 | grub | lilo (>= 19.1)\n Suggests: fdutils, linux-doc-3.11.0 | linux-source-3.11.0, linux-tools, linux-headers-3.11.0-18-generic\n Conflicts: hotplug (<< 0.0.20040105-1)\n Provides: fuse-module, ivtv-modules, kvm-api-4, linux-image, linux-image-3.0, redhat-cluster-modules\n\nWhen installing the kernel through apt-get install linux-{headers,image}-generic there is a depending 'wireless-crda' package.\nQuestion:\nHow to find out - before actually installing the Ubuntu kernel .deb file - all dependent packages that need to be installed?\n\nA: You can have a look packages.ubuntu.com. The apt-get install linux-{headers,image}-generic command installs two packages:\n\n*\n\n*linux-headers-generic\n\n*linux-image-generic\n1. linux-headers-generic\ndepends on linux-headers-3.11.0-18-generic, which depends on:\n\n*\n\n*libc6, which depends on libgcc1\n\n*linux-headers-3.11.0-18, which depends on coreutils\n2. linux-image-generic\ndepends on:\n\n*\n\n*linux-firmware\n\n*linux-image-3.11.0-18-generic\n\n*linux-image-extra-3.11.0-18-generic\n2.2. linux-image-3.11.0-18-generic\ndepends on:\n\n*\n\n*dpkg\n\n*initramfs-tools\n\n*module-init-tools\n2.3. linux-image-extra-3.11.0-18-generic\ndepends on:\n\n*\n\n*crda or wireless-crda\n\n*linux-image-3.11.0-18-generic\nAnd there you have found how the kernel .deb file is depending upon wireless-crda.\n\nA: With apt-cache showpkg pkg-name1 or dpkg -I pkg-name1_version.deb you can get the list of the dependencies for the pkg-name1. But one of the dependency package to pkg-name1 say pkg-name2 may depend on some other package pkg-name3 and so on.\nSo you'll need to not only know the pkg-name1's dependencies but also for their dependencies' dependencies ... ... and then you can download the packages (that are not already installed in your system.)\n", "Q: Are hard links equivalent to Windows shortcuts? Wikipedia defines a hard link as: \n\na directory entry that associates a name with a file on a file system. (A directory is itself a special kind of file that contains a list of such entries.) The term is used in file systems which allow multiple hard links to be created for the same file.\n\nI am wondering if the concept of hard link is equivalent to the Windows concept of Shortcut.\nIf hard links are not equivalent to shortcuts, then what's the closest Windows feature to hard links?\n\nA: No. In Linux things work differently.\nEach file is represented by an object called 'inode'. Every inode has a number (ID) associated with it.\nAs we know humans are not good at remembering numbers but names. (That's how phonebooks evolved)\nTherefore, filename came into the picture to give each inode a human readable name. Basically, a hardlink binds a filename to an inode. An inode can have multiple hardlinks. If there are no hardlinks present for a particular inode, disk space used by the inode may be re-allocated for new files. Which means, at least one hardlink must present for each file. The filename (visualized as the filename/icon you see in file browser) itself is a hardlink.\nIn Windows, shortcut is a separate file (*.lnk file). It contains information about the original file (understandably the file path). In Linux perception, a Windows shortcut would be another inode hardlinked to a filename ending with '.lnk'.\n\nA: A big difference , hard-link  cannot be created for folders , but for files .\n\nShortcut can be created for folders , so you cannot say they are\n  equivalent .\n\nYour question should be the difference between symbolic link or soft link  and shortcut .\nas according to this:\n\nA symbolic link is filesystem level, and everything sees it as the\n  original file. An application needs no special support to use a\n  symbolic link.\nA \"Shortcut\" is just a regular file that has a reference to the\n  destination file or directory .\n\nSo when you click a shortcut will change your directory to the actual file , while soft-link will refer to its location as if its the actual file , for that  in Linux you can use terminal and  cd to symbolic links while you cannot cd to shortcuts .\nA Windows shortcut and a Linux launcher (pointing to some location) would be identical.\n\nA: On Windows you can create hardlinks too if you have NTFS filesystem.\nfsutil hardlink create target_file source_file\n\nThe files has to be on the same logical drive.\n\nA: There's a good explanation of what soft and hard links are, but one thing needs to be clarified.\nWindows shortcuts are equivalent or similar to neither soft links nor hard links. On the file system level they are just files. It's the shell that understands their structure and interprets them as links. Windows shortcuts can also point to objects in shell namespaces which aren't related to the file system (printers, control panel items, virtual folders).\nWindows shortcuts, in addition to the name of the file system object, contain the following information: PIDL (opaque binary \"path\" within shell namespace), description, hotkey, icon, working directory. Windows also adds NTFS object identifiers if NTFS file system is used, to fix broken shortcuts.\nThe rough equivalent of a Windows shortcut is a .desktop file. See this question on SuperUser: Is there an equivalent of .lnk in Linux?\n\nA: No, a hard link is completely different. A soft link is closer to a Windows shortcut (though there are important differences, symbolic links are more similar to windows shortcuts than hard links are). A hard link is a different thing and one you will almost never need. \nBriefly, a soft link is created with this command:\nln -s foo bar\n\nIf you then run ls -l, you will see:\nlrwxrwxrwx 1 terdon terdon 3 Mar 10 15:58 bar -> foo\n-rw-r--r-- 2 terdon terdon 0 Mar 10 15:58 foo\n\nThe -> means that bar is a link to foo. So, opening bar, with a text editor for example, will actually open the separate file foo. However, deleting bar will just delete the shortcut, it will not affect the file foo.\nHard links, on the other hand, are created with this command:\nln foo bar\n\nIf you now run ls -l, there is no indication of any relationship between the files:\n-rw-r--r-- 2 terdon terdon 0 Mar 10 15:58 bar\n-rw-r--r-- 2 terdon terdon 0 Mar 10 15:58 foo\n\nBut—and this is very important—those are actually the same file. Files on Unix file systems are stored using inodes; an inode is basically the way the filesystem maps a file name to a particular location on the physical hard drive. So, hard links are files that point to the same inode as their target. Another way of putting this is that all files are actually hard links pointing to their inodes. Making a hard link to a file just creates a new pointer (file) on the file system that points to the same inode. Each inode can have multiple files pointing to it or one,  or none.\nTo understand this more clearly, use ls -i which shows the inode associated with a file. Let's create a soft link and a hard link and see what happens:\nln -s foo SoftLinkToFoo\nln foo HardLinkToFoo\n\nNow, check their inodes:\n\nAs you can see above, both foo and HardLinkToFoo have the same inode (16648029) while SoftLinkToFoo has a different one (16648036). \nWhat happens if we rename foo with mv foo bar?\n \nThe red color indicates a broken soft link, one whose target can no longer be found. This is because soft links point to a file's name, not its inode. Note that despite changing the name, the inode remains the same so the hardlink is fine, it still works.\nIn summary, hard links are actually two manifestations of the same file; they are pointers to the same section of the disk. Soft links are just shortcuts. To take a real world analogy, hardlinks are like two different phone numbers for the same phone line and soft links are like having two different phone lines in the same house. \n", "Q: What's the 'envelope' icon in the top panel and do I need it? After a default Ubuntu 12.04 install on a new system, there always seems to be some 'Envelope' icon on the menu bar at the top. If I click it, a menu appears with Available, Away, Busy, Offline etc.\nSmall screenshot:\n\nWhat is it, and do I need it? Or can I get rid of it, and how? I rather not have anything make unnecessary connections or poll my online status or whatever. \n\nA: That icon is called the Messaging Menu. \nMessaging applications like your IM, mail, and chat can integrate with this menu so that it is obvious to you when someone is trying to get a hold of you. You can remove it by following these instructions:\n\n\n*\n\n*How to remove the Mail icon indicator applet?\n\nA: You can safely ignore it. As you discovered it can indicates incoming messages or mails from a wide variety of softwares (Mail, irc, ...).\n\nA: The messaging menu in Ubuntu provides quick access to global messaging status and individual messaging applications.\nIt helps you messaging or chatting a network user   , or set up global account like Facebook and you can receive and send message from Facebook via it .\nIf you don't need it you can remove it :\nsudo apt-get remove indicator-messages\n\n", "Q: Dual boot disaster. Professional help needed I've had a disaster and need professional help. \nTo establish if I have lost Windows 8 entirely from No1 disk, this was professionally installed by the local Microsoft dealer, along with a second (new) solid state 250 GB hard drive for the 12.04 install.\nI installed 12.04 to disk No2, after ensuring I had the \"boot order\" correctly sorted and found No2 disk with no operating system on it. But something went wrong and it installed onto disk No1.?\nI found I had problem after I ran Boot Repair, as Windows 8 did not appear in the Ubuntu start up menu. 12.04 appears to be working 100% on diskNo1. \nI also ran the unistall part of the Boot Repair programme, according to that there is only 12.04 on the disk.\nThough; looking at the Disk Utility programme, there are two 8.5 GB partitions, one says \"extended\", and the other says \"unknown\". Could Windows be in the unknown partition?\nIs there a specialist in or around the Stevenage area, (Hertfordshire UK), who could do the necessary repairs and upgrades to my Cruz Microsystems, model itx system.\n\nsudo fdisk -l -u\n[sudo] password for dennis: \n\nDisk /dev/sda: 250.1 GB, 250059350016 bytes\n255 heads, 63 sectors/track, 30401 cylinders, total 488397168 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00058e9e\n\n   Device Boot      Start         End      Blocks   Id  System\n/dev/sda1   *        2048   471834623   235916288   83  Linux\n/dev/sda2       471836670   488396799     8280065    5  Extended\n/dev/sda5       471836672   488396799     8280064   82  Linux swap / Solaris\n\nDisk /dev/sdb: 250.1 GB, 250059350016 bytes\n255 heads, 63 sectors/track, 30401 cylinders, total 488397168 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x1efd1efc\n\nDisk /dev/sdb doesn't contain a valid partition table\n\nDisk /dev/mapper/cryptswap1: 8478 MB, 8478785536 bytes\n255 heads, 63 sectors/track, 1030 cylinders, total 16560128 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0xcef7eac1\n\nDisk /dev/mapper/cryptswap1 doesn't contain a valid partition table\n\n\nModel: ATA Samsung SSD 840 (scsi)\nDisk /dev/sda: 250GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\n\nNumber  Start   End    Size    Type      File system  Flags\n 1      1049kB  242GB  242GB   primary   ext4         boot\n 2      242GB   250GB  8479MB  extended\n 5      242GB   250GB  8479MB  logical\n\n\nError: /dev/sdb: unrecognised disk label                                  \n\nModel: Linux device-mapper (crypt) (dm)\nDisk /dev/mapper/cryptswap1: 8479MB\nSector size (logical/physical): 512B/512B\nPartition Table: loop\n\nNumber  Start  End     Size    File system     Flags\n 1      0.00B  8479MB  8479MB  linux-swap(v1)\n\n\nA: You have two disks. Your Linux is installed on the first one, /dev/sda which is probably where your Windows used to be. From the output you posted I am fairly sure that you have lost your Windows install. \nA Windows install needs a partition with a Windows file system (NTFS usually) and that would have been visible in the output of parted -l. Since no such thing is apparent, it is safe to conclude that you overwrote your Windows installation with Linux. \nYou have installed nothing, and in fact have not even setup any file system, on your second hard drive (/dev/sdb). The only thing you can do is restore from your backups if you have them or, if you had important data and no backups (argh!), you will have to pay a lot of money to get a professional data recovery company to attempt and get back some of your files. If you want to do the latter, to increase your chances of getting your old data back stop using your computer immediately. The more you use it, the likelier it is that any traces of your old data that might still be around will get lost. Sorry.\n", "Q: gPodder not recognising iPod classic In the past (on Ubuntu 12.04 LTS), I used gPodder without any problems to download and sync my podcasts with my iPod classic, however, now on Ubuntu 13.10 and with gPodder 3.5.1, my iPod is simply not being recognised.\nUbuntu itself recognises the iPod (as does iTunes itself on the windows 8 boot).\nWhat could be the problem? what things could I try to get gPodder to find my iPod?\n\nA: Thanks to the help of thp I resolved this.\nTurns out I need to install version 3.6.1, which can be done from the .deb file here.\nThis now made ipod reappear as a device option, and after a reinstall of libgpod4 with sudo apt-get install --reinstall libgpod4 my ability to sync with ctrl+s was restored.\nI also found that to enable the system tray icon for gpodder on Ubuntu 13.10 I need to manually install appindicator by sudo apt-get install python-appindicator. \nFinally, gpodder --verbose also gave the error No module named eyed3 on my system, this can be resolved by changing eyed3.mp3 to eyeD3.mp3 everywhere in \n/usr/lib/pymodules/python2.7/gpodder/sync.py. \nNow gpodder luanches without error and I can sync my ipod again!\nThe only thing that seems to be missing is the ability to right-click and sync a single podcast to ipod.\n\nA: I installed gpodder 3.8.3 (using this ppa: https://launchpad.net/~thp/+archive/ubuntu/gpodder), but I also needed to install python-gpod in order to get ipod syncing to work. \nCan't get album art to work, though.\n", "Q: gstreamer error : MP4 files and thumbnails doesn't work I think I have done something, but I can't tell what exactly... Now, my Ubuntu doesn't want to decode MPEG-4 and H.264 video-files (files extensions .avi .mp4). \nvlc still works (of course, it has built-in codecs) but totem and the thumbnailer stopped working. \nHere's what I did recently that might be related : \nsudo apt-get install libvo-aacenc-dev libx264-dev libtheora-dev librtmp-dev libvorbis-dev libfdk-aac-dev libmp3lame-dev libfaac-dev libpulse-dev libxvidcore-dev\n\nI used them to build libav-toolsfrom GIT. Now libavworks like a charm, and that makes me think that my libx264 is fine (which is, I think, used to decode H.264 and MPEG-4).\n\nI have this error message :\n$ ▶ totem video.mp4\n** Message: Missing plugin: gstreamer|1.0|totem|H.264 decoder|decoder-video/x-h264, stream-format=(string)avc, alignment=(string)au, level=(string)3.2, profile=(string)main, parsed=(boolean)true (H.264 decoder)\n\n\nI also tried this and I have plenty of gstreamer-* package installed. \nCan you help me ? \n\nA: Try to install gstreamer1.0-libav:\nsudo apt-get install gstreamer1.0-libav\n\n\nCheck if libthumbnailer0 is properly installed as well:\nsudo apt-get install libthumbnailer0\n\nThen, remove the thumbnails cache : \nsudo rm -r ~/.cache/thumbnails\n\nAnd finally restart Nautilus : \nnautilus -q\n\n", "Q: How can I get rid of the \"En\" icon in the notification area? How can I get rid of the keyboard indicator icon in the Notification area?\nI am running Ubuntu 13.10\n\nA: *\n\n*Click on En\n\n*Select Text Entry Settings\n\n*Uncheck Show Current Input Source in Menu Bar in the lower-left section.\n\n\n\n\nA: *\n\n*Open System Settings \n\n*Click on the ‘Region and Language’ tile\n\n*Uncheck the box next to ‘Show Current Input Source in Menu Bar’\n\n\nAnd that’s it. The switcher is now hidden.\nhttp://www.omgubuntu.co.uk/2013/10/turn-new-keyboard-applet-ubuntu-13-10\n\nA: You are talking about the \"keyboard layout notification\".\nIt allows you to easily switch between different keyboard layouts.\nTo disable it, right click on the icon, select text Entry Settings, you get a dialog, \n\nthere at the bottom unselect Show current input source in the menu bar.\n", "Q: How to unistall 13.10 on a dual boot XP machine I am new to Linux in general. As I am sure is the case with many of the new converts, I have an old XP machine that is getting slow and about to be unsupported so I decided to test the waters. I installed 13.10 along side XP only to find that my graphics chip doesn't support the Unity interface upgrade in 13.10 (no launcher, icons, etc). I did download 12.04 after the fact and confirmed that its interface does work (ran it from a flash drive). As I see it, I have 2 options: try to downgrade (which is officially unsupported) or remove 13.10 and install 12.04 fresh.\nI looked up the process on removing 13.10, which is pretty simple (wipe out the partitions containing Ubunutu), but it also takes GRUB with it. I downloaded and tried to run EasyBCD to restore the master boot record, but it does not support XP Home. I don't have the original XP disc to repair it via that avenue either. Do I have any other options here that I don't know about? Thanks!\n\nA: GRUB shouldn't be necessary for Windows XP to run so I'm pretty confident you can do that, but you should always back-up your data.\nSince the root cause is that you graphics chip isn't sufficient for Unity, you can skip the entire downgrade process by installing a different desktop environment.\nTo do so, you can boot into linux and open a terminal (if you are unable to open a terminal due to the graphics incompatibility, press ctrl + alt + F1 to start a new session without X running and log-in)\nYou can install a new desktop environment with apt-get. This article gives a few examples and screenshots. Perhaps a lightweight DE like XFCE would be a good choice, but just see what you like.\nWhen you log in again, you can select your newly chosen desktop environment.\n", "Q: How do I use NAT in iptables I have a domain set for my server, let's say example.com which is being forwarded by my router and is linked to my external IP 11.111.111.111 and it works fine if I ping the domain, or I do a lookup, it recognizes it and gives me the external IP of the domain. But when I listen in on any of the ports I have set to allow, it says they are closed. What rule should I set for this to forward correctly through to my router?\neth0 is my static internal interface and lo it my loop back.\nGateway: 192.168.0.1\nifconfig:\neth0      Link encap:Ethernet  HWaddr 00:0e:7f:a9:10:54  \n          inet addr:192.168.0.8  Bcast:192.168.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::20e:7fff:fea9:1054/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:8175 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:5730 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:6186702 (6.1 MB)  TX bytes:1444662 (1.4 MB)\n          Interrupt:20 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n\nA: If you have a LAN behind a router with NAT you can forward ports to your routers public IP address to a private address and port in your LAN. \nYou could also set something usually called DMZ or something to a machine in your LAN. Then all ports will be forwarded to that machine.\nAll this has to be done in the router and not in your local servers iptables. There iptables will work on connection to your machine and not with NAT.\nThat usually works well, sort of, outside of your LAN using the public IP address of your router. It also works from your LAN using the servers private address. But if you use your public address from within your LAN, there are usually problems connecting because the router get confused.\nThere are solutions to add ip rules in your router/NAT so it works, but then you get other problems. \nYes, NAT is an uggly hack where this is just one small problem with NAT. The real solution is to use IPv6.\nTo analysing this you need a machine inside the same LAN as the server and one other machine outside your LAN.\nYou should use nmap from server with localhost, local machine and use private and global address to the server and last from the machine outside your LAN to the global address of the server/router.\nAlso try traceroute from your local machine to your server using private and global address.\nFor more detailed analysis use wireshark from strategical points in your LAN.\n", "Q: Clustered web server How to build a redundant Webserver cluster based on the following requirements ?\n\n\n*\n\n*Two Ubuntu Server 12.04 LTS Active-Active nodes (really load-balanced; not round robin).\n\n*Apache web server\n\n*site content on a shared storage (or mirrored and synced on both servers)\n\n\nDetailed steps would be highly appreciated.\n\nA: Such setup is depending on the kind of content to be accessed via the web : strictly static, dynamic (PHP, ...), coming from an application server (tomcat, Jboss, ...)\nFor the load-balancing part, it is important to know if you need a cluster load-balancer (to avoid single point of failure at this level too), persistance of sessions, if you have ressources to put the load-balancer(s) outside the web servers.\nYou don't explain how you generate the content for your web server. If the content is generated once a while on an external device, it may not be necessary to have a shared storage or replicated storage for them. Just by pushing the new content to two servers instead of one from the machine where the developments occurs would suffice.\nA compact approach would be to install Linux Virtual Server on both web servers, along with apache.\nIf the site is doing modification in the file system of the Apache document root, there can be numerous solutions, depending of your application :\n\n\n*\n\n*Just perform rsync at regular interval between both server using crontab\n\n*Create an NFS share on a third server mounted as the document root of both Apache\n\n*If the content change a lot and you don't want to loose anything anytime, you can create a filesytem on a DRDB configuration, to do synchrone replication at block level of your document root.\n\n*Build a redundant shared storage box combining DRBD and a sharing mechanism (NFS = sharing at file level, iSCSI = sharing at block level). The choice of the method of sharing greatly depend of your application (number of parallel connections, amount of I/O, ...)\n\n\nIn conclucion, it is not easy to be detailed and exhaustive to answer your question as your input is too vague. The correct solution must be setup according to the requirements of the application which are not detailed here.\n", "Q: \"Invalid video format\" after installing Ubuntu I am having this problem every time I install Ubuntu on my PC. I used to connect my PC via a VGA cable to my screen and every time I install Ubuntu on any PC that uses a VGA cable, I will get an error message saying \nUnsupported video file, invalid video format\n\nIt also says cannot display this video mode. One time, I installed a DVI-D video cable and it worked fine. I just want to know why don't VGA cables work when installing Ubuntu? \n\nA: We first need to find out if your system recognizes the current resolution. If it does then perhaps we can force it.\nRun the following commands in the terminal.\nsudo apt-get install xresprobe\nsudo ddcprobe\n\nThis should reveal the supported resolutions.\nThen find out the name of your interface, like VGA1 or HDMI1 etc. as an example I am using HDMI2.\nAlso make note of the Resolution and refresh rate. (I assume you know these already).\nNow issue this command:\nxrandr\n\nNow replace the resolution and refresh rate in the command below with your own.\ngtf 1920 1080 59.9\n\nFrom the output copy every thing after the word \"Modeline\"\nWhat you copy will be something like this: \"1920x1080_59.90\" 172.51 1920 2040 2248 2576 1080 1081 1084 1118 -HSync +Vsync\nHaving done that run this one after another in Terminal using your outputs.\nxrandr --newmode \"1920x1080_59.90\"  172.51  1920 2040 2248 2576  1080 1081 1084 1118  -HSync +Vsync\n\nxrandr --addmode HDMI2 \"1920x1080_59.90\"\n\nxrandr --output HDMI2 --mode \"1920x1080_59.90\"\n\nThis should give you your desired monitor resolution. This is only temporary. \nTo make this permanent you will have to write a script and save it as follows:\nmkdir ~/Scripts\ngedit ~/Scripts/fixresolution.sh\n\nThis will open a blank document with gedit. Add following to the document and save it:\n#! /usr/bin/env sh\nxrandr --newmode \"1920x1080_59.90\"  172.51  1920 2040 2248 2576  1080 1081 1084 1118  -HSync +Vsync\nxrandr --addmode HDMI2 \"1920x1080_59.90\"\nxrandr --output HDMI2 --mode \"1920x1080_59.90\"\n\nNow to load this file at each start-up run following in terminal:\nchmod +x ~/Scripts/fixresolution.sh\nsudo ln -s ~/Scripts/fixresolution.sh /etc/X11/Xsession.d/45fixresolution\n\nTry restarting with your wide-screen and see with xrandr if it is using 1280x1024. \nIf it is then use your old dell monitor and see if it works. \nGood Luck\n", "Q: How do I repair a Disk (is not booting) My hard drive will not boot. The screen comes up blank. It was working fine yesterday. No changes made. I am using Ubuntu 13.10 on 64-bit. \nOn the same computer, I am using an USB emergency installation to do this work. It booted just fine, all computer hardware also tested OK; hence, the problem is the Ubuntu installation. \nThis computer is ubuntu dedicated (no dual boot.)\n\nA: Try use Boot-Repair for repair.\nTo add Boot-Repair to the repository use:\n$ sudo add-apt-repository ppa:yannubuntu/boot-repair\n\nTo update your repository:\n$ sudo apt-get update\n\nTo install boot-repair:\n$ sudo apt-get install -y boot-repair\n\nOnce Installation completes, run boot-repair on terminal by typing the following command or select it by System → Administration → Boot Repair.\n$ boot-repair\n\n", "Q: How to fix upgrade, install failure loop due to disk space issue I'm running into an upgrade / install failure loop due to disk space, but I don't see which drive is full. I've tried clean, autoclean and autoremove, but to no avail. This is Ubuntu on AWS. There are a bunch of kernels in my /boot directory (listed at bottom), but I don't know how to clean this up, since clean, autoclean, autoremove didn't work. I've listed the upgrade, install and df command outputs below:\nsudo apt-get upgrade\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nYou might want to run 'apt-get -f install' to correct these.\nThe following packages have unmet dependencies:\n linux-headers-virtual : Depends: linux-headers-3.2.0-59-virtual but it is not installed\n linux-virtual : Depends: linux-image-virtual (= 3.2.0.59.70) but 3.2.0.60.71 is installed\nE: Unmet dependencies. Try using -f.\n\nsudo apt-get -f install\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nCorrecting dependencies... Done\nThe following packages were automatically installed and are no longer required:\nlinux-headers-3.2.0-52-virtual libgudev-1.0-0 linux-image-3.2.0-45-virtual\nlinux-headers-3.2.0-55-virtual linux-headers-3.2.0-40 linux-headers-3.2.0-41 linux-headers-3.2.0-36\nlinux-headers-3.2.0-37 linux-headers-3.2.0-43 linux-headers-3.2.0-38 linux-headers-3.2.0-44\nlinux-headers-3.2.0-39 linux-headers-3.2.0-45 linux-headers-3.2.0-51 linux-headers-3.2.0-52\nlinux-headers-3.2.0-53 linux-headers-3.2.0-48 linux-headers-3.2.0-54 linux-headers-3.2.0-55\nlinux-headers-3.2.0-56 linux-headers-3.2.0-57 linux-headers-3.2.0-37-virtual\nlinux-image-3.2.0-53-virtual linux-image-3.2.0-48-virtual linux-image-3.2.0-40-virtual\nlinux-headers-3.2.0-45-virtual linux-image-3.2.0-56-virtual linux-image-3.2.0-43-virtual\nlinux-headers-3.2.0-53-virtual linux-headers-3.2.0-48-virtual linux-headers-3.2.0-40-virtual\nlinux-image-3.2.0-51-virtual linux-headers-3.2.0-56-virtual linux-headers-3.2.0-43-virtual\nlinux-headers-3.2.0-38-virtual linux-image-3.2.0-54-virtual linux-image-3.2.0-41-virtual\nlinux-headers-3.2.0-51-virtual linux-image-3.2.0-57-virtual gir1.2-gudev-1.0\nlinux-image-3.2.0-44-virtual linux-image-3.2.0-39-virtual linux-headers-3.2.0-54-virtual\nlinux-headers-3.2.0-41-virtual linux-headers-3.2.0-36-virtual linux-image-3.2.0-52-virtual\nlinux-headers-3.2.0-57-virtual linux-headers-3.2.0-44-virtual linux-headers-3.2.0-39-virtual\nlinux-image-3.2.0-55-virtual\nUse 'apt-get autoremove' to remove them.\nThe following extra packages will be installed:\nlinux-headers-3.2.0-60 linux-headers-3.2.0-60-virtual linux-headers-virtual linux-virtual\nThe following NEW packages will be installed:\nlinux-headers-3.2.0-60 linux-headers-3.2.0-60-virtual\nThe following packages will be upgraded:\nlinux-headers-virtual linux-virtual\n2 upgraded, 2 newly installed, 0 to remove and 41 not upgraded.\n3 not fully installed or removed.\nNeed to get 0 B/12.7 MB of archives.\nAfter this operation, 67.7 MB of additional disk space will be used.\nDo you want to continue [Y/n]? y\n(Reading database ... 463845 files and directories currently installed.)\nUnpacking linux-headers-3.2.0-60 (from .../linux-headers-3.2.0-60_3.2.0-60.91_all.deb) ...\ndpkg: error processing /var/cache/apt/archives/linux-headers-3.2.0-60_3.2.0-60.91_all.deb (--unpack):\nerror creating directory `./usr/src/linux-headers-3.2.0-60/arch/cris/arch-v32/drivers/mach-a3': No space left on device\nNo apport report written because MaxReports is reached already\ndpkg-deb: error: subprocess paste was killed by signal (Broken pipe)\nUnpacking linux-headers-3.2.0-60-virtual (from .../linux-headers-3.2.0-60-virtual_3.2.0-60.91_amd64.deb) ...\ndpkg: error processing /var/cache/apt/archives/linux-headers-3.2.0-60-virtual_3.2.0-60.91_amd64.deb (--unpack):\nunable to create `/usr/src/linux-headers-3.2.0-60-virtual/include/config/regulator/max8952.h.dpkg-new' (while processing `./usr/src/linux-headers-3.2.0-60-virtual/include/config/regulator/max8952.h'): No space left on device\nNo apport report written because MaxReports is reached already\ndpkg-deb: error: subprocess paste was killed by signal (Broken pipe)\nErrors were encountered while processing:\n/var/cache/apt/archives/linux-headers-3.2.0-60_3.2.0-60.91_all.deb\n/var/cache/apt/archives/linux-headers-3.2.0-60-virtual_3.2.0-60.91_amd64.deb\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvda1      7.9G  6.0G  1.6G  80% /\nudev            819M   12K  819M   1% /dev\ntmpfs           331M  200K  331M   1% /run\nnone            5.0M     0  5.0M   0% /run/lock\nnone            827M     0  827M   0% /run/shm\n/dev/xvdb       147G  188M  140G   1% /mnt\n\nThere are a bunch of kernels in my /boot directory but I don't know how to clean this up:\nls -alst /boot\ntotal 273760\n  12 drwxr-xr-x  3 root root   12288 Mar 10 17:58 grub\n   4 drwxr-xr-x  3 root root    4096 Mar 10 17:56 .\n4504 -rw-r--r--  1 root root 4608695 Mar 10 17:56 initrd.img-3.2.0-60-virtual\n   4 drwxr-xr-x 25 root root    4096 Mar 10 17:56 ..\n4504 -rw-r--r--  1 root root 4608640 Mar 10 17:54 initrd.img-3.2.0-59-virtual\n 780 -rw-r--r--  1 root root  795696 Feb 19 04:51 abi-3.2.0-60-virtual\n 140 -rw-r--r--  1 root root  140627 Feb 19 04:51 config-3.2.0-60-virtual\n2828 -rw-------  1 root root 2893967 Feb 19 04:51 System.map-3.2.0-60-virtual\n4856 -rw-------  1 root root 4969360 Feb 19 04:51 vmlinuz-3.2.0-60-virtual\n4504 -rw-r--r--  1 root root 4608261 Jan 15 19:49 initrd.img-3.2.0-58-virtual\n 780 -rw-r--r--  1 root root  795704 Jan  7 23:40 abi-3.2.0-59-virtual\n 140 -rw-r--r--  1 root root  140644 Jan  7 23:40 config-3.2.0-59-virtual\n2828 -rw-------  1 root root 2894157 Jan  7 23:40 System.map-3.2.0-59-virtual\n4856 -rw-------  1 root root 4970192 Jan  7 23:40 vmlinuz-3.2.0-59-virtual\n4504 -rw-r--r--  1 root root 4608753 Dec  9 23:12 initrd.img-3.2.0-57-virtual\n 780 -rw-r--r--  1 root root  795704 Dec  3 18:37 abi-3.2.0-58-virtual\n 140 -rw-r--r--  1 root root  140644 Dec  3 18:37 config-3.2.0-58-virtual\n2828 -rw-------  1 root root 2894046 Dec  3 18:37 System.map-3.2.0-58-virtual\n4852 -rw-------  1 root root 4968208 Dec  3 18:37 vmlinuz-3.2.0-58-virtual\n 780 -rw-r--r--  1 root root  795704 Nov 12 22:31 abi-3.2.0-57-virtual\n 140 -rw-r--r--  1 root root  140644 Nov 12 22:31 config-3.2.0-57-virtual\n2828 -rw-------  1 root root 2893904 Nov 12 22:31 System.map-3.2.0-57-virtual\n4852 -rw-------  1 root root 4967472 Nov 12 22:31 vmlinuz-3.2.0-57-virtual\n4500 -rw-r--r--  1 root root 4607041 Nov  9 06:42 initrd.img-3.2.0-56-virtual\n 780 -rw-r--r--  1 root root  795639 Oct 23 10:30 abi-3.2.0-56-virtual\n 140 -rw-r--r--  1 root root  140644 Oct 23 10:30 config-3.2.0-56-virtual\n2828 -rw-------  1 root root 2893791 Oct 23 10:30 System.map-3.2.0-56-virtual\n4852 -rw-------  1 root root 4966992 Oct 23 10:30 vmlinuz-3.2.0-56-virtual\n4500 -rw-r--r--  1 root root 4607180 Oct 22 06:42 initrd.img-3.2.0-55-virtual\n4500 -rw-r--r--  1 root root 4606152 Oct 21 06:05 initrd.img-3.2.0-54-virtual\n 780 -rw-r--r--  1 root root  795639 Oct  2 13:29 abi-3.2.0-55-virtual\n 140 -rw-r--r--  1 root root  140644 Oct  2 13:29 config-3.2.0-55-virtual\n2828 -rw-------  1 root root 2893791 Oct  2 13:29 System.map-3.2.0-55-virtual\n4852 -rw-------  1 root root 4967440 Oct  2 13:29 vmlinuz-3.2.0-55-virtual\n 780 -rw-r--r--  1 root root  795492 Sep 10 21:17 abi-3.2.0-54-virtual\n 140 -rw-r--r--  1 root root  140644 Sep 10 21:17 config-3.2.0-54-virtual\n2828 -rw-------  1 root root 2893300 Sep 10 21:17 System.map-3.2.0-54-virtual\n4852 -rw-------  1 root root 4966256 Sep 10 21:17 vmlinuz-3.2.0-54-virtual\n4500 -rw-r--r--  1 root root 4605968 Sep  7  2013 initrd.img-3.2.0-53-virtual\n 780 -rw-r--r--  1 root root  795492 Aug 22  2013 abi-3.2.0-53-virtual\n 140 -rw-r--r--  1 root root  140644 Aug 22  2013 config-3.2.0-53-virtual\n2828 -rw-------  1 root root 2893126 Aug 22  2013 System.map-3.2.0-53-virtual\n4852 -rw-------  1 root root 4966064 Aug 22  2013 vmlinuz-3.2.0-53-virtual\n4400 -rw-r--r--  1 root root 4502983 Aug 20  2013 initrd.img-3.2.0-52-virtual\n4400 -rw-r--r--  1 root root 4503043 Aug  8  2013 initrd.img-3.2.0-51-virtual\n 780 -rw-r--r--  1 root root  795318 Jul 26  2013 abi-3.2.0-52-virtual\n 140 -rw-r--r--  1 root root  140644 Jul 26  2013 config-3.2.0-52-virtual\n2828 -rw-------  1 root root 2892320 Jul 26  2013 System.map-3.2.0-52-virtual\n4852 -rw-------  1 root root 4964752 Jul 26  2013 vmlinuz-3.2.0-52-virtual\n 780 -rw-r--r--  1 root root  795318 Jul 24  2013 abi-3.2.0-51-virtual\n 140 -rw-r--r--  1 root root  140644 Jul 24  2013 config-3.2.0-51-virtual\n2828 -rw-------  1 root root 2892320 Jul 24  2013 System.map-3.2.0-51-virtual\n4848 -rw-------  1 root root 4964240 Jul 24  2013 vmlinuz-3.2.0-51-virtual\n4400 -rw-r--r--  1 root root 4502820 Jul 11  2013 initrd.img-3.2.0-48-virtual\n 780 -rw-r--r--  1 root root  795318 Jun  6  2013 abi-3.2.0-48-virtual\n 140 -rw-r--r--  1 root root  140637 Jun  6  2013 config-3.2.0-48-virtual\n2828 -rw-------  1 root root 2892052 Jun  6  2013 System.map-3.2.0-48-virtual\n4848 -rw-------  1 root root 4963440 Jun  6  2013 vmlinuz-3.2.0-48-virtual\n4400 -rw-r--r--  1 root root 4501891 May 31  2013 initrd.img-3.2.0-45-virtual\n 780 -rw-r--r--  1 root root  795099 May 29  2013 abi-3.2.0-45-virtual\n 140 -rw-r--r--  1 root root  140637 May 29  2013 config-3.2.0-45-virtual\n2824 -rw-------  1 root root 2890696 May 29  2013 System.map-3.2.0-45-virtual\n4848 -rw-------  1 root root 4962320 May 29  2013 vmlinuz-3.2.0-45-virtual\n4400 -rw-r--r--  1 root root 4502465 May 25  2013 initrd.img-3.2.0-44-virtual\n 780 -rw-r--r--  1 root root  795099 May 16  2013 abi-3.2.0-44-virtual\n 140 -rw-r--r--  1 root root  140637 May 16  2013 config-3.2.0-44-virtual\n2824 -rw-------  1 root root 2890696 May 16  2013 System.map-3.2.0-44-virtual\n4848 -rw-------  1 root root 4962032 May 16  2013 vmlinuz-3.2.0-44-virtual\n4400 -rw-r--r--  1 root root 4502610 May 16  2013 initrd.img-3.2.0-43-virtual\n 780 -rw-r--r--  1 root root  794949 May 15  2013 abi-3.2.0-43-virtual\n 140 -rw-r--r--  1 root root  140637 May 15  2013 config-3.2.0-43-virtual\n2824 -rw-------  1 root root 2890123 May 15  2013 System.map-3.2.0-43-virtual\n4848 -rw-------  1 root root 4961104 May 15  2013 vmlinuz-3.2.0-43-virtual\n4400 -rw-r--r--  1 root root 4502840 May  4  2013 initrd.img-3.2.0-41-virtual\n2824 -rw-------  1 root root 2890123 Apr 25  2013 System.map-3.2.0-41-virtual\n 780 -rw-r--r--  1 root root  794949 Apr 25  2013 abi-3.2.0-41-virtual\n 140 -rw-r--r--  1 root root  140637 Apr 25  2013 config-3.2.0-41-virtual\n4848 -rw-------  1 root root 4961584 Apr 25  2013 vmlinuz-3.2.0-41-virtual\n4400 -rw-r--r--  1 root root 4503343 Apr 10  2013 initrd.img-3.2.0-40-virtual\n4360 -rw-r--r--  1 root root 4461457 Mar 28  2013 initrd.img-3.2.0-39-virtual\n 780 -rw-r--r--  1 root root  794886 Mar 25  2013 abi-3.2.0-40-virtual\n 140 -rw-r--r--  1 root root  140601 Mar 25  2013 config-3.2.0-40-virtual\n2824 -rw-------  1 root root 2889468 Mar 25  2013 System.map-3.2.0-40-virtual\n4844 -rw-------  1 root root 4959408 Mar 25  2013 vmlinuz-3.2.0-40-virtual\n4356 -rw-r--r--  1 root root 4460205 Mar  1  2013 initrd.img-3.2.0-38-virtual\n 776 -rw-r--r--  1 root root  792783 Feb 28  2013 abi-3.2.0-39-virtual\n 140 -rw-r--r--  1 root root  140503 Feb 28  2013 config-3.2.0-39-virtual\n2820 -rw-------  1 root root 2887126 Feb 28  2013 System.map-3.2.0-39-virtual\n4844 -rw-------  1 root root 4956208 Feb 28  2013 vmlinuz-3.2.0-39-virtual\n 776 -rw-r--r--  1 root root  792783 Feb 19  2013 abi-3.2.0-38-virtual\n 140 -rw-r--r--  1 root root  140503 Feb 19  2013 config-3.2.0-38-virtual\n2820 -rw-------  1 root root 2886098 Feb 19  2013 System.map-3.2.0-38-virtual\n4840 -rw-------  1 root root 4954288 Feb 19  2013 vmlinuz-3.2.0-38-virtual\n4356 -rw-r--r--  1 root root 4460212 Feb 18  2013 initrd.img-3.2.0-37-virtual\n4356 -rw-r--r--  1 root root 4460424 Feb 18  2013 initrd.img-3.2.0-36-virtual\n 776 -rw-r--r--  1 root root  792720 Jan 24  2013 abi-3.2.0-37-virtual\n 140 -rw-r--r--  1 root root  140520 Jan 24  2013 config-3.2.0-37-virtual\n2820 -rw-------  1 root root 2884868 Jan 24  2013 System.map-3.2.0-37-virtual\n4840 -rw-------  1 root root 4955792 Jan 24  2013 vmlinuz-3.2.0-37-virtual\n 776 -rw-r--r--  1 root root  792720 Jan  8  2013 abi-3.2.0-36-virtual\n 140 -rw-r--r--  1 root root  140520 Jan  8  2013 config-3.2.0-36-virtual\n2820 -rw-------  1 root root 2885084 Jan  8  2013 System.map-3.2.0-36-virtual\n4840 -rw-------  1 root root 4955248 Jan  8  2013 vmlinuz-3.2.0-36-virtual\n4304 -rw-r--r--  1 root root 4405492 Dec 23  2012 initrd.img-3.2.0-25-virtual\n2820 -rw-------  1 root root 2885491 May 24  2012 System.map-3.2.0-25-virtual\n 776 -rw-r--r--  1 root root  791085 May 24  2012 abi-3.2.0-25-virtual\n 140 -rw-r--r--  1 root root  140422 May 24  2012 config-3.2.0-25-virtual\n4840 -rw-------  1 root root 4955600 May 24  2012 vmlinuz-3.2.0-25-virtual\n 176 -rw-r--r--  1 root root  176764 Nov 27  2011 memtest86+.bin\n 176 -rw-r--r--  1 root root  178944 Nov 27  2011 memtest86+_multiboot.bin\n\n\nA: I managed to solve it by doing this:\n\n\n*\n\n*sudo dpkg --configure -a\n\n*Cleanup old kernels: sudo apt-get autoremove -f\n\n*sudo apt-get update\n\n*sudo dpkg --remove linux-server\n\n*sudo apt-get install -f\n\n*sudo apt-get install linux-server\nAlso see: https://askubuntu.com/a/253115/173701\n", "Q: FileNotFoundError OTA update 188 -> 226 Updating Ubuntu Touch from r188 to r226 in the system settings gives me the error after full download:\nFileNotFoundError /var/.../blacklist...\nWhat is the easiest way to fix this error?\n\nA: Per https://bugs.launchpad.net/ubuntu-system-image/+bug/1277589/comments/40\nI plugged the phone into my Ubuntu laptop via USB and typed into the terminal:\n$ adb shell\n\nroot@ubuntu-phablet:/# system-image-cli --dry-run\nUpgrade path is 192:194:226\n\nroot@ubuntu-phablet:/# system-image-cli\n\nNow I am on 226.\n", "Q: Where do files in shared folders go when deleted? I have a shared folder between ubuntu users , this shared files contains files for my company work , if a user delete a file ( normal delete not shift+delete) .\nWhere does this file go , what solution should I have?\n\nA: If You delete files, the files are gone forever\nAssuming You're using samba as your sharing server.\nThere's a stackable VFS module in Samba called \"recycle\"\n\nWhat it basically does, is instead of actually deleting the file, it\n  moves it to another directory that you specify. This allows you to get\n  the file back to them that's as current as the time that they deleted\n  it, rather than from the previous night's backup.\n\nTo install vfs:\nsudo apt-get install samba-vfs\n\nTo enable it edit your /etc/samba/smb.conf and \n[Docs]\nread only = no\npath = /mnt/array/docs\nwrite list = @users\nforce directory mode = 770\nforce create mode = 660\nvalid users = @users\ninherit acls = Yes\ninherit permissions = Yes\nvfs objects = full_audit recycle\nconfig-file = /etc/samba/recycle.conf\nrecycle:repository = /mnt/recycle/%u\nrecycle:directory_mode = 770\nrecycle:keeptree = Yes\nrecycle:versions = Yes\nrecycle:touch_mtime = yes\nfull_auditrefix = %u|%I\nfull_audit:success = open mkdir rmdir write unlink rename\nfull_audit:failure = mkdir rmdir write unlink rename\n\nand here's the /etc/samba/recycle.conf file contents:\n##Recycle Bin Configuration File##\nname = Recycle Bin\nmode = KEEP_DIRECTORIES|VERSIONS|TOUCH\nmaxsize = 0\nexclude = *.o|*.obj|~$*|*.~??|*.log|*.trace\nexcludedir = /mnt/array/misc|/tmp|/temp|/cache\nnoversions = *.dat|*.ini\n\nSource\n\nA: They are still written on your hard drive, the computer just doesn't know they are there. The file will be written on the hosts HDD. You may be able to get some recovery application to get back the file. But if people are writing on the drive often, then it will probably have been over-written.\n", "Q: 12.04 nvidia graphics resolution problem I am trying to use OpenGL on my laptop, a Dell Inspiron n5110 with Nvidia GeForce GT 525M.\nI managed to install my graphics card by using the following commands:\nsudo apt-add-repository ppa:ubuntu-x-swat/x-updates\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install nvidia-current\nsudo apt-get install nvidia-settings\nsudo reboot\n\nBut then I had some errors at my OpenGL program and since then I entered a lot of commands and managed to do something and now my resolution is fixed at 640X480.\nThese are the commands I entered to fix my OpenGL problem:\nsudo apt-get purge nvidia*\nsudo apt-get install --reinstall xserver-xorg-video-intel libgl1-mesa-glx libgl1-   mesa-dri xserver-xorg-core\nsudo dpkg-reconfigure xserver-xorg\n\nAnd after running these commands I noticed that even though my graphics card was properly installed, in System settings->Details it did not appear. So I read this Nvidia Graphics shown as unknown and entered the following commands and that's when my resolution got stuck at 640X480\nsudo apt-get install mesa-utils\nsudo reboot\nsudo nvidia-xconfig\n\nSo I guess that what I am trying to ask is how can I revert my laptop to it's previous state\nAlso here is the output of the lspci | grep VGA command:\n00:02.0 VGA compatible controller: Intel Corporation 2nd Generation Core Processor Family Integrated Graphics Controller (rev 09) \n01:00.0 VGA compatible controller: NVIDIA Corporation GF108M [GeForce GT 525M] (rev a1)\n\n\nA: Try first to disable the ppa and then install nvidia-current from ubuntu archives:\nsudo add-apt-repository --remove ppa:ubuntu-x-swat/x-updates\nsudo apt-get update\nsudo apt-get install nvidia-current\nsudo apt-get install nvidia-settings\n\n", "Q: Cannot install ubuntu 12.04 or 13.04 in dualboot with windows 8.1, UEFI Hardware : asus g53sx laptop, nvidia 560m,sda SSD (Windows on it),sdb HDD  (subpartition with desired Ubuntu shrinked from it sdb5)\nI tried to install 12.04. It works in Legacy Mode but after I install it i cannot boot it. (Secureboot unsupported, fastboot off). When I try to run the installer in UEFI, it freezes after the grub menu (\"install ubuntu\"). I tried all the noalpic, nomodeset etc, nothing seemed to work.\nThen I installed 13.10 worked flawless, but found out in the end that i have to install either 12.04 or 13.04 (some packages that i need are only on those platforms) . So i tried 13.04\nWith 13.04, installer works fine in uefi, instalation goes flawless, but every time after, it loads just grub command line. so i run liveUSB, run RepairBoot, and after grub loads. If i select Ubuntu it will purple freeze. If i select \"safe-mode\" i get black screen! If i select windows boot loader it boots windows just fine.\nRepairBoot file : http://paste.ubuntu.com/7069272\nI read already checked a lot of simmiliar questions but none helped me whatsoever.\nGeorge\n\nA: Since sdb is a MBR(msdos) partitioned drive it will only boot in BIOS mode. You would need to convert  it to gpt partitioning to boot with UEFI.\nIt also looks like you did the Boot-Repair 'buggy' UEFI rename. If booting Ubuntu in BIOS mode you do not need that. And best not to use that if your system will boot ubuntu if in UEFI mode. Only required for those systems/vendor that modify UEFI to only boot Windows. Boot-Repair cannot tell and just offer it if you run it more than once.\nTo undo & to rename files to their original names, you just need to tick the \"Restore EFI backups\" option of Boot-Repair.\nUEFI and BIOS are not compatible. So once you start to boot in one mode you cannot change or use grub to select system. Or you can only boot from UEFI or perhaps one-time boot key if your system auto switches to match install mode. Some require you to turn on/off UEFI or CSM/BIOS boot mode to change in UEFI menu also.\nI would suggest backing up data on sdb & convert to gpt partitioning since sda is UEFI with gpt partitioning.\nGPT Advantages (older but still valid)  see post#2 by srs5694:\nhttp://ubuntuforums.org/showthread.php?t=1457901\nhttps://wiki.archlinux.org/index.php/GUID_Partition_Table#Advantages_of_GPT\nYou may be able to convert, but need good backups anyway.\nhttp://www.rodsbooks.com/gdisk/mbr2gpt.html\n", "Q: (ACX 111) driver problems on Ubuntu server 12.04.4 This is basically what my wireless card looks to.\n*-network UNCLAIMED\n      description: Network controller\n      product: ACX 111 54Mbps Wireless Interface\n      vendor: Texas Instruments\n      physical id: 1\n      bus info: pci@0000:05:01.0\n      version: 00\n      width: 32 bits\n      clock: 33MHz\n      capabilities: pm bus_master cap_list\n      configuration: latency=32\n      resources: memory:fbffe000-fbffffff memory:fbfc0000-fbfdffff\n\nI've tried many methods to no avail.\nAs listed \n\"ndiswrapper\" (to use windows drivers) doesn't work for some reason.\n\"linksys\" driver\n\"modprobe\" to work with ndiswrapper. Broken, reinstalled, still broken.\nWhat in gods earth am I doing wrong?\nAlso: One of the error messages I'm getting for the linksys\ndriver; -bash: LSTINDS.new: Permission denied\n\nA: I doubt you are doing anything wrong. A search for acx111 here and on ubuntuforums.org tells us that there is probably no way at all to get this device going. For whatever reason, there is no interested software maintainer for this fairly uncommon device. Although I always hesitate to solve problems with money, in this instance, I suggest you invest in a newer, supported network card. \n", "Q: Apache restart after updating php pages I have to restart apache every time i update a php file. It's not a client browser cache problem, I tried multiple browsers. The strange thing is I only need to do it with php files, html files updates fine.. \n\nA: At last... The trouble was caused by OPcache, I just deleted the config ini and now its working :)\n", "Q: My Ubuntu 12.04 Installation hangs after \"Preparing to install Ubuntu\". What can I do to work around the problem? I did download Ubuntu 12.04LTS. I tried to install - no progress. I tried to remove all partition using a bootable version of GParted. I created one big partition ext4 formatted. It all did not help. The installation stops after \"Preparing to install Ubuntu\". All three checkmarks are checked an I can click \"Continue\" but then nothing for hours.\nWhat can I do? Please help!\n\nA: Thanks KodduX and Jonathan Acosta - you brought me to the right track!!!\nI did three things and in combination they worked. Actually I don't know which of those (or the combination) made the big difference.\nAs it did not work from CD, I made a bootable USB stick and started from there (opposite of what worked for Jonathan)\nI started with the \"try out\" (like suggested from KodduX - Thanks!!) version and there click on Install Ubuntu\nI did uncheck the two checkboxes (Update from Internet and install software) - with those checekd it did not work\nThanks for all that helped!!!\n", "Q: Problems with recompiling Swish++ I'm working with Swish++ in Ubuntu 12.04. Due to my thesis I must install Swish++ from the source code. During the installation I faced with several problems, but finally I solved them and Swish++ package was successfully installed.\nAlthough I found a discrepancy with Swish++ names (I asked this question, but got no answers there). Anyway, despite this, everything went ok. I could use index and search with all the functions of index++ and search++.\nBut now I have another problem. I changed config files of Swish++ and need to recompile it. The first time I did it I used command make. How can I delete Swish++ and install it again? The command sudo apt-get remove --auto-remove swish++ says that package hasn't been istalled and can't be removed.\nHow can I remove programms having been installed from the source code?\n\nA: I you still have the source directory where you built Swish++ for the first time you can uninstall it using the same Makefile with:\nsudo make unistall\n\n\nA: I also tried to install Swish++ from sources:\n\n\n*\n\n*First I downloaded the latest version here:\n~/Downloads/swish++-6.1.5\n\n*From this directory I can successfully run make uninstall\nIf that doesn’t work for you this it all the steps that the uninstall command performed:\ncd /usr/local/bin && rm -fr index search extract\ncd /usr/local/lib && rm -fr WWW.pm\nrm -fr /etc/init.d/searchd \\\n        /etc/rc1.d/K99searchd \\\n        /etc/rc2.d/K99searchd \\\n        /etc/rc3.d/S99searchd \\ \n        /etc/rc5.d/S99searchd \\\n        /etc/rc6.d/K99searchd\ncd /usr/local/man/man1 && rm -fr extract.1 httpindex.1 index.1 search.1 splitmail.1\ncd /usr/local/man/man3 && rm -fr WWW.3\ncd /usr/local/man/man4 && rm -fr swish++.conf.4 swish++.index.4\ncd /usr/local/man/man8 && rm -fr searchd.8 searchmonitor.8 \n\nrun them individually with sudo to get root privileges.\n", "Q: Permission on shared folder are correct but files can't be saved I have a shared folder set up on an ubuntu machine. When someone connects to the folder and creates a file, the file permissions set the group to read/write. I can check the permission on Ubuntu or Windows and they both show the group has read/write permission.\nThe problem comes when a user tries to edit a file created by another user. For example, user1 creates a text document. If user2 connects to the shared folder they can open the text document but when they try to save the file there is an error saying they don't have permission. Each user is also a part of the same group.\nMy samba.conf file addition looks like this:\n[foldername]\n    page = /home/path/to/directory\n    writeable = yes\n    browseable = yes\n    read only = no\n    valid users = user1, user2, user3, user4\n\n\nA: Another possible solution is to set the \"setgid\" bit on your shared directory. This means that all files/directories created in the shared dir will automatically belong to the group. Like this:\nchmod g+s <directory name>\n\nYou may also have to do this on existing subdirectories. In the future, when new directories are created, the setgid bit will automatically be turned on for them.\n\nA: I just tested it out according to this simple tutorial (\"quick 'n dirty\") and I think it cannot miss, it works perfectly for all users (I tried). The key is \n   create mask = 0777\n   directory mask = 0777\n\n...which will take care of the permissions in the way you want it.\n", "Q: What will happen with ubuntu if I reinstall windows 8.1 The title pretty much sums up the question.\nI'm using windows 8.1 and ubuntu 12.04 in dualboot and now something in windows 8.1 broke and by the looks of it I may have to refresh/reinstall it. \nSince I had to go through hell installing ubuntu (removing uefi boot, manually installing ubuntu then launching boot repair which created boot-grub for both ubuntu and windows) I can't figure out what will happen if I let windows 8.1 refresh/reinstall itself (windows 8.1 comes with a button for that and I may have to use it).\nThere are numerous questions about installing ubuntu alongside windows 8.1 but how to safely remove one or the other without having to throw your HDD?\n\nA: If you reinstall windows it will make ubuntu not bootable. Ubuntu will still be there unless you repartition your drive, it just will not be accessible:\nThere is a section in this wiki that deals with installing windows after ubuntu.\nhttps://help.ubuntu.com/community/WindowsDualBoot\n", "Q: Is there a way to get Smarty syntax highlight in gedit? I'm using smarty to develop a website and I need syntax highlighting. Currently gedit only highlights the html. Since my tpl files contains only html and smarty template functions. \nI've Google'd for this functionality and found this solution posted on github, but I didn't get it to work. \nDoes anyone have a solution for this? \nI just want a basic editor I don't care for fancy stuff that eclipse and other programs have. I just want a text editor with syntax highlighting. \n\nA: I got the github link to work. The steps I took was the following: \n\n\n*\n\n*Copy the files to a folder.\n\n\n*\n\n*smarty.lang\n\n*smarty.xml\n\n*smarty.sh\n\n\n*Navigate to the folder with the cd command in a terminal. \n\n*Make smarty.sh executable\nchmod +x ./smarty.sh\n\n*And finally install it!\n./smarty.sh\n", "Q: Windows 7 / Ubuntu dual-boot with shared data partition I have a laptop running Windows 7 64-bit Home Premium on an Intel Core i5 processor.  The laptop has 4 GB RAM and a 640 GB hard drive.  I would like to install Ubuntu in a dual-boot configuration such that there is a partition for data that is accessible regardless of whether I boot into Windows or Ubuntu. Besides the Windows, Ubuntu, and shared data partitions, any recommendations of other partitions that would optimize performance would be appreciated. I've searched the forum and cannot find any posts that have this (or somewhat similar) partition scheme. Any help would be appreciated. \nAlso, I know you can run Ubuntu from a DVD or a USB stick, but can you install from a USB stick rather than a DVD?\n\nA: For your second question, yes. You can install from a USB stick. It is well documented.\nSo, I don't have the exact solution to what you are looking for but this info may be helpful. Windows uses the NTFS filesystem which recent Ubuntu distros are able to read out of the box. If not, you can install a package to do so. Ubuntu uses the ext4(or 3 or 2 depending on how old) filesystem which is unreadable by Windows without extra software. \nIdeally, you would want it to read both ways, but that is not supported natively by Windows so what you could do, is install Ubuntu on a smaller partition of your drive. You only need about 8GB for the OS so making you partition 20GB would be plenty. Once installed, you should be able to access your Windows partition like a external drive. If you really want to, you can have it mount on boot but it is easy enough to access as is. \n", "Q: Eclipse Kepler won't start Hi am trying to learn about developing andoid apps using ubuntu 12.04lts and eclipse kepler. Had it all downloaded and set up which took ages. Tried to run an example and it crashed eclipse. Now Eclipse does the splash screen then an error message comes up referring to the file below:\n!SESSION 2014-03-11 10:08:17.323 -----------------------------------------------\neclipse.buildId=4.3.2.M20140221-1700\njava.version=1.7.0_45\njava.vendor=Oracle Corporation\nBootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_NZ\nFramework arguments:  -product org.eclipse.epp.package.standard.product\nCommand-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.standard.product\n\n!ENTRY org.eclipse.osgi 4 0 2014-03-11 10:08:53.775\n!MESSAGE Application error\n!STACK 1\njava.lang.LinkageError: Error reading class bytes: org.eclipse.e4.core.internal.services.EclipseAdapter\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:558)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395)\n    at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(SingleSourcePackage.java:35)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultHeadlessContext(E4Application.java:450)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultContext(E4Application.java:463)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createE4Workbench(E4Application.java:199)\n    at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:581)\n    at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\n    at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567)\n    at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)\n    at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124)\n    at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1450)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1426)\nCaused by: java.util.zip.ZipException: invalid distance too far back\n    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:164)\n    at org.eclipse.osgi.baseadaptor.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:157)\n    at org.eclipse.osgi.internal.baseadaptor.AdaptorUtil.getBytes(AdaptorUtil.java:247)\n    at org.eclipse.osgi.baseadaptor.bundlefile.BundleEntry.getBytes(BundleEntry.java:96)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:554)\n    ... 31 more\n!SESSION 2014-03-11 10:49:46.805 -----------------------------------------------\neclipse.buildId=4.3.2.M20140221-1700\njava.version=1.7.0_45\njava.vendor=Oracle Corporation\nBootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_NZ\nFramework arguments:  -product org.eclipse.epp.package.standard.product\nCommand-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.standard.product\n\n!ENTRY org.eclipse.osgi 4 0 2014-03-11 10:49:50.801\n!MESSAGE Application error\n!STACK 1\njava.lang.LinkageError: Error reading class bytes: org.eclipse.e4.core.internal.services.EclipseAdapter\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:558)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395)\n    at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(SingleSourcePackage.java:35)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultHeadlessContext(E4Application.java:450)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultContext(E4Application.java:463)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createE4Workbench(E4Application.java:199)\n    at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:581)\n    at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\n    at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567)\n    at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)\n    at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124)\n    at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1450)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1426)\nCaused by: java.util.zip.ZipException: invalid distance too far back\n    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:164)\n    at org.eclipse.osgi.baseadaptor.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:157)\n    at org.eclipse.osgi.internal.baseadaptor.AdaptorUtil.getBytes(AdaptorUtil.java:247)\n    at org.eclipse.osgi.baseadaptor.bundlefile.BundleEntry.getBytes(BundleEntry.java:96)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:554)\n    ... 31 more\n!SESSION 2014-03-11 10:50:41.308 -----------------------------------------------\neclipse.buildId=4.3.2.M20140221-1700\njava.version=1.7.0_45\njava.vendor=Oracle Corporation\nBootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_NZ\nFramework arguments:  -product org.eclipse.epp.package.standard.product\nCommand-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.standard.product\n\n!ENTRY org.eclipse.osgi 4 0 2014-03-11 10:50:48.115\n!MESSAGE Application error\n!STACK 1\njava.lang.LinkageError: Error reading class bytes: org.eclipse.e4.core.internal.services.EclipseAdapter\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:558)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395)\n    at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(SingleSourcePackage.java:35)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultHeadlessContext(E4Application.java:450)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultContext(E4Application.java:463)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createE4Workbench(E4Application.java:199)\n    at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:581)\n    at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\n    at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567)\n    at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)\n    at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124)\n    at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1450)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1426)\nCaused by: java.util.zip.ZipException: invalid distance too far back\n    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:164)\n    at org.eclipse.osgi.baseadaptor.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:157)\n    at org.eclipse.osgi.internal.baseadaptor.AdaptorUtil.getBytes(AdaptorUtil.java:247)\n    at org.eclipse.osgi.baseadaptor.bundlefile.BundleEntry.getBytes(BundleEntry.java:96)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:554)\n    ... 31 more\n!SESSION 2014-03-11 10:54:08.659 -----------------------------------------------\neclipse.buildId=4.3.2.M20140221-1700\njava.version=1.7.0_45\njava.vendor=Oracle Corporation\nBootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_NZ\nFramework arguments:  -product org.eclipse.epp.package.standard.product\nCommand-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.standard.product\n\n!ENTRY org.eclipse.osgi 4 0 2014-03-11 10:54:12.495\n!MESSAGE Application error\n!STACK 1\njava.lang.LinkageError: Error reading class bytes: org.eclipse.e4.core.internal.services.EclipseAdapter\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:558)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395)\n    at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(SingleSourcePackage.java:35)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultHeadlessContext(E4Application.java:450)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultContext(E4Application.java:463)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createE4Workbench(E4Application.java:199)\n    at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:581)\n    at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\n    at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567)\n    at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)\n    at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124)\n    at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1450)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1426)\nCaused by: java.util.zip.ZipException: invalid distance too far back\n    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:164)\n    at org.eclipse.osgi.baseadaptor.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:157)\n    at org.eclipse.osgi.internal.baseadaptor.AdaptorUtil.getBytes(AdaptorUtil.java:247)\n    at org.eclipse.osgi.baseadaptor.bundlefile.BundleEntry.getBytes(BundleEntry.java:96)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:554)\n    ... 31 more\n!SESSION 2014-03-11 10:54:51.432 -----------------------------------------------\neclipse.buildId=4.3.2.M20140221-1700\njava.version=1.7.0_45\njava.vendor=Oracle Corporation\nBootLoader constants: OS=linux, ARCH=x86_64, WS=gtk, NL=en_NZ\nFramework arguments:  -product org.eclipse.epp.package.standard.product\nCommand-line arguments:  -os linux -ws gtk -arch x86_64 -product org.eclipse.epp.package.standard.product\n\n!ENTRY org.eclipse.osgi 4 0 2014-03-11 10:55:01.654\n!MESSAGE Application error\n!STACK 1\njava.lang.LinkageError: Error reading class bytes: org.eclipse.e4.core.internal.services.EclipseAdapter\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:558)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClassImpl(ClasspathManager.java:492)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findLocalClass(ClasspathManager.java:465)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.findLocalClass(DefaultClassLoader.java:216)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findLocalClass(BundleLoader.java:395)\n    at org.eclipse.osgi.internal.loader.SingleSourcePackage.loadClass(SingleSourcePackage.java:35)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:461)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:421)\n    at org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:412)\n    at org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultHeadlessContext(E4Application.java:450)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createDefaultContext(E4Application.java:463)\n    at org.eclipse.e4.ui.internal.workbench.swt.E4Application.createE4Workbench(E4Application.java:199)\n    at org.eclipse.ui.internal.Workbench$5.run(Workbench.java:581)\n    at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)\n    at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:567)\n    at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)\n    at org.eclipse.ui.internal.ide.application.IDEApplication.start(IDEApplication.java:124)\n    at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)\n    at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:354)\n    at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:181)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:636)\n    at org.eclipse.equinox.launcher.Main.basicRun(Main.java:591)\n    at org.eclipse.equinox.launcher.Main.run(Main.java:1450)\n    at org.eclipse.equinox.launcher.Main.main(Main.java:1426)\nCaused by: java.util.zip.ZipException: invalid distance too far back\n    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:164)\n    at org.eclipse.osgi.baseadaptor.bundlefile.ZipBundleEntry$ZipBundleEntryInputStream.read(ZipBundleEntry.java:157)\n    at org.eclipse.osgi.internal.baseadaptor.AdaptorUtil.getBytes(AdaptorUtil.java:247)\n    at org.eclipse.osgi.baseadaptor.bundlefile.BundleEntry.getBytes(BundleEntry.java:96)\n    at org.eclipse.osgi.baseadaptor.loader.ClasspathManager.findClassImpl(ClasspathManager.java:554)\n    ... 31 more\n\n\nA: It looks like your eclipse installation has been corrupted.\nYou could try to start eclipse in clean mode with this command \neclipse -clean.\nOtherwise you will probably need to download and set up eclipse again.\nIf you want to minimize your setup process somewhat for Android app development you could try and install googles \"Android ADT\" instead, it is an eclipse version that comes pre configured for android development.\nYou can download it from http://developer.android.com/sdk/index.html\n", "Q: How do I profile (and possibly control) demands on my GPU? My GPU gets ungodly hot very quickly and I would like to see what is pushing it, how hard it is being pushed and then make an informed choice about upgrade, adding cooling or reconfiguring.\nHow do I profile my GPU's use and the applications making demands upon it?\nI'm using: 12.04 (precise) [64-bit]\nIt's a GeForce GT that I want to profile.\n\nA: This answer is more generic because you don't give more info like if you run a mobile device and what drivers you are use.\nFirst of all, check your module:\n$ modinfo nvidia|grep -e Mobile\nparm:           NVreg_Mobile:int\n\nOn notebooks you should have set NVreg_Mobile=1.\n$ cat /etc/modprobe.d/nvidia.conf\noptions nvidia NVreg_Mobile=1 NVreg_EnableMSI=1\n\nand rebuild you initrd with update-initramfs -c -t -k all.\nThe MSI setting is generally good for memory copy with a fast interface.\n$ grep nvidia /proc/interrupts\n45:  3969293       0   PCI-MSI-edge      nvidia\n\nYou should also use the lm-sensors package, which shows you the\nsystem temperatures, voltages and fan speeds:\n$ sensors\ncoretemp-isa-0000\nAdapter: ISA adapter\nPhysical id 0:  +43.0 C  (high = +80.0 C, crit = +85.0 C)\nCore 0:         +40.0 C  (high = +80.0 C, crit = +85.0 C)\nCore 1:         +42.0 C  (high = +80.0 C, crit = +85.0 C)\n\npkg-temp-0-virtual-0\nAdapter: Virtual device\ntemp1:        +44.0 C  \n\nnct6775-isa-0290\nAdapter: ISA adapter\nVcore:          +0.98 V  (min =  +0.00 V, max =  +1.74 V)\nin1:            +1.10 V  (min =  +0.00 V, max =  +0.00 V)  ALARM\nAVCC:           +3.33 V  (min =  +2.98 V, max =  +3.63 V)\n+3.3V:          +3.33 V  (min =  +2.98 V, max =  +3.63 V)\nin4:            +1.02 V  (min =  +0.00 V, max =  +0.00 V)  ALARM\nin5:            +1.04 V  (min =  +0.00 V, max =  +0.00 V)  ALARM\nin6:            +1.07 V  (min =  +0.00 V, max =  +0.00 V)  ALARM\n3VSB:           +3.38 V  (min =  +2.98 V, max =  +3.63 V)\nVbat:           +3.31 V  (min =  +2.70 V, max =  +3.63 V)\nfan1:          1110 RPM  (min =    0 RPM, div = 32)  ALARM\nfan2:          1028 RPM  (min =    0 RPM, div = 32)  ALARM\nfan3:           562 RPM  (min =    0 RPM, div = 32)  ALARM\nfan4:             0 RPM  (div = 128)\nSYSTIN:         +34.0 C  (high = +85.0 C, hyst = +75.0 C)  sensor = CPU diode\nCPUTIN:         +35.0 C  (high = +80.0 C, hyst = +75.0 C)  sensor = CPU diode\nPECI Agent 0:   +43.5 C  (high = +80.0 C, hyst = +75.0 C)  sensor = Intel PECI\nPCH_CHIP_TEMP:  +49.0 C  \nPECI Agent 1:    +0.0 C  (high = +80.0 C, hyst = +75.0 C)\ncpu0_vid:      +0.000 V\nintrusion0:    OK\n\nIf you think your GPU-fan is to slow, and the particular fan is listed,  then you can use the fancontrol tool to adjust it.\nTo read the temperature of you GPU use:\n$ DISPLAY=:0 nvidia-settings -q GPUCoreTemp -n -t\n51 \n\n", "Q: How can I install Windows 7 alongside Ubuntu? I am a new user of Ubuntu. A while ago attempted to install Ubuntu alongside Windows 7 but it didn't work. It installed Ubuntu but deleted all the Windows file and I did everything correctly.\nNow, I am new to the Ubuntu world and I like the OS and I would like to keep it and learn more but since my desktop is not used only by me, I need to install Windows 7 to dual-boot\nalongside Ubuntu.\nIs there any guide on how to do that?\nI have got only one USB stick to save something and I don't even know how to download the Windows ISO file.\n\nA: The windows installer is not likely to detect the Ubuntu install, and will overwrite the entire drive by default unfortunately.  There are ways to create separate partitions with Gparted\\windows tools to create an additional install partition, but that can be a bit tricky.\nIn my experience, the Ubuntu installer does a good job of detecting Windows installs, and will do all the difficult partition resizing for you -- I have 3 computers dual booting Ubuntu\\Mint\\WinXP\\Win7\\Win8(non-uefi)\nSteps for a simple clean dual boot(Ubuntu 13.10):\n\n\n*\n\n*Backup all important files\n\n*Install Windows, and allow it to format entire drive(make sure install is 100% complete)\n\n*Boot into an Ubuntu live session(CD or USB)\n\n*Use the installer from the desktop\n\n*The installer should offer an option to install alongside Windows 7\n\n*Select how much space each OS gets and wait for it to finish.\n\n*Your computer will now boot into GRUB and allow you to select Windows or Ubuntu each time you boot.\n\n\nIt's unfortunate that this did not work for you the first time, but I know it should work, barring any encryption\\odd partitions.\nTo help you get Windows iso on a bootable USB: http://www.microsoftstore.com/store/msusa/html/pbPage.Help_Win7_usbdvd_dwnTool\nLinux Mint(based on Ubuntu) also has an ISO to USB tool built in, and it may be installable in Ubuntu as well:http://community.linuxmint.com/software/view/usb-creator\n--Bryan\n", "Q: Running bash does \"segmentation fault core dumped\" I rebooted recently, and now terminal fails to work. If I click the terminal shortcut or use Guake or ctrl-alt-T, the terminal opens briefly with no prompt, then immediately closes again. I installed xterm as well and the same thing happens.\nIf I use ctrl-alt-F1 to get to a command line session and type gnome-terminal I get the error message:\nFailed to parse arguments: Cannot open display\n\nHow can I diagnose and fix this? \nEDIT TO ADD .bashrc\nPATH=$PATH:$HOME/.rvm/bin # Add RVM to PATH for scripting\n\n[[ -s \"$HOME/.profile\" ]] && source \"$HOME/.profile\"\n\n[[ -s \"$HOME/.rvm/scripts/rvm\" ]] && source \"$HOME/.rvm/scripts/rvm\"\n\n### Added by the Heroku Toolbelt\nexport PATH=\"/usr/local/heroku/bin:$PATH\"\nalias zf=/home/julio/ZendFramework-1.12.3/bin/zf.sh\n\nEDIT 2-- adding .profile:\n# if running bash\nif [ -n \"$BASH_VERSION\" ]; then\n    # include .bashrc if it exists\n    if [ -f \"$HOME/.bashrc\" ]; then\n    . \"$HOME/.bashrc\"\n    fi\nfi\n\n# set PATH so it includes user's private bin if it exists\nif [ -d \"$HOME/bin\" ] ; then\n    PATH=\"$HOME/bin:$PATH\"\nfi\n\nexport SCALA_HOME=/usr/share/scala\nexport PATH=$PATH:$SCALA_HOME/bin\nsource ~/.profile\n\n\nA: This has nothing to do with gnome-terminal, when you hit Ctrl Alt F1, logged in from the virtual console and tried running bash, you got a segmentation fault core dumped which means that bash itself crashes.\nAnyway, what's happening is that your bash is entering an infinite loop. When bash first starts, it reads ~/.bashrc (actually, this is a simplification, see here for more details). In your case (and in most if not all Ubuntu versions), the default .bashrc, for reasons that have never been clear to me, sources (reads) ~/.profile as well. Now, your ~/.profile includes this line:\nsource ~/.profile\n\nThe result of that is that bash reads ~/.bashrc => reads ~/.profile => reads ~/.profile => reads ~/.profile => reads ~/.profile etc. This is called an endless loop. Eventually, it freaks out and crashes. \nRemoving the source ~/.profile line from your ~/.profile should set everything back to normal.\n\nA: For mayank\n\"Removing the source ~/.profile line from your ~/.profile\" means just searching for the files ~/.bash_profile, ~/.profile, ~./bashrc, ~/bash_login, /etc/bash.bashrc and /etc/profile (as mentioned in comment), opening them and removing the line:\nsource ~/.profile\n\nor\n#[[ -s \"$HOME/.profile\" ]] && source \"$HOME/.profile     \n\nFYI: '~' is not a strange symbol, it just means your home directory. so its basically the path of .profile file. \nIts HOME_DIRECTORY/.profile.\n\n", "Q: Changing opacity of inactive windows in KDE Is there a way to set a customization in Plasma environment so that inactive windows will have opacity 30%?\nI know one can set specific titlebar colors for active and inactive windows . But I could not find anything about opacity.\n\nA: You can do this via a generic Window Rule that covers all windows.\nSystem Settings > Workspace Appearance and Behaviour > Window Behaviour > Window Rules > New…\nYou probably want to limit Window matching rules, so that (e.g.) the panel will not have its opacity changed. I'm not really sure which you want. Perhaps chose \"Normal Window\" to start with, and possibly \"Dialogue Window\" if you like.\nChange tabs to \"Appearance & Fixes\", then check Active opacity > Force; 100%. Also check Inactive opacity > Force; 30%. Click OK then Apply.\n\n", "Q: Why does Ubuntu's default ~/.profile source ~/.bashrc? These are the contents of the stock ~/.profile that came with my 13.10 (commented lines removed):\nif [ -n \"$BASH_VERSION\" ]; then\n    if [ -f \"$HOME/.bashrc\" ]; then\n    . \"$HOME/.bashrc\"\n    fi\nfi\n\nif [ -d \"$HOME/bin\" ] ; then\n    PATH=\"$HOME/bin:$PATH\"\nfi\n\nThis is inherited from Debian but why did Canonical decide to keep it? As far as I know, it's not the standard *nix way and I have seen various systems where this did not happen, so I assume they must have had a good reason to. This can cause unexpected behavior when running login shells (such as when sshing into the machine for example) where the user would not expect to have ~/.bashrc sourced. \nThe only benefit I can think of is to not confuse the user with many startup files  and allow them to edit .bashrc alone and have that read irrespective of shell type. That, however, is a dubious benefit since it is often useful to have different settings for login and for interactive shells and this blocks you from doing so. Also, login shells are very often not run in a graphical environment and that can cause errors and warnings and problems (oh my!) depending on what you've set in those files.\nSo why does Ubuntu do this, what am I missing? \n\nA: This is Ubuntu's standard behaviour, ~/.bashrc is user-level per-interactive-shell start up file. When you open a terminal basically you start a non-login, interactive shell\nwhich reads ~/.bashrc and contents of ~/.bashrc get sourced and exported into your current shell environment. It helps one to obtain all his user defined shell variables and functions in the current shell. Also you could find lines like this \nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\nto obtain user defined aliases in current shell environment.\nThis is important in order to provide good user experience also. For example one could store proxy credential in .bashrc, unless it get sourced none of terminal applications (viz, ping, wget, curl, lynx etc.) will work properly. Or you have to provide the proxy credentials every time you open a terminal.\nBesides Ubuntu's default .bashrc contains many user friendly aliases (for ls and grep to print colourized output), many new definitions for different shell variables which increases user experience.\nBut in case of your ssh login, or login in virtual console, you basically get an interactive login shell. There the shell initiation file is ~/.profile. Hence unless you source ~/.bashrc you miss all those helpful settings in your .bashrc. That is why Ubuntu's default ~/.profile source ~/.bashrc\nCase to avoid\n\n\n*\n\n*you should never source ~/.profile form inside ~/.bashrc at the same time when ~/.bashrc is being sourced from ~/.profile. It will create an infinite loop of situation and as a result your terminal prompt will be suspended unless you hit Ctrl+C. In such a situation if you put a line in your ~/.bashrc\nset -x\nThen you could see that the file descriptor is stopping when you open a terminal.\n\nA: This is an upstream decision coming from Debian. The rationale for it is explained in this very nice wiki post, of which the following is an excerpt. The executive summary is \"to ensure that GUI and non GUI logins work in the same way\":\n\nLet's take xdm as an example. pierre comes back from vacation one day and discovers that his system administrator has installed xdm on the Debian system. He logs in just fine, and xdm reads his .xsession file and runs fluxbox. Everything seems to be OK until he gets an error message in the wrong locale! Since he overrides the LANG variable in his .bash_profile, and since xdm never reads .bash_profile, his LANG variable is now set to en_US instead of fr_CA.\nNow, the naive solution to this problem is that instead of launching \"xterm\", he could configure his window manager to launch \"xterm -ls\". This flag tells xterm that instead of launching a normal shell, it should launch a login shell. Under this setup, xterm spawns /bin/bash but it puts \"-/bin/bash\" (or maybe \"-bash\") in the argument vector, so bash acts like a login shell. This means that every time he opens up a new xterm, it will read /etc/profile and .bash_profile (built-in bash behavior), and then .bashrc (because .bash_profile says to do that). This may seem to work fine at first -- his dot files aren't heavy, so he doesn't even notice the delay -- but there's a more subtle problem. He also launches a web browser directly from his fluxbox menu, and the web browser inherits the LANG variable from fluxbox, which is now set to the wrong locale. So while his xterms may be fine, and anything launched from his xterms may be fine, his web browser is still giving him pages in the wrong locale.\nSo, what's the best solution to this problem? There really isn't a universal one. A better approach is to modify the .xsession file to look something like this:\n[ -r /etc/profile ] && source /etc/profile\n[ -r ~/.bash_profile ] && source ~/.bash_profile\nxmodmap -e 'keysym Super_R = Multi_key'\nxterm &\nexec fluxbox\n\nThis causes the shell that's interpreting the .xsession script to read in /etc/profile and .bash_profile if they exist and are readable, before running xmodmap or xterm or \"execing\" the window manager. However, there's one potential drawback to this approach: under xdm, the shell that reads .xsession runs without a controlling terminal. If either /etc/profile or .bash_profile uses any commands that assume the presence of a terminal (such as \"fortune\" or \"stty\"), those commands may fail. This is the primary reason why xdm doesn't read those files by default. If you're going to use this approach, you must make sure that all of the commands in your \"dot files\" are safe to run when there's no terminal.\n\n", "Q: Encrypted files on a server There is a way of encrypting the data files stored on the server to harden them against direct access or hacking.\nThe website is in /var/www as usual and uses PHP to access data on another drive mounted as /home/data if that is any help.  I coded up the site myself and with my level of coding I doubt it it is uncrackable.  \nI'm also concerned that someone may gain physical access to the computer, and get access to the data that way.\n\nA: If you're serving on plain HTTP, you don't need to entirely worry about a break-in. Anyone can already perform a simple Man in the Middle attack to gain access to a user's account, or can grab the data as it is transmitted.\nIf you're going to do all encryption and decryption on the server side, rather than on the client, then the data is still being transmitted in the clear between the client and server.\nIf you want a secure server, then you need to get a valid HTTPS certificate for the site, serve only on HTTPS (automatically redirect any HTTP connection to the HTTPS URL instead), and do all encryption and decryption of data, on the client side, and must be done with a separate key for each user (otherwise, using the same key for all users means any user who is compromised will result in all files for all users having been compromised).\n\nA: Although my question was answered by Ahmadgeo I have found it does not solve my problem.  This is my mistake for not understanding what I needed to do.\neCrypt, and any other tools that encrypt files, directories or drives, need to be turned on and off.  As, in my case, the files need to accessible 24/7, so the drive needs to be mounted in an unencrypted state 24/7.  Also, if the server has a power blip and reboots then the files need to be available when it comes back up so we need to save the password somewhere to automate that process.  The end result is that the files are accessible in an unencrypted form whenever the machine is running so there is no protection from hacking or theft of the machine.\nI now understand that I need to build into my software a method of encrypting the files and then saving them to disk once they are uploaded (and decrypting on the download).  This way the confidential data can only be accessed by the user with a valid password.  Although the password is used as an encryption key only a MD5 of the password is stored in the machine.\nAlthough dobey makes some good points about using HTTPS, this machine is in my office and is not on a fixed IP address.  Yes, I can provide a \"self signed\" certificate but at the moment I'm a little worried about what effect a big warning sign about the certificate not being trusted will have on charity workers who still think the cough they had last week was caused by a computer virus.\n\nA: If you are concerned with physical disk security, have a look at eCryptfs\n and this Linux security article.\nAlso; since you had a break in, you might consider Console Security.\nFor overall security, look into these Ubuntu security guidelines.\nOne last thing ; have a look at this great Linux Foundation publication on Linux security.\n", "Q: Transpose Album names for a bunch of MP3 files I am looking for a script or tool that can move around elements of the Album name of a big bunch of mp3 files.\nThey currently have Album names like:   1999 - The Music of Canada\nI would like the Album names to be: Canada (1999) Music of\nThere are around 200 albums that I need to rename.\n\nA: sudo apt-get install tagtool\n\nIt's very easy to use. Just select the files and then edit their metadata.\n\n", "Q: Where is mono ide? I just installed Ubuntu on my local mounted thumb drive.  I went to software and installed mono.  Then I looked in the application folder and saw two icons for mono, one for a terminal which I did not install.  I clicked on the other icon and selected open and nothing happened.  I do I access the mono IDE?\n\nA: MonoDevelop is the IDE typically used for Mono development. You can install it with:\nsudo apt-get install monodevelop\n\nSee: How do I install Monodevelop 2.10 or later on 12.04?\n\nA: I just ran into this, and I believe the question is specifically: where can the executable be found.\nAs of Ubuntu 14.04, the executable for MonoDevelop will be found at: \n/usr/bin/monodevelop\n\n", "Q: Changing the Sampling Rate in UBUNTU 12.04 I have used POCKETSPHINX for speech recognition in my project. Pocketsphinx is recognizing words but as it works on a sample rate of 16000 Hz and our laptop takes input at 22050 Hz, output is not as efficient as we would like. So, please tell me the procedure of changing the sampling rate to 16000 Hz in Ubuntu 12.04. I am stuck at this point and need help. Any suggestions from your side regarding this issue are welcome.\nFor changing the sampling rate, I have tried to modify pulse.conf, alsa.conf in UBUNTU 12.04. I have also tried to add .asoundrc file. But nothing has worked. So, I want to know the exact procedure of changing the sampling rate to 16000 Hz in UBUNTU 12.04.\n\nA: pocketsphinx_continuous -adcdev hw:1  (this wont work in your case, obviously swap the \"1\" for the card index you want - derived from aplay -l or alsamixer, then press F6 or w/e )\nGiving an error like:\nAvailable samping rate 44100 is too far from requested 16000\nFATAL_ERROR: \"continuous.c\", line 246: Failed to open audio device\n\nHowever:\npocketsphinx_continuous -adcdev plughw:1  (This will silently handle your conversion)\nHope it helps (if a little late)\n\nA: If the hardware supports 16 kHz, it will use this rate automatically.\nIf the hardware does not support 16 kHz, nothing you do in software can change this.\n", "Q: how to convert multiple images to cbr? this might be a newbies question, i have a lot of image files with different extension (*.jpg, *.png) and i want to convert it to cbr file format. \nIs there a way to achieve this or are there command to do this ? (preferably using terminal)\n\nA: after reading the wiki page , it turns out that cbr is rar file format. so, the solution is very simple :\nsudo apt-get install rar       # install rar\nrar a <comic_name>.cbr *.jpg   # compress it and add to cbr\n\nvery simple. hopefully, this will be helpful to someone.\nthx to anyone who has read this article.\n", "Q: How do I find and set my $EDITOR environment variable? When I am using ipython or ipython3, I can use the %edit command to open up an editor to write my python scripts in. My problem is that the default editor is vim and I really do not get how to use that editor. What I would like to do is to change the editor to either nano or gedit. I think to stay with the terminal I would prefer to change it to the nano editor.\nWhen I type in the 'edit?' command into the ipython terminal it says :\n\n%edit runs IPython's editor hook. The default version of this hook is\n  set to call the editor specified by your $EDITOR environment variable.\n  If this isn't found, it will default to vi under Linux/Unix and to\n  notepad under Windows. See the end of this docstring for how to change\n  the editor hook.\n\nThen when I see the end of that docstring I see this:\n\nChanging the default editor hook:\nIf you wish to write your own editor hook, you can put it in a\n  configuration file which you load at startup time.  The default hook\n  is defined in the IPython.core.hooks module, and you can use that as a\n  starting example for further modifications.  That file also has\n  general instructions on how to set a new hook for use once you've\n  defined it.\n\nSorry to be such a newbie, but I get lost here.  I am not sure how to get to the IPython.core.hooks module, or just simply set an environment variable $EDITOR to nano.\nAny suggestions?\n\nA: You can set the $EDITOR variable with this command:\n\nexport EDITOR=\"/usr/bin/nano\"\n\nThis will define the variable EDITOR for the current session and pass it into the environment of all its child processes. To set it permanently you must define it in one of the system configuration files. The highest level at which you can do this is to set it in /etc/environment. This defines it globally:\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\"\nEDITOR=\"/usr/bin/nano\"\n\nCheck that variable is defined:\n$ echo $EDITOR\n/usr/bin/nano\n\nEditor's note: it's often preferable to put environment variables in your own ~/.profile, which is a lot easier to fix if something goes wrong.\n\nA: Add line\nexport EDITOR=nano\n\nto your ~/.profile and ~/.bashrcas in following picture. Do not put quotes around nano \n\nand then run \nsource ~/.profile \nsource ~/.bashrc\n\nat the prompt after modifying .profile and .bashrcfor the modification to take effect.\n\nNow the %edit in ipython will open nano.\n~/.bashrc will be called for interactive + non-loginshell\nwhereas\n~/.profile will be called for interactive + login shell\nIn your case it is enough to just add it in ~/.bashrc instead of ~/.profile.\n", "Q: When to use single or double quotes in Ubuntu command-line? Is there simple a rule to understand when to use quotes in Ubuntu command line and when single quotes and when double quotes are needed? \nFor example, how to explain the difference here:\n$ echo $'a\\naa\\nac\\nb\\ncc\\tdd\\ne\\se'\na\naa\nac\nb\ncc  dd\ne\\se\n$\n\nand\n$ echo $\"a\\naa\\nac\\nb\\ncc\\tdd\\ne\\se\"\na\\naa\\nac\\nb\\ncc\\tdd\\ne\\se\n$\n\n\nA: Normally, double quotes (\" \") are used for print the value of any variable and single quotes are used to print the exact string.\nFor example, you have a variable foo which contains pwd as value. \nfoo=pwd\nnow, when you do:- \n\n\n*\n\n*echo \"$foo\" - it will print the value of variable foo i.e. pwd\n\n*echo '$foo' - it will print $foo (exact string passed in single quotes \nAlso, Back quotes are used in command line/shell scripting, which is normally used to run the command stored in variable. \n\n*echo `$foo ` will print your current directory, i.e. output of pwd command. \n\n\nA: In your case, there is a special quoting syntax used, namely $'...' and $\"...\". It looks like this syntax came from the Korn shell to Zsh and Bash, and is now in POSIX (see for example the \"expand sequences\" line in http://mywiki.wooledge.org/Bashism). \nThis syntax is not mentioned in the answers to Differences between doublequotes \" \", singlequotes ' ' and backticks ´ ´ on commandline?. \nDetails on this syntax can be found in the bash(1) manpage:\n   Words of the form $'string' are treated specially.  The word \n   expands to string, with backslash-escaped characters replaced as specified \n   by the  ANSI C standard.  Backslash escape sequences, if present, are \n   decoded as follows:\n              \\a     alert (bell)\n              \\b     backspace\n              \\e\n              \\E     an escape character\n              \\f     form feed\n              \\n     new line\n              \\r     carriage return\n              \\t     horizontal tab\n              \\v     vertical tab\n              \\\\     backslash\n              \\'     single quote\n              \\\"     double quote\n              \\nnn   the eight-bit character whose value is the octal value \n                     nnn (one to three digits)\n              \\xHH   the eight-bit character whose value is the hexadecimal \n                     value HH (one or two hex digits)\n              \\uHHHH the Unicode (ISO/IEC 10646) character whose value is \n                     the hexadecimal value HHHH (one to four hex digits)\n              \\UHHHHHHHH\n                     the Unicode (ISO/IEC 10646) character whose value is the \n                     hexadecimal value HHHHHHHH (one to eight hex digits)\n              \\cx    a control-x character\n\n       The expanded result is single-quoted, as if the dollar sign had not\n       been present.\n\n       A double-quoted string preceded by a dollar sign ($\"string\") will\n       cause the string to be translated according to the current locale.  If \n       the current locale is C or POSIX, the dollar sign is ignored.  If the\n       string is translated and replaced, the replacement is double-quoted.\n\nThis also means that a variable will be expanded in $\"...\", but not in $'...'. Please compare:\n$ echo 'I am using\\t$SHELL.\\n'\nI am using\\t$SHELL.\\n\n$ echo $'I am using\\t$SHELL.\\n'\nI am using  $SHELL.\n\n$ echo \"I am using\\t$SHELL.\\n\"\nI am using\\t/bin/bash.\\n\n$ echo $\"I am using\\t$SHELL.\\n\"\nI am using\\t/bin/bash.\\n\n\nIn the first example, neither the $SHELL variable nor the backslash escapes are expanded. In the second example, the backslash examples are expanded, but not the variable. The third and fourth examples give identical results: Only the variable is expanded.\nThe form $'...' can be useful to assign contents with meta-characters like \\t or \\n to variables. I could not find an application for the form $\"...\", though.\n\nA: $ echo $'a\\naa\\nac\\nb\\ncc\\tdd\\ne\\se'\na\naa\nac\nb\ncc  dd\ne\\se\n$\n\nIn the above example, \\n represents new line.For this Syntax  $'code\\ncode1', terminal first prints  the code on first line and on  the next line, it prints code1.\nSo in the  example, terminal first start to executes the code.prints a on the 1st line, then it moves to the next character.The next character is \\n which represents new line.So the it prints aa in new line.And the the bash interpreter executes like that.On seeing this code cc\\tdd, it prints cc and after some space, it prints dd.Because \\t represents tab.Next it prints e\\se asusual because there is no value for \\s.\n\n$ echo $\"a\\naa\\nac\\nb\\ncc\\tdd\\ne\\se\"\na\\naa\\nac\\nb\\ncc\\tdd\\ne\\se\n$\n\necho $\"text\".In this the echo command displays whatever given inside $\"\" as it as.It won't parse.\necho $'code' - It parses the code.\necho $\"code\" - If the code contains dollar variable,it should be expanded otherwise it won't for \\n \\t and prints all the other contents as it is.\n\nA: Check accepted answer in Differences between doublequotes \" \", singlequotes ' ' and backticks ´ ´ on commandline?\nFor example purpose, consider that variable foo contains uname.\necho \"$foo\" outputs uname, subtitute variables in text.\necho '$foo' outputs $foo, the exact string (only ' should be escaped \\').\necho `$foo` outputs Linux, execute the content of the variable and echo outputs it.\n\nHere is also some nice Command Line Guides\n", "Q: Ubuntu 12.04 stuck at \"reboot: Restarting System\" I know this has been asked multiple times before, but most of these threads don't have an answer. I tried user62664's solution here and ran sudo update-grub successfully, but nothing changed. This happens whether I type sudo reboot or sudo shutdown -h now. Here is what it looks like when it hangs. There are no error messages, everything shows up with '[OK]', and then:\n* Deconfiguring network interfaces...          [OK]\n* Deactivating swap...                         [OK]\n* Unmounting local filesystems...              [OK]\n* Will now restart\n[ 1306.738916] mei_me 0000:00:16.0: stop\n[ 1306.739745] reboot: Restarting system\n_\n\nThis seems like a very common problem, yet there are very few answers and they don't seem to help in my case. Does this mean there is no one solution? In which case, where should I check to check to find out the root cause?\n\nA: From the man shutdown:\n\nOPTIONS\n       -r     Requests  that  the system be rebooted after it has been brought\n              down.\n\n       -h     Requests that the system be either halted or powered  off  after\n              it has been brought down, with the choice as to which left up to\n              the system.\n\n       -H     Requests that the system be halted after  it  has  been  brought\n              down.\n\n       -P     Requests  that  the  system  be  powered  off  after it has been\n              brought down.\n\nAs you can see, options -H and -P will poweroff your system. And sudo reboot will only reboot your computer, because it is so designed.\nFor rebooting your system wishout hanging up I can recommend sudo shutdown -r and sudo init 6. 【⬅This did not work out for me @biohazard】\n\nA: Passing a reboot= parameter to the kernel can solve this issue, no matter which shutdown command is used.\nSee\nhttp://linux.koolsolutions.com/2009/08/04/howto-fix-linux-hangfreeze-during-reboots-and-restarts/\nfor more details.\nIn my case, reboot=pci fixed the problem for a Dell Optiplex 790.\n\nA: When you make shutdown press super+F1 you will see the problem if it is like the following :\n\nBuffer I/O error on device fd0 logical Block 0\n\nyou must then go to BIOS and stop the floppy drive !\nif it is something else just say at add comment\n", "Q: How to mount an old /home directory after OS clean re-install? Before re-installing Ubuntu 12.04 LTS, I unmounted the /home directory. After a clean re-install, I recreated some of the users and installed the ubuntu-desktop package, then re-mounted the old /home directory. All of the documents have been restored, and I have no problem as long as I login with the shell. However, when I try to login to the GUI, it just re-loads the login screen. This has been happening ever since I included the old /home directory in /etc/fstab. \nTrying to follow the solution here, I looked for the .Xauthority files in every user's /home directory and noticed something weird, the users seem to have been mixed up. For example, ls -lah | grep Xauthority in /home/bob would show as:\n-rw-------  1 emily emily   53 Nov 29 10:19 .Xauthority\n\nand so on. My guess is that I didn't re-create the users in the same order as in the old system, so that things went weird when I mounted the old /home directory. However! I need to be able to plug the old /home directory files as is because they are several TB and I don't have the space to transfer them here and there freely, nor am I allowed to delete anything. What should I do to fix this?\nIs it a good idea to replace all hidden files in each old /home/user directory by the new ones?\n[Additional information]\nContents of ls -l /home (after mounting old /home);\nnote: lost+found was NOT supposed to be an user.\ntotal 36\ndrwxr-xr-x 22 bob   bob    4096 Mar 11 12:23 alice\ndrwxr-xr-x 44 marc  marc   4096 Mar 11 12:21 emily\ndrwxr-xr-x 23 1004  1004   4096 Jul 29  2013 bob\ndrwxr-xr-x  4 1005  1005   4096 Jul 30  2013 ken\ndrwx------  2 root  root  16384 Mar 27  2012 lost+found\ndrwxr-xr-r 40 emily emily  4096 Mar 11 12:49 marc\n\nContents of cat /etc/passwd (restricted to the users listed above):\nroot:x:0:0:root:/root:/bin/bash\nmarc:x:1000:1000:marc,,,:/home/marc:/bin/bash\nemily:x:1001:1001:emily,,,:/home/emily:/bin/bash\nbob:x:1002:1002:bob,,,:/home/bob:/bin/bash\nken:x:1003:1003:ken,,,:/home:ken:/bin/bash\n\nNote: user alice was not re-created after OS re-install because the account was no longer needed.\nOutput of lsblk:\nNAME        MAJ:MIN RM  SIZE        RO  TYPE    MOUNTPOINT\nsda     8:0     0   931.5G  0   disk\n+sda1   8:1     0   285M        0   part    \n+sda2   8:2     0   1K      0   part\n+sda5   8:5     0   18.6G       0   part\n+sda6   8:6     0   93.1G       0   part    /home\n+sda7   8:7     0   93.1G       0   part\n+sda8   8:8     0   698.4G          0   part    /home/marc/Data\n+sda9   8:9     0   9.3G        0   part    [SWAP]\n+sda10  8:10        0   18.6G       0   part    /   \nsr0     11:0        1   1024M       0   rom\nsdb     8:16        0   1.8T        0   disk\n+sdb1   8:17        0   1.8T        0   part    /home/marc/Data2\nsdc     8:32        0   1.8T        0   disk\n+sdc1   8:33        0   200M        0   part    \n+sdc2   8:34        0   465.8G          0   part    /home/marc/USB_Disk/Disk1\n+sdc3   8:35        0   465.8G          0   part    /home/marc/USB_Disk/Disk2\n+sdc4   8:36        0   465.8G          0   part    /home/emily/Data\n+sdc5   8:37        0   465.6G          0   part    /var/www\nsdf     8:80        0   3.7T        0   disk\n+sdf1   8:81        0   1.8T        0   part    /home/ken\n+sdf2   8:82        0   1.8T        0   part    /home/bob\nsde     8:64        1   29.8G       0   disk\n+sde1   8:65        1   29.8G       0   part    [SWAP]\n\nAs you can see, user marc has Documents shattered over a number of different disks and partitions.\n\nA: ln -n will show you what the filesytem thinks the UID and GIDs for the users should be. Here's an example from my system.\n$ ls -ln /home/\ntotal 12\ndrwxr-xr-x  5  111  120 4096 Mar 15 10:11 hts\ndrwxr-xr-x 11 1000 1000 4096 Mar 15 12:34 oli\ndrwxr-xr-x  4 1001 1001 4096 Mar 13 08:46 test\n\nIn this system, oli has the right UID of 1000 but if I did something so that it was 1001, I could simply use usermod to punch it around. Let's say I want to swap oli and test's UIDs around. This is a three-hop game as two users can't share a UID. They can share a group though.\nsudo usermod -u 1099 -g 1000 test\nsudo usermod -u 1001 -g 1001 oli\nsudo usermod -u 1000 test\n\nOne note: If your current user is one of the users in the changearound, sudo su before you start and run everything as root. Just remember that the safety's off. You don't want to get halfway through this process and have your sudo privileges bug out on you.\nYou'll need to play this sort of ballet until the usernames in /home/ line up with their UIDs (as shown in ls -ln /home). Alternatively you can alter all the files with a few find calls but I personally think this is a big fat waste of time. It's easier, quicker and potentially less destructive to fix this centrally through the user system.\nNext time remember to check the UIDs beforehand. The --uid nnn argument on adduser will make this painless.\n", "Q: Loading directly to the commandline For a completely unrelated problem, I ran update-grub following the instructions in user62644's answer to this post. Ever since, the GUI has been loading by default upon boot, and I have to type Ctrl+Alt+F1 to access the bash shell. I would like the bash shell to load by default upon startup, and just type startx whenever I need the GUI. I'm running Ubuntu 12.04 LTS.\n\nA: Edit /etc/default/grub and change this:\nGRUB_CMDLINE_LINUX_DEFAULT=\"acpi=noirq quiet splash\"\n\nto this:\nGRUB_CMDLINE_LINUX_DEFAULT=\"acpi=noirq quiet text\"\n\nThis assumes you actually need the acpi=noirq that was in the linked answer. I can't tell you that, it depends on your hardware. Anyway, once you've done this, refresh grub:\nsudo update-grub\n\nAnd you should now load directly to text. \n\nA: Use\nsudo update-rc.d lightdm remove\n\nAnd you will see desired bash logon shell on startup\nTo restore:\nsudo update-rc.d lightdm defaults\n\n", "Q: Cannot set proper resolution I have an AMD Raedon 6770 graphics card in my computer, and for some reason I'm unable to get Ubuntu 13.10 to read it. I had another copy of 13.10 on my desktop, but when I tried to install the .run file for the card from the terminal, it corrupted something within my operating system and I could no longer get Ubuntu to boot. I'm fairly new to this operating system, but am beginning to grasp the concept pretty fast. Is there anyway to add a library of screen resolutions? I really need something with a 16:9 ratio for my Emerson TV screen which I'm using as my monitor, and currently only 4:3 is available (linked tv to computer through a monitor cable).\nI've also tried to run a few xrandr commands without any success. Any suggestions would be greatly appreciated!\n\nA: If I understand correctly, you don't have a black screen, but rather are having trouble setting up the correct resolutions? If that's the case, then you should be able to follow this guide.\n\nA: Can you try this workaround to see if it helps?\n$ sudo gedit /etc/defaults/grub &\n\nIn this file, find the line starting with GRUB_GFXMODE and set to to your screen resolution. For example, if your screen resolution is 1366x768, then,\nGRUB_GFXMODE=1366x768\n\nSave the file and close Text Editor. Then execute the following command and reboot to see if it works.\n$ sudo update-grub2\n\n\nA: If you choose to simply install the drivers after running the .run file rather than generating packages, you may have to run sudo aticonfig --initial and reboot.\nIn case you aren't aware, there is an easy way to install hardware drivers from Software Sources > Additional Drivers.\nTry using the option while running the .run installer to create distribution-specific packages instead. That option will create three .debs, which you should install in this order by clicking the files:\n\n\n*\n\n*fglrx_<version>-0ubuntu1_<architecture>.deb\n\n*fglrx-dev_<version>-0ubuntu1_<architecture>.deb\n\n*fglrx-amdcccle_<version>-0ubuntu1_<architecture>.deb\nOr, with the terminal command: (assuming the .run file and thus resulting .deb files were directly in your home folder):\nsudo dpkg -i fglrx*.deb\n\nAnd reboot. It's a cleaner way to do things and shouldn't require configuration afterwards, except with dual-monitor scenarios and the like. But probably no terminal stuff.\nIf you use Kubuntu, you will also have to enable OpenGL detection in System Settings > Desktop Effects.\n", "Q: Motorola Defy USB Debug Driver I am trying to connect a Motorola Defy(MB525) phone to my computer that is running Ubuntu 13.10. I can't connect my phone with my computer system successfully. What steps do I need to take for this to work?\n\nA: In some Ubuntu versions by default, it won't support MTP mode.So you have to connect your phone in Mass storage Mode to view it's contents on Ubuntu PC.\n", "Q: How to install python-guestfs and libguestfs-tools in python virtual environment? Can any one help me out to install python-guestfs and libguestfs-tools in python virtual environment? \nI tried to install those packages with the help of pip install but it fails to install because it throws an error package not found.\n\nA: Try these commands,\nsudo apt-get install python-guestfs\nsudo apt-get install libguestfs-tools\n\nOR\nsudo apt-get install python-pip\nsudo pip install python-guestfs\nsudo pip install libguestfs-tools\n\n\nA: I have started work on this.  See the commit here which will allow you to build a python distribution of guestfs:\nhttps://github.com/libguestfs/libguestfs/commit/fcbfc4775fa2a44020974073594a745ca420d614\nUnfortunately we are waiting on the Python Software Foundation to resolve a licensing problem with the PyPi website before I am able to upload anything.\n\nA: It is possible to pip install it from their self hosted folder that is provided here.\nYou will end up running the command:\npip install http://libguestfs.org/download/python/guestfs-1.XX.YY.tar.gz\n\nThis will trigger Python to pull down raw source and build it. Make sure that you have libguestfs library for C installed on your system as well as python3-devel package for this to work.\nNOTE: instructions are listed on http://libguestfs.org/guestfs-python.3.html\n", "Q: Ubuntu 13.10 32 bit or 64? Lenovo ThinkPad E531 - i3-3110m - 8gb ram I wonder what version of Ubuntu should I install: 32 or 64 bit?\nMy hardware:\n\n\n*\n\n*ThinkPad E531 \n\n*i3-3110m \n\n*8gb ram\n\n\nA: According to the official Intel page about your processor, it is 64-bit. As such, it's optimal to install the 64-bit version of ubuntu.\n", "Q: zoneminder on 13.10 cannot click on add new monitor I've installed zoneminder on 13.10, however, when I access the browser interface (localhost/zm) I cannot click on \"add new monitor\". It's like this feature is disabled or something. When I click on \"add new monitor\", nothing happens. Absolutely useless.\n\nA: Solved! \nsudo apt-get install python-software-properties\nsudo add-apt-repository ppa:iconnor/zoneminder\nsudo nano /etc/apt/sources.list.d/iconnor-zoneminder-saucy.list\n\nchange 'saucy' to 'precise', ctrl-o to save, ctrl-x to exit\nsudo apt-get update\nsudo apt-get install zoneminder\n\nselect 'I' to overwrite existing file and 'y' to convert tables to InnoDB\n\nA: In my case (Ubuntu 14.04 ZoneMinder v1.27.1) I solved it:\ninstead of\nsudo add-apt-repository ppa:iconnor/zoneminder\n\nI used this\nsudo add-apt-repository ppa:iconnor/zoneminder-master\n\n\nA: May be you need to disable option 'OPT_USE_AUTH' in 'Options --> System'. After that, restart ZoneMinder and Bingo!\n", "Q: bashrc shortcuts in Tmux I have sets many shortcuts in .bashrc profile of local user, and they work properly. Currently on my 12.04 system but when ever I tried to used them in tmux, I always get the same response command not found. Is their any extra files which I have to edit for those shortcuts to work on tmux ?\n\nA: A user-specific configuration file should be located at ~/.tmux.conf, while a global configuration file should be located at /etc/tmux.conf. Default configuration files can be found in /usr/share/tmux/.\nEdit the ~/.tmux.conf file to include whatever shortcuts you want on tmux\nKey bindings may be changed with the bind and unbind commands in tmux.conf. \nFor example, you can change the prefix key (i.e. Ctrl-b) to Ctrl-a by adding the following commands in your ~/.tmux.conf configuration file:\nunbind C-b\nset -g prefix C-a\nbind a send-prefix\n\nAnother example:\nTo use PgUp and PgDown, to switch windows in tmux:\nbind -n PageUp previous-window\nbind -n PageDown next-window\n\n", "Q: i installed eclipse via terminal and installed i want to know where sdk is located I installed eclipse (ultimate edition 3.5) in Ubuntu 12.04 via the terminal. I also installed the ADT plugin in the eclipse program via install new software. Everything has completed but eclipse is asking  for the location of sdk. Where is sdk located on my computer?\n\nA: You need to download Android sdk manually from Android official website. \nDownload the file and extract it wherever you want. \nNow open your eclipse and go to Window → Preferences → Android → SDK Location  and click on browse button to select the exacted sdk folder.\nYou can also use ADT Bundle which is preconfigured with all components in portable form\nPlease see here for more information.\n\nA: *\n\n*Download latest sdk from here\n\n*Extract file using below command.\ntar -zxvf DOWNLOAD-FOLDER/android-sdk_r22.6-linux.tgz\n\n\n*Move this folder where you want to keep your Android SDK.\n\n*Open Eclipse  Window → Preferences → Android → SDK Location & set sdk location to your extracted SDK folder.\n\n*Next you need to download google API from Android SDK manager.\n\n*Click on Android SDK manager, select components you want to install & click on Install Packages.\nOr best option is download ADT Bundle which contains Eclipse, ADT & Android SDK inbuilt.\nEDIT :\n\nMight be adb don't have execute permissions. Try below command to correct permissions.\nchmod -R +x /media/New\\ Volume/softwares/ADT\\ Ubuntu/android-sdk-linux/platform-tools/*\n", "Q: bug in gforth.el preventing emacs24 from ppa from installing I'm having trouble installing emacs24 from the repository ppa:cassou/emacs because of an error in gforth.el. The problem is with a known-bug in gforth.el failing on a byte-compile. I'm currently not able to install anything else with apt. There's no bug on the related launchpad site either. I'm guessing apt noticed I have gforth installed and tried to install the matching emacs mode for it, rather than this being a bug all installations run into.\nI have a version of gforth.el on a non-Ubuntu machine that works (just removed the byte compile call), but I'm don't know much about the inner-workings of apt to be able to replace the one provided with this new gforth.el.\nFrom the error message below, would anyone know how to have apt use this file instead of the one provided?\nAttempts so far\nI've found gforth.el at /usr/share/emacs24/site-lisp/gforth/gforth.el and /usr/share/emacs/site-lisp/gforth/gforth.el. I've replaced both with the working version of the file, but the error message remains the same.\nError message\n% sudo apt-get install emacs24\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nemacs24 is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n1 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue [Y/n]? y\nSetting up emacs24 (24.3+1-2~ppa1~saucy1) ...\nInstall dictionaries-common for emacs24\ninstall/dictionaries-common: Already byte-compiled for emacs24. Skipping ...\nInstall gforth for emacs24\ninstall/gforth: Byte-compiling for emacsen flavour emacs24\n\nIn toplevel form:\ngforth.el:734:18:Error: Don't know how to compile nil\ngforth.el:734:18:Error: Don't know how to compile nil\ngforth.el:734:18:Error: Don't know how to compile nil\ngforth.el:734:18:Error: Don't know how to compile nil\ngforth.el:734:18:Error: Don't know how to compile nil\nERROR: install script from gforth package failed\ndpkg: error processing emacs24 (--configure):\n subprocess installed post-installation script returned error exit status 1\nErrors were encountered while processing:\n emacs24\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: I think you can temporarily solve the problem by commenting (removing) the following lines in /usr/share/emacs(24)/site-lisp/gforth/gforth.el:\n(eval-when-compile\n  (byte-compile 'forth-set-word-properties)\n  (byte-compile 'forth-next-known-forth-word)\n  (byte-compile 'forth-update-properties)\n  (byte-compile 'forth-delete-properties)\n  (byte-compile 'forth-get-regexp-branch))\n\nI have solved this problem by using this method.\n\nA: I uninstalled the (3) packages with gforth in their name and called \"sudo apt-get install -f\".\n(This can be a workaround and is no solution if you need gforth.)\n", "Q: Set headphones as default sound output (defaults to HDMI) Ubuntu 13.10 on Lenovo U410.\nThe screenshot explains it best\n\nafter every reboot HDMI is selected as output device. I always have to switch to Headphones (which in fact are speakers and not headphones). They both work perfectly, but how do I make Headphones the default?. The UI doesn't offer any options for that.\nHardware infos\n$: sudo lspci -nn\n00:00.0 Host bridge [0600]: Intel Corporation 3rd Gen Core processor DRAM Controller [8086:0154] (rev 09)\n00:01.0 PCI bridge [0604]: Intel Corporation Xeon E3-1200 v2/3rd Gen Core processor PCI Express Root Port [8086:0151] (rev 09)\n00:02.0 VGA compatible controller [0300]: Intel Corporation 3rd Gen Core processor Graphics Controller [8086:0166] (rev 09)\n00:14.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB xHCI Host Controller [8086:1e31] (rev 04)\n00:16.0 Communication controller [0780]: Intel Corporation 7 Series/C210 Series Chipset Family MEI Controller #1 [8086:1e3a] (rev 04)\n00:1a.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB Enhanced Host Controller #2 [8086:1e2d] (rev 04)\n00:1b.0 Audio device [0403]: Intel Corporation 7 Series/C210 Series Chipset Family High Definition Audio Controller [8086:1e20] (rev 04)\n00:1c.0 PCI bridge [0604]: Intel Corporation 7 Series/C210 Series Chipset Family PCI Express Root Port 1 [8086:1e10] (rev c4)\n00:1c.1 PCI bridge [0604]: Intel Corporation 7 Series/C210 Series Chipset Family PCI Express Root Port 2 [8086:1e12] (rev c4)\n00:1c.2 PCI bridge [0604]: Intel Corporation 7 Series/C210 Series Chipset Family PCI Express Root Port 3 [8086:1e14] (rev c4)\n00:1d.0 USB controller [0c03]: Intel Corporation 7 Series/C210 Series Chipset Family USB Enhanced Host Controller #1 [8086:1e26] (rev 04)\n00:1f.0 ISA bridge [0601]: Intel Corporation HM77 Express Chipset LPC Controller [8086:1e57] (rev 04)\n00:1f.2 SATA controller [0106]: Intel Corporation 7 Series Chipset Family 6-port SATA Controller [AHCI mode] [8086:1e03] (rev 04)\n00:1f.3 SMBus [0c05]: Intel Corporation 7 Series/C210 Series Chipset Family SMBus Controller [8086:1e22] (rev 04)\n01:00.0 VGA compatible controller [0300]: NVIDIA Corporation GF119M [GeForce 610M] [10de:1058] (rev ff)\n03:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8101E/RTL8102E PCI Express Fast Ethernet controller [10ec:8136] (rev 05)\n04:00.0 Network controller [0280]: Qualcomm Atheros AR9285 Wireless Network Adapter (PCI-Express) [168c:002b] (rev 01)\n\n\n$: cat /proc/asound/cards\n0 [PCH            ]: HDA-Intel - HDA Intel PCH\n                     HDA Intel PCH at 0xeb610000 irq 46\n\n\n$: cat /proc/asound/card0/codec#0\nCodec: Conexant CX20590\nAddress: 0\nAFG Function Id: 0x1 (unsol 1)\nVendor Id: 0x14f1506e\nSubsystem Id: 0x17aa400b\nRevision Id: 0x100003\nNo Modem Function Group found\nDefault PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\nDefault Amp-In caps: N/A\nDefault Amp-Out caps: N/A\nState of AFG node 0x01:\n  Power states:  D0 D1 D2 D3 D3cold CLKSTOP EPSS\n  Power: setting=D0, actual=D0\nGPIO: io=4, o=0, i=0, unsolicited=1, wake=0\n  IO[0]: enable=0, dir=0, wake=0, sticky=0, data=0, unsol=0\n  IO[1]: enable=0, dir=0, wake=0, sticky=0, data=0, unsol=0\n  IO[2]: enable=0, dir=0, wake=0, sticky=0, data=0, unsol=0\n  IO[3]: enable=0, dir=0, wake=0, sticky=0, data=0, unsol=0\nNode 0x10 [Audio Output] wcaps 0xc1d: Stereo Amp-Out R/L\n  Control: name=\"Headphone Playback Volume\", index=0, device=0\n    ControlAmp: chs=3, dir=Out, idx=0, ofs=0\n  Control: name=\"Headphone Playback Switch\", index=0, device=0\n    ControlAmp: chs=3, dir=Out, idx=0, ofs=0\n  Device: name=\"CX20590 Analog\", type=\"Audio\", device=0\n  Amp-Out caps: ofs=0x4a, nsteps=0x4a, stepsize=0x03, mute=1\n  Amp-Out vals:  [0x4a 0x4a]\n  Converter: stream=7, channel=0\n  PCM:\n    rates [0x560]: 44100 48000 96000 192000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x11 [Audio Output] wcaps 0xc1d: Stereo Amp-Out R/L\n  Control: name=\"Speaker Playback Volume\", index=0, device=0\n    ControlAmp: chs=3, dir=Out, idx=0, ofs=0\n  Control: name=\"Speaker Playback Switch\", index=0, device=0\n    ControlAmp: chs=3, dir=Out, idx=0, ofs=0\n  Amp-Out caps: ofs=0x4a, nsteps=0x4a, stepsize=0x03, mute=1\n  Amp-Out vals:  [0x80 0x80]\n  Converter: stream=7, channel=0\n  PCM:\n    rates [0x560]: 44100 48000 96000 192000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x12 [Audio Output] wcaps 0x611: Stereo Digital\n  Converter: stream=0, channel=0\n  Digital:\n  Digital category: 0x0\n  IEC Coding Type: 0x0\n  PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x5]: PCM AC3\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x13 [Beep Generator Widget] wcaps 0x70000c: Mono Amp-Out\n  Control: name=\"Beep Playback Volume\", index=0, device=0\n    ControlAmp: chs=1, dir=Out, idx=0, ofs=0\n  Control: name=\"Beep Playback Switch\", index=0, device=0\n    ControlAmp: chs=1, dir=Out, idx=0, ofs=0\n  Amp-Out caps: ofs=0x07, nsteps=0x07, stepsize=0x0f, mute=0\n  Amp-Out vals:  [0x07]\nNode 0x14 [Audio Input] wcaps 0x100d1b: Stereo Amp-In R/L\n  Control: name=\"Internal Mic Capture Volume\", index=0, device=0\n    ControlAmp: chs=1, dir=In, idx=2, ofs=0\n  Control: name=\"Inverted Internal Mic Capture Volume\", index=0, device=0\n    ControlAmp: chs=2, dir=In, idx=2, ofs=0\n  Control: name=\"Internal Mic Capture Switch\", index=0, device=0\n    ControlAmp: chs=1, dir=In, idx=2, ofs=0\n  Control: name=\"Inverted Internal Mic Capture Switch\", index=0, device=0\n    ControlAmp: chs=2, dir=In, idx=2, ofs=0\n  Control: name=\"Mic Capture Volume\", index=0, device=0\n    ControlAmp: chs=3, dir=In, idx=0, ofs=0\n  Control: name=\"Mic Capture Switch\", index=0, device=0\n    ControlAmp: chs=3, dir=In, idx=0, ofs=0\n  Device: name=\"CX20590 Analog\", type=\"Audio\", device=0\n  Amp-In caps: ofs=0x4a, nsteps=0x50, stepsize=0x03, mute=1\n  Amp-In vals:  [0x80 0x80] [0x80 0x80] [0x80 0x80] [0x80 0x80]\n  Converter: stream=4, channel=0\n  SDI-Select: 0\n  PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 4\n     0x17 0x18 0x23* 0x24\nNode 0x15 [Audio Input] wcaps 0x100d1b: Stereo Amp-In R/L\n  Amp-In caps: ofs=0x4a, nsteps=0x50, stepsize=0x03, mute=1\n  Amp-In vals:  [0x4a 0x4a] [0x4a 0x4a] [0x4a 0x4a] [0x4a 0x4a]\n  Converter: stream=0, channel=0\n  SDI-Select: 0\n  PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 4\n     0x17* 0x18 0x23 0x24\nNode 0x16 [Audio Input] wcaps 0x100d1b: Stereo Amp-In R/L\n  Amp-In caps: ofs=0x4a, nsteps=0x50, stepsize=0x03, mute=1\n  Amp-In vals:  [0x4a 0x4a] [0x4a 0x4a] [0x4a 0x4a] [0x4a 0x4a]\n  Converter: stream=0, channel=0\n  SDI-Select: 0\n  PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x1]: PCM\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 4\n     0x17* 0x18 0x23 0x24\nNode 0x17 [Audio Selector] wcaps 0x30050d: Stereo Amp-Out\n  Control: name=\"Mic Boost Volume\", index=0, device=0\n    ControlAmp: chs=3, dir=Out, idx=0, ofs=0\n  Amp-Out caps: ofs=0x00, nsteps=0x04, stepsize=0x27, mute=0\n  Amp-Out vals:  [0x00 0x00]\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 4\n     0x1a* 0x1b 0x1d 0x1e\nNode 0x18 [Audio Selector] wcaps 0x30050d: Stereo Amp-Out\n  Amp-Out caps: ofs=0x00, nsteps=0x04, stepsize=0x27, mute=0\n  Amp-Out vals:  [0x00 0x00]\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 4\n     0x1a* 0x1b 0x1d 0x1e\nNode 0x19 [Pin Complex] wcaps 0x400581: Stereo\n  Control: name=\"Headphone Jack\", index=0, device=0\n  Pincap 0x0000001c: OUT HP Detect\n  Pin Default 0x04211040: [Jack] HP Out at Ext Right\n    Conn = 1/8, Color = Black\n    DefAssociation = 0x4, Sequence = 0x0\n  Pin-ctls: 0xc0: OUT HP\n  Unsolicited: tag=01, enabled=1\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10* 0x11\nNode 0x1a [Pin Complex] wcaps 0x400481: Stereo\n  Control: name=\"Mic Jack\", index=0, device=0\n  Pincap 0x00001324: IN Detect\n    Vref caps: HIZ 50 80\n  Pin Default 0x04a11030: [Jack] Mic at Ext Right\n    Conn = 1/8, Color = Black\n    DefAssociation = 0x3, Sequence = 0x0\n  Pin-ctls: 0x24: IN VREF_80\n  Unsolicited: tag=02, enabled=1\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x1b [Pin Complex] wcaps 0x400581: Stereo\n  Pincap 0x00011334: IN OUT EAPD Detect\n    Vref caps: HIZ 50 80\n  EAPD 0x2: EAPD\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x00: VREF_HIZ\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10* 0x11\nNode 0x1c [Pin Complex] wcaps 0x400581: Stereo\n  Pincap 0x00000014: OUT Detect\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x40: OUT\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10* 0x11\nNode 0x1d [Pin Complex] wcaps 0x400581: Stereo\n  Pincap 0x00010034: IN OUT EAPD Detect\n  EAPD 0x2: EAPD\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x40: OUT\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10* 0x11\nNode 0x1e [Pin Complex] wcaps 0x400481: Stereo\n  Pincap 0x00000024: IN Detect\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x00:\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x1f [Pin Complex] wcaps 0x400501: Stereo\n  Control: name=\"Speaker Phantom Jack\", index=0, device=0\n  Pincap 0x00000010: OUT\n  Pin Default 0x90170110: [Fixed] Speaker at Int N/A\n    Conn = Analog, Color = Unknown\n    DefAssociation = 0x1, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x00:\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10 0x11*\nNode 0x20 [Pin Complex] wcaps 0x400781: Stereo Digital\n  Pincap 0x00000010: OUT\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x00:\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 1\n     0x12\nNode 0x21 [Audio Output] wcaps 0x611: Stereo Digital\n  Converter: stream=0, channel=0\n  Digital:\n  Digital category: 0x0\n  IEC Coding Type: 0x0\n  PCM:\n    rates [0x160]: 44100 48000 96000\n    bits [0xe]: 16 20 24\n    formats [0x5]: PCM AC3\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x22 [Pin Complex] wcaps 0x400781: Stereo Digital\n  Pincap 0x00000010: OUT\n  Pin Default 0x400001f0: [N/A] Line Out at Ext N/A\n    Conn = Unknown, Color = Unknown\n    DefAssociation = 0xf, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x00:\n  Unsolicited: tag=00, enabled=0\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 1\n     0x21\nNode 0x23 [Pin Complex] wcaps 0x40040b: Stereo Amp-In\n  Control: name=\"Internal Mic Boost Volume\", index=0, device=0\n    ControlAmp: chs=3, dir=In, idx=0, ofs=0\n  Control: name=\"Internal Mic Phantom Jack\", index=0, device=0\n  Amp-In caps: ofs=0x00, nsteps=0x04, stepsize=0x2f, mute=0\n  Amp-In vals:  [0x00 0x00]\n  Pincap 0x00000020: IN\n  Pin Default 0x90a60150: [Fixed] Mic at Int N/A\n    Conn = Digital, Color = Unknown\n    DefAssociation = 0x5, Sequence = 0x0\n    Misc = NO_PRESENCE\n  Pin-ctls: 0x20: IN\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\nNode 0x24 [Audio Mixer] wcaps 0x20050b: Stereo Amp-In\n  Amp-In caps: ofs=0x4a, nsteps=0x4a, stepsize=0x03, mute=1\n  Amp-In vals:  [0x00 0x00] [0x00 0x00]\n  Power states:  D0 D1 D2 D3 D3cold EPSS\n  Power: setting=D0, actual=D0\n  Connection: 2\n     0x10 0x11\nNode 0x25 [Vendor Defined Widget] wcaps 0xf00000: Mono\n\n\nA: pavucontrol\nFor a much better fine-tuning of our default audio setup we may install and run pavucontrol which also has an option to set a fallback device (below shown for a bluetooth headset):\n\nIf this does not work as expected you may have an issue with the module-switch-on-port-available loaded from the default.pa settings. You may try to disable this module.\n\nA: Actually there is a pulseaudio module (module-switch-on-connect) that when enabled, it may do exactly what is requested, as shown in this answer. It is a simple answer and works like a charm, seems in all Ubuntu versions from 12.04 till 17.04. \n", "Q: Couldn't connect to accessibility bus When using ssh with X11 forwarding, I am getting various errors and warnings when running gui applications.\nAs an example, any time I am running gitg, I get the following warning:\n** (gitg:15904): WARNING **: Couldn't connect to accessibility bus: Failed to connect to socket /tmp/dbus-ychCoQcrqT: Connection refused\n\nBesides being ugly, does that suggest any real error?\nI get the same warning running evince:\n** (evince:16634): WARNING **: Couldn't connect to accessibility bus: Failed to connect to socket /tmp/dbus-ychCoQcrqT: Connection refused\n\n... or eog:\n** (eog:16872): WARNING **: Couldn't connect to accessibility bus: Failed to connect to socket /tmp/dbus-ychCoQcrqT: Connection refused\n\nAnd so on.\nPerhaps it worth mentioning: I am connecting from 12.04 to (yes, unsupported) 13.04.\n\nA: I don't think the warnings are important (unless you need the accessibility bus). Apparently forwarding the accessibility bus over SSH isn't supported yet.\nHowever, you could try the following to suppress the errors if it annoys you:\nPrepend the following to any commands:  \nNO_AT_BRIDGE=1\n\nOr (a long-shot) try using the -Y option with -X in SSH to enable trusted forwarding.\n\nA: I had disabled conda with:\nconda config --set auto_activate_base False\nsource ~/.bashrc\n\nAfter this, when I started GDL, similar error was thrown at me. Fixed with:\nconda init bash\n\nHope it works for others.\n", "Q: xsp4 address already in use error. Can't run mono application I compiled mono 3.0, xsp and other related libs.\nMy web aplication directory is /var/www/mvctest/public_html\nI configured apache sites-default file just like in this tutorial\nI put my Mono+nancy application application inside /var/www/mvctest/public_html.\nWhen I start xsp4 in this directory, I get the following error\nxsp4\nListening on address: 0.0.0.0\nRoot directory: /var/www/mvctest/public_html\nAddress already in use\n  at System.Net.Sockets.Socket.Bind (System.Net.EndPoint local_end) [0x00000] in <filename unknown>:0\n  at Mono.WebServer.XSPWebSource.CreateSocket () [0x00000] in <filename unknown>:0\n  at Mono.WebServer.ApplicationServer.Start (Boolean bgThread, Int32 backlog) [0x00000] in <filename unknown>:0\n  at (wrapper remoting-invoke-with-check) Mono.WebServer.ApplicationServer:Start (bool,int)\n  at Mono.WebServer.XSP.Server.DebugMain (System.String[] args, Boolean root, IApplicationHost ext_apphost, Boolean quiet) [0x00000] in <filename unknown>:0\nroot@servername:/var/www/mvctest/public_html#\n\nWhat's wrong with xsp? what is a right way to deploy a mono application? how am I supposed to set any other configs? \n\nA: It can mean three things  check all and make sure none of them is true your problem will     be gone\n\n\n*\n\n*xsp was already running and you tried to run it again.\n\n*The directory is root directory of another server like apache etc.\n\n*xsp can not find the required assemblies in the mono path , which means during compiling the mono prefix you gave was wrong.\n\n\nJust a Suggestion\nAnother sugestion for you if possible upgrade to ubuntu 14.04 and get all these mono packages already build for you, i personally tried mvc 3 and mvc 4 and even the AspInfoMvc application that is given in the articles that you have mentioned, mono and asp.net works like a charm on 14.04 and auto-hosting also works great with some minor issues which will be fixed soon i hope.\n\n\nA: i have same problem xsp4 insists on running on port 8080 and i have tomcat running there. kill some other server (oracle, tomcat.. etc) that you have running on 8080 and it shall run.\ni really wish to get to know how to explain to xsp to run using different port within monodevelop. from command line is easy: xsp4 -port xxxx \nbut default configs mean nothing to monodevelop ide, it has its own mind\n", "Q: Can not find file Am new in Ubuntu, I have install kde plasma desktop, and want to install kde base plug in, and I have to run a configure.sh script file, and I try to type in:\n./Home/michael/downloads/document/kdebase/configure.sh\n\nit can not find the file but the file is there, How can I run install.sh file same place. Can someone help me.\nThanks.\n\nA: First make it executable using chmod u+x /home/michael/downloads/document/kdebase/configure.sh \nand then execute it using /home/michael/downloads/document/kdebase/configure.sh\n\nA: It seems just a typo error:\n/home in Ubuntu is /home not /Home\nDownloads is with capital D\nso I think you must first locate correctly your script.\nAnyway the easiest way to do that just open the directory containing the script in GUI using nautilus(file manager) Then just drag and drop the script to the terminal.\nTo make it executable \nchmod +x /The-dragged-path\n\nThen run it:\n./The-dragged-path\n\nYou may need be sudo\nsudo ./The-dragged-path\n\n", "Q: How to know which processes have the DISPLAY variable set? Sometimes I face some problems in display and mostly I do want to know which files or processes are using the DISPLAY environment variable. \nSo how to list all processes that having DISPLAY set?\n\nA: I came up to this command after many searches and tries:\nfor file in /proc/[0-9]*; do grep -ao 'DISPLAY=[^[:cntrl:]]*' $file/environ 2>/dev/null && grep -ao '(.*)' $file/stat; done | sed 'N;s/\\n/\\t/'\n\nA sample of the output is:\nDISPLAY=:0  (unity-files-dae)\nDISPLAY=:0  (unity-music-dae)\nDISPLAY=:0  (unity-lens-vide)\nDISPLAY=:0  (zeitgeist-daemo)\nDISPLAY=:0  (zeitgeist-fts)\nDISPLAY=:0  (zeitgeist-datah)\nDISPLAY=:0  (cat)\nDISPLAY=:0  (unity-scope-vid)\nDISPLAY=:0  (unity-musicstor)\nDISPLAY=:0  (dconf-service)\nDISPLAY=:0  (gdu-notificatio)\nDISPLAY=:0  (telepathy-indic)\nDISPLAY=:0  (mission-control)\nDISPLAY=:0  (goa-daemon)\nDISPLAY=:0  (VBoxXPCOMIPCD)\n\nTo explain what's going on, this loop searches recursively in the /proc directory searching for DISPLAY in each file. Those files are really the processes running, so every file containing the word DISPLAY means that this process is using it.\n\nA: Ideally, all the current processes that correspond to the programs that you execute on the local machine, post login, are gonna carry the same display variable as your first open pts (pseudo-terminal session) console.\nFor instance, when you open your first terminal session (gnome-terminal) and run the who or w command you will notice some output like this:\n$ who\n\nyourusername   :0        2015-06-08 14:05 (:0)\nyourusername   pts/0     2015-06-08 14:22 (:0)\n\nor some folks might look like this (but not it your case)\nyourusername   :0        2015-06-08 14:05 (:0)\nyourusername   pts/0     2015-06-08 14:22 (:0.0)\n\nusing the light display manager if the DISPLAY variable is set differently for post login execution of shells (e.g. :0.0), then the environment variable for DISPLAY would yield the same display variable as the post-login display variable of the first open pts (:0.0), but the host variable, at login, would still be (:0).\nBy echoing the DISPLAY variable, or running set piped to less as shown below:\n:~$ echo $DISPLAY\n\nor\n:~$ set | less\n\nyou can also check your sessions current display variable, and see what it is set to, for post login execution of shells. So basically the display variable of the processes you execute are gonna have the same display variable as your first open pts, post login.\nThe output of the script\nfor file in /proc/[0-9]*; do grep -ao 'DISPLAY=[^[:cntrl:]]*' $file/environ 2>/dev/null && grep -ao '(.*)' $file/stat; done | sed 'N;s/\\n/\\t/'\n\nthat Maythux posted, suggests that your first open pts is gonna have the same display variable as your display manager's login, in this case :0.\nNow for the second example, the output would look something like this:\nDISPLAY=:0.0    (gvfs-udisks2-vo)\nDISPLAY=:0.0    (zeitgeist-daemo)\nDISPLAY=:0.0    (zeitgeist-fts)\nDISPLAY=:0.0    (zeitgeist-datah)\nDISPLAY=:0.0    (gvfs-mtp-volume)\nDISPLAY=:0.0    (gvfs-gphoto2-vo)\nDISPLAY=:0.0    (gvfs-afc-volume)\nDISPLAY=:0.0    (geyes_applet2)\nDISPLAY=:0.0    (indicator-apple)\nDISPLAY=:0.0    (cat)\nDISPLAY=:0.0    (python)\nDISPLAY=:0.0    (gvfsd-trash)\nDISPLAY=:0.0    (indicator-keybo)\nDISPLAY=:0.0    (gvfsd-burn)\nDISPLAY=:0.0    (cat) \nDISPLAY=:0.0    (cat)\nDISPLAY=:0.0    (gnome-terminal)\nDISPLAY=:0.0    (bash)\nDISPLAY=:0.0    (bash)\nDISPLAY=:0.0    (sed)\n\nAlso for additional reading you can look at the the man pages for ptmx\n$ man ptmx\n\nThis might lend some insight into the master-slave relationship of pseudo-terminals.\n\nA: With a small modification to the Maythux script, we can also get the PID of the processes using the DISPLAY variable. \nfor file in /proc/[0-9]*; do grep -ao 'DISPLAY=[^[:cntrl:]]*' $file/environ 2>/dev/null && grep -ao '[0-9]* (.*)' $file/stat; done | sed 'N;s/\\n/\\t/' |column -t |sort -n -k2\n\nThe output is: \nDISPLAY=:0  590    (lxsession)\nDISPLAY=:0  645    (unclutter)\nDISPLAY=:0  705    (gvfsd)\nDISPLAY=:0  710    (gvfsd-fuse)\nDISPLAY=:0  727    (openbox)\nDISPLAY=:0  729    (lxpolkit)\nDISPLAY=:0  732    (lxpanel)\nDISPLAY=:0  734    (pcmanfm)\nDISPLAY=:0  772    (menu-cached)\nDISPLAY=:0  781    (gvfs-udisks2-vo)\nDISPLAY=:0  791    (gvfs-gphoto2-vo)\nDISPLAY=:0  795    (gvfs-mtp-volume)\nDISPLAY=:0  799    (gvfs-afc-volume)\nDISPLAY=:0  804    (gvfs-goa-volume)\nDISPLAY=:0  816    (gvfsd-trash)\nDISPLAY=:0  21053  (npm)\nDISPLAY=:0  21102  (sh)\nDISPLAY=:0  21103  (sh)\nDISPLAY=:0  21104  (node)\nDISPLAY=:0  21110  (electron)\nDISPLAY=:0  21112  (electron)\nDISPLAY=:0  21149  (electron)\nDISPLAY=:0  21154  (electron)\nDISPLAY=:0  21180  (rec)\n\n", "Q: How can \"git gui\" open repository from parent directory? I start Git GUI tool using command git gui or git citool. \nI wanted to add another entry to right click script menu (already have dozens of commands) and created a script like this:\n#!/bin/sh\ngit citool $1\n\nor\n#!/bin/sh\ngit gui $1\n\nbut any of these opens a blank Git GUI\n\nThis does not happen if I open the Terminal and run git gui from it. \nWhere am I making a mistake? Dozens of other apps work with the same parameter $1. Could it be that extra parameter gui or citool is causing the error?!\n\nA: Let me suppose you wrote script.sh\n#!/bin/bash\ngit gui $1\n\nChange it like\n#!/bin/bash\ncd $1 && git gui\n\nUsing && will prevent execution of git gui if something goes wrong.\n", "Q: Script not running in crontab, file not found I need your help to run a bash script in crontab. As many other posts in askubuntu I'm facing the problem that a script that is properly running in terminal mode does not run in crontab. The error I get is:\n/usr/local/rams60/build/fdgrib2/fdgrib2: error while loading shared libraries: libhdf5.so.8: cannot open shared object file: No such file or directory\n\nCron output also shows TERM environment variable not set.\nbut of course libhdf5.so.8 exists:\nlrwxrwxrwx 1 root root 16 ene 20 12:54 /usr/local/hdf5/lib/libhdf5.so.8 -> libhdf5.so.8.0.1\n\nI found some posts about similar issues like\nWhy crontab scripts are not working?\nhttps://stackoverflow.com/questions/5064518/shell-script-and-cron-problems?rq=1\nFollowing that posts I set PATH in my script adding both /usr/local/rams60/build/fdgrib2/ and /usr/local/hdf5/lib/\nFor sure I am missing some simple setting but I can't see where.\nThanks in advance for your help\n\nA: Try\nsudo ln -s /usr/local/hdf5/lib/libhdf5.so.8 /usr/local/lib/\nsudo ln -s /usr/local/hdf5/lib/libhdf5.so.8 /usr/lib/\n\nThat's the general way for adding something inside PATH.\nAlso, for check, use\nldd /usr/local/rams60/build/fdgrib2/fdgrib2\n\nThis command will show what's missing in your libraries.\n", "Q: Cannot seem to get bash history along with others working This is very similar to all the other questions out there but at the same time not.\nI am running Ubuntu 12.04.4 LTS (GNU/Linux 3.2.0-59-generic x86_64) to be precise.\nI successfully setup a new user with: useradd -m webuser, however, no matter what I do I cannot seem to get most the bash functions like auto complete and history to work.\nFor example my bashrc file has:\n# If not running interactively, don't do anything\n[ -z \"$PS1\" ] && return\n\n# don't put duplicate lines or lines starting with space in the history.\n# See bash(1) for more options\nHISTCONTROL=ignoredups:ignorespace\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\nHISTSIZE=1000\nHISTFILESIZE=2000\n\nbut when I echo \"$HISTFILESIZE\" I do not get null but I do not get a result either:\n$ echo \"$HISTFILESIZE\"\n\n(Unfortunately this site doesn't allow me to actually show you since it tries to be very intelligent).\nThis goes for all history variables.\nNo matter what I do I cannot seem to get the basic environment variables to work and, as it seems the .bashrc to be read.\nOntop of this my set -o is pathetically small:\nCurrent option settings\nerrexit         off\nnoglob          off\nignoreeof       off\ninteractive     on\nmonitor         on\nnoexec          off\nstdin           on\nxtrace          off\nverbose         off\nvi              off\nemacs           off\nnoclobber       off\nallexport       off\nnotify          off\nnounset         off\nnolog           off\ndebug           off\n\nand all the question I try don't help, i.e.: https://superuser.com/questions/174306/how-can-i-enable-the-bash-command-history\nI am logging in using SSH via PuTTY.\nEdit\nOutput of echo $0 straight from the ssh temrinal:\n$ echo $0\n-sh\n\n\nA: I'm not 100% sure what -sh is, but you might be using sh, not bash. From memory, new users default to sh. To make them automatically use bash, modify /etc/passwd with root permission. e.g. one of\nsudo vim /etc/passwd\nsudo nano /etc/passwd\ngksu gedit /etc/passwd\n\nThen, find the line with your username in it. Change the final part from (e.g.) /bin/sh to /bin/bash. Restart the terminal or log in/out again.\n", "Q: Issues with Wine screen resolution Hardware: Very old Dell Inspiron 6400 laptop, onboard video, no driver support.  Planning on buying a new computer soon, but wondering if this is a hardware issue which could be solved by buying a new machine, or a software issue which can be solved with the machine I have by me not being a dolt.\nAnyway, I'm trying to play Hearthstone on Wine 1.7.14 under Ubuntu 13.10.  I've set my Wine to have a virtual desktop, because otherwise starting up Hearthstone locks my computer, as if a new process is getting mouse focus, but since that process doesn't start properly I just lose the ability to use my mouse (keyboard works fine though, and the system doesn't lag at all, just the mouse dies).  When I start up Hearthstone in my virtual desktop, I get a popup in my virtual desktop telling me something about screen resolution or some such.  I'm not quite sure what the problem is or how to fix it, and was wondering if anyone here could be of assistance.  Unfortunately I'm new to this site so I can't post an image of the error message, but here's the text of the message:\nCouldn't setup OpenGL for the requested monitor resolution\nGLContext: failed to share context 40000: Success\nScreen: could not setup GL for resolution (1152x864 fs=1 hz=60 wi...[error message gets cut off here]\nGLContext: failed to share context 30002: Success\nScreen: could not setup GL for resolution (1152x864 fs=0 hz=0 win...\n\n\nA: Thanks to RevExNET comment I solved this with the following command:\n sudo apt-get install libgl1-mesa-dri libgl1-mesa-dri:i386 \n\nFor me, only the :i386 was missing, but I'm guessing you need both.\nI believe this is an issue faced by those using intel graphic cards.\n\nA: I got the same error on my netbook. It seems to me that this error is related with https://bugs.winehq.org/show_bug.cgi?id=33407\nI built wine with a patch attached to that bug. This helps me but I found out that my netbook (Atom N570, 1Gb RAM) is too slow :) Nevertheless you can try.\nDownload a build script from https://github.com/Unity3D-Wine-Support/Unity3D-on-Wine by commands below and then edit it. I'm not sure about 'build-essential' package but I think it is better to have it installed.\nsudo apt-get install build-essential\nsudo apt-get install git\ngit clone https://github.com/Unity3D-Wine-Support/Unity3D-on-Wine\ncd Unity3D-on-Wine/Compile-Wine\nnano compile-wine-ubuntu-32bit.sh\n\nReplace version number 1.7.21 by 1.7.17 at line 48 and save the script. Then build wine and install it:\n./compile-wine-ubuntu-32bit.sh\ncd ~/wine-git\nsudo make install\n\n", "Q: msi gs70 ubuntu 13.10 stuck on boot, loading initial ramdisk new laptop, msi, 4th generation intel chip\nubuntu 13.10 installed.\ni was able to login, work normally.\nafter a couple of days I got a message 'loading initial ramdisk' on boot screen.\nreading through the forums, i added to grub cmd:\ni915.i915_enable_rc6=1, acpi_osi=Linux (without comma, can't remember which order)\nand it worked.\nthen after a couple of days, i was not able to login again.\nso i tried different options from http://www.phoronix.com/scan.php?pag...tel_i915_power\nand it worked again.\ntwo days later, i am again not able to login to ubuntu.\npreviously i had tried to install nvidia drivers (because i have nvidia geforce card). this caused a catastrophe, i had to reinstall ubuntu.\ndoes anyone have ideas on how to solve this problem?\nalso more importantly why is it happening? why would the options above work, only to fail after a couple of days?\nlaptop model is msi gs70.\nnote: i have also tried acpi=0, acpi_backlight=vendor, i915.modeset=0, nouveau.modeset=0, nomodeset, video=1280x1024-24@60, video=1:1280x1024-24@60, none of these options worked.\nany help/comments would be appreciated. \n\nA: I am having a similar issue. I have Ubuntu 13.10 dual booting with Win 8. Both OS were working fine until today when I got a blank screen trying to boot into Ubuntu from the GRUB menu. When I tried to boot via advanced options and in recovery mode I noticed it stuck on \"Loading initial ramdisk\". I have not been able to fix it yet since I am at a hotel and do not have my liveUSB. \nThe only thing that I can think of that changed on my system between the last time I logged into Ubuntu successfully and today was a windows 8 update. I foolishly never changed it from automatic updates so I have no idea what it installed. Is it possible that the windows updated somehow effected GRUB? It sounds like this is a graphics driver issue, so I am not sure how a windows update would have been to blame.\n", "Q: move forward and backward by one word In a GNOME terminal, the standard ways of moving forward or backward by one word do not work.\nIn spite of what the documentation says:\n\nalt+b : Goes back one word at a time.\nalt+f : Moves forward one word at a time.\n\nIf I do the above, I just open the drop-down menu for Tabs and Edit.\nHow can I fix this?\n\nA: From the readline manpage (readline is the library that implements these commands):\n\nAn emacs-style notation is used to denote keystrokes.  Control keys denoted  by C-key, e.g., C-n means Control-N.  Similarly, meta keys are denoted by M-key, so M-x means Meta-X.  (On keyboards  without a meta key,  M-x means ESC x, i.e., press the Escape key then the x key.  This makes ESC the meta prefix.  The combination M-C-x means  ESC-Control-x, or  press the Escape key then hold the Control key while pressing the x key.)\n\n@Galgalesh is correct that you use the Ctrl+arrow keys to jump words in Ubuntu.  In many (most?) other distributions the key combo is Alt+arrows.\nIn order to use Alt+f/Alt+b without interfering with the menus, use Esc, f (press Esc, THEN press f, not both at the same time).\nThe reason I mention this is that you can use the Esc then (key) trick for other commands, too.  E.g., if you've started editing a previous command and decide you want to revert it, use Esc, r.\n\nA: just press ctrl-→ and ctrl-←\n\nA: In the Terminal, go to Edit → Keyboard Shortcuts... and untick the Enable menu access keys box.\n", "Q: Is there a way to restrict the packages installable from a repository? I want to restrict the packages installable from a repo, eg restrict some packages to the  main Ubuntu repos, even if they are available from launchpad or some other third party repos, something like pinning some packages to certain repository.\nNormally the repository last added repo takes over all the packages which were available in other earlier repos.\n\nA: To set up AptPreferences for a set of packages add a new file in /etc/apt/preferences.d/.\nsudo gedit /etc/apt/preferences.d/my-packages-pin\n\nAdd add the following lines in that file:\nPackage: package1 package2\nPin: release o=Ubuntu\nPin-Priority: 900\n\nI will prevent ppa versions to replace packages provided by the main Ubuntu archives\nTo check if the package pin version run:\nsudo apt-cache policy package1\n\nVisit https://help.ubuntu.com/community/PinningHowto \n", "Q: What does lsof|gawk '$4~/txt/{next};/REG.*\\(deleted\\)$/{printf \">/proc/%s/fd/%d\\n\", $2,$4}' command mean I'm reading some articles and I've seen this command:\nlsof|gawk '$4~/txt/{next};/REG.*\\(deleted\\)$/{printf \">/proc/%s/fd/%d\\n\", $2,$4}'\n\nCould some body help me to understand it\n\nA: This command will print files from lsof that need truncation. \n(It actually does not remove or truncate any files).\nlsof will return a list of open files (file descriptors) that is piped into the awk which processes it as follows.\ngawk '$4~/txt/{next};/REG.*\\(deleted\\)$/{printf \">/proc/%s/fd/%d\\n\", $2,$4}'\nThe above expression contains two regular expressions separated by a semi colon ;\nlets consider the first part gawk '$4~/txt/{next};\nHere, if the 4th field contains txt then  the next line of text will be read, which the script will start processing from the start again.\nThe next statement forces awk to immediately stop processing the current record and go on to the next record. This means that no further rules are executed for the current record, and the rest of the current rule's action isn't executed. \nNow lets consider the second part of the script  /REG.*\\(deleted\\)$/{printf \">/proc/%s/fd/%d\\n\", $2,$4}'\nHere if the line matches the regular expression /REG.*\\(deleted\\)$ (the $ means that (deleted) should be the last word on the line), it just prints >/proc/%s/fd/%d\\n\", $2,$4.\nIn lsof command $4 is the file descriptor number (for example 53w, the w means the filer has been opened for writing) or filetype, depending on the file. The %d in the printf ensures that only the numbers will be printed, removing any text characters (like the w). $2 prints the process id of process which uses the file so it will print something like >/proc/3989/fd/53 and so on it will print all files that have been deleted but whose file descriptor remains open, in other words, file descriptors that can be truncated safely.\n\nA: This command will truncate deleted files from lsof.\nThis first will list open fileslsof\nthen search for lines recursively one then one{next} that contain REG '$4~/txt/{next};/REG.*\\(deleted\\)$/ as the fourth parameter then this process relative to this line will be deleted \nand then print all results without the lines containing REG and marked as deleted.{printf \">/proc/%s/fd/%d\\n\", $2,$4}'\n", "Q: How to increase cpu usage For my Thesis I want to write fortran program. I have a K53-Sm ASUS laptop with core i7 and 8Gig ram. When I run my program my CPU usage is 13%.\nHow can I increase my CPU usage to 100% on Ubuntu 13.04 and all of 8 cores CPU cores active?\n\nA: I'd suggest using the stress tool (to impose load on and stress test systems) available from the repos:\nsudo apt-get install stress\n\nAlternatively you could also try:\nhttp://bazaar.launchpad.net/~manjo/checkbox/stress-test/view/head:/checkbox-old/scripts/cpustress.c\n\nIt will stress CPU integer and floating point paths. It also execises CPU path that deals with data and text cache misses.\n\nA: You can install a power-management tool like TLP. That has a function which is turbo mode. The latter will give you all your CPU horsepower. \nIf you really want to use every single CPU to 100% you will probably also have to do some multi-threading programming, viz. create different simultaneous threads to do the computations at the same time.\n\nA: You will have to implement a message passing interface so that the CPU's can communicate.The compiler will vectorize loops (enable Software parallelization but this is only basic level of parallelism,to make full use of your CPU you will have to implement a MPI.\nNote that this will require you to restructure the program for this purpose.\nYou may also look into co-fortran.\n", "Q: Hotspot does not allow android to obtain an ip address I'm using the instructions from \nhttp://www.webupd8.org/2013/06/how-to-set-up-wireless-hotspot-access.html\nand I've tweaked it for infrastructure mode, however my android 4.2.2 device is stuck in an \"obtaining ip address loop\"\n\nA: When your Android Device doesn't get an IP it may not be served by one. Please make shure that there is a DHCP Server Process/Deamon running on your PC. Also you should have a look for a DNS Server Process/Deamon.\n", "Q: Error mounting/format/part bootable USB Error mounting: mount: block device /dev/sde2 is write-protected, mounting read-only\nmount: wrong fs type, bad option, bad superblock on /dev/sde2,\n       missing codepage or helper program, or other error\n       In some cases useful info is found in syslog - try\n       dmesg | tail  or so\n\n\ndmesg |tail output:\n[35386.452383] ieee80211 phy0: rt2800usb_entry_txstatus_timeout: Warning - TX status timeout for entry 6 in queue 0\n[35386.452401] ieee80211 phy0: rt2800usb_entry_txstatus_timeout: Warning - TX status timeout for entry 6 in queue 0\n[35386.452404] ieee80211 phy0: rt2800usb_entry_txstatus_timeout: Warning - TX status timeout for entry 6 in queue 0\n[36189.980082] isofs_fill_super: bread failed, dev=sde1, iso_blknum=16, block=32\n[37247.825497] hfsplus: invalid secondary volume header\n[37247.825501] hfsplus: unable to find HFS+ superblock\n[37542.436324] hfsplus: invalid secondary volume header\n[37542.436328] hfsplus: unable to find HFS+ superblock\n[38649.462360] hfsplus: invalid secondary volume header\n[38649.462365] hfsplus: unable to find HFS+ superblock\n\nOtherwise I usually get read-only errors etc.\nAny way of formatting/erasing this?\nI'm trying to make a bootable disk for Mac OSX, but somewhere along the way something is corrupted. I've tried programs and admin settings in Mac OSX (terminal and disk util) and similar things and programs in windows (partition manager, hp usb etc.). I've also tried the standard f-disk and such. \nI cant seem to open the graphical user interface for gparted either, even though it is installed. Any way of just wiping the whole disk clean?\nAny -su options or otherwise would be great. Thanks!\nEDIT: after 3 days and countless efforts i found the simple solution. i simply used:\nsudo nautilus\nexited the nautilus \nopened disk utility and i have no problems wiping the USB.\nHowever, windows still recalls this is a RAW, mac osx can't boot since file system almost got to fat32(but corrupted) error in diskutility: error: creating partition table: helper exited with exit code 1: cannot open /dev/sdd: Read-only file system\ntried sudo chmod in all variations, still no access...i feel like im soo close...\n\nA: If you have ever had an isohybrid image on that usb, you could have a leftover \"iso9660 filesystem\".  Since that filesystem is in the first 64 sectors of the disk, you can't delete it by deleting partitions.\nI have always been successful in repairing uncooperative usb drives with the dd command. It will wipe the whole drive, so be double-d sure that you enter the command correctly, for the correct drive. Run the command sudo parted -l first to check the correct device.\nUse this command to wipe the drive.\nsudo dd if=/dev/zero of=/dev/sdX bs=512\n  - where sdX is your usb drive, in this case, sde    \nIt will take about 20 minutes to complete an 8 GB usb drive, so be patient.     After that you can create partitions and format them.\n", "Q: No File-Preferences Menu I am using Ubuntu 13.10 and Nautilus, in order to configurate my image preview, i wanted to access the file menu.. but there are no preferences at all. is it possible to enable / disable them?\n\nA: I can't find the preferences dialog (and the hud is empty) but in between you may configure something using dconf-editor (installing the package dconf-editor) and modify some value in org.gnome.nautilus.\nI use it to switch on treeview in list : org.gnome.nautilus.list-view.use-tree-view\n", "Q: What is the \"t\" letter in the output of \"ls -ld /tmp\"? When running the command ls -ld /tmp, the output would be:\ndrwxrwxrwt 30 root root 20480 Mar 11 14:17 /tmp\n\nSo I have two main questions:\n\n\n*\n\n*What is the letter t after the permissions?\n\n*As far as I know /tmp is used to create temporary files related to\ndifferent users in the system, so how come it has permission rwxrwxrwx (777)?\n\n\nThis seems wrong for me. Please I need your help to understand what is going here.\n\nA: \nA Sticky bit is a permission bit that is set on a file or a directory that lets only the owner of the file/directory or the root user to delete or rename the file. No other user is given privileges to delete the file created by some other user.\n\nSometime it happens that you need Linux directory that can be used by all the users of the Linux system for creating files. Users can create, delete or rename files according to their convenience in this directory.\n\nNow, what if an user accidentally or deliberately deletes (or rename) a file created by some other user in this directory?\nWell, to avoid these kind of issues, the concept of sticky bit is used. Since /tmp is used for this purpose. So to avoid the above scenario, /tmp use  sticky bit.\n\nFor example:\nmkdir demo\nchmod 777 demo\n\nI also created two file with different user in this folder having permission 777.\nls -ld demo\ndrwxrwxrwx 2 guru guru 4096 Mar 11 18:17 demo\n\nls -l demo\n-rwxrwxrwx 1 abhi abhi    0 Mar 11 17:11 file1\n-rwxrwxrwx 1 anshu anshu   0 Mar 11 18:15 file2\n\nNow turn on the sticky bit on this\n chmod +t demo/\n ls -ld demo\n drwxrwxrwt 2 guru guru 4096 Mar 11 18:17 demo\n\nNow what happens if one user(abhi) want to rename the 2nd user(anshu)\nmv /home/guru/demo/file2  /home/guru/demo/file3\nmv: cannot move '/home/guru/demo/file2' to  '/home/guru/demo/file3': Operation not   permitted  \n\nThe origin of the sticky bit\nOn Linux, the sticky bit only has the use described above, on directories. Historically, it was used for something completely different on regular files, and this is where the name comes from.\n\nWhen a program is executed, it takes time to load the program into memory before the user can actually start using it. If a program, for example an editor is used frequently by users the the start-up time delay was an overhead back then.\nTo improve this time delay, the sticky bit was introduced. The OS checked that if sticky bit on an executable is ON, then the text segment of the executable was kept in the swap space. This made it easy to load back the executable into RAM when the program was run again thus minimizing the time delay.\n\nModern systems such as Linux manage their cache of executables and other files automatically and don't need the sticky bit for that.\nSource: “Linux Sticky Bit Concept Explained with Examples” at The Geek Stuff\n\nA: A stickybit is a workaround method for shared directories not to be deleted accidentally. When a directory has a stickybit then only the owner or the root can delete it even that every user can take the full other permissions.\n/tmp is the most shared directory between processes and users and for that it contains the stickybit to ensure that no user can delete the directory, even that the permission is 777 , and it must be so to give the ability to the users and processes to use the directory without conflict in permissions.\n\nA: So what is the sticky bit?\nA sticky bit is a permission bit that is set on a directory that allows only the owner of the file within that directory, the owner of the directory or the root user to delete or rename the file. No other user has the needed privileges to delete the file created by some other user.\nThis is a security measure to avoid deletion of critical folders and their content (sub-directories and files), though other users have full permissions.\nWhy does /tmp have the t sticky bit?\nThe /tmp directory can be used by different Linux users to create temporary files. Now, what if a user deletes/renames a file created by some other user in this directory?\nWell, to avoid these kind of issues, the concept of sticky bit is used. So for that a 777 is given but preserving the sticky bit is not a bad idea.\nHow can I set up the sticky bit for a directory?\nI'll set a sticky bit on a directory called test on my Desktop.\nUsing symbolic notation (t represents the sticky bit):\nchmod o+t ~/Desktop/test\n\nor\nchmod +t ~/Desktop/test\n\nUsing octal notation (1 in the first position represents the sticky bit):\nchmod 1757 ~/Desktop/test\n\nNow let us test the results:\nls -li ~/Desktop/test\n\n1551793 drwxrwxrwt 45 hadi hadi 20485 Mar 11 14:35 ~/Desktop/test\n\nTo delete/Remove a sticky bit\nchmod o-t ~/Desktop/test\n\nNow let us test the results:\nls -li ~/Desktop/test\n\n1551793 drwxrwxrwx 45 hadi hadi 20485 Mar 11 14:35 ~/Desktop/test\n\nSource: “What is a sticky Bit and how to set it in Linux?” at The Linux Juggernaut\n", "Q: Problems reading filesystem of recorded DVD-R I am experiencing problems when trying to read DVD-Rs or DVD+Rs recorded by different TV DVD Recorders. Usually the problem is that when I try to manually Mount the dvd with the udf option (with auto option same output):\n   giankun@giankun-imedia-S3810:~$ sudo mount -o ro -t udf  /dev/sr0 /media/giankun/dvd\n   mount: tipo fs errato, opzione non valida, superblocco su /dev/sr0 danneggiato,\n   codepage o programma ausiliario mancante, o altro errore\n   In alcuni casi si possono trovare informazioni utili in syslog. Provare\n   ad esempio 'dmesg | tail'\n\nWhich says \"fs type wrong, invalid option, superblock on /dev/sr0 damaged, etc. \nAnd dmesg | tail\n   [ 2525.446871] UDF-fs: error (device sr0): udf_read_tagged: read failed, block=36641552,       location=0\n   [ 2525.446878] UDF-fs: warning (device sr0): udf_fill_super: No fileset found\n   [ 2892.059449] nouveau E[     DRM] DDC responded, but no EDID for VGA-1\n   [ 4317.181251] UDF-fs: error (device sr0): __udf_read_inode: (ino 2145710) failed !bh\n   [ 4317.282267] UDF-fs: error (device sr0): __udf_read_inode: (ino 2145709) failed !bh\n   [ 4317.383362] UDF-fs: error (device sr0): __udf_read_inode: (ino 2145708) failed !bh\n   [ 4317.484452] UDF-fs: error (device sr0): __udf_read_inode: (ino 2145707) failed !bh\n   [ 4317.484464] UDF-fs: Failed to read VAT inode from the last recorded block (2145710), retrying with the last block of the device (2145711).\n   [ 4317.485948] UDF-fs: error (device sr0): udf_read_tagged: read failed, block=36641552, location=0\n   [ 4317.485954] UDF-fs: warning (device sr0): udf_fill_super: No fileset found\n\nAnd this when I try to mount as iso9660\n   giankun@giankun-imedia-S3810:~$ sudo mount -o ro -t iso9660 /dev/sr0 /media/giankun/dvd\n   mount: tipo fs errato, opzione non valida, superblocco su /dev/sr0 danneggiato,\n   codepage o programma ausiliario mancante, o altro errore\n   In alcuni casi si possono trovare informazioni utili in syslog. Provare\n   ad esempio 'dmesg | tail'\n\nwith relative dmesg | tail\n   [ 4395.151558] ISOFS: Unable to identify CD-ROM format.\n\nI think this is not a problem with my hardware because on the same machine W7 (I have dual boot) can read the disks and extract the files (most of those disks must then be decrypted since they are CPRM encoded coming from a Japanese DVD recorder). However the drive is an ATAPI DVD A DH16ABSH. I already tried switching to IDE mode from AHCI (bios setting) but nothing worked. \nI must add any other disk (including DATA DVD and original Video DVDs) is correctly mounted. Is there a way to Mount these particular disks? Is this a known bug (I have found some short references of people having the same problem online, but no solutions like in this discussion)?\nHere is what I can exctract from one of those disks by Nero, KB, and a Windows util I downloaded:\nNero:\nDisc Information (E:\\)\n------------------\nType                                                                              : :DVD-R\nCapacity                                                                          : 487:54.50  (828 MB)\nTracks                                                                            : 3\nSessions                                                                          : 1\n\nFile System                                                                       : , UDF\nTitle                                                                             : n/a\nDate                                                                              : n/a\nPublisher                                                                         : n/a\nApplication                                                                       : n/a\n\nKB:\nMedium\n\nType:   DVD-R Sequential\nMedia ID:   MXL RG04\nCapacity:   487:54:50 min (4,2 GiB)\nUsed Capacity:  487:54:50 min (4,2 GiB)\nRemaining:  00:00:00 min (0 B)\nRewritable: no\nAppendable: no\nEmpty:  no\nLayers: 1\nSessions:   1\nSupported writing speeds:   6.0x (8310 KB/s)\n8.0x (11080 KB/s)\n12.0x (16620 KB/s)\n16.0x (22160 KB/s)\nISO9660 Filesystem Info\n\nSystem Id:  -\nVolume Id:  -\nVolume Set Id:  -\nPublisher Id:   -\nPreparer Id:    -\nApplication Id: -\nVolume Size:    0 B (0 B * 0 blocks = 0 B)\nTracks\n\nType    Attributes  First-Last Sector   Length\n1   (Data)  no copy/uninterrupted   0 - 543 544 (00:07:19)\n2   (Data)  no copy/uninterrupted   560 - 831   272 (00:03:47)\n3   (Data)  no copy/uninterrupted   848 - 2195599   2194752 (487:43:27)\n\nDvd Info:\n----------------------------------------------------------------------------\nUnique Disc Identifier : [DVD-R:MXL RG04]\n----------------------------------------------------------------------------\nDisc & Book Type :       [DVD-R] - [DVD-R]\nManufacturer Name :      [Hitachi Maxell Ltd.]\nManufacturer ID :        [MXL RG04]\nBlank Disc Capacity :    [2,298,496 Sectors = 4.71 GB (4.38 GiB)]\n----------------------------------------------------------------------------\n[ DVD Identifier V5.2.0 - http://DVD.Identifier.CDfreaks.com ]\n----------------------------------------------------------------------------\n\n\n** INFO : Hex Dump Of 'Media Code'-Block Listed Below\n** INFO : 4-Byte Header Preceding 'Media Code'-Block Discarded\n** INFO : Format 0Eh - Pre-Recorded Information In Lead-In\n0000 : 01 40 c1 fd 9e d8 52 00  02 85 0e 0d 99 ab 80 00   .@....R.........\n0010 : 03 4d 58 4c 20 52 47 00  04 30 34 00 00 00 00 00   .MXL RG..04.....\n0020 : 05 88 80 00 00 00 02 00  06 09 0b 15 87 78 90 00   .............x..\n0030 : 07 88 80 00 00 00 00 00  08 08 13 0d 11 0c 08 00   ................\n0040 : 09 95 07 0e 0b 78 88 00  0a a0 00 20 00 20 10 00   .....x..... . ..\n0050 : 0b 09 19 17 97 88 85 00  0c b6 89 2b 82 30 23 00   ...........+.0#.\n0060 : 0d 00 00 d0 00 00 00 00  00 00                     ..........      \n\n** INFO : Hex Dump Of 'Control Data Zone'-Block Listed Below\n** INFO : 4-Byte Header Preceding 'CDZ'-Block Discarded\n** INFO : Format 10h - Physical Format Information Of Control Data Zone\n0000 : 25 0f 02 00 00 03 00 00  00 26 12 7f 00 00 00 00   %........&......\n\n\nA: You have to choose the filesystem type:\nsudo mount /dev/sr0 /media/x/dvd -t FILESYSTEMTYPE\n\nOptions are: \n\n\nauto - this is a special one. It will try to guess the fs type when you use this.\next4 - this is probably the most common Linux fs type of the last few years\next3 - this is the most common Linux fs type from a couple years back\nntfs - this is the most common Windows fs type or larger external hard drives\nvfat - this is the most common fs type used for smaller external hard drives\niso9660 mostly for CDs\nudf mostly for DVD on newer windows\n\n\ncd and dvd filesystems are mostly iso9660 or udf\n", "Q: Nvidia drivers making unity not working fine I just installed Ubuntu 12.04 on my Gigabyte P35K. Unity was working fine at the first boot, but then I installed the Nvidia driver and now when I move a window it is pretty slow, when I take the window to one border it does not resize, etc... I know that it is not a problem from the unity configuration because I broke my last install trying to fix this problem...\nIs there a problem with the latest nvidia driver? I installed it using sudo apt-get install nvidia-current.\nThank you in advance for your answers.\n\nA: I found out that after installing nvidia-current there is a new pilot in the Additional Drivers section of the system settings. Activating this new pilot fixed everything!\nHope it works if it happens to someone else.\n", "Q: 13.10 Support Cycle I am running 12.04 LTS and want to upgrade to 13.10.\nWhen does the 9 month support cycle end?\nWhat happens to 13.10 when it ends?\nDoes the Update manager upgrade you to the next version / release when available and before the cycle ends for 13.10?\n\nA: Ubuntu 13.10 will be supported until July 2014. Here's a graph that shows support cycles for every ubuntu versions:\n\n", "Q: grep keeps printing the same string I typed grep ch->spl[4] * into my shell to look for something in a mud code and its broken grep now.\nAny time I try to grep anything pretty much it puts the spl[4] before the filename like this.\n[:spl[4]:spl[4]:spl[4]:spl[4]:spl[4]:spl[4]:spl[4]:spl[4]:spl[4]:act_wiz.c:           if ( vch->timer > 0 )\n\nQuestion is how do I clear/stop this so I can get my normal grep back?\n\nA: What does grep ch->spl[4] * do? It will search for the pattern ch- in all files (and directories) in your current directory and save the result in the file spl[4]. To avoid this, you should always quote your grep patterns:\ngrep \"ch->spl[4]\" *\n\nStill, the behavior you describe is very strange, there is no reason why this would have changed you your grep works. What is probably happening is that you keep searching through the spl[4]  file (because you are grepping *) and that file contains the output you see. Chances are that if you delete it, things will go back to normal.\n", "Q: First steps in verifying random crashes? Recently my system has been acting weird. I consider it stable and I leave my system pretty much running 24/7. However, just about an hour ago I decided to get out of the PC for a bit and do my things, when I come back I noticed that the PC somehow rebooted to the login screen and some of the things I had running somehow got corrupted. \nThings that got corrupted: \nKDE configurations: lost my wallpaper settings and folder widgets I had set. I'm glad it was only this since it's pretty trivial.\nAnyway, I want to become more... efficient in analyzing and resolving these issues if I can. What are the recommended steps to verify these issues? \nWhat I did at least today was read the syslog and kernel logs but nothing gave me any indication that there was anything wrong to cause a crash or force it to reboot.\n\nA: First 2 basic Steps are:\n\n\n*\n\n*Read the syslog and dmesg (/var/log/syslog* and /var/log/dmesg*) and check for errors\nright before the last boot. In dmesg the boot is at [0.000000], so you want right before that.\n\n*Memtest! Your RAM may have gone byebye.\n\n\nA: It depends on where the problem is. If you're loosing you KDE wallpapers for example, system logs will be irrelevant, instead you should check ~/.xsession-errors and /var/log/xorg.0.log where progrms about GUI programs are listed.\nRunning dmesg (or /var/log/dmesg which is the same thing) will often give useful information but it is very unlikely to contain any information about this type of thing.\nKDE probably has it's own logs as well but I don't use it so I'm not sure. They might be under /var/log but more likely are .dotfiles somewhere in your $HOME.\nDifferent problems end up in different log files, the only general advice is \"check the log files\". \n", "Q: Access folders with sudo priviliges via Nautilius-Connect to remote server I need to access the /var/logs folder & many such folders on my remote server from nautilus, using \"Connect to server\" via ssh. I avoid root logins & have disabled it. I would like to use sudo instead, just like I do it with SSH sessions in terminal.  How can I have nautilus use sudo on the remote server to gain access? (Root login is disabled on server)\nIf not nautilus itself, are there any alternates that may help accomplish this ?\n\nA: Obviously running Nautilus as your local root account (with sudo, gksu, etc) isn't going to give you root access on the server.\nThe problem is that the SFTP server within OpenSSH (which is what Nautilus is connecting to) doesn't support commands like sudo — it's not a shell environment. What you're asking for simple isn't possible through the standard mechanisms.\nHowever you are not without options. I'm not sure how familiar with SSH you are but you can tunnel ports back across a connection so you could connect normally, run a simple FTP server as root and tunnel all that back to your computer over SSH. Sounds horrible but it's fairly simple.\nOn the server, run:\n# newer Ubuntu installs:\nsudo apt-get install python-pyftpdlib\n\n# older Ubuntu installs\nsudo apt-get install python-pip\nsudo pip install pyftpdlib\n\nThen from your computer, just run a short SSH command:\n# If you installed with pip\nssh -tL localhost:2121:localhost:2121 -L localhost:21212:localhost:21212 user@server \"sudo python -m pyftpdlib -i localhost -w -p 2121 -r 21212-21212 -d /\"\n\n# If you installed with apt-get (and pyftpdlib is pre-1.3, true in 13.10)\nssh -tL localhost:2121:localhost:2121 -L localhost:21212:localhost:21212 user@server \"sudo python -m pyftpdlib.ftpserver -i localhost -w -p 2121 -r 21212-21212 -d /\"\n\nAnd then in Nautilus (on your computer), connect to ftp://localhost:2121. The magic of SSH will forward that over to the FTP server running as root.\nThere are other protocols (I've spent a while looking for a better one) but FTP is the easiest to get up and running thanks in large part to pyftpdlib. You could do similar things with webdav et al, I'm sure... It would just be a lot more hacking around.\n\nA: \nIf not nautilus itself, are there any alternates that may help accomplish this ?\n\nHave you tried WinSCP? You can download a portable executable from their website and execute it using WINE.\n\n\n*\n\n*Install WINE using sudo apt-get install wine\n\n*Download and unpack the portable executable from http://winscp.net/eng/download.php\n\n*Run WinSCP.exe using the context menu or run wine WinSCP.exe\n\n*Set the File protocol to SCP and input your Host and User name\n\n*Open the \"Advanced\" window and set the Shell option in Environment-> SCP/Shell to sudo su -\n\n*Login to your host\n\n*You can now access the logs using the internal editor or WINEs Notepad\n\n\nDrag & Drop from Nautilus is also possible.\n\nA: Launch nautilus from a terminal with gksudo nautilus.\nRemember that GUI tools running with root permissions is not a good policy. \n\nA: This might not be the best way, but just a thought, \nif your remote server has X11 enabled, you can simply prelaod a command \n\nssh -X usr@svr:~/ gksudo nautilus.\n\nBut @Oli got it covered, you can't use SFTP server within OpenSSH \nAlso this isn't too bad of an idea, but if you also allow your sshuser only read access to the files you need, your  problem is solved. \n\nA: I'm not sure if I am properly answering but maybe I can help a little.\nssh into your server with ssh -XC user@address\nThe -XC tag will pipe the window to your computer when something is opened. \nThen try sudo nautilus and then your server's nautilus will open on your local screen. \n", "Q: Installation of dual-boot 13.10 on MBP freezes I've been trying to install Ubuntu 13.10 on my Macbook Pro (15\", Mid-2009, i.e. with dual graphics chips) via bootcamp. I can boot off the disk, select a language, and select \"Install Ubuntu\". Then a whole lot of text scrolls past quickly but at some point it stops and freezes (attached picture shows the frozen screen). I have waited for ca. half an hour for any change, nothing happens. The DVD drive seems to stop reading as well. \nSome more info:\n\n\n*\n\n*My MacOS version is 10.9.2 (not sure this is relevant)\n\n*I am using the desktop-amd64+mac.iso burned to a DVD\n\n*My internal DVD drive appears to be broken so I am using an external drive\n\n\n\nAny help would be much appreciated.\n\nA: Macbook pro's boot in EFI mode, whereas the bootcamp loader emulates a legacy bios in order to boot windows.\nThis is not the best solution for installing ubuntu 13.10 to a mac, as it can be handled natively in efi mode via grub2, or if you prefer refind.\n\n\n*\n\n*Decide on a bootloader that will manage your operating systems. I suggest grub as it can be repaired in the event of problems using the boot-repair app (which works very well with my mac5,5), and it can detect your OSX/Windows partitions. Alternatively as already mentioned refind is an elegant solution for mac's.\n\n*Follow the steps here to get a live USB working for your mac, then hold 'alt' on boot. This should give you the option to boot and install ubuntu in EFI mode.\n\n*When installing select the 'something else' option to partition your disk. Ensure you only install the grub bootloader to the partition of your ubuntu installation.\n\n*Refind will detect a linux partition automatically, however if you have opted for grub you may (as in my case)\nneed to run boot-repair from the live usb.\n\n\nTo download the boot-repair you will need to enable networking (use the proprietary driver to get this up and running on the macbook):\n\n\n*\n\n*open a new Terminal, then type:\n$ sudo add-apt-repository ppa:yannubuntu/boot-repair && sudo apt-get update\n$ sudo apt-get install -y boot-repair && (boot-repair &)\n\n*Press ENTER\nFollow the instructions, then reboot. You should now have ubuntu working natively on the macbook pro.\nGood luck, I hope this helps.\n", "Q: CPU is running significantly hotter after installing gfx driver and using Ubuntu 3D I have an HP 17\" laptop with an ATI graphics card. I'm using Ubuntu 12.04 LTS.\nA while ago I noticed that Ubuntu is running in 2D mode and I didn't like that so after some research I stumbled upon this https://askubuntu.com/a/252040/74345 and followed the exact steps to fix things. Everything went fine and I'm using 3D mode now.\nHowever, after the restart I noticed my CPU is significantly hotter. Before the changes I made the temp never passed 50 degrees and after the update it's never getting below 70 degrees -_-.\nIs this a known thing? What's happening exactly? At least where do I start my investigation? \nIs it possible that it's using the CPU for the animations insdead of the GPU?\nThank you!\n\nA: This is just how ATI GPUs work; they run hot.  You can lower the performance setting to help some though:\nsudo -s\necho low > /sys/class/drm/card0/device/power_profile\nexit\n\nYou can use mid instead of low for a more balanced setting.\n", "Q: Fatal error: gl/glut.h: no such file or directory I'm attempting to write a program and I keep getting this error:\nFatal error: gl/glut.h: no such file or directory\n\nI've read through other similar problems that people were having, and nothing has worked for me. What can I do to solve this problem?\n\nA: On Ubuntu 13.10 this file is available in the freeglut3-dev package.\n$ sudo apt-get install freeglut3-dev\n\nYou must also be aware that C++ and Ubuntu are both case-sensitive. The correct include line in your program is:\n#include <GL/glut.h>\n\nThe upper-case \"GL\" is important.\n\nA: On a Debian based system, do\nsudo apt-get install libglfw3-dev libgl1-mesa-dev libglu1-mesa-dev\n\n", "Q: How to send/receive files via Bluetooth using commands/Terminal? I have installed Bluetooth dongle software and\nwith the help of commands (using a terminal), I want to send and receive files from a smartphone.\nHow can I pair my devices and send files over Bluetooth using Terminal?\n\nA: I tested this with Ubuntu Bionic Beaver (18.04) and Android Lollipop.\n\n\n*\n\n*Ubuntu. Install the needed packages:\nsudo apt install bluez bluez-tools\n\nbluez-tools come with the following tools: bt-adapter bt-agent bt-device bt-network\n\n*Ubuntu. Turn on the visibility:\nbt-adapter --set Discoverable 1\n\n\n*Smartphone. Scan for remote devices to ID your Ubuntu machine.\n\n*Ubuntu. Prep for managing incoming requests interactively with:\nbt-agent\n\n\n*Pair devices:\n\n\n*\n\n*Smartphone. Initiate pairing request;\n\n*Ubuntu. Accept the request from the bt-agent screen.\n\n\n*Ubuntu. Send files to smartphone with: \nbt-obex -p [remote_mac] [file]\n\nwhere [remote_mac] is the mac address of the smartphone. For example:\nbt-obex -p F0:6B:CA:A2:C4:69 ~/book.pdf\n\n\n*Receive files from your smartphone: \n\n\n*\n\n*Ubuntu First create a Bluetooth file (obex) server:\nbt-obex -s [path]\n\n[path] is where to download files. For example:\nbt-obex -s ~/Downloads\n\n\n*Smartphone. Send the file;\n\n*Ubuntu. Accept the request from the bt-agent screen.\n\n\n\nA: Send files:\nbluetooth-sendto --device=12:34:56:78:9A:BC filename\n\nTo know your device name (12:34:56:78:9A:BC), you can issue this command:\nhcitool scan\n\nReceive files:\nHaven't found it yet, but will let you know if it can be done using terminal\nedit: \nit looks like it can't be done through terminal. Blueman seems to do the trick but it's in GUI\n\nA: This works on my computer:\nbluedevil-sendfile -u /org/bluez/hci0/dev_<address with underscores instead of colons> -f <file_with_absolute_path>\n\nFor example:\nbluedevil-sendfile -u /org/bluez/hci0/dev_00_FF_00_FF_00_FF -f /home/tux/test.pdf\n\n", "Q: How are packages classified in apt-mark showauto/showmanual? I compare the outputs of\n$ dpkg --get-selections | grep -v deinstall | awk ' { print $1 } ' > dpkg.txt\n\n$ apt-mark showmanual > manual.txt\n\n$ apt-mark showauto > auto.txt\n\nI think that  \n\n\n*\n\n*dpkg.txt will be all packages\n\n*manual.txt will be \"primary\" packages\n\n*auto.txt will be dependencies of packages in manual.txt\n\n\nI checked and dpkg.txt is the \"sum\" of auto.txt and manual.txt as I expect but I am seeing \"primary\" packages such as apport, locate, unzip, zip in auto.txt and lots of lib files (dependencies?) in manual.txt.\nWhy is that?\nI have looked at man apt-mark but that does not explain my question:\n\n       showauto\n           showauto is used to print a list of automatically installed packages with each package on a new line. All automatically installed\n           packages will be listed if no package is given. If packages are given only those which are automatically installed will be shown.\n\nand\n\n       showmanual\n           showmanual can be used in the same way as showauto except that it will print a list of manually installed packages instead.\n\nI also point out that I have not marked packages using apt-mark auto or apt-mark manual.\nPlease note that I don't have any problems with my system. This is only for my understanding.\n\nA: We cannot just say that apt-mark showmanual shows only dependecies that are automatically installed.\nSome packages which normally would be auto-installed\nare marked otherwise because they or their depender are in special\nsections.\nSo its normal that if you do:\n$ apt-get install foo\nNEW: foo\n\nyou get it as manually installed\non the other hand, if it is:\n$ apt-get install foo\nNEW: foo foo-data\n\nfoo-data will appear as automatical installed.\nMorover\nIf foo is automatical installed and you do:\n$ apt-get install foo\n\nat the end of the operation foo will be marked as manually installed.\nWe are asking a machine to be clever, but machines are idiots.\nWe might not have installed an Xserver,which is there in manually installed (You must be like when did I install Xserver manually), but the installer did because it\nbelieves we need it and don't want it removed. The same goes for installing\ngnome and marking everything gnome depends on as manual because\nusers assume that removing just the (metapackage) gnome will not\nautomatically also remove all the gnome applications they grow used to.\nThen we follow a tutorial or we use one of those diseases like crappy\ninstaller scripts from dubious sources which just apt-get install everything.\nThis is distinct from your usecase of getting to know which packages are\ninstalled by you rather than some automated process. It might overlap at\ntimes, but not always. The big problem you have to face is that it is\npretty hard to decide if you or software ordered an installation. Many\ntimes its both. \nExample: An application which installs packages (for you)\nto enable hardware support (for you). [do you see what I did here?]\nIs this auto or manually installed?\nFirst: An auto-installed packages has 'Auto-Installed: 1' Flag set.\nSecond: If you have no data, default to a safe option and this is here\n\"auto-installed: 0\" (= manually installed) as it isn't removing anything.\nSo you can't just say that one contains completely manually installed and the other one completely automatically installed.\n(It has also historical reasons as this tracking wasn't implemented from\n the beginning and there was a time people cared about upgrades a lot).\n", "Q: Print from command line How can I print the command line output directly to the printer.\nI am using ubuntu server 12.04 and I have to copy files into a shared directory and then download them from a desktop ubuntu distribution to print them.\nAny help is appreciated\n\nA: Mainly there are two default commands:\nlpr and lp\nman lpr gives the output:\n\nlpr  submits  files  for  printing. Files named on the command line\n  are\n         sent to the named printer (or the default destination if no destination\n         is  specified).  If  no files are listed on the command-line, lpr reads\n         the print file from the standard input.\n\nman lp gives the output:\n\nlp submits files for printing or alters a pending job. Use  a \n  filename\n         of \"-\" to force printing from the standard input.\n\nso easily use the command:\nlp /path-to-file-to-print\n\nOr\nlpr /path-to-file-to-print\n\n\nA: If you have them installed, another pair of options worth knowing about are\n\n\n*\n\n*enscript\nand \n\n\n*\n\n*a2ps\nThese are useful for providing numbered pages with headings and optional line-numbers.\nYou can also use then to print booklet style (e.g. two pages on each side of a sheet)\nI use these with Postscript-capable printers but I believe that Ubuntu's print system can rasterize PS for any supported printer.\n\nA: You may want to find out how the printer is accessed first - lpstatwill give you that information. If you compare its output across both systems, you can probably tell whether the printer in question has been configured on both of them. lpstat -p -d lists all printers with their status and tells which one has been set as default printer.\nYou can simply pipe your output to the lp or lpr command then. You may want to insert a filter for pretty-printing or pagination though. There's a good summary of tools at the debian manual \"Highlighting and formatting plain text data\", but I'm usually just using sed to highlight prompts and other stuff before sending everything through a2ps\n\nA: To print a .txt file in a  use :\ncommand | lpr -P printername -p ( periority from 1 to 100 )\n\nExample : \nls -l | lpr -P printername -p 1 \n\n\nA: You can use the lp command.\nTo print the output of a command to the default printer (use lpstat -d to see what the default printer is):\necho \"test\" | lp\n\nTo print to a specific printer (use lpstat -p | awk '{print $2}' to list available printer names):\necho \"test\" | lp -d printername\n\nTo print a file, rather than a command output:\nlp /path/to/file\n\n\nA: You can use lp\nFor example:\nman firefox | lp -d printername\n\nThis will print the man page from firefox to the specified printer\n\nA: The question is about how to print from the command line on a server, and it sounds like you don't yet have any printers defined on that system. I don't have a system to check on so the following are approximate, but they should give you the general idea:\n\n\n*\n\n*Make sure the CUPS system is installed and running. It provides the\ndaemons that will handle your print jobs.\n\n*Once this is up, you need to set up one or more network printers to\nprint to. The usual way to install printers is with the Printer\nAdmin utility, but you evidently aren't set up to run any GUI\nprograms from your server-- just commandline access via ssh. Since\nyou already have an Ubuntu desktop system on the same network, I'd\ntry copying the contents of the directory /etc/cups from the desktop box to the\nserver. It should contain all the printer definitions and drivers you need. \nCheck the files for any necessary adjustments (in case your\nset-up mentions user IDs or passwords that differ between the two systems),\nrestart cupsd, and if you're lucky you'll be able to use lpr to\nprint from the commandline.\n\n\nPS. In a pinch, you could install enough X utilities to run the Print Admin GUI utility via a remote X connection to your desktop Ubuntu box (log in with ssh -X), and define the printers you need. But hopefully this won't be necessary.\n\nA: If you want to control various layout options, fonts, font size, etc. you can use enscript as suggested by RedGrittyBrick.\nsudo apt install enscript\n\nA few details that may be useful:\n\n*\n\n*The fonts you can use are the ones which have an .afm file in /usr/share/enscript/afm/\n\n*The font name to use with the -f option must be the short name listed as FontName in it's .afm file. For example: \"ZapfDingbats\", not \"ITC Zapf Dingbats\".\nThese names are also listed in the /usr/share/enscript/afm/font.map file.\n\n*If you want to see which monospaced fonts you have available, you could use something like this:\nfor f in /usr/share/enscript/afm/*.afm; do grep -q '^IsFixedPitch true' \"$f\" && grep FontName \"$f\"; done\n\n*To set the font size, append \"@n\" to the font name.\n\n*You can get the list of printer names to use for the -d or -P option withlpstat -p\nExample print command :\nfont=Courier@9\nprinter=HP-4350\n\nyour_command | enscript -P $printer -f $font --tabsize=4\n\n# or for files:\nenscript -P $printer -f $font --tabsize=4 $Your_file_to_print\n\nThere are of course many more options listed with man enscript.\n", "Q: Will a kernel update overwrite my wireless driver from a newer kernel? i run ubuntu Release 12.04 (precise) 64-bit Kernel Linux 3.2.0-59-generic but I installed the wireless driver from backports-3.13-rc2-1. Now all works well. \nMy question is about the kernel update because if I install the proposed security update to Linux 3.2.0-60-generic it overwrite the wireless driver I patched. \nIs there a way to install the new kernel maintaining the wireless driver from backports-3.13-rc2-1??\nBest Regards\n\nA: You compiled backports against your currently running kernel only. That means that when a later kernel version is installed by Update Manager, you must recompile:\ncd ~/Desktop/backports-3.13-rc2-1  <-or wherever you downloaded the file\nmake clean\nmake defconfig-rtlwifi  <-or whatever suite you compiled\nmake\nsudo make install\n\nAnother option is to simply install the 3.13 kernel from here: http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.13-trusty/ I suggest you get all the deb files appropriate to your architecture; either 32- or 64-bit; find out with:\narch\n\nFor instance, if yours is a 32-bit system (i686), then I suggest you download linux-image i386, linux-headers i386 and linux-headers all. Download them to your desktop and install with:\ncd ~/Desktop\nsudo dpkg -i linux*.deb\n\nReboot and you should be all set.\n", "Q: A setting which disables a network connection after a specified period Is there any program or setting which can automatically disable a network connection after 5 minutes when it is enabled manually?\nSo that the user will have to enable the connection every 5 minutes manually, if they need it more than 5 minutes.\n\nA: No need to ping google, you can check the status of the network directly with nmcli.\nHere's a script I whipped up for ya real quick:\n#!/bin/bash\n\nwhile :; do\n    if $(nmcli nm enable | grep -q enabled); then\n        echo 'Found connection! You got 5 minutes!'\n        sleep 300\n        nmcli nm enable false\n    else\n        echo 'No connection, checking again in 30s.'\n        sleep 30\n    fi\ndone\n\nJust run this script at startup and it will stay running forever, constantly checking for an internet connection, and if it finds one it will disable it 5 minutes later.\n\nA: Just to archive the answer:\n#!/bin/bash\n\nwhile :; do    \n    if $(nmcli dev list iface eth0 | grep -q \"not connected\"); then\n        sleep 60        \n    else        \n        sleep 300        \n        nmcli dev disconnect iface eth0\n    fi\ndone\n\nwhere eth0 is the connection that is to be disconnected.\n", "Q: Unable to start my apache After I downgraded my php5.5 to php5.3.10, I no longer able to start my apache2. \nHere is what I get:\nsudo service apache2 start \n[sudo] password for fcasili:   \n* Starting web server apache2                                                \napache2: Syntax error on line 210 of /etc/apache2/apache2.conf: Could not open configuration file\n/etc/apache2/mods-enabled/access_compat.load: No such file or directory Action 'start' failed. The Apache error log may have more information.\n\nI already tried purging my apache2 and re-install it again. Please help\n\nA: You've made a downgrade, I suppose by removing and re-installing packages.\nThis probably not removed all the configuration done previously.\nThe way the configuration of Apache is made in Ubuntu is no more to link every module load and configuration file separately and explicitely in the main config file but just by pointing to the site-enabled/, mods-enabled/ and conf-enabled/ directories for files ending by .conf and .load.\nThe content of these directories is in turn symbolic links towards a file in the site-available/, mods-available/ and conf-available/ directories, where the packages provided files are stored.\nI suspect that the downgrade you've done removed the access_compat.load file in the mods-available/ directory but left the symbolic link mods-enable/access_compat.load untouched, so making it a dead link.\nLook in your mods-enable/ directory for dead links and remove it (or them).\n\nA: It seems your problem is in  /etc/apache2/apache2.conf\nSo all you have to do is disable the line that makes the problem:\n\n\n*\n\n*Open the file:\ngksu gedit  /etc/apache2/apache2.conf\n\n*Find the line:\nPress CTRL+F\ntype access_compat.load\n\n*Comment it as follows:\n#Include mods-enabled/access_compat.load\n\n*save file and restart apache\nsudo service apache2 restart\n\nA: apt-get install libapache2-mod-php5\n", "Q: Unable to install ccmake [Preface: I have seen similar questions, but that did not help me and so this new question. To explain in more detail, I followed the steps in How do I resolve unmet dependencies after adding a PPA?, without rectifying the problem]\nI am trying to install ccmake.\nHowever, I get the following error:\nsudo apt-get install cmake-curses-gui\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n cmake-curses-gui : Depends: cmake (= 2.8.7-0ubuntu4)\nE: Unable to correct problems, you have held broken packages.\n\nI tried sudo apt-get -f install, but it did not help.\nI am unable to find broken packages either.\n\nA: cmake-curses-gui depends on cmake (= 2.8.7-0ubuntu4) for a precise installation.\nIf you're unable to install this particular version it means that you installed a different version on your system.\nTry first to uninstall cmake:\nsudo apt-get remove cmake\n\nAnd install again cmake-curses-gui:\nsudo apt-get install cmake-curses-gui\n\nIf it doesn't work check if you're not pulling a different version of cmake from a ppa.\n", "Q: How can I download and install refind bootloader (0.7.7.1)? I've seen an answer on installing Ubuntu on MSI-GT60 laptop on this site. It suggests that I should install rEFInd bootloader but I can't find it anywhere.\nHow can I install this?\n\nA: Download rEFInd Boot Manager for Ubuntu from its page here or the current version 0.7.8 from  Sourceforge. \nSince it is .deb file installation is as easy as double clicking the .deb file which will open the installer to install it. \nor from the terminal you can do \ndpkg -i name_of_file_you_downloaded.deb\n\nto install it.\n\nA: Instructions for refind are here:\nhttp://www.rodsbooks.com/refind/\nhttp://www.rodsbooks.com/linux-uefi/#troubleshooting\n", "Q: Run bash script from php I want to run a shell script within a php webpage to check some processes running on my system (Ubuntu 12.04). Googleing I've found about shell_exec() but I can't manage to run the script when loading php.\nThis is the php code I use.\n$output = shell_exec('./dirlist.bash');\necho \"<pre>$output</pre>\";\n\nand the piece of html I get\n<pre></pre>\n\nAlso tried $output = shell_exec('sudo -u www-data ./dirlist.bash');\ndirlist.bash does ls -l     (just for testing script and shell_exec)\nI think it is not a permission problem. Running directory grants write and execute privileges for all users (I should be careful here).\ndrwxrwxrwx  4 meteo meteo 4096 mar 11 15:20 RAMS\n\nUser www-data has been added to sudoers file in case it was needed\nwww-data ALL = (meteo) NOPASSWD: /home/meteo/www/RAMS/dirlist.bash\n\nThanks in advance\n\nA: You probably need to chdir to the correct directory before calling the script. This way you can ensure what directory your script is \"in\" before calling the shell command.\n$old_path = getcwd();\nchdir('/my/path/');\n$output = shell_exec('./script.sh var1 var2');\nchdir($old_path);\necho \"<pre>$output</pre>\";\n\n", "Q: Install 64bit Ubuntu in VirtualBox I installed VirtualBox and downloaded Ubuntu 64 bits. When I select Linux under VirtualBox, only Ubuntu 32 bits is shown. \nAm I doing something wrong that stops the 64bit option from appearing? \nMy machine as a Windows 7 64 bit OS with 8GB of RAM.\nVBox screenshot\n\nA: Most probably your processor is not the 64-bit one, thats why VirtualBox is not able to run 64-bit kernels,or in most cases of new computers VT  (Virtualization Technology) which is required to run 64-bit guest is disabled in BIOS settings which you could change in BIOS section of your machine.\nTo check whether your processor is able to support VT or not,run the following commands in your terminal window.\n grep --color vmx /proc/cpuinfo.\n\n grep --color svx /proc/cpuinfo\n\nAs vmx is a flag for Intel's processor and svm is for AMD's processor. If the output shows vmx or svm your machine is capable to VT. \n\nA: Your issue is that you need to create a 64bit virtual machine. You have probably created a 32bit one which is why the option does not appear. From the VBox website (emphasis mine):\n64-bit guests\n\nVirtualBox supports 64-bit guest operating systems, even on 32-bit\n  host operating systems, provided that the following conditions are\n  met:\n  \n  \n*\n  \n*You need a 64-bit processor with hardware virtualization support (see the section called “Hardware vs. software virtualization”).\n  \n*You must enable hardware virtualization for the particular VM for which you want 64-bit support; software virtualization is not supported for 64-bit VMs.\n  \n*If you want to use 64-bit guest support on a 32-bit host operating system, you must also select a 64-bit operating system for the particular VM. Since supporting 64 bits on 32-bit hosts incurs additional overhead, VirtualBox only enables this support upon explicit request.\nOn 64-bit hosts (which typically come with hardware virtualization support), 64-bit guest operating systems are always supported\n  regardless of settings, so you can simply install a 64-bit operating\n  system in the guest.\nWarning\nOn any host, you should enable the I/O APIC for virtual machines that\n  you intend to use in 64-bit mode. This is especially true for 64-bit\n  Windows VMs. See the section called “\"Advanced\" tab”. In addition, for\n  64-bit Windows guests, you should make sure that the VM uses the Intel\n  networking device, since there is no 64-bit driver support for the AMD\n  PCNet card; see the section called “Virtual networking hardware”.\nIf you use the \"Create VM\" wizard of the VirtualBox graphical user\n  interface (see the section called “Creating your first virtual\n  machine”), VirtualBox will automatically use the correct settings for\n  each selected 64-bit operating system type.\n\nSo, just try creating a new Virtual Machine and select Ubuntu 64 as the OS. All the settings should be correctly configured by VirtualBox and you should be able to install with no problems. \n", "Q: Ubuntu installation on Windows 7 Can anyone provide me with link of ubuntu setup(non .iso file) so that i can install it side-by-side on windows without writing on cd or usb flash drive?\n\nA: You want the wubi installer. A very nice guide for that is available here. https://wiki.ubuntu.com/WubiGuide. I suggest you read it thoroughly and then step through it. I've used this method before with excellent results for clients who wanted to try Ubuntu but were uncomfortable with the idea of completely dumping windows. \nEdit: It doesn't appear as if the official wubi is currently in development, however an active fork  of the project can be found here that supports all currently supported versions of Ubuntu. There are some differences between the official wubi and the fork, so it's a good idea to read the docs on the home page as well as the related info for Mok Manager.\n\nA: Here you have the solution:\nhttp://www.ubuntu.com/download/desktop/windows-installer\nBut anyone provided you with the same answer.\nI have one Ubuntu 13.10 with Windows 7. Please avoid Windows 8.\n", "Q: How to copy a file to multiple folders using the command line? I have tried to copy a file test.txt to multiple directories with one command:\ncp ~/test.txt ~/folder1 ~/folder2\n\nBut I didn't succeed. Is there a way to do that in one command so I can copy a file or even a folder to multiple directories?\n\nA: cp can copy from multiple sources, but can't copy to multiple destinations. See man cp for more info.\nThe only bash command that I know which can copy/save to multiple destinations is tee. \nYou can use it in your case as follows:\ntee ~/folder1/test.txt ~/folder2/test.txt < ~/test.txt\n\nNote that tee also writes the input to the standard output (stdout). So if you don't want this, you can prevent it by redirecting standard output to /dev/null as follow:\ntee ~/folder1/test.txt ~/folder2/test.txt < ~/test.txt >/dev/null\n\n\nA: Another way to achieve a copy to multiple locations is the following command :\nfind dir1 dir2 -exec cp file.txt {} \\;\n\nIf dir1 or dir2 have sub-directories that you don't want the file copied into, add\n-maxdepth 0option :\nfind dir1 dir2 -maxdepth 0 -exec cp file.txt {} \\;\n\nNote that this will overwrite every file in dir1 and dir2 with file.txt's contents, in addition to copying it. To only copy file.txt without affecting other files in these directories, tell find to only act on directories:\nfind dir1 dir2 -type d -exec cp file.txt {} \\;\n\n\nA: The command\ncp ~/test.txt ~/folder1 ~/folder2\n\ntries to copy two files (~/test.txt and  ~/folder1) to the destination folder2. (And if ~/folder2 exists and is a directory you will have an \"omitting directory\" warning).\nIf you want to make multiple copies of the file test.txt, you have to use a loop or multiple commands...\nfor i in ~/folder1 ~/folder2; do cp  ~/test.txt $i; done \n\n(...and be careful if you have spaces embedded in the file names, you'll need quoting).\nTo copy whole directories you have to use the -r option:\nfor i in ~/folder1 ~/folder2; do cp -r ~/folder3 $i; done\n\nthis will create ~/folder1/folder3 and ~/folder2/folder3 with all the files included.\n(Learnt 8 years further down the line: notice that you must be careful with spaces in file names. If you have them, change $i with \"$i\", and be careful about quoting them).\n\nA: You can create a help script , or you can do it with xargs and a print function (in this case, echo ):\necho firstDir secondDir | xargs -n 1 cp test\n\nThis will make each directory as an argument to the cp function , using test file as a parameter.\n\nA: After a long search this work like a Charm also !\nfor dir in *; do [ -d \"$dir\" ] && cp /path/file.txt \"$dir\" ; done\n\nThis will copy file.txt to every directory in your current location in terminal.\nfor dir in *; do [ -d \"$dir\" ] && cp -rf /path/folder \"$dir\" ; done\n\nThis will copy a folder to every sub directory in your current location in terminal.\nI share it hope it helps others too .\n\nA: If you want to copy the file test.txt in every directory in /tmp/target/ ...\ncreate a test environment:\nmkdir /tmp/target\ncd /tmp/target\nmkdir -v {folder1,folder2,folder3}\ntouch test.txt\n\ncopy it:\nfind * -maxdepth 0 -type d -exec cp -vi test.txt {} \\;\n\n\nA: Just thought to give a variation to the answer of Sylvain Pineau \nwhere dir1 and dir2 are not in your current directory.\nfind ./ -maxdepth 2 -type d -name dir1 -exec cp file.txt {} \\;\nhere find will look for dir1 two levels deep or you can leave out -maxdepth parameter to find dir1 in all folders in current directory and below it.\n\nA: For files only without preserving attributes. Great if you're copying huge files and only want to read them once:\ncat file1 >file2 >file3\n\nFor files or directories\nxargs -n 1 cp file1 <<< 'file2 file3'\nxargs -n 1 cp -r dir1 <<< 'dir2 dir3'\n\n\nA: I needed to post html index files in the home directory of 10 newly created sub-domains. I created a file with the markup called sites-index and placed it in my working directory and another called sites-home that contained a list of full paths to the copied files on each line (eg /var/path/to/site1/public_html/index.html).\nAfter a bit of searching here I lighted on the following bash script:\nwhile read file; do cp sites-index \"$file\"; done < sites-home\n\nThe script loops through the list, copies the html file at each iteration and sets each line in the list as the new path to which the html is copied.\nTo run in terminal, type sudo -i to start a root shell (enter your password when prompted). Execute the script.\nAlternatively, you can save the command in a text file, for example index.sh and invoke it by typing at the terminal prompt, sudo bash index.sh.\nIf you run the script without sudo you'll see a list of the files that weren't created due to insufficient permission. If it executes correctly your files will be created without notice.\n\nA: parallel cp foo {} ::: */ will copy foo to all the directories in the current directory in parallel:\n$ cd \"$(mktemp --directory)\"\n$ mkdir a 'b c'\n$ touch foo\n$ parallel cp foo {} ::: */\n$ ls --recursive \n.:\n a  'b c'   foo\n\n./a:\nfoo\n\n'./b c':\nfoo\n\nUseful if you want to do this quickly. Just remember that you need to quote the command or double-escape, for example:\n$ cd \"$(mktemp --directory)\"\n$ mkdir 'a b' 'c d' 'e f'\n$ touch 'a b/foo'\n$ parallel \"cp 'a b/foo' {}\" ::: 'c d' 'e f'\n$ ls --recursive \n.:\n'a b'  'c d'  'e f'\n\n'./a b':\nfoo\n\n'./c d':\nfoo\n\n'./e f':\nfoo\n\n", "Q: how to mount with udisks to specified directory I have ubuntu 12.04 and I need a portable solution (to work on various linux systems) and to be in my user's home directory for mounting a partition after login or after boot.\nFrom what I searched on web I saw that using udisks is the best solution but what I did not find is how to mount the auxiliary partition to a specified mount point (directory path)\nWhat I have so far is (by device name):\n/usr/bin/udisks --mount /dev/sdbX\n\nor (by uuid):\n/usr/bin/udisks --mount /dev/disk/by-uuid/1313-F422\n\nbut there is no example on how to specify the mount point.\nFor me, it is mandatory to have a specific directory target (/media/AUX/ for example).\nIs there a way to do this (not necessarily using udisks) ?\n\nA: udisks won't mount your partitions like this. Moreover if you want persistent mount I'd suggest to edit /etc/fstab to add:\nUUID=YOUR_OWN_PARTITION_UUID /media/AUX/ ext4 defaults 0 0\n\nNote: edit /etc/fstab using sudo as it requires root privileges\nThen reboot to see your drive / partition properly mounted\n\nA: Not with udisks\nIf this is a USB connected device (portable solution), all you have to do is change the label on the disk to match what you want. (you can use gparted or Disk Utility for this for example). A USB connected drive/partition labelled AUX will automatically be mounted at /media/AUX.\n", "Q: Why is kswapd0 running on a computer with no swap? I have a cloud server with ~14G of RAM and no swap. However, I occasionally see kswapd0 taking up some CPU when I run top. Why would kswapd0 be running at all if there's no swap space for it to manage?\n\nA: Swap space is only used for data that is not backed by any other file.  Data that is mapped from other files on disk ( such as executable programs ) is still swapped to their respective files even if you don't have a swap device.\n\nA: If you have no swap and kswapd0 is running, your system is actually using nearly all of the RAM at that moment. It's time to get better tools to monitor memory usage (or free/available memory in the system).\nFor example, consider a case where you have zero swap and system is nearly running out of RAM. The kernel will take memory from e.g. Firefox (it can do this because Firefox is running executable code that has been loaded from disk - the code can be loaded from disk again later if needed). If Firefox then needs to access that RAM again N seconds later, the CPU generates \"hard fault\" which forces Linux kernel to free some RAM (e.g. take some RAM from another process), load the missing data from disk and then allow Firefox to continue as usual. This is pretty similar to normal swapping and kswapd0 does it\nThe real fix is to reduce memory usage (run processes with less memory leaks, run less processes, skip running some processes at all, limit number of children/worker processes of some server software) or to get more RAM. If the need for RAM is caused by memory leaks, you may opt to use swap instead. Linux should be pretty smart getting the leaked parts to swap given enough time. Having swap is better than nothing but that is not a real substitute for having adequate amount of RAM.\n\nA: Malware running as guest\nIf you have ever enabled Ubuntu's guest account and later enabled SSH, you may have malware running using your guest account.\nsudo find /home -f kswapd0\n\nYou might find it under /home/guest/.configrc/\nMany people are finding this question today on machines that require no swapping, and seeing that their available memory is normal, only to find out mining software has been installed and is running under the guest account, even automatically on startup.\nOne sign of this is that a single CPU core is being throttled to 100%, while disk activity is normal. In my case, the computer was running incredibly hot with an abnormal amount of outgoing network data.\nJoining any network (conference, cafe, city) that has a compromised machine, or if you use a service like ngrok, all while having SSH open on your system leaves your computer exposed to this simple guest vulnerability.\nAn entry dedicated to this problem is here: CPU 100% with kswapd0 process, although no swap is needed\n\nA: It is a well known problem that when Linux run out of memory it can enter swap loops instead of doing what it should be doing, killing processes to free up ram. There are an OOM (Out of Memory) killer that does this but only if Swap and RAM are full.\nHowever this should not really be a problem. If there are a bunch of offending processes, for example Firefox and Chrome, each with tabs that are both using and grabbing memory, then these processes will cause swap read back. Linux then enters a loop where the same memory are being moved back and forth between memory and hard drive. This in turn cause priority inversion where swapping a few processes back and forth makes the system unresponsive.\nIf you disable swap you make this problem worse as kswapd0 now have no option than to swap out mapped memory such as executables. If you swap out executables it is even more likely that they will be swapped back in again rather quickly.  \nI tried triggering this behavior in NetBSD for testing and what happened there is that the the offending process became incredible slow while the OS itself was very responsive. Meaning that the swapping problem do occur but there are no priority inversion. However NetBSD doesn't have AMDGPU drivers so I am sticking to Linux for time being. Perhaps NetBSD doesn't memory map executables and that is why it doesn't enter swap loops but I don't really know enough about it's implementation to say why it doesn't become unresponsive.\nFacebook had this problem as well and created the OOMD which is the Out Of Memory Daemon. This is daemon that detects kswapd0 activity and starts killing processes. And according to Facebook this almost entirely removed the problem of Linux servers becoming unresponsive. However I have not tested it and I don't know how well it will work on other servers or desktop/laptops. Appealingly OOMD has some logic deciding what processes to kill first in order to preserve system processes and the part of their server system that are responsible for relaunching whatever was killed. \nHowever this is not how it should be solved. OOMD is an UGLY HACK. The real solution is to fix the priority inversion that a swap loop causes as well as making the kernel OOM Killer more aggressive at killing processes to free memory. The fix belong in the kernel because that's the only place where it we can be sure that the problem is detected in time and processes are being properly killed.\nSetting swappiness=0 is no solution because when the system is out of free RAM it starts swapping no matter what. There are no option to guarantee that the system doesn't start swapping. \nAnd also fixing the offending applications is not a fix. Expecially not if a user wants to exploit this bug in order to intentionally make the OS unresponsive. To be responsive is the responsibility of the kernel. If Firefox makes itself unresponsive then the fix is to the application. However it is not only making itself unresponsive but causing the entire OS to become very slow and unresponsive. To the level that it can take half an hour to log in to SSH. The SSH has nothing to do with and if it doesn't get to run that is a bug in the kernel, not in any other part of the system. And it is not a bug it is two bugs. One bug is priority inversion where a off the rails swapping cycle is allowed to interfere with other processes than the offending process(es) and that in itself is bad. The other bug is that it doesn't detect that it is in a swap loop and that causes insane wear on the HDD/SSD or whatever storage that is backing the swap. When swapping executable this is less of a problem as they are read only memory maps which aren't written back to disks but kswapd0 still gets locked reading back what it at the same time are deleting from memory. \nOh and there is a third bug. The fact that there are no way to protect disk CACHE from being eaten when memory hungry applications swallow all available memory. This is one of the reasons that kswapd0 makes the system unresponsive. The most hot memory mapped data are usually stored in the disk cache but when firefox has eaten that cache, well it obviously means that disk reads will have to occur. \nIt's not necessarily Firefox that are causing your problem but it is the default browser, not Chrome. And both are widly known to trigger this problem as they treat available memory as something that is wasted, including cache and swap memory which in Linux counts as \"available memory\". So in order not to get \"available memory\" get's wasted it use it for caching and other stuff. Obviously using SWAP for DISK CACHE is a VERY BAD IDEA but the fellows at both Firefox and Chrome respond to that with \"free memory is wasted memory\". \nSo what we have here is three kernel bugs that the kernel team do not seem to consider bugs. And a bug in Firefox, Chrome and all derivatives that they do not consider a bug. I tried building Firefox on my Fedora laptop in order to look into this problem and perhaps patch it. Guess what. Building Firefox with GCC on a 4 core CPU with 4GB ram triggers a SWAP LOOP with PRIORITY INVERSION. So one of the applications that has to be rewritten is GCC. On NetBSD what happens is just the 4 running instances of GCC gets slower than running one instance but it doesn't freeze the system. \nYeah this is a bit of a rant but I hope that it clarifies the current problem with the Linux memory subsystems as well as the applications that cause it. \n\nA: It still has a process to check if there's any swap. To reduce it, you'll need to set your swappiness -\nedit \"/etc/sysctl.conf\" as root, then change (or add)\nvm.swappiness = 0\n\n\nA: Anybody facing this issue, it happens due to crypto malware on the server.\nPlease check  if there is a folder called .rsync (or .configrc in my case) under /root. Usually you will find the program kswapd0 under the folder a/.\nIf you find that suspicious folder, then with high probability your server is infected.\nThis will also create some cronjobs looks like below:\n# crontab -l\n1 1 */2 * * /root/.configrc/a/upd>/dev/null 2>&1\n@reboot /root/.configrc/a/upd>/dev/null 2>&1\n5 8 * * 0 /root/.configrc/b/sync>/dev/null 2>&1\n@reboot /root/.configrc/b/sync>/dev/null 2>&1  \n0 0 */3 * * /tmp/.X206-unix/.rsync/c/aptitude>/dev/null 2>&1\n\nAlso, you may find some strange ssh-key added to your server:\n#cat .ssh/authorized_keys\nssh-rsa AAAAB3NzaC1yc2EAAAABJQAAAQEArDp4cun2lhr4KUhBGE7VvAcwdli2a8dbnrTOrbMz1+5O73fcBOx8NVbUT0bUanUV9tJ2/9p7+vD0EpZ3Tz/+0kX34uAx1RV/75GVOmNx+9EuWOnvNoaJe0QXxziIg9eLBHpgLMuakb5+BgTFB+rKJAw9u9FSTDengvS8hX1kNFS4Mjux0hJOK8rvcEmPecjdySYMb66nylAKGwCEE6WEQHmd1mUPgHwGQ0hWCwsQk13yCGPK5w6hYp5zYkFnvlC8hGmd4Ww+u97k6pfTGTUbJk14ujvcD9iUKQTTWYYjIIu5PmUux5bsZ0R4WFwdIe6+i6rBLAsPKgAySVKPRK+oRw== mdrfckr\n\nYou may see kswapd0 process consuming the CPU 100% and no swap is used.\nIf you have all these symptoms,\n\n*\n\n*kill all kswapd0 processes,\n\n*delete /root/.configrc folder,\n\n*delete the cronjobs,\n\n*delete the suspicious ssh keys\n\n*reboot\n\nMonitor the server after this. If is reoccurs, then have the backup of your data and re-install the server asap.\n\nA: Well, I had the issue, taking lots of RAM, no swap, and my laptop hangs completely.  Killing the offending processes automatically did not seem to work, so now I made sure I had swap installed, to stabilize my machine.  This seems to have worked.\nLike 20 years ago, this also worked in Linux, it just killed what didn't fit, and that was that, now I had to hard boot my machine every time it took up too much RAM, and that's really not what I had expected.  At all.\n", "Q: 2operating systems on same desktop? \"After your computer restarts, choose 'Ubuntu' from the boot menu.\"\nis it possible to choose between ubuntu and windows each time the desktop is started up ?\n\nA: Yes it is possible to do this.  If you install Ubuntu from a live disk or live USB, it will ask you if you want to erase windows or install alongside.  If you select install alongside every time you turn on your computer it will ask you to boot either Ubuntu or Windows. \n\n", "Q: Installed libgdx and OpenGl in ubuntu first let me say thanks for all the help in my other questions; the answers have really help a lot.  Now I'm in the process in developing game for tablet, pc and android platform.  \nI have decided to use libgdx and opengl for my games in the future since I'm focusing in java; the big question is how do i installed it in Ubuntu?\nThanks in advance\np.s if i have to use eclipse in the process or terminal I'm game:)\n\nA: Your hardware/driver need to support the required OpenGL version, you can check the version reported using\nglxinfo | grep \"OpenGL version\"\n\nThe first step is to install the development libraries of OpenGL/Glut in Ubuntu:-\nsudo apt-get install freeglut3 freeglut3-dev\n\nFor newer versions of Ubuntu (>= 11.10) you have to install another package because the linker does’t link anymore.\nsudo apt-get install binutils-gold\n\nFor libgdx its really hard to state all things here but please refer to this link to learn how to configure and install.\n", "Q: Moving tab title position from top to bottom in Ubuntu terminal I had to recently moved to Ubuntu 12.04 from 10.04. I am used to see terminal titles in the bottom and prefer the same. Is there some way that I can change the tab title from top to bottom?\n\nA: I am assuming that you are using gnome-terminal, the default terminal emulator in Ubuntu. In this case, as Elder Geek said in his answer, I don't think that you have any possibilities to do this.\nAs alternative, you can use Konsole, a terminal emulator built for the KDE Platform, which also works great in Ubuntu and which has exactly the behavior about you asked:\n\n\nA: Move to top\ngsettings set org.gnome.Terminal.Legacy.Settings tab-position top \n\nMove to bottom\ngsettings set org.gnome.Terminal.Legacy.Settings tab-position bottom\n\n\nA: Currently there is no way to do this (other than possibly rewriting the source code).\n\nA: It is possible to move the tab position from the top default to the bottom of the Terminal window in Ubuntu (I have version 18.10)\ngsettings set org.gnome.Terminal.Legacy.Settings tab-position bottom\nTo move the tabs to the top just issue the same command as above but with top:\ngsettings set org.gnome.Terminal.Legacy.Settings tab-position top\n", "Q: Flash suddenly stopped working in SeaMonkey / Ubuntu 13.10 Somehow flash just stopped working in SeaMonkey. It has version 11.2.202.291 which is relatively recent, and was working until a few days ago (I do not know exactly when it stopped working.)\nFirefox gets its version from /usr/lib/flashplugin-installer/libflashplayer.so and that one works just fine. However, if I try to use that version with SeaMonkey, it doesn't even get detected...\nAlso, I clicked on the link \n\nFind updates for installed plugins at mozilla.com/plugincheck\n\nand the plugin is shown as current / valid.\nAny idea what would be happening?\n\nA: Well! I had the 32 bit version because a while back the 64 bit version of SeaMonkey would crash all the time. I tried to run the stock 64 bit version of SeaMonkey and it crashed over and over again but I had the time to see that it was version 2.0.1. I guess no one bothered updating that crashing version. Oh well...\nI went to Mozilla and downloaded the latest (2.5.x) and installed that 64 bit version. That works like a charm! Not only is it capable to use the same Flash binary than Firefox, but that way I have access to all sorts of plugins, way more than before.\nNote that in the process I lost all my bookmarks, but the files from the 32 bit version were still available so all I had to do is load them and I got my bookmarks back. To load those, you have to go in your ~/.mozilla folder, then find the \"default\" directory for SeaMonkey. It should be fairly easy to find.\n", "Q: Mac os X theme for Ubuntu 13.10 I installed Mac OSX theme for Ubuntu 13.10 (I am a new Ubuntu user), and I am wondering how I can remove (not hide) the left menu bar, and move all programs to the bottom menu bar (Max OSX theme).\n\nA: You can't. \"Unity\" is the Desktop Environment you are currently using and it is built to be with a left menu bar and a dash. You could hide it, but there isn't any option to remove it.\nIf you want to get closer to the OSX look, you should change your Desktop Environment.\nIn my opinion, I would think that the best suited for this would be \"Cinnamon\" or \"Xfce\".\nNote : those 2 screenshots were found on Google Image and show how you can turn Cinnamon & Xfce into a OSX-look-alike. None of these Desktop Environment are like this by default.\n\nCinnamon :\n\nCinnamon is a Linux desktop created by the Linux Mint Team, which provides advanced innovative features and a traditional user experience. The desktop layout is similar to GNOME Panel (GNOME 2); however, the underlying technology was forked from GNOME Shell (GNOME 3). The emphasis is put on making users feel at home and providing them with an easy to use and comfortable desktop experience.\nTo install cinnamon 2.0 on Ubuntu :\nsudo add-apt-repository ppa:gwendal-lebihan-dev/cinnamon-stable\nsudo apt-get update\nsudo apt-get install cinnamon\n\nAfter installing all the necessary packages, just log out and change the log-in option to Cinnamon.\nThis D.E. (Desktop Environment) has a built-in theme manager provided by Linux Mint and Cinnamon Community.\n\nXfce :\n\nXfce is a lightweight and modular Desktop environment currently based upon GTK+ 2 though in the future it may be ported to GTK+ 3. Xfce contains a suite of applications such as a window manager, a file manager, and a panel to provide a complete user experience. Xfce is popular with many users, partly because it is lightweight but also because a large amount of settings are exposed in a GUI. This is in sharp contrast to desktops such as GNOME Shell which hide many settings from the user.\nTo install xfce 4.10 on Ubuntu :\nsudo apt-get install xubuntu-desktop\n\nAfter installing all the necessary packages, just log out and change the log-in option to Xfce.\n\nAfter a tour, and if you are satisfied with one of these new D.E., you can uninstall Unity.\nBut please aknowledge that I (personnaly) think that you should use Ubuntu the way it was meant to be used, even if the possibility of tweaking the OS is one of the main Linux-feature. In my humble opinion, I think that if you like OSX, you should buy a MAC instead of making Ubuntu looking like it, because Ubuntu will never be OSX (and it's not his goal).\n", "Q: When repairing package catalog: Failed to remove essential system package I recently made the mistake of trying to install a newer version of libattr1 from Trusty on my Precise installation so I could use Trusty's newer CMake(bad idea, I know). Halfway through the installation, it failed with an error. Now, the Software Center wants me to repair the package catalog. When I try, however, I get this:\n\nApt-get gives a slightly more descriptive error when I try to install something:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nYou might want to run 'apt-get -f install' to correct these.\nThe following packages have unmet dependencies:\n libattr1 : Breaks: libattr1:i386 (!= 1:2.4.46-8ubuntu2) but 1:2.4.46-5ubuntu1 is installed\n libattr1:i386 : Breaks: libattr1 (!= 1:2.4.46-5ubuntu1) but 1:2.4.46-8ubuntu2 is installed\nE: Unmet dependencies. Try using -f.\n\nSeems to be a circular dependency issue or something. When I run sudo apt-get install -f, this appears:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nCorrecting dependencies... Done\nThe following packages were automatically installed and are no longer required:\n  bluez-alsa:i386 libsdl-ttf2.0-0:i386 libgconf-2-4:i386 libstdc++5:i386\n  libgail18:i386 libqt4-qt3support:i386 libcupsimage2:i386 libnss3:i386\n  gtk2-engines:i386 libgudev-1.0-0:i386 libcairo-gobject2:i386\n  libavc1394-0:i386 libaio1:i386 odbcinst1debian2:i386 libqt4-test:i386\n  libqt4-designer:i386 libsdl-mixer1.2:i386 libcap2:i386 libproxy1:i386\n  ibus-gtk:i386 libdbus-glib-1-2:i386 libtdb1:i386 libspeex1:i386\n  libibus-1.0-0:i386 libcanberra-gtk-module:i386 libcanberra0:i386\n  gtk2-engines-murrine:i386 libwavpack1:i386 libqt4-opengl:i386\n  libsoup-gnome2.4-1:i386 gstreamer0.10-plugins-good:i386 libiec61883-0:i386\n  libsdl-image1.2:i386 libxaw7:i386 libgdbm3:i386 libesd0:i386 libmikmod2:i386\n  libpulse-mainloop-glib0:i386 libaa1:i386 libao4:i386 pax libxmu6:i386\n  libcanberra-gtk0:i386 libvorbisfile3:i386 libqt4-svg:i386\n  libgail-common:i386 libraw1394-11:i386 libnspr4:i386 libshout3:i386\n  libdv4:i386 rpm librpmbuild2 gstreamer0.10-x:i386 libsdl-net1.2:i386\n  libgnome-keyring0:i386 libxtst6:i386 gtk2-engines-pixbuf:i386\n  libtag1c2a:i386 libssl0.9.8:i386 libmad0:i386 gtk2-engines-oxygen:i386\n  lib32z1 xaw3dg:i386 librpmsign0 libpulsedsp:i386 libodbc1:i386\n  libqt4-scripttools:i386 lsb-core libxp6:i386 alien libxmlrpc-core-c3\n  ncurses-term icc-profiles-free glib-networking:i386 libsoup2.4-1:i386\n  libtag1-vanilla:i386 libaudiofile1:i386\nUse 'apt-get autoremove' to remove them.\nThe following packages will be REMOVED:\n  google-earth-stable ia32-libs ia32-libs-multiarch:i386 libacl1:i386\n  libattr1:i386 softmaker-freeoffice\n0 upgraded, 0 newly installed, 6 to remove and 0 not upgraded.\n2 not fully installed or removed.\nAfter this operation, 484 MB disk space will be freed.\nDo you want to continue [Y/n]? \n\nThe thought of removing all those packages that seem critical freaks me out. What should I do? I don't even dare restart my computer now.\n\nA: Sometimes if everything is broken, this command help. \nsudo dpkg --configure -a\n\nA: Solved! I checked the answer pointed out in the comments and ended up doing this:\nsudo mv /usr/share/doc/libattr1/changelog.Debian.gz # /usr/share/doc/libattr1/changelog.Debian.gz.old\n# the above was because apt-get was complaining about files not being the same\nsudo apt-get install -f libattr1=1:2.4.46-5ubuntu1\n\n", "Q: How to serve .deb files compiled for amd64 without receiving errors that i386 .deb files are not available? I have a repository on a ubuntu 12.04 server that is serving .deb files for only 64 bit architectures.\nWhen I run apt-get update I get the following\nW: Failed to fetch https://test.com/repo/dists/precise/Release Unable to find expected entry 'main/binary-i386/Packages' in Release file (Wrong sources.list entry or malformed file)\n\nI'm using reprepro to add the .deb files to the repository\nreprepro -Vb . includedeb precise package_amd64.deb\n\nAnd in my distributions file /var/www/site/repo/conf/distributions I am only specifying amd64 bit architectures.\nOrigin: apt.site.com\nLabel: apt repository\nCodename: precise\nArchitectures: amd64 source\nComponents: main\nDescription: debian package repo\nSignWith: yes\nPull: precise\n\nI circumvent the error by having my sources.list file include an entry that includes [arch=amd64]\ndeb [arch=amd64] https://apt.site.com/repo precise main\n\nHowever I would like to avoid having to specify that in my sources.list file.  Is there anything I can configure on the repository to tell clients trying to pull files from the repo that they should only expect .deb files compiled for amd64 architectures?\n\nA: On amd64 systems, apt tries to get both amd64 packages and i386 packages. This is (at least partially) because i386 packages are installable on amd64, and some applications and libraries are i386 only (Skype comes to mind). Therefore, apt has to get the list of i386 packages as well. Therefore, you get that error.\nAs for something on the server side, one way is edit the configuration file to allow i386 as well, and run reprepro -Vb . export. This will create an empty i386 Release and Packages file.\n", "Q: Mouse and keyboard not working after 10 minutes my laptop for a whole week has gone crazy, what I mean?\nWell... when I open it, all works good, the mouse and the keyboard, but, after 10 minutes, all stops working, and I can't move the mouse or write anything.\nDoes anybody know what is the problem, please...?\nThank you!\n\nA: Try shutting down and restarting the laptop.\nCheck the logs for errors. \nRun a memory test. If you can't find the memtest86+ option on the menu see this.\nCheck smart status of drives.\nIn case of overheating, blow out the vents and consider installing TLP.\n\nA: Might be worth playing with power manager settings. Just trying this on my clean install of 20.04. Thought it was specific to wireless keyboard and mouse but borrowing a wired one same thing. In my case mouse pointer still moves but buttons don't respond. Will report back shortly.\nHappens even if no programs running.\nWill report back in half an hour or so.\nEdit: so far no joy with power manager settings but found this https://fitzcarraldoblog.wordpress.com/2018/08/06/how-to-move-a-mouse-pointer-automatically-in-linux-to-simulate-user-activity/ and that has solved the problem for me.\n", "Q: UnicodeDecodeError when running ubuntu-support-status I had a problem during update 12.04 and asked the question yesterday.I tried the suggested solutions. Now I got the following message (update problem still remains):\nthomas@thomas-Satellite-P200:~$ ubuntu-support-status \n\n\nTraceback (most recent call last): File \"/usr/bin/ubuntu-support-status\", line 79, in help=_(\"Show unsupported packages on this machine\").decode(enc)) UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 13: ordinal not in range(128)\n\nAny ideas?\nEdit:\nThe topic yesterday was: Problem after updating 12.o4\nAnswer was to try one of the solutions of:\n\"How do I fix a “Problem with MergeList” or “status file could not be parsed” error when trying to do an update?\" \nI tried that and came up with the above file.\n@ Florian Diesch: \n\"locale\" created the following file:\nthomas@thomas-Satellite-P200:~$ locale\nLANG=C\nLANGUAGE=de_DE:en\nLC_CTYPE=\"C\"\nLC_NUMERIC=de_DE.UTF-8\nLC_TIME=de_DE.UTF-8\nLC_COLLATE=\"C\"\nLC_MONETARY=de_DE.UTF-8\nLC_MESSAGES=\"C\"\nLC_PAPER=de_DE.UTF-8\nLC_NAME=de_DE.UTF-8\nLC_ADDRESS=de_DE.UTF-8\nLC_TELEPHONE=de_DE.UTF-8\nLC_MEASUREMENT=de_DE.UTF-8\nLC_IDENTIFICATION=de_DE.UTF-8\nLC_ALL=\n\n\nA: As you have the environment varable $LANGUAGE set to de_DE:en programs (like ubuntu-support-status) will use German messages if possible. But as $LC_CTYPE is set to C they will assume ASCII character encoding. This leads to errors with messages containing umlauts and other non-ASCII characters.\nIf you want messages in English set $LANGUAGE to C. Otherwise set $LC_CTYPE to de_DE.UTF-8 (or some other UTF-8 locale).\n", "Q: Resource monitor I have a VPS that I have just purchased and I want to start monitoring the resources as I refuse to pay for the additional feature on the management tool to do that.\nI wondered if there is something out there that can log resource usage (CPU, Mem, Disk) that just sits in the background logging and if resources get too hi then notify me. Is this something I should write in bash and run as a cron job??\nI just want something light that wont be resource hungry.\nThanks\n\nA: If you want web interface - try munin it works quite good out of the box, for cli users i'd recommend atop utility.\nBy default atop will write system info to log in /var/log/atop/atop_YYYYMMDD or to /var/log/atop.log (depending on version) with 10 minutes resolution, only way to change it now is to edit atop's init script :(\nReports for atop can be generated with atopsar.\nNote that any monitoring installed on the same host it's watching will not be available in case of severe problems on that host (and when you'll probably need it most).\n", "Q: How to connect to a L2TP VPN given some info from a sysadmin I have been given some details of a VPN I am meant to connect to, and can't for the life of me get it to work under Kubuntu.\nThe info I have been given is (fake values substituted where appropriate of course):\n\nI have configured a new VPN account for you on our server.\nYour login details are as follows:\nIP address: 1.2.3.4\nusername: myfullname\npassword: wordpass\nshared secret: XXXXXXXXXX\n\nThe connection type is L2TP.\nEnsure that you select the option to send all traffic over the VPN.\n\nI have tried 2 routes:\n1) Using the KDE widget to configure this\n2) Using config files to configure this\nUsing the widget:\nI add the https://launchpad.net/~seriy-pr/+archive/network-manager-l2tp PPA, and install network-manager-l2tp.\nThen, I add an L2TP connection and I come across the following fields (which I fill in):\nGateway (1.2.3.4)\nUser name: (myfullname)\nPassword: (wordpass)\nThen I go into IPsec Settings, and (after checking \"Enable IPSec tunnel to L2TP host):\nGroup Name\nGateway ID\nPre-shared Key\nI fill in Pre-shared Key with XXXXXXXXXX, and click OK.\nThen I try to connect, and get the following error:\n\"Necessary secrets for the VPN connection were not provided.\"\nUsing config files, and using https://www.elastichosts.com/support/tutorials/linux-l2tpipsec-vpn-client/ as a guide, I do the following:\nI add the following to /etc/ipsec.conf:\nconfig setup\n....\n    protostack=netkey\n    plutoopts=\"--interface=wlan0\"\n....\nconn tab-vpn\n    authby=secret\n    pfs=no\n    auto=add\n    keyingtries=3\n    dpddelay=30\n    dpdtimeout=120\n    dpdaction=clear\n    rekey=yes\n    ikelifetime=8h\n    keylife=1h\n    type=transport\n    left=%defaultroute\n    leftnexthop=%defaultroute\n    leftprotoport=17/1701\n    right=1.2.3.4\n\nI add the following to /etc/ipsec.secrets:\n%any 1.2.3.4: PSK \"XXXXXXXXXX\"\n\nThen when I restart ipsec with:\nsudo ipsec auto --up tab-vpn\n\nI get:\n104 \"tab-vpn\" #1: STATE_MAIN_I1: initiate\n003 \"tab-vpn\" #1: ignoring Vendor ID payload [MS NT5 ISAKMPOAKLEY 00000009]\n003 \"tab-vpn\" #1: received Vendor ID payload [RFC 3947] method set to=115 \n003 \"tab-vpn\" #1: received Vendor ID payload [draft-ietf-ipsec-nat-t-ike-02_n] meth=106, but already using method 115\n003 \"tab-vpn\" #1: ignoring Vendor ID payload [FRAGMENTATION]\n003 \"tab-vpn\" #1: ignoring Vendor ID payload [MS-Negotiation Discovery Capable]\n003 \"tab-vpn\" #1: ignoring Vendor ID payload [IKE CGA version 1]\n106 \"tab-vpn\" #1: STATE_MAIN_I2: sent MI2, expecting MR2\n003 \"tab-vpn\" #1: NAT-Traversal: Result using draft-ietf-ipsec-nat-t-ike (MacOS X): both are NATed\n108 \"tab-vpn\" #1: STATE_MAIN_I3: sent MI3, expecting MR3\n003 \"tab-vpn\" #1: we require peer to have ID '1.2.3.4', but peer declares '192.168.122.2'\n218 \"tab-vpn\" #1: STATE_MAIN_I3: INVALID_ID_INFORMATION\n\nI and the server in question are behind the same firewall.\nIt SHOULD allow me to connect so I can move onto setting up the xl2tpd.conf options, but I don't get that far.\nHelp?\n\nA: Try:\nconn tab-vpn\n    ...\n    rightid=192.168.122.2\n\nin /etc/ipsec.conf\nThe rightid parameter can be used to specify the IP address that the server identifies itself as (ie. it's LAN IP address rather than the public IP address of the router).\nIf the expected IP address and the IP address that the server identifies as don't match then ipsec abandons the connection attempt.\n", "Q: Deploying a specific version of a software from a juju charm? Suppose I'm using the postgresql charm to deploy my databases. How can I control the version of the PostgreSQL (9.1, 9.2, 9.3, etc) that is deployed?\nThank you\n\nA: The PostgreSQL charm has a configuration option for version \nhttp://manage.jujucharms.com/charms/precise/postgresql\nAssuming your PostgreSQL service is called postgresql you would run the following command after it's deployed.\njuju set postgresql version=1.0\nPre-deployment you can also pass a yaml configuration file. See juju help deploy for more information. \n", "Q: faster (and less precise) alternatives to dd Sometimes dd takes too long and I don't actually need byte by byte exact hdd replicas.\nI was thinking of resizing the partition in question to the minimum free space possible and then running dd so it would only copy the actual files;\nOr zipping works quite nice, especially if that partition was formatted beforehand and had lots of blank spaces with 0s\nBut are there any other alternatives to backup only the files (I love to restore windows with dd, but images are big), or wipe unused space before dd|gzip, or just make dd faster sacrificing unallocated partition space?\n\nA: If you prefer a full, mountable, image backup, then e2image has gained the ability to copy the filesystem with data, skipping the free space in 14.04.  Of course, tar or dump also lets you do incremental backups.\n", "Q: How can I install the development version of Node? I want to get the latest updates for Node (evented I/O for v8 javascript).\nI already have installed Node using:\nsudo apt-get install -y python-software-properties python g++ make\nsudo add-apt-repository ppa:chris-lea/node.js -y\nsudo apt-get update\nsudo apt-get install nodejs -y\n\nHow can I get the latest updates? Maybe using a PPA for development version?\n\nA: You have added the stable node.js PPA; for the development version you'll want to use this PPA:\nhttps://launchpad.net/~chris-lea/+archive/node.js-devel\nsudo add-apt-repository ppa:chris-lea/node.js-devel -y\nsudo apt-get update\nsudo apt-get install nodejs -y\n\nYou'll also likely want to remove the first PPA you added:\n\n\n*\n\n*How can PPAs be removed?\n\nA: Type in terminal:\nAfter add repository:\nsudo apt-get update      \nsudo apt-get dist-upgrade\n\n", "Q: installing a new hard drive on an existing Ubuntu machine I have a desktop machine running Ubuntu for a few years. \nI needed more space for my files and for that purpose I purchased and installed a brand new HDD in it.\nEverything is working great. The only issue is that the HDD is not mounting when the computer boots.\nIn order to my applications to find the files in the new HDD I have to click on the icon of the new HDD to cause it to mount. I have been clicking on that thing for a long time because I can't figure out how to manage fstab.\nI followed the instructions from the following link: Auto mount a drive that located on Ubuntu and auto share that drive for Window\nWhen I follow the instruction it does not seem to mount the HDD in the same place as if I had clicked on the icon of the HDD in Nautilus and Unity.\nThis is what I put on my fstab\n/dev/sdb1 /media/jean/2 ext4 users,user 0 0\n\nNote that my user name account is jean. I wrote on fstab  what I believe should work to mount the HD on boot and allow access to the files and folders within that hard drive by my applications. The applications do not seem to be able to handle the files and folders. Do I need to set permissions? Is the path correct? What does users,user 0 0 means?\nThat application \"Disks\" have no use either! Could not make it happen.\n\nA: There are a number of different approaches that will resolve your problem. The simplest one to describe would be to copy the original drive to the larger drive using dd or dc3dd. Another option is to determine what is using the most space and moving all that data to the new drive and mounting the new drive in the location on the tree where the data came from. du can help you determine usage by directory. du -h ~/Documents from a terminal prompt will give you the disk usage of your documents directory. \nChanging the command to ~/Downloads, ~/Pictures, ~/Music or ~/Videos will give you the usage for those directories as well. Comparing the totals will tell you where you are using all your space. If you have multiple users on the system it may be appropriate to move the entire /home directory to the new drive and mount that in fstab. Fair warning: dd dc3dd and du are all CLI tools that are run from the terminal and dd & dc3dd if improperly used can wipe your data. To understand permissions see How do file permissions work? The /media directory is usually used for temporarily connected storage like flash drives and external drives. Your data lives at /home/yourusername or perhaps /home/jean. the ~ in the above is shorthand for that and literally means my home directory (so if you are jean it means /home/jean and if you are bob it means /home/bob). When deciding where to mount your new drive you might find How to understand the Ubuntu file system layout? useful. For a rundown on fstab options open a terminal and issue the command \n    man fstab\n", "Q: Half done do-release-upgrade -- now at grub rescue My computer is running single boot Ubuntu 12.04 server version.\nI was trying to upgrade the release to 12.10 (following https://help.ubuntu.com/community/QuantalUpgrades)\nAfter executing sudo do-release-upgrade, and agreed to proceed with the download, somehow I lost my video output (hdmi). Nothing was shown to vga output either.\nI was able to ssh to my server but was not able to know what was going on with the release upgrade. I just waited long enough till dpkg no longer shows up on top, then I rebooted my server. (yeah, that was a dumb reboot )\nNow I'm stuck at \nerror: file not found\ngrub rescue>\n\nI can see my disk using \ngrub rescue> ls (hd0, msdos1)/\n\n\nA: These kinds of issues are notoriously hard to fix. Something went wrong with your grub, so what I can think of are three options: \n\n\n*\n\n*Load in a Ubuntu Live CD and do a grub repair on that partition. One of the best tools for the job is Boot Repair. \n\n*Backup data and reformat hard drive. \n\n*[Sorta don't advice] Try to manually fix grub. \n\n\nI would strongly suggest you go with the first one. \n", "Q: libav : deinsterlace option? I have compiled from GIT sources the libav 2014-march-10. \nOn usual libav from Ubuntu repositories, I was able to use -deinterlace to... well, deinterlace the video. Now this option appears to be missing. \nAny ideas ? \n\nA: The deinterlace option is now deprecated (see this git commit):\n\nPatchwork ffmpeg: Replace -deinterlace (which was broken by the buffer\n  ref stuff) with yadif injection\n\nYou have to use yadif to deinterlace the input video (yadif means \"yet another deinterlacing filter\").\nVisit libav.org for further details about yadif\n\nIn short, you will have to add -filter:v yadif to your command-line.\n", "Q: How to set temperature warnings to avoid overheat? Is there a way to set an alarm or something for when my Ubuntu computer is about to overheat? \nMy computer has some temperature issues, so when it's about to overheat I'd like to turn on an external fan. \n\nA: System-monitor GNOME extension\nYou also have system-monitor:\n\nAnd choose your threshold\n\nAFAIK it just changes the temperature color. No notification or acoustic alarm. There is a feature request about this issue.\n\nA: You can use psensor to monitor the computer temperature. This is a GUI application that readout the CPU and Mainboard sensors.\nsudo apt-get install psensor \n\nAfter starting psensor, go to the \"Sensor preference Menu\", choose your CPU sensor and click on  Alarm - Activate Desktop Notifications. You can modify the temperature limit for your needs:\n\nCan also start after login:\n\n", "Q: How do I remove Lubuntu and Keep my files? I run Lubuntu 13.10 on A S10 Lenovo Ideapad netbook. I recently installed  Xubuntu using sudo apt-get instal xubuntu-desktop .\nI want to install Xubuntu ana remove Lubuntu but keep my files .\nAny help ?\n\nA: If I understood correctly, you have originally installed Lubuntu and installed Xubuntu in addition, so you now have both of them installed and can choose one from them at the login screen. If you want to get rid off Lubuntu, apt-get remove lubuntu-desktop should be enough.\n\nA: As I'm understanding it, OP has one partition with Lubuntu on it, and one partition with Xubuntu on it. When OP boots computer, OP chooses between Lubuntu and Xubunutu.\nIf that is correct, then you want to boot into Xubuntu, and then mount the Lubuntu partition as if though it were, say, an external harddrive. You should be able to see all the files on it. Navigate to your home directory in the Lubuntu partition, select the files that you want to keep, and drag them into your Xubuntu home directory. You have now copied files from Lubuntu to Xubuntu.\nAs for actually getting rid of the Lubuntu partition, that is a little more complex and potentially dangerous. Do not attempt this without backing up all your data first.c\n", "Q: Call shell script \"inline\" in another shell script So the bottom line here is that I am trying to have one go-to script work to set environment variables (let's call it setenv.sh) that will be used in subsequent scripts.  In Windows (I know, that is a 4-letter word here...) I can use a batch file to set a environment variable for after the batch file is over.  I am looking for that same effect.\nHowever, I have just learned, through perusing the internet, that environment variables set in a script (aka a shell) only persist in child shells, and do not affect the parent shells.  Okay whatever, well now what I want to know is can I run a script inline in another script?  By inline, I am talking about something analogous to C/C++'s #include directive.  I want this because if I can call a script as if it were running in the current script, my environment variables would at least persist through the duration of my desired script.\nFor example, something like this:\ncat ~/install/setenv.sh | /bin/bash\necho \"JBoss home directory is set to $JBOSS_HOME\"\n\nBut I realize even that won't quite work, and I am starting a child shell with a call to /bin/bash.  I am fine if I have to call this setenv.sh for each script I want it to run inline with.\n\nA: if you want to include env variables, you can set those variables in a file, and then source that file in your script.\nFor example:\nin myconfig I could do:\n#!/bin/bash\nEDITOR=emacs\nJBOSS_HOME=/path/to/jboss/home\n\nthen in my shell script:\n#!/bin/bash\nsource /path/to/myconfig\necho \"JBOSS home dir is $JBOSS_HOME\" \n\nand that would work.\n", "Q: USB Mouse not recognized at boot-up When I boot up my system, the mouse cursor does not appear.  If I then manually unplug and then replug the mouse, the mouse cursor appears and I can use it.  \nI am running Ubuntu 13.10 on a system with the following specs:\nmotherboard: Asus Z87-Pro  \nCPU: i7-4770K  \nmemory: 16GB  \ngraphics: GeForce GTX 770  \ndisk: samsung 840 solid state 500GB drive (primary) + 2 WD 3TB sata drives  \nkeyboard/mouse: logitech MK120  (USB)\n\nI tried swapping out the mouse for a different brand, but this did not help.  I also tried disabling legacy USB in the BIOS, but this did not help either.\nThanks in advance from a long-ago unix hacker for any advice on how to troubleshoot and resolve this problem.\n\nA: You need to enable USB 3.0 legacy support in the BIOS if it offers such an option.\nSome boards do implement BIOS level \"legacy\" support which allows keyboards and mice to work on USB 3.0 ports. I've seen it, but it doesn't always work.\nUntil native core-logic-chipset-based USB 3.0 support arrives, the only option is to have keyboard and mouse plugged in to USB 2.0 ports.  Current chipsets from both Intel and AMD lack native USB 3.0 support.\n", "Q: Running Ubuntu from a USB drive I have been \"trying\" Ubuntu on a USB drive. I did some work today. Shut down the laptop. started it again (directing the boot to the USB drive so Ubuntu loaded up), but none of my saved text (.odt) or a few downloaded .pdf files can be found.\nDid I create a virtual desktop and documents folder when running Ubuntu from my USB? Were these files deleted when the computer was shut down.\nSearches for them on the heard drive 9PC) and on the USB do not turn up the files.\nSuggestions?\nThanks\n\nA: Yes unfortunately you are right. The files were deleted when you shut down the laptop. Depending on how you set up your live usb stick there is no persistence file where your work is stored.\nWhen booting from live stick Ubuntu essentialy loads itself into your RAM in order to run and doesn't really use the usb stick anymore. When you shut down your pc the RAM is deleted.\nTo avoid this in the future follow this guide to install the live system onto your usb stick again:\nhttp://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows \nIn the last frame there you see a little slider at the bottom of the window titled \"Step 4: Set a persistent file size for storing changes. (optional)\"\nUse this slider to allocate persistent memory for the live stick.\n\nA: I don't think the files are going to be saved when you are just \"trying it out\", I think you need to install it ( Given you like ubuntu).\n\nA: When you created your bootable usb stick you were probably asked if you wanted to have a dedicated space to store the files and settings of your Ubuntu Live session (you also had to specify the size).\nIf you did not set such a dedicated space, then your files and settings are not stored.\nIf you did, then they are stored in a file called casper.rw and should be accessed by Ubuntu Live transparently.\nSee this.\n", "Q: How to use GRUB2 to boot system rescue CD iso saved on unmounted partation at hard drive? I want to make a helper partition which may include a lot of rescue ISO files like 'Hiern's Boot', 'System Rescue', any live CD and Others.\nI started to make a partition by using the following command:\n\n$ sudo fdisk /dev/sdb\n\n\nI used fdisk command parameters (or sub commands ) to make a partition /dev/sdb6 [ extended partition ] \n\nThen I made a mount point by using the following commands:    \n\n$ sudo mkdir /mnt/Rescue\n$ sudo mount /dev/sdb6 /mnt/Rescue\n$ sudo chmod +rwx /mnt/Rescue\n\nI then made a menu entry at /etc/grub.d/40_custom file with the following entries \n\nmenuentry \"Ubuntu-12.04-ISO\" {\n\nset isofile=\"/mnt/ubu12-04/ubuntu-12.04-desktop-i368.iso\"\n\nloopback loop (hd0,6)$isofile\n\nlinux (loop)/casper/vmlinuz boot=casper iso-scan/filename=$isofile \nnoprompt noeject\n\ninitrd (loop)/casper/initrd.lz }  \n\n\n\n\nafter all this I restarted my computer and found just the following entry: \"Ubuntu-12.04-ISO \" in the grub menu but it doesn't work. \nWhat did I do wrong?\nNote: \nI am using 2 hard disks 1st one with /dev/sda and the 2nd with /dev/sdb\n\nHow can I make Boot for SystemRescueCD.iso , Heirn's Boot.iso and Ubuntu-12.04.iso ?\n\nA: The fact that you had previously mounted this partition in /mnt doesn't matter and grub doesn't have any idea about that.  The file name within that partition is just /ubuntu-12.04-desktop-i386.iso, so you just need to drop the /mnt prefix.\n", "Q: Surface Pro 2 keyboard cover not working in Ubuntu I'm trying to install Ubuntu 12.04 on my Surface Pro 2 at the moment and it seems to be working fine, except for the fact that neither one of my keyboard covers is working. The keys light up on my Type Cover 2, but nothing registers and the same is true for my old Touch Cover!\nI'm therefore unable to complete the installation, cannot enter a username and so on...\nHow can I fix it?\nThanks from Austria! :)\nP.S.: I used this guide: Dual boot Surface Pro with Ubuntu?\n\nA: As this is proprietary hardware the linux kernel just can't seem to handle it yet. See: https://bbs.archlinux.org/viewtopic.php?id=175657, https://bugzilla.kernel.org/show_bug.cgi?id=64811 and the follow up discussion: http://linux-kernel.2935.n7.nabble.com/PATCH-Add-HID-s-to-hid-microsoft-driver-of-Surface-Type-Touch-Cover-2-to-fix-bug-td790242.html. So kernel people seem to be already on it. I couldn't find out if the patch landed in any upstream kernel yet. If you don't want to wait you can try to compile a custom kernel with their patch included. Here are two resources with some information: https://wiki.ubuntu.com/KernelCustomBuild,Correct way to apply patches to your kernel?\nDisclaimer\nNever tried this myself\n\nA: I just solved this problem while trying to get the wireless drivers working.\nI am using a Surface Pro 2 with a type cover and a fresh installation of ubuntu 14.04-1.\nI installed ndiswrapper, but I doubt this is related to this.  Then I installed wine, and I set the \"Windows Version\" to \"Windows 8\" in the Concigure Wine Application.  Works perfectly on my machine. :)\n", "Q: Nautilus crashes, no desktop icons I need your help,\nwhen I launch Nautilus it crashes in 2 secons + desktop icons aren't displayed.\nI tried to uninstall python-nautilus but it doesn't work for me + don't have any zero byte file.\nUsing terminal: Unauthorized access to memory SIGSEGV\nThank you :)\n\nA: After 2 days trying fix it, I found the problem. Nautilus couldn't display .j2k file on desktop. When I deleted this .j2k file (which btw was not zero byte!) nautilus started working fine.\nI wonder that .j2k is not supported!!!\n", "Q: File counts not adding up: finding files ls -a misses Filelight alleges that I have 112,028 files in my home directory, on the first level (not recursing). But: ls -1a ~ | wc -l  thinks I have 225. find ~ -maxdepth 1 | wc -l says 224. The difference comes from ls's totals header.\nWhere did the other 111,804 files come from?\nSo to search further, I found the recursive totals, but I found they were pretty close, within 111k.\n\n\n*\n\n*find ~ | wc -l: 572,152\n\n*filelight: 569,320\n\n\nOriginally I thought so many unaccounted for files might indicate a rootkit, but chkrootkit only finds suckit, which is only on account of a bug.\nHow might I find these mysterious files? Do they really exist?\n\nA: I'm not familiar with Filelight, but it sounds like it might be an issue in that software.\nParticularly, if you have a lot of hard links in your filesystem, filelight will read them as if they are duplicate files, which can greatly inflate both the number and size count.\nSee here for more info: https://bugs.kde.org/show_bug.cgi?id=144948\nYou may have a lot of hard links if you use some backup software, for example.\nThat said, 111,804 vs 225 is a big difference.  And I can't see how it would explain why the recursive counts are OK.\n", "Q: Linux (Ubuntu 12.04) driver for Broadcom Corp BCM 4352 Wireless Network Adapter I've recently purchased a Dell Alienware 17 laptop and I've installed Ubuntu 12.04 LTS (kernel = 3.11.0-15) on it.\nThe problem is that the wireless card (Broadcom Corporation BCM4352 802.11ac Wireless Network Adapter (rev 03)) doesn't work in my Linux installation.\n I see that the drivers Dell offers on its website (http://www.dell.com/support/drivers/us/en/19/driverdetails?driverid=W49DT) are all for Windows.\nBroadcom's Linux drivers (http://www.broadcom.com/support/802.11/linux_sta.php) are only for the BCM4311-, BCM4312-, BCM4313-, BCM4321-, BCM4322-, BCM43224-, and BCM43225-, BCM43227- and BCM43228-based hardware (and not for the BCM4352 hardware that I have) and supported till kernel 3.8.x (mine is 3.11.0.15).\nI notice that Dell now sells Alienware machines with Ubuntu 12.04 LTS on them and must have a driver for this card. Where can I access that and how do I go about installing it?\n\nA: I had the exact same problem with my precision m4800. I found the DELL Ubuntu driver package which worked for me here :\nM4800_M6800_A03.fish.tar.gz\nI un-tared the file looked in the \"debs\" directory and found the kernel for the bcm 4352 (or dell 1550 as they brand it)\nMake sure you install the headers in the /debs/main directory first and it should be as simple as double clicking to install. You might want to restart after installing the package and blacklisting any of the other broadcom drivers you might have installed whilst testing\nThis is what I installed :\n/debs/bcmwl-kernel-source-dw1550.deb\n/debs/bt-dw1550-firmware_0.1_all.deb\n\nGood luck!\nEdit:\nOn Ubuntu 14.04 you can also simply do:\nsudo apt-get update\nsudo apt-get install bcmwl-kernel-source\n\n", "Q: Windows 8 missing from GRUB menu I have windows 8 preinstalled on my laptop. Initially I installed Ubuntu 12 LTS but I coudnt boot it with UEFI enabled, on using boot-repair it told me that this version of ubuntu is not supported by EFI.\nSo i installed ubuntu-13.10-desktop-amd64 and during the setup choose the option remove Ubuntu 12 LTS and install ubuntu 13.\nAfter the installation ubuntu starts but there is no windows entry in grub, so I ran boot repair from the live cd again but still it did not show windows 8. This is the url it generated:\npaste.ubuntu.com/7076240\nThen I ran boot-repair from ubuntu and it finished with this url:\npaste.ubuntu.com/7076405\nNow there is one more entry in Grub but none of them open Windows 8. Also I am unable to mount the windows partiton to reach my files.\nI tried the method said in one of the forums where you update the grub manually to point to windows efi file but I coudnt find the (hdo,gptx) x number recquired to do it.\nAny help would be appreciated. Thank You.\n\nA: You've wiped out your Windows installation. You'll need to contact Microsoft or your laptop's manufacturer to get a DVD set or USB flash drive with a set of recovery images. I recommend trying Microsoft, because the set provided by the manufacturer will probably wipe out your Ubuntu installation. (Even to install a version provided by Microsoft, you'll need to resize your Linux partition before you begin.)\n", "Q: Dropbox 1.6.1 doesn't link to account For the life of me, I can't seem to get Dropbox installed in such a way that it links to my account and starts syncing files. I've tried the following:\n\n\n*\n\n*sudo apt-get install dropbox\n\n*sudo apt-get install nautilus-dropbox\n\n*install from (1) .deb (2) CLI per https://www.dropbox.com/install?os=linux\n\n*installing from dropbox repo per this answer\nA couple of these methods had me running ~/.dropbox-dist/dropboxd. I was expecting to see the url to link the account at some point, but every time I ran this command, there was no output, although the icon would pop up.\nWhen I click the dropbox icon, it just says \"Connecting...\" even though it never queries me for credentials.\nI even tried installing using ubuntu-tweak to see if that would work. I got a dependency error with that, so I couldn't really find out.\n\nA: I was not able to find a solution to the issue with Dropbox version 1.6.1. However, installing version 2.6.5 from this link did resolve the issue.\nwget https://dl-web.dropbox.com/u/17/dropbox-lnx.x86_64-2.6.5.tar.gz\ntar xzvf dropbox-lnx.x86_64-2.6.5.tar.gz\n\nThe files will be removed from the archive and placed in the appropriate location for you. Keep in mind, this is not (as far as I know), available from the Ubuntu repos, so you'll need to do a few extra steps to set it up properly.\n\n\n*\n\n*Set up Dropbox as a service by following Alvin Row's instructions in this post\n\n*If you want Dropbox to start on system start, add bash -c \"sleep 20s && ~/.dropbox-dist/dropboxd\" to your Startup Applications. Alternatively, add the same command as an @reboot task in your crontab. You can try it without the sleep portion, but the icon didn't show up for me unless I included it.\n\n", "Q: Remove lines with less than 4 characters and more than 3 numbers in bash So for example, I have this text file:\nuse\nuser_99\n12345\n\n+10k lines...\nAnd I want to remove those that have less than 4 characters from the command line,\nI've already searched in google but no results came.\nAny ideas? : )\nI'd also like to remove lines with more than 3 numbers in the beginning.\n\nA: You can make a GNU sed regex for at least 4 characters as .{4,} - then to delete all lines except those with at least 4 characters:\nsed -r '/.{4,}/!d' file\n\nSimilarly, a line starting with more than 3 consecutive digits would be ^[0-9]{4,} so to delete all those\nsed -r '/^[0-9]{4,}/d' file\n\nYou can combine them either using -e or ;\nsed -r -e '/.{4,}/!d' -e '/^[0-9]{4,}/d' file\n\nor\nsed -r '/.{4,}/!d ; /^[0-9]{4,}/d' file\n\nNote that . matches space characters as well as non-space characters - if that is not what you want then you can change it by replacing . with a character range or POSIX class such as [[:alnum:]].\n\nA: sed or awk are good choices:\nsed -rn '/^.{0,3}$/n; /^[0-9]{3,}/n; p' file\n\nawk --re-interval 'length > 3 && !/^[0-9]{3,}/' file\n\n", "Q: Ubuntu wireless on lenovo 9s does not work with linksys driver or network Will not detect or connect to Ubuntu on my netbook. Worked when xp was installed I am using a Lenovo 9s netbook. How can I and where can I get the drivers for my Lenovo to work with the linksys e1200  and network adapter m600\n\nA: Try the Additional Drivers App\n", "Q: How to install mods for Skyrim on Playonlinux? I was successful last night running Playonlinux and installing steam and accessing my game account with my already purchased skyrim game. I am almost finished installing Skyrim. I am do not know how to incorporate mods to the game from playonlinux and I am worried that that will be a very difficult task to complete. How does one install mods for skyrim on playonlinux?\n\nA: One option would be to image your windows drive and run it as a guest os under virtual box. You won't have to buy a new copy and you'll have all your favourite mods from windows because you copied the entire drive and since you'll be running it under windows and not wine you'll have no wine debugging. I'm not sure what the game performance will be like. Maybe someone else can chime in with a better answer but if I were in your shoes I'd start testing there. Of course reviewing the respective license agreements to insure that this complies is legally necessary. There's a good although lengthy writeup on how to do this here. https://forums.virtualbox.org/viewtopic.php?f=2&t=31759#p172460\nBackup, backup, backup. One mistake can lose a lifetime of data.\n", "Q: Nvidia multiple monitor with different resolution I have 2 monitor that have different resolution which is 1440x900 and 1360x768. But the default settings for my 1360x768 monitor in Nvidia-settings is 1024x768 and when I tried to change it to 1360x768 the screen is off the monitor or its out of it margin.\nHere's my xorg.conf\n# nvidia-settings: X configuration file generated by nvidia-settings\n# nvidia-settings:  version 331.38  (buildd@fermium)  Tue Jan 14 12:07:21 UTC 2014\n\n# nvidia-xconfig: X configuration file generated by nvidia-xconfig\n# nvidia-xconfig:  version 331.49  (buildmeister@swio-display-x86-rhel47-10)  Wed Feb 12 21:00:07 PST 2014\n\nSection \"ServerLayout\"\n    Identifier     \"Layout0\"\n    Screen      0  \"Screen0\" 0 0\n    InputDevice    \"Keyboard0\" \"CoreKeyboard\"\n    InputDevice    \"Mouse0\" \"CorePointer\"\n    Option         \"Xinerama\" \"0\" EndSection\n\nSection \"Files\" EndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Mouse0\"\n    Driver         \"mouse\"\n    Option         \"Protocol\" \"auto\"\n    Option         \"Device\" \"/dev/psaux\"\n    Option         \"Emulate3Buttons\" \"no\"\n    Option         \"ZAxisMapping\" \"4 5\" EndSection\n\nSection \"InputDevice\"\n\n    # generated from default\n    Identifier     \"Keyboard0\"\n    Driver         \"kbd\" EndSection\n\nSection \"Monitor\"\n\n    # HorizSync source: builtin, VertRefresh source: builtin\n    Identifier     \"Monitor0\"\n    VendorName     \"Unknown\"\n    ModelName      \"CRT-0\"\n    HorizSync       28.0 - 55.0\n    VertRefresh     43.0 - 72.0\n    Option         \"DPMS\" EndSection\n\nSection \"Device\"\n    Identifier     \"Device0\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    BoardName      \"GeForce GT 630\" EndSection\n\nSection \"Screen\"\n\n# Removed Option \"metamodes\" \"DVI-I-0: 1440x900 +0+0, VGA-0: nvidia-auto-select +1440+0\"\n# Removed Option \"nvidiaXineramaInfoOrder\" \"CRT-0\"\n# Removed Option \"metamodes\" \"DVI-I-0: 1360x768 +1440+0, VGA-0: 1440x900 +0+0\"\n    Identifier     \"Screen0\"\n    Device         \"Device0\"\n    Monitor        \"Monitor0\"\n    DefaultDepth    24\n    #Option         \"TwinView\" \"1\"\n    #Option         \"TwinViewXineramaInfoOrder\" \"CRT-0\"\n    Option         \"Stereo\" \"0\"\n    Option         \"nvidiaXineramaInfoOrder\" \"CRT-1\"\n    Option         \"metamodes\" \"DVI-I-0: 1360x768 +1440+0, VGA-0: 1440x900 +0+0\"\n    Option         \"SLI\" \"Off\"\n    Option         \"MultiGPU\" \"Off\"\n    Option         \"BaseMosaic\" \"off\"\n    SubSection     \"Display\"\n        Depth       24  Modes \"1440x900\" \"1360x768\"     Virtual 2800 900\n    EndSubSection EndSection\n\n\nA: found this on this site for you:\nhttp://www.howopensource.com/2012/10/install-nvidia-geforce-driver-in-ubuntu-12-10-12-04-using-ppa/\nsudo apt-add-repository ppa:xorg-edgers/ppa\nsudo apt-add-repository ppa:ubuntu-x-swat/x-updates\nsudo apt-get update\nsudo apt-get install nvidia-current nvidia-settings\nGeForce 600 series:\nGTX 690, GTX 680, GTX 670, GTX 660 Ti, GTX 660, GTX 650, GT 645, GT 640, GT 630, GT 620, GT 610, 605\n", "Q: Alt-Gr key is not working in Ubuntu 13.10 I installed Ubuntu with mostly default configuration; the keyboard seems not to detect the Alt Gr key so that I can not type international characters.\nHow can I enable Alt Gr key?\n\nA: In order to set up the Alt-Gr  key you must go to (setting -> keyboard -> layout settings -> keyboard settings -> then go to the typing tab -> press and hold the Alternative Keyboard Key setting -> move you mouse down to select the key you want to assign Alt-Gr to. \n\n\n\n\n\nA: This answer has screenshots for Gnome-Shell (Ubuntu Gnome 13.10). I suppose it will be similar for standard Unity, but if not, please chime in. \nFirst of all (and this is the most common problem), to have AltGr working you need a keyboard layout which uses it. For example, this is my keyboard layout (Settings -> Region and Language): \n\n\n\n*\n\n*English (US, international with dead keys) has AltGr.\n\n*English (US) has NO AltGr.\n\n*English (international AltGr dead keys) has AltGr.\n\n\n(My preferred layout is the third one, really). \nIf the layout does not map AltGr+Key to anything, like for example the default \"English (US)\", AltGr will not work even if it's activated in the Keyboard -> Shortcuts panel.  \nThis is normally sufficient. To change the position of the AltGr you go to Settings -> Keyboard and set the \"Alternative Characters Key\":\n\nFor example, my keyboard has no physical AltGr key, so I mapped it to the Right Alt key.\nNow with the third layout, pressing AltGr and n together gives ñ.\nCompose (the option before) is a very different beast. If you enable it, then you will have a set of characters available with three (or more) keystrokes. For example, pressing Compose, o, e  gives œ. That's three sequential keystrokes, not together.\nTake into account that there is a bug related to the layout switching in 13.10 which is being worked on, so check it if you have problems changing layout. \n\nA: AltGr sounds like a lot of trouble for only a few symbols.  A better choice might be the United States Alternative International keyboard.  This one gives a choice of dozens of letters with diacritical marks .  The k'bd is just like the standard k'bd except that the `~ ^' and the \" are --dead-- keys  ( delayed action ) until the next key is pressed. \nThese are the accent grave, tilde, circumflex and the accent agut.  Just these 5 added to all the vowels and many consonants gives dozens of extra characters .  If you want to type the apostrophe by it self just hit the space bar.  ( Or the quote sign )  I have Ubuntu 12.10 and it works OK.  I used the instructions for Ubuntu 14.04 so I had to do some guessing but I finally got it to work.\nhttp://www.wikihow.com/Change-Keyboard-Layout-in-Ubuntu\n  ã â ś Ḱ ç ŕ ï ḿ ĝ  ĥ â ŝ ó õ------samples\n\nthe 'and the v  =   ǘ  this u with 2 marks above it ,,, wonder where it is used ?\n", "Q: Identify udev subsystems and devtypes I have to write a python script to monitor for usb mass storage devices. To successfully filter the required media it must be identified by its subsystem and DEVTYPE.\nDoes anyone know the required subsystem and DEVTYPE for a usb mass storage device?\nAlternatively, can anyone tell me where I could find a list of all subsystems and DEVTYPEs?\n\nA: *\n\n*I may have found the answer after some lurking in IRC for a while. \nSUBSYSTEM:block\nDEVTYPE:disk\n\n\n*Here's how I found it. it was suggested this command:\nsudo udevadm info --root  --name=/dev/sdX\n\nHere 'X' in sdX must be replaced by the device that represents your USB mass storage device. If you need  to find that out, go to /dev and enter ls, once with the device connected to your machine and once without. Find the missing sdX and voila!\nThis also shows properties such as ID_FS_TYPE, ID_BUS ,etc...\n\n*However I'm not too sure about the DEVTYPE of USB mass storage devices. There's a chance it could be partition. If anyone knows, please comment or add an answer!\n", "Q: Will not allow me to install playonlinux! Says I have 'held broken packages When I try to download 'playonlinux' I get:\n\nThe following packages have unmet dependencies:\n playonlinux : Depends: icoutils but it is not installable\n               Depends: curl but it is not installable\nE: Unable to correct problems, you have held broken packages.\n\nAnd I also can't install literally anything else.\n\nA: First make sure you have wine windows loader installed play on linux relies on it\nopen your terminal (Ctrl+Alt+T) type the following:\nsudo add-apt-repository ppa:ubuntu-wine/ppa\n\nsudo apt-get update\n\nsudo apt-get install wine1.7   hit Y when prompt\n\nsudo apt-get install winetricks\n\nInstall Synaptic Package Manager and once installed open in authorization mode. Once open click on custom filters, then broken, there should never be anything in that list… Click all packages in that list, set them for install and hit apply. Try again with your install of Play on Linux \nif you cannot through software center terminal it again type:\nsudo apt-get install synaptic  \n\nHit Y when prompted.\nthen open it\nif this doesn't help I'm sorry that question may be a little over my head… when a package is broken it is places in that list \n-Thamas\nPS the Linux systems are great once you learn to use them and learn to get around on them. I used windows for years and finally started to use Ubuntu and would never go back. You can get a virtual windows on virtual box and you can use wine for a lot of games.\n", "Q: How do I Remove Pokemon Online? I was told to try sudo apt-get remove pokemon-online-client but it says command not found: pokemon-online-client. what should I do to remove it?\n\nA: If you downloaded this program then just remove the folder where you extracted the contents of the .tar.gz file to.\nOptionally you can run apt-get autoremove or try to manually remove the libraries the install.sh script installed.\n", "Q: Why virtual console(Ctrl+Alt+F1) asked for password after logged into it? I want to run sudo service lightdm restart command on virtual console, so i pressed Ctrl+Alt+F1 after that VC login prompt appears,\n\nLogin:\nPassword:\n\nI logged into the vc with my login credentials.If i run sudo service lightdm restart command on that prompt, it again asked for sudo password.\n\n~$ sudo service lightdm restart\n[sudo] password for avinash:\n\nWhy there is a two step verfication proces?\n\nA: The first time you entered your password was to log into your account.  The second time it prompted you for your password was because you entered a command starting with 'sudo'.\nWhen you use 'sudo' you are telling the system to run the next command as if you are the root (admin) account.  When this occurs it asks for your password again as a security feature in case you decide you don't want to run the command or if it might be an unauthorized person (say you forgot to log out and another person attempted this).\n", "Q: Problem with changing login screen I tried several time to change my log in screen by using sudo dpkg-reconfigure lightdm. I choose lightdm from here. But my log in screen is unchanged and look like below.\nHow can I change this and back to my default unity log in screen??\n\nA: If the command sudo dpkg-reconfigure lightdm not work, edit /etc/lightdm/lightdm.conf file with your favorite editor:\ngksudo gedit /etc/lightdm/lightdm.conf\n\nMake sure the greeter-session is the unity-greeter, then restart.\ngreeter-session=unity-greeter\n\nIf the problem continue then give a try to this command:\nsudo apt-get -o Dpkg::Options::=\"--force-confnew\" install --reinstall lightdm \n\n", "Q: Removing Ubuntu completely on the same partition where my Windows is also installed I installed Ubuntu on the same partition with my windows & now both are inside drive C. I've already uninstalled it from the control panel but Ubuntu still showing when booting. Is there a way to remove the Ubuntu without re-install my windows?\n\nA: Hmm... Well, if you don't want to work hard for this Windows installation, I can't help you. If you want to work quite a bit to save it, I can, but it does involve you having to reinstall windows 7... I assume you have a lot of stuff on the windows partition. Follow these steps to create a live-usb to copy windows to another partition (if you still have your installation usb you used to install Ubuntu, skip to step :\n1. Boot your Live-USB system\n2. Partition the hard-drive with gparted. Make a partition at least... 120 gigs. If that is the size of your hard drive or fairly close, make it 60 gigs. Format it with FAT32 or NTFS (if your UBUNTU live-usb can handle them).\n3. Go to the file explorer and then to the new partition. It is now mounted. Now go to the computer box. Click it.\n4. Move the following folders to the partition you created in step 2:\nWindows\nProgram Files\nUsers\nProgram Files (x86) (this is only here on x64 machines. DO NOT PANIC IF IT ISN'T HERE)\n5. When those are finished copying, you can insert your windows installation media and reinstall windows 7. When it's done installing, you can move everything back EXCEPT THE PROGRAM FOLDERS. YOU WILL HAVE TO REINSTALL EVERYTHING.\nOh, and when you have windows reinstalled, you have a NICE PARTITION TO INSTALL UBUNTU TO! :D\nSorry, you had to go through this... Just be careful next time.\n", "Q: Going into Substitute user I can't seem to be able to type in a password so that I may acquire access to #apt-get. I'm looking to update my system via terminal, but typing out my password does no good to get me into su, as the spaces stay blank, and what I know is the password won't go through. Has anyone else had this issue? \n\nA: Even though no characters appear when you type your password, you are actually typing your password.\nFor security reasons, characters typed in at the password request prompt are not echoed back to the terminal. The characters are there, you just can't see them, that's all.\nSo type password, then hit Enter and see.\n\nA: Adding to Hadi's answer you can enable visual feedback when typing passwords by editing your /etc/sudoers file and changing the Defaults line from:\nDefaults env_reset\n\nto\nDefaults env_reset,pwfeedback\n\nBut this is not a good thing because people will get to know the length of your password and it becomes easy to crack it.\nsource\n", "Q: Unable to install mysql 5.6 in ubuntu 12.04 I download mysql-5.6.16-debian6.0-x86_64.deb from official site.\nInstall using dpkg -i mysql-5.6.16-debian6.0-x86_64.deb\nIt does create file in /opt/mysql/server-5.6/.\nroot@ubuntu:~# cd /var/lib/mysql/\nbash: cd: /var/lib/mysql/: No such file or directory\nroot@ubuntu:~$ service mysql start\nmysql: unrecognized service\nroot@ubuntu:~$ chown -R mysql /opt/mysql/server-5.6/\nchown: invalid user: mysql\nroot@ubuntu:~$ chgrp -R mysql /opt/mysql/server-5.6/\nchgrp: invalid group: mysql\n\nI don't know how to deal with this...\nroot@ubuntu:~# ls -l /opt/mysql/server-5.6/\ntotal 152\ndrwxr-xr-x  2 root root  4096 Mar 12 11:56 bin\n-rw-r--r--  1 root root 17987 Jan 14 23:38 COPYING\ndrwxr-xr-x  2 root root  4096 Mar 12 11:56 docs\ndrwxr-xr-x  3 root root  4096 Mar 12 11:56 include\n-rw-r--r--  1 root root 88109 Jan 14 23:38 INSTALL-BINARY\ndrwxr-xr-x  3 root root  4096 Mar 12 11:56 lib\ndrwxr-xr-x  4 root root  4096 Mar 11 16:32 man\ndrwxr-xr-x 10 root root  4096 Mar 12 11:56 mysql-test\n-rw-r--r--  1 root root  2496 Jan 14 23:38 README\ndrwxr-xr-x  2 root root  4096 Mar 12 11:56 scripts\ndrwxr-xr-x 28 root root  4096 Mar 12 11:56 share\ndrwxr-xr-x  4 root root  4096 Mar 12 11:56 sql-bench\ndrwxr-xr-x  3 root root  4096 Mar 12 11:56 support-files\n\n\nA: You don't have to do that:\neasily you can install mysql:\nserver:\nsudo apt-get install mysql-server\n\nclient only\nsudo apt-get install mysql-client\n\n\nIf you want newer versions than default in Ubuntu\nfor version 5.5;\nsudo  apt-add-repository ppa:ondrej/mysql-5.5\n\nfor version 5.6;\nsudo  apt-add-repository ppa:ondrej/mysql-5.6\n\nAfter adding your needed version, update sources lis:\nsudo apt-get update\n\nnow install mysql\nserver:\nsudo apt-get install mysql-server\n\nclient only\nsudo apt-get install mysql-client\n\n\nA: According to the official MySql Site for community Server Installation, you can follow the guide described here. \nThis guide helps you configure an apt repository for MySQL products according to your OS Version and MySQL Product (server, connectors) version. In brief for Ubuntu 12.04 and MySQL Server 5.6 you follow the step below.\n\n\n*\n\n*Download the APT package, in our case mysql-apt-config_0.3.5-1ubuntu12.04_all.deb\n\n*Run it using # dpkg -i mysql-apt-config_0.3.5-1ubuntu12.04_all.deb\n\n*Update APT source list # apt-get update\n\n*Install as usual # apt-get install mysql-server\n\nA: If you install mysql server from .deb file, it stores the service file inside /etc/init.d directory as mysql.server.So to start the mysql server service, you have to run the below command,\nsudo service mysql.server start\n\nTo initialize mysql Data directory, see this documentation page.\n\nA: ppa:ondrej/mysql-5.6 stopped working a few days ago for me on CircleCI for some reason (the tests suddenly broke and Circle didn't change anything). I'm now upgrading MySQL 5.5 -> 5.6 based on instructions here. It uses the official MySQL apt.\necho \"deb http://repo.mysql.com/apt/ubuntu/ precise mysql-apt-config\" | sudo tee /etc/apt/sources.list.d/mysql.list\necho \"deb http://repo.mysql.com/apt/ubuntu/ precise mysql-5.6\" | sudo tee /etc/apt/sources.list.d/mysql.list\ncurl -s http://ronaldbradford.com/mysql/mysql.gpg | sudo apt-key add -\nsudo apt-get update\nsudo service mysql stop\nsudo apt-get install -y mysql-server\nsudo mysql_upgrade -uroot # -p omitted as the circleci default container has no password\n\n", "Q: Clickable notifications that allow to interact with programs which have spawned them? There are Notifications in KDE's System Tray.\nThe problem is that Notifications don't provide access to the apps that spawn those notifications. The only available action is to dismiss the notification.\nFor example, a notification pops up and tells me that an archive extraction has been finished. I would like to click that notification for the extracted files to be opened in a file manager. Instead, i have to manually browse for those files.\nOr a notification pops up and tells me that there are system updates available. I would like to click the notification to access the updates manager (or even immediately initiate the update). Instead, i have to look for the update manager's icon and open it manually.\nIs there a way to enhance the Notification system to enable that? Or there's some Plasma widget capable of interacting with notifications?\n\nA: KDE notifications\nKDE doc page: http://docs.kde.org/development/en/kde-runtime/kcontrol/kcmnotify/index.html\nKDE UserBase page: http://userbase.kde.org/System_Settings/Application_and_System_Notifications\nAlternative notifications\nColibri: http://kde-apps.org/content/show.php/Colibri?content=117147+kde-apps.org+page\n\nColibri notifications look lighter and are completely passive: they do\n  not provide any buttons. You may or may not like this...\n\nUbuntu package available: http://packages.ubuntu.com/search?keywords=colibri&searchon=names&suite=all&section=all\nUSU Notifications: http://kde-apps.org/content/show.php/?content=158063\n\nAlternative KDE notifications, based on QML and org.kde.notofications,\n  but with more features...\n\nThe USU notifications seem to have the option 'to click that notification for the extracted files to be opened in a file manager'\n\nIt is a scrip -> Add Widgets > Get New widgets... \n\n\n*\n\n*Right click the System Tray\n\n*System Tray Settings\n\n*Disable the standard notifications and enable the USU\n\n\n\n", "Q: Bumblebee error in ubuntu 13.10 I installed bumblebee couple times in ubuntu 13.10,12.04 but now it's not working for ubuntu 13.10. I followed the instruction here (including nvidia-319-updates). When i try to run optirun it shows errors.\n$optirun -vv firefox\n[   37.843018] [DEBUG]Reading file: /etc/bumblebee/bumblebee.conf\n[   37.843234] [INFO]Configured driver: nvidia\n[   37.843318] [DEBUG]optirun version 3.2.1 starting...\n[   37.843325] [DEBUG]Active configuration:\n[   37.843328] [DEBUG] bumblebeed config file: /etc/bumblebee/bumblebee.conf\n[   37.843331] [DEBUG] X display: :8\n[   37.843333] [DEBUG] LD_LIBRARY_PATH: /usr/lib/nvidia-319-updates:/usr/lib32/nvidia-319-updates\n[   37.843336] [DEBUG] Socket path: /var/run/bumblebee.socket\n[   37.843339] [DEBUG] Accel/display bridge: auto\n[   37.843342] [DEBUG] VGL Compression: proxy\n[   37.843344] [DEBUG] VGLrun extra options: \n[   37.843347] [DEBUG] Primus LD Path: /usr/lib/x86_64-linux-gnu/primus:/usr/lib/i386-linux-gnu/primus\n[   37.863100] [DEBUG]Using auto-detected bridge primus\n[   38.752137] [INFO]Response: No - error: [XORG] (EE) Failed to load /usr/lib/xorg/modules/libglamoregl.so: /usr/lib/xorg/modules/libglamoregl.so: undefined symbol: _glapi_tls_Context\n\n[   38.752152] [ERROR]Cannot access secondary GPU - error: [XORG] (EE) Failed to load /usr/lib/xorg/modules/libglamoregl.so: /usr/lib/xorg/modules/libglamoregl.so: undefined symbol: _glapi_tls_Context\n\n[   38.752158] [DEBUG]Socket closed.\n[   38.752171] [ERROR]Aborting because fallback start is disabled.\n[   38.752176] [DEBUG]Killing all remaining processes.\n\nI purge/install bumblebee, nvidia-319-updates etc couple of times but no luck.\ndmesg message after start bumblebee.\n[   38.020998] nvidia: module license 'NVIDIA' taints kernel.\n[   38.021003] Disabling lock debugging due to kernel taint\n[   38.027124] [drm] Initialized nvidia-drm 0.0.0 20130102 for 0000:04:00.0 on minor 1\n[   38.027131] NVRM: loading NVIDIA UNIX x86_64 Kernel Module  319.60  Wed Sep 25 14:28:26 PDT 2013\n[   38.752497] vgaarb: this pci device is not a vga device\n[   38.778036] NVRM: failed to copy vbios to system memory.\n[   38.780897] NVRM: RmInitAdapter failed! (0x30:0xffffffff:711)\n[   38.780907] NVRM: rm_init_adapter(0) failed\n[  334.417657] bbswitch: version 0.7\n[  334.417663] bbswitch: Found integrated VGA device 0000:00:02.0: \\_SB_.PCI0.GFX0\n[  334.417670] bbswitch: Found discrete VGA device 0000:04:00.0: \\_SB_.PCI0.RP05.PXSX\n[  334.417682] bbswitch: failed to evaluate \\_SB_.PCI0.RP05.PXSX._DSM {0xF8,0xD8,0x86,0xA4,0xDA,0x0B,0x1B,0x47,0xA7,0x2B,0x60,0x42,0xA6,0xB5,0xBE,0xE0} 0x100 0x0 {0x00,0x00,0x00,0x00}: AE_NOT_FOUND\n[  334.417689] bbswitch: failed to evaluate \\_SB_.PCI0.RP05.PXSX._DSM {0xA0,0xA0,0x95,0x9D,0x60,0x00,0x48,0x4D,0xB3,0x4D,0x7E,0x5F,0xEA,0x12,0x9F,0xD4} 0x102 0x0 {0x00,0x00,0x00,0x00}: AE_NOT_FOUND\n[  334.417700] bbswitch: failed to evaluate \\_SB_.PCI0.GFX0._DSM {0xA0,0xA0,0x95,0x9D,0x60,0x00,0x48,0x4D,0xB3,0x4D,0x7E,0x5F,0xEA,0x12,0x9F,0xD4} 0x102 0x0 {0x00,0x00,0x00,0x00}: AE_NOT_FOUND\n[  334.417701] bbswitch: No suitable _DSM call found.\n\nbumblebee.conf\n# Configuration file for Bumblebee. Values should **not** be put between quotes\n\n## Server options. Any change made in this section will need a server restart\n# to take effect.\n[bumblebeed]\n# The secondary Xorg server DISPLAY number\nVirtualDisplay=:8\n# Should the unused Xorg server be kept running? Set this to true if waiting\n# for X to be ready is too long and don't need power management at all.\nKeepUnusedXServer=false\n# The name of the Bumbleblee server group name (GID name)\nServerGroup=bumblebee\n# Card power state at exit. Set to false if the card shoud be ON when Bumblebee\n# server exits.\nTurnCardOffAtExit=false\n# The default behavior of '-f' option on optirun. If set to \"true\", '-f' will\n# be ignored.\nNoEcoModeOverride=false\n# The Driver used by Bumblebee server. If this value is not set (or empty),\n# auto-detection is performed. The available drivers are nvidia and nouveau\n# (See also the driver-specific sections below)\nDriver=nvidia\n# Directory with a dummy config file to pass as a -configdir to secondary X\nXorgConfDir=/etc/bumblebee/xorg.conf.d\n\n## Client options. Will take effect on the next optirun executed.\n[optirun]\n# Acceleration/ rendering bridge, possible values are auto, virtualgl and\n# primus.\nBridge=auto\n# The method used for VirtualGL to transport frames between X servers.\n# Possible values are proxy, jpeg, rgb, xv and yuv.\nVGLTransport=proxy\n# List of paths which are searched for the primus libGL.so.1 when using\n# the primus bridge\nPrimusLibraryPath=/usr/lib/x86_64-linux-gnu/primus:/usr/lib/i386-linux-gnu/primus\n# Should the program run under optirun even if Bumblebee server or nvidia card\n# is not available?\nAllowFallbackToIGC=false\n\n\n# Driver-specific settings are grouped under [driver-NAME]. The sections are\n# parsed if the Driver setting in [bumblebeed] is set to NAME (or if auto-\n# detection resolves to NAME).\n# PMMethod: method to use for saving power by disabling the nvidia card, valid\n# values are: auto - automatically detect which PM method to use\n#         bbswitch - new in BB 3, recommended if available\n#       switcheroo - vga_switcheroo method, use at your own risk\n#             none - disable PM completely\n# https://github.com/Bumblebee-Project/Bumblebee/wiki/Comparison-of-PM-methods\n\n## Section with nvidia driver specific options, only parsed if Driver=nvidia\n[driver-nvidia]\n# Module name to load, defaults to Driver if empty or unset\nKernelDriver=nvidia-319-updates\nPMMethod=auto\n# colon-separated path to the nvidia libraries\nLibraryPath=/usr/lib/nvidia-319-updates:/usr/lib32/nvidia-319-updates\n# comma-separated path of the directory containing nvidia_drv.so and the\n# default Xorg modules path\nXorgModulePath=/usr/lib/nvidia-319-updates/xorg,/usr/lib/xorg/modules\nXorgConfFile=/etc/bumblebee/xorg.conf.nvidia\n\n## Section with nouveau driver specific options, only parsed if Driver=nouveau\n[driver-nouveau]\nKernelDriver=nouveau\nPMMethod=auto\nXorgConfFile=/etc/bumblebee/xorg.conf.nouveau\n\nxorg.bumbleebee.nvidia\nSection \"Device\"\n    Identifier  \"DiscreteNvidia\"\n    Driver      \"nvidia\"\n    VendorName  \"NVIDIA Corporation\"\n    BusID \"PCI:04:00:0\" #changed to 04:00.0 but no luck. So revert back.\n\nlspci\n04:00.0 3D controller: NVIDIA Corporation GK208M [GeForce GT 740M] (rev a1)\n\n\nA: At last i found the solution. I am posting it for future reference.\nThere are two problem.\n1. bbswitch\n2. nvidia-driver\n\nubuntu 13.10 is using 3.11.x kernel and bbswitch is not working in 3.8 to 3.11. It's kernel issue(according to blogs) and fixed in >= 3.12. I solved bbswitch problem by upgrading my kernel to 3.12.6. here\nnvidia-304, nvidia-319 is not working in ubuntu 13.10. I am telling this because i run my card(740M) with nvidia-319 in 13.04. You have to install nvidia-331. This is a useful reference, how to install bumblebee with nvidia-331.\n", "Q: How can I get install the Cool computer language for Ubuntu? I am considering taking an online class through Coursera.org. The class is offered by Stanford University. They use the Cool programming language. Does anyone have experience installing  Cool in Ubuntu?\n\nA: The installation instructions are on the coursera wiki page (it's very well hidden and took me some time to find).\nNote that you must install the files where it tells you to, the paths seem to be hardcoded.\n@chaskes's answer doesn't work because it's missing the instructions for where to install the files from the tar, as well as some required packages.\n\nA: According to the \"longer description\" document linked from the Cool Wiki page and the Stanford Compilers course page at Coursera, you won't have any trouble running Cool on Ubuntu.\n\nA student distribution of the project is available. These distributions include object code for the coolc reference compiler, assignments, and all documentation.\n  (Source: Cool main page)\n\nThe student distribution appears to be available only as part of a class or on request, so you can wait until you take the class.\nAs for installing and running:\n\nCool is highly portable and easy to install on any Unix machine with standard GNU     software tools gmake, bison, and flex....A separate Linux distribution is made\n  available for students to use on their home PCs. (Source: Cool \"longer description\")\n\nSo, again, once you receive the student version you shouldn't have any trouble. You can make sure you have the standard tools installed with:\nsudo apt-get install build-essential flex bison\n\nThe Stanford course at Coursera says: Students who choose to do the project can implement it in either C++ or Java.\nIf you choose to use Java, you can install the JDK with:\nsudo apt-get install openjdk-7-jdk\n\n", "Q: List all manually installed packages similar to history.log file I searched the whole internet for this but did not find any satisfactory answer for this question. \naptitude search ‘~i !~M’ | less\n\ndoes not show the manually installed packages. On my system it shows a huge list:\ni   accountsservice                 - query and manipulate user account informat\ni   acl                             - Access control list utilities             \ni   acpi-support                    - scripts for handling many ACPI events     \ni   acpid                           - Advanced Configuration and Power Interface\ni   add-apt-key                     - Command line tool to add GPG keys to the A\ni   adduser                         - add and remove users and groups           \ni   alsa-base                       - ALSA driver configuration files           \ni   alsa-utils                      - Utilities for configuring and using ALSA  \ni   anacron                         - cron-like program that doesn't go by time \ni   apache2                         - Apache HTTP Server                        \ni   apache2-bin                     - Apache HTTP Server (binary files and modul\ni   apache2-data                    - Apache HTTP Server (common files)         \ni   apache2-mpm-prefork             - transitional prefork MPM package for apach\ni   apg                             - Automated Password Generator - Standalone \ni   apt                             - commandline package manager               \n:\n\nand many others...\nBut obviously I did not install all of these. On the other hand a much more effective solution is this:\nzcat /var/log/apt/history.log.*.gz | grep 'apt-get install'\n\nOutput:\nCommandline: apt-get install wine1.7 winetricks\nCommandline: apt-get install ubuntu-restricted-extras\nCommandline: apt-get install pi\nCommandline: apt-get install gparted\nCommandline: apt-get install virtualbox\nCommandline: apt-get install ardour3\nCommandline: apt-get install kubuntu-restricted-extras ubuntu-restricted-extras\nCommandline: apt-get install apache2\nCommandline: apt-get install tasksel\n\nwhich are exactly the packages I installed manually. But the problem with the above solution is that the logs can be messed up. So what I want is the exact same output of the history.log file from some aptitude command. So that the log messing up won't pose any problem.\n\nA: To get a list of packages installed locally run this command:\ndpkg --get-selections | grep -v deinstall\n\nyou can save a file list of all installed packages\ndpkg --get-selections | grep -v deinstall > myInstalledPackages.txt\n\n", "Q: Ubuntu 12.04 & fglrx 13.1 drivers My computer has an ATI/AMD Radeon Mobility 4650.\nI have attempted to install the drivers as described in What is the correct way to install proprietary ATI Catalyst Video Drivers (fglrx) directly from AMD?, however the AMD website currently only allows the downloading of the newest drivers, which do not appear to work for 12.04 Precise Pangolin.  \nI cannot find a mirror with the older releases (12.8 is what I'm looking for), and the information provided in the link above only goes up to 12.8.\nI am having a lot of trouble with this, and my video card has lots of overheating issues.  Any help would be GREATLY appreciated.  More info can of course be provided (as long as you let me know what you need!)\nThanks\n\nA: Try to install latest drivers from Xorg-Edgers PPA:\nsudo add-apt-repository ppa:xorg-edgers/ppa\nsudo apt-get update\nsudo apt-get install fglrx-12\n\nAnd if you want more stable drivers, use ppa:ubuntu-x-swat/ppa\n", "Q: How do I save a modified buffer for video resolution uncommented? I've been getting a \"Signal out of range\" message when trying to boot up.  Press down arrow, enter to get to recovery menu and go to system root prompt. From there I run \nsudo nano /etc/default/grub\n\nThen uncomment the \nGRUB_GFXMODE=1280x1024 \n\nline and try to save.  It asks for a file name but the prompt is: /etc/default/grub.  Can't seem to do anything from there.\n\nA: That is normal behavior – Nano asks you about filename under which to save file. So just press Enter and it will save the file.\nFor exiting Nano, press Ctrl+X.\nAlso, do not forget to mount / filesystem in Read-Write mode:\nmount -o rw,remount /\n\n", "Q: How to know all files in Ubuntu having stickybits? I now understand sticky bits and why I should use them based on my question: What is the \"t\" letter in the output of \"ls -ld /tmp\"? \nNow I have a new question.\nHow could I list all files that have stickybits in my Ubuntu Linux?\n\nA: This command should serve you (-perm flag used to be +1000) \nfind / -perm /1000 \n\nDetails:\nTo add a stickybit Numerical/octal way you have to add \"1\" to the beginning of the directory.\nexample:\nchmod 1757 ~/Desktop/test\n\nso know to search for a stickybit you have to search for all files having \"this one\" which means having permissions +1000 (1 here goes for stickybit and \"000\" for whatever the initial permissions are)\nSo this command will search the whole filesystem for every file that have permission \"+1000\".\nNow if you have test this command then you can notice that many errors raise here which make the output unclear, and this errors happen because you are trying to search in some places and you don't have a read access on it.\nSo to get rid of these errors you can redirect those errors to /dev/null\n find / -perm +1000 2> /dev/null\n\nMoreover you can redirect the output to a file\"output.txt\" rather than keep output in the \"terminal stdout\"\nfind / -perm +1000 >output.txt 2>/dev/null\n\n\nA: I'd just like to make a couple of points, expanding on Hadi's very good answer. First of all, the sticky bit has no effect on files in Linux. As explained in man chmod:\n\nSTICKY FILES\n         On  older  Unix  systems,  the sticky bit caused executable files to be\n         hoarded in swap space.   This  feature  is  not  useful  on  modern  VM\n         systems,  and  the Linux kernel ignores the sticky bit on files.  Other\n         kernels may use the sticky bit on files  for  system-defined  purposes.\n         On some systems, only the superuser can set the sticky bit on files.\n\nTherefore, there's no point in looking for files with the sticky bit set so we may as well limit the search to directories only, which will speed things up enormously. This can be done using find:\nfind / -type d -perm /1000 2>/dev/null\n\nAlso, note that I'm using the -perm /mode syntax instead of -perm +mode. This is because +mode is deprecated and can return in unexpected results. From man find:\n   -perm /mode\n          Any of the permission bits mode are set for the file.  \n\n   -perm +mode\n          Deprecated,  old way of searching for files with any of the per‐\n          mission bits in mode set.  You should use -perm  /mode  instead.\n          Trying to use the `+' syntax with symbolic modes will yield sur‐\n          prising results.  For example, `+u+x' is a valid  symbolic  mode\n          (equivalent to +u,+x, i.e. 0111) and will therefore not be eval‐\n          uated as -perm +mode but instead as  the  exact  mode  specifier\n          -perm  mode  and so it matches files with exact permissions 0111\n          instead of files with any execute bit set.  If  you  found  this\n          paragraph  confusing,  you're  not alone - just use -perm /mode.\n          This form of the -perm test  is  deprecated  because  the  POSIX\n          specification  requires  the  interpretation of a leading `+' as\n          being part of a symbolic mode, and so we switched to  using  `/'\n          instead.\n\nFinally, you can also use symbolic instead of octal modes which might be easier to read if you're not used to it:\nfind / -type d -perm +'+t' 2>/dev/null \n\n", "Q: Why subdomain not working after rename in ubuntu I had xyz.mydomain.com subdomain in ubuntu server.It was working fine.\nI just want to change that xyz to xyz1 , so i rename all folders as well as the virtual host settings in cd /etc/apache2/sites-available/\nI used below commands...\ncd /etc/apache2/sites-available/\nsudo nano xyz1.mydomain.com\n<VirtualHost *:80>\nServerName xyz1.mydomain.com\nServerAlias www.xyz1.mydomain.com\nDocumentRoot /var/www/xyz1/\n</VirtualHost>\n<Directory /var/www/xyz1/>\n        Options -Indexes FollowSymLinks MultiViews\n        AllowOverride All\n        Order allow,deny\n        allow from all\n</Directory>\nsudo a2ensite xyz1.mydomain.com\nsudo /etc/init.d/apache2 reload\nsudo a2enmod vhost_alias\nsudo /etc/init.d/apache2 reload\n\nNow i am unable to view xyz1.mydomain.com website. Is there any thing missing?\n\nA: If your output posted is correct, you ended the <VirtualHost> statement before the <Directory> statement. Move the </VirtualHost> line to the end and reload your config.\n", "Q: Umbrello UML tool not opening I'm using version of Ubuntu 13.10 and I install Umbrello tool for UML diagrams. But the problem is when I click on the icon its not opening. When I open it using terminal like:\n$ umbrello\n\nIts give me error:\numbrello(5801)/kdeui (kdelibs): Attempt to use QAction \"edit_undo\" with KXMLGUIFactory! \numbrello(5801)/kdeui (kdelibs): Attempt to use QAction \"edit_redo\" with KXMLGUIFactory! \numbrello(5801) UMLListView::findView: could not find  \"class diagram\"  in  UMLListViewItem: \"Logical View\", type=\"lvt_Logical_View\", id=\"Logical View\", children=1 \numbrello(5801) UMLListView::findView: could not find  \"class diagram\"  in  UMLListViewItem: \"Logical View\", type=\"lvt_Logical_View\", id=\"Logical View\", children=1\n\nI don't know how to launch it. Any one know about it?\n\nA: I came across the same problem and here is the solution \nsudo umbrello --geometry 600x400+0+0\n\nand that should solve your problem \n\nA: This bug has been fixed, see  https://bugs.kde.org/show_bug.cgi?id=329831 for details\n\nA: First just try to open from dash.\nopen your dash ans search for umbrello\n\nIf it doesn't open then try to purge\nsudo apt-get purge umbrello\n\nThen\nsudo apt-get install umbrello\n\nand try again\n", "Q: Disc burning software of Ubuntu I want to compile and write Xvid movie files to a disc for playing them on a standalone DVD player which requires ISO 9660 file system. How can I choose this file system with  the Brasero disc burner?\n\nA: You should take a look on k3b\nsudo apt-get install k3b\n\nWhen you start burning click on filesystem tab\n\nBy default this will support ISO 9660 file system but yo can configure more by clicking the custom button\n\n", "Q: Exit from fish shell I have Fish setup as my default shell. I want to exit from fish to bash. \nHow can I do that with opened fish shell?\n\nA: Just type bash and you'll start the bash shell. type exit to return to fish shell when you're done.\n", "Q: using nmap for information regarding web host am trying to get info of host run in linux about open/closed port \nthe host is attacked randomly by hackers changing the content of the page.deleting files,homepage content changed.\nhow can it be stopped?\ni scan ports using nmap i found it normal to have ports open like 3306 for mysql 80 for apache and other like mail server pop3 the list of open ports are:\n21/tcp ftp\n\n22/tcp ssh\n\n53/tcp domain\n\n80/tcp http\n\n110/tcp pop3\n\n143/tcp imap\n\n443/tcp https\n\n587/tcp submission\n\n993/tcp imaps\n\n995/tcp pop3s\n\n3306/tcp mysql\n\nwhen i use scan firewall protected for a Network\n# nmap -sA 192.168.1.77\n\nYou requested a scan type which requires root privileges. \nQUITTING!\n\nwhat tools to be used rather than nmap to take control over hacking?\nany ideas or concept how to stop this nuisance\nreferring to here for using nmap\n\nA: The nmap tool will help you to draw a map of the services available from the outside world to your server. As such, it won't help you to protect your server but will tell you where to pay attention. The more open ports you have, the more potential problems you may have.\nAn open source tool like OpenVAS will be certainly more helpfull to you. OpenVAS is vulnerability scanner that will not only show which ports are open on your server(s) but also try various kind of well-know attacks on these services and report what he found, with link to official security news explaining what the vulnerability is and how to overcome it.\nRunning this tool on your server will certainly help you to understand how it is possible that your server is regularly hacked.\nTo secure the servers I'm responsible for, I follow these guidelines :\n\n\n*\n\n*Reducing the number of open ports\n\n*Reducing the number of installed software to what is stricly necessary\n\n*Removing unwanted users and groups\n\n*Be sure that each users has a good password or are locked in case of system accounts\n\n*For each application running, review the security guidelines available in their official documentation\n\n*Performing software update when available\n\n*Enabling a valid logging and auditing mechanism to be able to determine how the hacking was done\n\n\nAn successful attack can be a combination of multiple factors : e.g. : weak password allowing unwanted FTP access, bad FTP configuration allowing to go the web root, bad permissions on filesystem allowing to write in the web root.\nAt your place, I would review all my users password, my FTP setup, my web server setup, the permissions in use and also I would have a look to the log files to see if I can find back a trace of the commands that were run to try understand where the weakness really lay.\nA tool like OpenVAS will help you to figure out what is possible to do on your server you'd never thinked about.\n\nA: To overcome the following message :\n nmap -sS --privileged --send-eth 192.168.1.77\n\nSo nmap will overcome the fact to have a root privileges .\nOr use this tutorial to run it as privileged user Site .\n\nA: If you have an active intrusion, scanning with Nmap is not going to get you anywhere. You need to replace the server with a properly-secured one and do forensics on the old one to determine the way the attackers got in. Linode has a decent guide to securing a server here.\n", "Q: How to give a quicklauncher or shortcut administration privilege? I have a quicklauncher in a plasma widget (which is the same as a shortcut) which runs a command which needs administration privilege. I use the quicklauncher frequently and do not want to type root password each time.\nIs there a way to give root privilege to the icon or  somehow add the password to the command which is run by the icon?\n\nA: if you would like to run it without a terminal window, and set the password in the command specifically (without editing sudoers), another option is to create a script like:\n#!/bin/bash\necho <password> | sudo -S <command>\n\n-and run it from your launcher (quicklauncher). \nThe command in the launcher would be: \n/bin/bash 'path_to_script.sh'\nThe downside is that you have your password stored in a file on a risky location. To work around the safety issue, you could locate the scrypt on a small truecrypt volume.\n(inpsired by this thread)\n", "Q: Why is my Laptop Brightness reset to minimum after every restart? I have an Acer Aspire 6930G with an Nvidia 9600MGS and Ubuntu 12.04 LTS. Every time I turn off my computer and then turn it back on the brightness is always set back at the lowest possible level. I like to use max brightness but the computer keeps reverting back to minimum brightness after I turn it off.\nI installed Ubuntu on this computer a week ago and this has been happening since the first day.\nCan anyone offer some solutions? I've tried a few and none of them worked for me, that's why I'm asking here\n\nA: You could always try this:\nedit /etc/rc.local to insert your preffered value:\nsudo gedit /etc/rc.local\n\nand add the following\necho X > /sys/class/backlight/intel_backlight/brightness\n\nreplace X by the value of your need\n\nA: This is weird action from some Video cards to solve this problem you can do the following:\nFirst let us check yiour VGA device code\nlspci | grep VGA\n\nThe device code looks like 00:03.0 for example.\nTo set brightness\nsudo setpci -s '00:03.0' F4.B='xy'\n\nwhere 00:03.0 is your VGA device code && xy is hexadecimal value of your screen brightness varies between 00 and FF.\nNow add this command to the /etc/rc.local file to run always on startup.\n", "Q: Makedepend: Command not found I'm trying to compile a source code and I'm getting this error\nmake[1]: makedepend: Command not found\n\nDo you have any suggestions?\nI have Ubuntu 12 04 LTS, 2.6.28-17 kernel and gcc version 4.6.3\n\nA: $ makedepend\nThe program 'makedepend' is currently not installed. You can install it by typing:\nsudo apt-get install xutils-dev\nYou will have to enable the component called 'main'\n\nFor future, typing the command automatically searches it inside repository and suggests variants of packages which can be installed in case the command not found in system.\n\nA: \n$ apt-cache search makedepend\nxutils-dev - X Window System utility programs for development\n\nSo you have to install xutils-dev package(which includes the program makedepend) .Install xutils-dev package by running the below command on terminal,\nsudo apt-get install xutils-dev\n\n", "Q: how to create an empty virtual machine without os in kvm? Can any one help me to create virtual machine in kvm hypervisor without os. Just the vm should have 8GB disk, 512 MB RAM and default NIC interface.\n\nA: First, create an empty image which will be used by the virtual machine to store data as:\nqemu-img create vm_no_os 8G\n\nHere, an 8GB disk is created of type raw with name vm_no_os.\nNext, use this image as the hard-disk for the virtual machine and boot the virtual machine without any OS:\nqemu-system-x86_64 -m 512 -hda vm_no_os -name vm -net nic\n\nHere, you can replace qemu-system-x86_64 with qemu-system-i386 if you are using a 32-bit system.\n-m 512 represents using 512 MB of RAM\n-name vm represents a name given to the VM being created\n-net nic creates a new Network Interface Card for the VM.\nRefer manual page of qemu-system-x86_64 for more.\n", "Q: How to add 'new docx' item in Ubuntu file manager context menu? I'm using Ubuntu 13.10 with it's default 'Files' file manager. It's really annoying to have to save every newly created documents to manually specified location in Libre writer every time. So, is there any way to add new entry to the file manager context menu so that I can create empty docx file by one click.\n\nA: The easiest way to do this is to add a document to ~/Templates (the Templates folder in your home directory).  For example, if you put stuff.docx in this folder, under the \"new document\" option in the context menu, \"stuff\" will be an entry and will create a docx document when clicked.  This actually creates a copy of the file in the \"Templates\" folder so you can put text into the document and it will be copied into every document created from this menu.\nThis can be used to add any document type you wish to the \"New Document\" right-click option.\n", "Q: Permission denied while installing matlab in ubuntu 12.04 I'm installing Matlab in Ubuntu 12.04 LTS by using terminal commands.\nAs mentioned in installation guide I am entering the following command:\n/path_to_dvd/install &\n\nbut when I enter the command it shows permission denied.\n$ /home/pawan/Documents/matlab/Matlab_Unix_2012a/ml2012au/install &\n[1] 19068\nbash: /home/pawan/Documents/matlab/Matlab_Unix_2012a/ml2012au/install: Permission denied\n\nI have mounted my .iso file and given path of that as well but it didn't work and\nI gave path of my .iso also.\n\nA: I have MATLAB running on Kubuntu 14.04. The reason you are unable to install it is because I think you are confusing the installation procedures with the downloaded files with the DVD installation procedures in the pdf.\nAfter extracting your Linux installer (which should be \"matlab_R2014a_glnxa64\" for the latest release for Linux), open a terminal and change your directory to the installation folder, than type ./install.\nAccording to your folder structure, the installer should be in \"/home/pawan/Documents/matlab/Matlab_Unix_2012a/ml2012au/\"\nTry\n$ cd /home/pawan/Documents/matlab/Matlab_Unix_2012a/ml2012au/\n$ ./install\n\nHowever, your folder name is \"Matlab_Unix_2012a\" which tells me you are using both an old version and it is probably the wrong operating system as well. I wouldn't know until you report back. If you are installing via an institution, I suggest getting the latest stable release for Linux. Ubuntu is explicitly mentioned.\n", "Q: ubuntu 32bit 13.04 iso image for virtual box \nHello folks\nFrom where i can download 32bit for 13.04 version for my virtual box.\nOnly 32bit.\nThanks\nshazz\n\n\nA: You can download the 13.04 32bit version from this link:\nhttp://releases.ubuntu.com/13.04/ubuntu-13.04-desktop-i386.iso\n\nA: You can use this link Site\nDownload this file : \n\n\nA: If you are using the standard desktop iso and installing in virtual box you will have to run the commands sudo apt-get install virtualbox-guest-dkms. After this it will become usable. \nThere are prebuilt virtual box images availible from many sites, but no \"offical image\" so to say.\n\nA: Here you can find all linux iso image \nhttp://releases.ubuntu.com/raring/\nhere they can given download iso image using wget you can also use this too\nDownload 13.04 iso with wget\n", "Q: The command could not be located because '/sbin' is not included in the PATH environment variable I have a severe problem today: when I type ifconfig it does not show ip configuration on ubuntu 12.04. Can anyone help me on this?\nHere is the result of ifconfig:\nCommand 'ifconfig' is available in '/sbin/ifconfig'\nThe command could not be located because '/sbin' is not included in the PATH environment variable.\nThis is most likely caused by the lack of administrative privileges associated with your user account.\nifconfig: command not found\n\n\nA: You can do either of the following:\n\n\n\n\n*\n\n*Open your ~/.bashrc file and write the following to the end:\nexport PATH=$PATH:/sbin\n\nand then do source ~/.bashrc or open a new terminal instance.\n\n\n*\n\n*or open your /etc/environment and add /sbin to end of the PATH variable, so that is as follows:\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/bin:/usr/games:/sbin\"\n\n\nA: Add /sbin  to the system path by running,\nexport PATH=$PATH:/sbin\n\nIf you follow @nux's answer, you have to create symbolic links for all the command files which are presented inside /sbin directory.But if you follow this or @jobin's answer, you don't need to go for that.\n\nA: You'll need to add /sbin to your path environment variable\n\n\n*\n\n*Create a new file in /etc/profile.d/custom-envs.sh (file must ends with .sh)\nset the following file content:\nexport PATH=$PATH:/sbin\n\n\n*Add execute permissions\nsudo chmod +x /etc/profile.d/custom-envs.sh\n\nTo apply changes, you'll need to logout and login again\n\nA: Try this command :\nsudo ln -s /sbin/ifconfig /usr/bin/ifconfig\n\n", "Q: How to get MacBook Air 6.2 webcam to work in Ubuntu 13.10 I just installed Ubuntu on my MacBook Air 6.2 and I am wondering if there is anyone that has got the new webcam in MacBook Air 6.2 to work? It seems like Apple has changed a lot since the last MacBook Air.\n\nA: There is no solution yet.\nKeep an eye on this  kernel bug\n", "Q: How to prevent the recorded video using ffmpeg get corrupt Actually I have an device that record the audio and video. when the recording is started the video file also started to persist into the hard drive.\nBut if device goes off unfortunately between the recording. The video file get corrupted and gives an error: This file not contain playable stream\nI am using the Ubuntu system and record the video using ffmpeg\nAny one can help me..!!!\nI am using the webcam for recording the video and bluetooth mic for audio using the ffmpeg.\nFollowing are the command that I am using to store the audio and video recording on other device(hard drive):\nffmpeg -loglevel warning -y  -i /home/prakash/../../output/2013-10-07T22-39-05/right_cam.mp4 -i /home/prakash/../.. output/2013-10-07T22-39-05/left_cam.mp4 -filter_complex '[1:0] pad=108:28:5:2:black [padvidleft]; [0:0] setpts=PTS+0.8786787543577881/TB [right_cam_pts]; [padvidleft][right_cam_pts] overlay=544:0 [mergedvid] ; [1:2] channelsplit [ll][lr]; [ll][lr] amix [leftmix];\n               [1:3] channelsplit [rl][rr]; [rl][rr] amix [rightmix];\n               [leftmix][rightmix] amix [cam_all];\n               [1:4] channelsplit [btl][btr] ; [btl][btr] amix [btmix] ;\n               [btmix][cam_all] join [bt_mixcam]' -f mp4 -crf 20 -r 24 -pix_fmt yuv420p -vcodec libx264 -vprofile baseline -map [mergedvid] -map [bt_mixcam] -map 1:2 -map 1:3 -map 1:4 /home/prakash/../../output/combos/combo-2013-10-07T22-39-05_dgrt6546533w471567f880abf287a855c_1088x288.mp4\n\nIf the recording is started and in the middle we turns off the recording device the recorded video and audio get persisted on hard drive but it is not able to play. When we try to play this recording the vlc gives the error this files contains no playable stream\n\nA: You should try a different output container format such as MKV.\nYour -f mp4 seems superfluous (unless this is part of a script where the output name is or part of a variable), but if you wanted to continue using this option the change it to -f matroska and give your output the mkv extension instead of mp4.\nMP4 requires additional information to be written to the file, but this can only occur after encoding is completed properly. If the encoding does not complete properly then the information may not be present resulting in a non-playable output.\n\nA: There is another great solution I got. It don't corrupt the audio and video files in any how.\nYou can use -f mpegts instead of -f mp4 in ffmpeg\n", "Q: How to remove temp files with a command other then \"apt-get autoremove\"? I have Ubuntu 12.04 lts.\nI want to know that if there is a command other than:\nsudo apt-get autoremove\n\nto remove temp files?\n\nA: You can use Ubuntu-tweak (see http://ubuntu-tweak.com/downloads/) to clean your Ubuntu installation ;)\nIf you have an SSD hard drive, you should also run sudo fstrim -v / at least once a week to trim your hard drive.\n\nA: Try the below command to remove temp files,\nsudo rm -rf /tmp/*\n\napt-get autoremove will remove   automatically all unused packages.\n\nA: Slow ubuntu may not be because of low disk space. Is this a recent problem? (i.e was it signficantly faster before?) If not:\n\n\n*\n\n*run free -m and post the results. \n$free -m\n             total       used       free     shared    buffers     cached\n\nMem:          5812       4919        892          0        164        822\n-/+ buffers/cache:       3932       1879 \nSwap:         9050       2076       6973\n\nIf the -/+ buffers/cache:       xxx       yyy line has very little free memory (yyy <150) then you might be short of ram. This line is the one that tells you what the actually used/free memory is. (The first line is a bit misleading because it also counts spare ram that was used to pre-cache files as used).\n1.1 if you are short of ram (and you had at least 1GB in total) open the system monitor form the dash and arrange the processes in by memory usage. see if any process is taking up too much memory and try killing it. A usual culprit is zietgeist.\n\n*find out if any processes are hogging the CPU\n\n*Do you have a graphics card hat can handle unity? (it needs hardware acceleration for it's perfectly purple pixels) You might need to install the necessary drivers (search for \"drivers\" in the dash and run the application that is suggested. \nIf you dont have a dedicated graphics card you need to have a core-i processor from intel. (e.g. i3 and above. they have a tiny integrated graphics processor).\n3.1 If you dont have a graphics card and/or you can't set up the drivers you will need to make unity a little easier on the CPU. follow the instructions here to drop some unecessary bling (Unity runs slow, how can I improve its performance?) \n3.2 alternatively install a lighter DE like XFCE or LXDE. This will make a world of a difference on older machines.\nFinally: if you have oodles of RAM and are just plain impatient with opening files install ureadahead. It finds the files you read the most often and loads them into ram, so they appear to open faster.\n", "Q: Header files missing I'm trying to compile a source code and I'm getting many errors indicating that header files are missing from my system\nchecking sys/ioccom.h usability... no\nchecking sys/ioccom.h presence... no\nchecking for sys/ioccom.h... no\nchecking sys/sockio.h usability... no\nchecking sys/sockio.h presence... no\nchecking for sys/sockio.h... no\nchecking for net/pfvar.h... no\nchecking for linux/wireless.h... no\nchecking bluetooth/bluetooth.h usability... no\nchecking bluetooth/bluetooth.h presence... no\nchecking for bluetooth/bluetooth.h... no\n\nSo, I'm starting to think I'm missing some important packages\nCan you list them for me?\nI have Ubuntu 12.04 LTS, 2.6.28-17 kernel and gcc version 4.6.3 and I'm trying to compile this package http://nrg.cs.ucl.ac.uk/mptcp/mptcp_userland_0.1.tar.gz \nThanks in advance\n\nA: Missing Headers and Libs\nIf you haven't installed the libs on your computer, here are the libs on an Ubuntu system:\n\n\n*\n\n*ioccom.h \n\n\n*\n\n*lib: freebsd-glue\n\n\n*pfvar.h \n\n\n*\n\n*lib: linux-headers-generic\n\n\n*wireless.h and sockios.h \n\n\n*\n\n*lib: linux-libc-dev\n\n\n*bluetooth.h \n\n\n*\n\n*lib: libbluetooth-dev\n\n\n\nTo install the packages:\nsudo apt-get install freebsd-glue libbluetooth-dev linux-headers-generic linux-libc-dev\n\n\nA: I used find / -iname 'wireless.h' for example, and found that most of the header files are there but the compiler didn't find them\nSo, I copied them to /usr/include/ directory and it worked fine\n\nA: Use the locate command\nFor instance if you like to find the ioccom.h header on your system use:\nlocate -b '\\ioccom.h'\n\nsearch in your database for this filename. So you get the paths and so on, assumming these headers are on your machine.\nMaybe you have additional to update your database before:\nsudo updatedb\n\nThat's the way I'm searching my headers location. It's much faster than using the find command.\n", "Q: A command to add a customized icon or symbol to Plasma's Default Panel Is there a command, that can add/remove a simple icon in KDE environment tray or anywhere in plasma's Panel (taskbar)?\nI need a customized notification icon or any other persistent symbol which shows a customized condition is on or off. (for me, it will show whether a network cable traffic is limited or is free)\n\nA: Just to archive an answer.\nThanks to Sparhawk I could add something in  Panel which shows the state of a connection.\nI have scripts for limiting a connection:\n\neach can be run by quicklaunch shortcuts located in panel.\nFor example 64kbits can contain something like:\n#!/bin/bash\n\nwondershaper eth0 64 64 \n\necho 64 > /home/Walesa/mycommands/kbits/state.txt\n\nBut running each script should show a persistent easy to see sign, so that the user knows about the limitation. With STDIN widget the contents of state.txt can be displayed:\n\nHere 32 shows the connection has speed 32 kbits. state.txt is what the scripts prepare. But the widget checks its contents every 30 seconds. Not an ideal solution.\n", "Q: Sublime Text 2 not saving preferences I recently installed Sublime Text 2 on my Ubuntu 12.04. The problem is that whenever I open it, by default it opens up to two files: sublime.desktop and defaults.list. Also, whatever preferences I try to set aren't saved and I always get the default configuration (with these two files opened) every time I start it up. This wasn't the case with Sublime Text 1. It used to save my preferences and open on my last opened files. Why is this happening? How can I make it save my preferences as Sublime Text 1 did?\n\nA: Since, when I first accessed Sublime Text, I accessed it as root, it's file permissions would need to be changed. It worked by the following command:\nsudo chown -R username /home/username/.config/sublime-text-2/\n\nin my case, it'll be:\nsudo chown -R ranveer /home/ranveer/.config/sublime-text-2/\n\nThanks to the comments by @SylvainPineau\n", "Q: How to drag stencil images in drawing in Calligra Flow? How do you drag stencil symbols from the palette into the drawing with Calligra Flow 2.8?\nI am just trying to drag and drop and it doesn't work. Is there some mode switching step I have missed?\n\nA: There is a bug in the drag and drop function for Stencils.\nIn the meantine the Stencil palette needs to be switch to List view for dragging Stencil images into the drawing. It is expected to be fixed in Calligra Flow 2.8.1.\n", "Q: How to know the release date of my BIOS version? It's pretty easy to check the release date of BIOS version directly from the terminal emulator using a simple single command. So how to do that?\n\nA: Easily use the command dmidecode.\nFirst install if you haven't do yet:\nsudo apt-get install dmidecode\n\nNow to check the release date of BIOS easily run the command:\nsudo dmidecode --string bios-release-date\n\nThe output will look like(my output):\n07/23/2012\n\n\nA: dmidecode is indeed the easiest way but it should be used with caution. As mentioned at the end of man dmidecode:\nBUGS\n   More often than not, information contained in the DMI tables is inaccu‐\n   rate, incomplete or simply wrong.\n\nSo, the authors themselves warn the user that the information returned might be crap. \nAnother program that is useful for getting information about the BIOS (though not the release date) is biosdecode which used to be part of dmidecode but has now been separated from it. Example output:\n# biosdecode 2.12\nSMBIOS 2.6 present.\n    Structure Table Length: 3650 bytes\n    Structure Table Address: 0x000F2430\n    Number Of Structures: 67\n    Maximum Structure Size: 253 bytes\nPCI Interrupt Routing 1.0 present.\n    Router ID: 00:1f.0\n    Exclusive IRQs: None\n    Compatible Router: 8086:2912\n    Slot Entry 1: ID 00:01, on-board\n    Slot Entry 2: ID 00:02, on-board\n    Slot Entry 3: ID 00:1f, on-board\n    Slot Entry 4: ID 00:1d, on-board\n    Slot Entry 5: ID 00:1a, on-board\n    Slot Entry 6: ID 00:1b, on-board\n    Slot Entry 7: ID 00:1c, on-board\n    Slot Entry 8: ID 00:19, on-board\n    Slot Entry 9: ID 02:00, slot number 33\n    Slot Entry 10: ID 03:00, slot number 34\n    Slot Entry 11: ID 04:00, slot number 8\n    Slot Entry 12: ID 06:00, slot number 9\n    Slot Entry 13: ID fe:00, slot number 10\n    Slot Entry 14: ID fe:00, slot number 16\n    Slot Entry 15: ID fe:00, slot number 17\n    Slot Entry 16: ID 00:16, on-board\n    Slot Entry 17: ID 0c:03, slot number 4\n    Slot Entry 18: ID 0c:02, slot number 3\n    Slot Entry 19: ID 0c:00, slot number 1\n    Slot Entry 20: ID 0c:01, slot number 2\n    Slot Entry 21: ID 0c:05, slot number 2\n    Slot Entry 22: ID 00:03, on-board\n    Slot Entry 23: ID 00:04, on-board\n    Slot Entry 24: ID 00:05, on-board\n    Slot Entry 25: ID 00:06, on-board\n    Slot Entry 26: ID fe:00, slot number 1\n    Slot Entry 27: ID fe:00, slot number 3\n    Slot Entry 28: ID 00:00, on-board\nPNP BIOS 1.0 present.\n    Event Notification: Polling\n    Event Notification Flag Address: 0x000004B4\n    Real Mode 16-bit Code Address: F000:E2F1\n    Real Mode 16-bit Data Address: 0040:0000\n    16-bit Protected Mode Code Address: 0x0001D2F6\n    16-bit Protected Mode Data Address: 0x00000400\nACPI 2.0 present.\n    OEM Identifier: DELL  \n    RSD Table 32-bit Address: 0xCF67DF18\n    XSD Table 64-bit Address: 0x00000000CF67DE18\nBIOS32 Service Directory present.\n    Revision: 0\n    Calling Interface Address: 0x000FFA10\n\n", "Q: How to kill libreoffice from command line I am using Ubuntu 12.04.4 LTS 64 bit. My LibreOffice suite (especially Writer) freezes.\nHow can I kill LibreOffice and Can I kill only the writer? (not the Calc,Impress,..)\nI tried to search for the executable process at System Monitor and command line (ps) but didn't find it.\nEDIT: I want something like this:\npkill -9 writer\n\nI need some kind of minified command.\n\nA: You should try:\nkillall soffice.bin\n\n\nA: First search for open libreoffice files:\nps aux | grep libre\n\nFor example the output of mine is:\nhadi  21426  0.1  0.0 205328  3468 ?        Sl   14:17   0:00 /usr/lib/libreoffice/program/oosplash --writer\nhadi  21445  9.8  0.7 1269272 179872 ?      Sl   14:17   0:01 /usr/lib/libreoffice/program/soffice.bin --writer --splash-pipe=6\n\nthen \nsudo kill -9 ID\n\nthe ID is the second number for (soffice.bin) not for oosplash\nso in my example:\nsudo kill -9 21445\n\n\nYou need professional Ok:\nps aux | grep -i office | awk {'print $2'} | xargs kill -9\n\nhope this is professional in your evaluation!!\nor more minified command\nkill -9 `pgrep -lf soffice.bin | awk {'print $1'}`\n\nor more minified minified minified command\npkill soffice.bin\n\n\nEDIT:\nAll libreoffice open files take the same PID, for that you can't just kill writer and keep impess for example.\nAnd to prove my point of view the recovery tool in office is unique for all files. What i mean if you close a writer in imporper way and then open an impress for example then impress will request you to recovery the writer file and it did so and this proves my answer\n\nA: use ps -e to list all processes running (not just those spawned by your current terminal). You can then search for the name you are looking for (Perhaps 'writer' or 'Libre'). If you know exactly the name you're looking for you could use ps -e | grep writer to give you the results for that process only.\nYou should see a number which is the process id (PID). To kill the process, enter kill x where x is the PID of the process. You should get a message saying something along the lines of killed 1 process. If the process is still running, try kill -KILL x to force the program to quit.\n\nA: Using killall\nI usually just get away with killing oosplash\nkillall oosplash\n\nor soffice.bin\nkillall soffice.bin\n\noosplash shows up higher in the pstree -p. \nUsing pstree\nThis function can be placed in your .bashrc file as a shortcut command. It searches the output of pstree -p for the PID of your search term.\npiddler(){\n    searchTerm=$1\n    echo \"Searching for ${searchTerm} processes:\" \n    pstree -p | grep -oE \"([a-zA-Z.-])*${searchTerm}([a-zA-Z.-])*\\([0-9]{3,7}\\)\" | grep -oE \"[a-zA-Z]([a-zA-Z.-])*\\([0-9]{3,7}\\)\"\n}\n\nYou can use it to find a system process like this:\npiddler office\n\nIt'll output something like this:\nSearching for office processes:\nsoffice.bin(8707)\n\n\nThen you can kill the process with:\nkill -9 8707\n\n\nA: In a makefile\nIn a makefile, error messages can be avoided with either:\n-killall -q oosplash\n\nor\n-@killall oosplash\n\nThe characters in front of the killall command do the trick.\nHowever, even more gracefully would be:\n-@wmctrl -c LibreOffice\n\nor, even safer:\n-@wmctrl -c filename\n\n\nA: I had this problem, when I opened second document in LO Writer. I was not able to close not only LO, but anything, even UBUNTU. A simple, not ideal solution was:\n\n*\n\n*Open Terninal\n\n*shutdown\n\nWhen I opened the UBUNTU and LO again, it asked me, if  I want to save the last document before the crash. My answer was (to be careful) no.\nThen I had no problem.\n\nA: Usung killall -e\nAs Thomas Nyman said in https://unix.stackexchange.com/a/91540/382418\n\nkillall somewhat safer to use compared to pkill\n\nTherefore i use: killall -e soffice.bin using (kUbuntu 20.4)\n\nThe -e, --exact option can be specified to also require exact matches for names longer than 15 characters.\n\n", "Q: Is there a terminal commands cheat sheet application? I stumbled upon a terminal cheat sheet here and I started wondering if there was anyway to display this in Ubuntu 12.04, much in the way that holding the [Super] key displays tips for window managing and shortcuts.\nIs there any app or desklet or something that provides this effect? I'm very new to Linux and this quick reference would be very useful to me.\n\nA: A better solution to looking at an image to learn text commands is to use apropos with a search term. apropos permissions, apropos disk, apropos network, apropos search &c\n\nA: Not quite what you are looking for, but cheat.sh is a very nice thing. This is an universal cheat sheet for almost anything, not only Linux terminal commands but also many programming languages etc.\nIt works online by accessing the webpage which is under this very address cheat.sh. You can use it right from the browser, but the preferred way is to install curl (sudo apt install curl) and then running the following command in terminal:\ncurl cheat.sh\n\nIt will explain how to use it and use more commands.\n", "Q: Presentations on Lubuntu? Is there a lightweight package for doing powerpoint presentations on Lubuntu?  I have Abiword for wordprocessing and Gnumeric for spreadsheets,  but I'm not sure about Powerpoints?  I heard there was a thing called \"Ease\" or something but I don't know how to find it.\n\nA: I have been using Lubuntu since version 11.04 and I use Libre Office.  Unless you have very little RAM you can as well.  Information concerning Ease can be found \nhttps://launchpad.net/~natesm/+archive/ease\nand\nhttps://launchpad.net/easeproject\n", "Q: What is the minimal amount of RAM to built an 3.11.0 x86_64 kernel on 13.10 with 8 cores? I have configured a KVM virtual machine (VM) with 8 processor cores and 256 MB of RAM and no swap. A minimal text based Ubuntu Saucy 13.10 amd64 was done. The essential packages to build/recompile the 3.11.0 kernel were installed.\n\n\n*\n\n*The intended architecture for building the kernel is ARCH=x86_64.\n\n*The running kernel is amd64 3.11.0-18-generic.\n\n*Gcc is version 4.8.1 (Ubuntu/Linaro 4.8.1-10ubuntu9).\n\n\nWhen executing the command:\nfakeroot make-kpkg -j 8 --initrd --append-to-version=-custom kernel_image kernel_headers\"\n\nIt finally ends with:\nmake: *** [debian/stamp/build/kernel] Error 2\n\nThe first error in the console output is:\n  CC      drivers/gpio/gpio-stmpe.o\n{standard input}: Assembler messages:\n{standard input}:2242: Warning: end of file not at end of a line; newline inserted\n{standard input}:4413: Error: unknown pseudo-op: `.l'\n{standard input}: Error: open CFI at the end of file; missing .cfi_endproc directive\ngcc: internal compiler error: Killed (program cc1)\nPlease submit a full bug report,\nwith preprocessed source if appropriate.\nSee <file:///usr/share/doc/gcc-4.8/README.Bugs> for instructions.\nmake[3]: *** [net/ipv6/udp.o] Error 4\nmake[2]: *** [net/ipv6] Error 2\nmake[2]: *** Waiting for unfinished jobs....\n\nMy first idea is that the amount of random access memory (RAM) is confired to low (256MB). \nUpdate #1\nAfter having a look at the console, I am sure that the build machine has too little RAM:\nOut of memory: Kill process 8128 (cc1) score 117 or sacrifice child\nKilled process 8128 (cc1) total-vm:102432kB, anon-rss:23184kB, file-rss:0kB\n\nUpdate #2\nIncreasing to 384MB, 512 or even 640MB of RAM is not enough to stop \"Out of memory\" error messages.\nWhat is the minimum amount of RAM required to build the kernel?\n\nA: 768MB of RAM was enough to compile the 3.11.0 kernel where ARCH=x86_64. \nNote that 640MB was not enough.\nIn this case the .config file was modified to localmodconfig and later on some options were disabled and others enabled. The resulting .config file size is 86458 bytes.\n", "Q: Ubuntu 12.04(32bit) Dropbox keep showing \"Connecting\" I have some questions about executing Dropbox on Ubuntu 12.04 LTS ( 32bit ).\nAfter I followed this instruction and tried to install Dropbox,\n32-bit:\ncd ~ && wget -O - \"https://www.dropbox.com/download?plat=lnx.x86\" | tar xzf - \n\nwhen I typed this instruction to continue, \n~/.dropbox-dist/dropboxd\n\nthe cursor is left at the same position,\nand nothing popped out, so I can't continue...\nThe Dropbox icon on the right-up-side bar remains grey...\nand when I type this in the terminal\ndropbox status\n\nit keeps showing \"Connecting...\", and nothing happens.\nI tried to reinstall (remove and install again, logout and login), it just can't work.\nCan someone please help me on this issue ?\n\nA: In my case it was because I set Dropbox to sync to an automounted partition. When I changed it to a local system partition and restarted the service it started working.\n\nA: Remove that installation. \nThen go to your home folder and delete .dropbox and .dropbox-dist folders. \nInstall it again from here:\nhttps://www.dropbox.com/download?dl=packages/ubuntu/dropbox_1.6.0_i386.deb\n", "Q: What does this mean in \"crontab -e\"? When I run crontab -e, I see this bit:\n\nNotice that tasks will be started based on the cron's system daemon's notion of time and timezones.\n\nHow to convert the cron's system daemon's notion of time and timezones to something I understand or is there some way I can work it out?\nI don't keep my machine on all the time and so I would like to set a daily time when my machine is most likely to be on.\n\nA: *\n\n*You can add\n* * * * * date > /tmp/current_time.txt\n\nand see what time cron is running with. Cron will use local time so it should (by default) show UTC.\n\n*See /etc/default/cron if you want to change it. It will show TZ=UTC (by default).  \n\nA: Problem: the introductory comments one sees when running crontab -e include these words:\n\nNotice that tasks will be started based on the cron's system daemon's notion of time and timezones. \n\nWhat that actually means is not clear to me that is why I asked the question.\nSo I ran crontab -e to have this line:\n45 16 * * * touch /home/dbk/Desktop/$(date +\\%H:\\%M:\\%S).txt\n\nWhat I'm asking cron to do is to create a file with the current time as prefix and .txt as extension and to do this at 16:45 h based on the cron's system daemon's notion of time and timezones.\nWhenever the file is created, I can compare the prefix of the file with the \"date modified\" and thereby come to know what time cron ran the job.\nAs it so happens, cron ran the job at 16:45 IST which is my local time.\n", "Q: How do I recreate /dev/shm after removing it by mistake? I'm running Ubuntu 13.04 and I removed by mistake few folders from /dev/. As a result i have some problems with some applications like Chrome, which is not able to work.\n\nA: /dev/shm is a way processes use to share memory (see man shm_open for more information). Its content is determined by the processes you run, therefore you can't \"download\" it. You can however re-create it.\nOn Ubuntu, /dev/shm is a symlink to /run/shm; this is the command that you have to use to re-create it:\nsudo ln -s /run/shm /dev/shm\n\nThis action is also performed by the /etc/init/mounted-dev.conf Upstart script. This means that (as it was already suggested) rebooting your system without doing anything special is an another way of fixing the problem.\n\nA: /dev/shm is nothing but implementation of traditional shared memory concept. It is an efficient means of passing data between programs. One program will create a memory portion, which other processes (if permitted) can access. This will result into speeding up things on Linux.\nyou need to add or modify entry in /etc/fstab file so that system can read it after the reboot. Edit, /etc/fstab as a root user, enter:\nsudo gedit /etc/fstab\n\nadd /dev/shm entry as follows to set size to XXGB\nnone      /dev/shm        tmpfs   defaults,size=XXG        0 0\n\nreplace XX by the size you wish to use as shared memory.\nSave and close the file.\nNow reboot.\n\nIf you just want to restore your old /dev/shm file then use the current running memory which is a copy of /dev/shm\nsudo cp /run/shm /dev/shm -r\n\nthen reboot\n", "Q: Computer will not turn off properly I have Ubuntu Gnome 13.10 x86 on my old ~2007 iMac. It is not dual booting and it runs an intel processor. It has 2 GB of RAM.\nMy issue is that after I push the \"Shutdown\" button from the user menu the system just stops in the middle of the shutdown process. To be specific at the \"Will now halt\"\nPlymouth works (the boot screen still moves) and i can press ESC to view the consol output.\nI also noticed that modem manager was not shutting down properly so I uninstalled it because I use Ethernet at my place.\nAnother error message is: Mount '/' busy\nI think that is the main consern but I can't figure it out. I have o hold the power button down.\n\nA: It turns out that various drivers were missing.\nHere are the drivers that I installed and it shut down properly after instalation:\niSight and Wi-Fi.\n\nHope this helps others!!! :)\nHave a nice day!\n", "Q: Is there a NSA backdoor in ubuntu desktop os? I heard talk of selinux being in ubuntu and it being a nsa backdoor.\nSource of my worrying :(\nSo are these guys right? Is there a backdoor in Ubuntu (I use xubuntu if that matters)?\nHave any of you guys ever checked ubuntu/xubuntu source for NSA backdoors?\nI would but I don't know how.\n\nA: A few points:\n\n\n*\n\n*SELinux isn't included in Ubuntu by default but it is installable\n\n*Ubuntu uses AppArmor by default (does roughly the same job)\n\n*The NSA working on code does not translate to \"The NSA leaving backdoors everywhere\"\n\n*The NSA is responsible for helping the US government have secure computers and making SELinux the best it possibly could be would aid that goal. Punching holes in SELinux would be a monumentally stupid idea.\n\n*A few people bickering in a forum thread without evidence is not a viable security threat\n\n*I've just seen your comment drawing parallels between this and the Amazon integration. Don't conflate the issue of privacy and advertising with unknown security threats. They're very different beasts.\n\n\nAre there known backdoors in the code? Of course not... Linux is used all over the place and a publicly known issue like that would be too devastating to leave in.\nBut could there be some? Sure. It's impossible to say that every line of code submitted has had security analysis but at the very least (and this is the security boon that most new FOSS advocates allude to) you can inspect the code if you're suspicious and then track the provenance. You can also hope that other people have reviewed the code. You don't have that choice or hope in close-source software.\nAs with everything, you just have to work on who you trust most... This isn't something local to SELinux. Consider your entire software stack, but if you're too paranoid you'll very quickly end up not using any software at all.\n", "Q: How do I loopback 2 input streams + line-in to line-out? (12.04) I'm trying to put together a simple Karaoke system with 2 microphones. I've fiddled with the config from this post and am able to get 1 mic to loopback, along with youtube, to the the line-out. \nBut I cannot seem to get 2 mics to loopback simultaneously. It appears I have to choose which input stream is selected in the sounds app on the inputs tab. Any suggestions?\n\nA: It is possible to loopback multiple sources to same sink.\n\n\n*\n\n*Check sources list (For me, I have only one microphone source: id=2)\n$ pactl list short sources\n0   alsa_output.pci-0000_01_00.1.hdmi-stereo.monitor    module-alsa-card.c  s16le 2ch 44100Hz   SUSPENDED\n1   alsa_output.pci-0000_00_1b.0.analog-stereo.monitor  module-alsa-card.c  s16le 2ch 44100Hz   IDLE\n2   alsa_input.pci-0000_00_1b.0.analog-stereo   module-alsa-card.c  s16le 2ch 44100Hz   SUSPENDED\n\n\n*Create a new virtual sink\npactl load-module module-null-sink sink_name=Virtual1 sink_properties=device.description=Virtual1\n\n\n*Loopback sources to Virtual1 sink (one by one), by id:\npactl load-module module-loopback sink=Virtual1 source=2\n\nor by name:\npactl load-module module-loopback sink=Virtual1 source=alsa_input.pci-0000_00_1b.0.analog-stereo\n\nSee Share an audio playback stream through a live audio (video) conversation like Skype\n", "Q: Not getting output after dmesg I am a beginner. I wrote a hello world module (actually copied from the o'Reilly book).\nthe code is:\n#include <linux/init.h>\n#include <linux/module.h>\n\nMODULE_LICENSE(\"Dual BSD/GPL\");\n\nstatic int hello_init(void)\n{\n    printk(KERN_ALERT \"\\nHello World\");\n    return 0;\n}\n\nstatic void hello_exit(void)\n{\n    printk(KERN_ALERT \"\\nGood bye\");\n}\n\nmodule_init(hello_init);\nmodule_exit(hello_exit);\n\nSo when i insert the module, and dmesg nothig would appear. But when i remove it, and then dmesg, i can see \nHello World\n\nGood Bye\n\n\nA: This is because the buffer is not cleared when you print \"\\nHello world\" and cleared when ultimately you remove the module.\nTo deliberately clear the buffer, instead print\nHello world\\n\n\nand similarly,\nGood bye\\n\n\nNote the newline \\n at the end of each printk statement.\nRefer to this SO question to know why a newline is necessary:\n\n\n*\n\n*Why does printf not flush after the call unless a newline is in the format string?\n", "Q: How to print multiple copies of an image on a single page I have an image, about 300x300 pixels large. I want to print as many copies as possible on a single page (I am planning to cut them apart with scissors afterwards).\nIs there a way to do this? Is there a way to generate a PDF with copies (without opening something like gimp and manually doing copy-paste work).\n\nA: From Command-Line Printing in Linux. \n\nN-Up Printing\nThe -o number-up=value option selects N-Up printing. N-Up printing\n  places multiple document pages on a single printed page. CUPS supports\n  1, 2, 4, 6, 9, and 16-Up formats; the default format is 1-Up:\nlp -o number-up=1 filename \nlp -o number-up=2 filename \nlp -o number-up=4 filename \nlpr -o number-up=16 filename\n\nThe -o number-up-layout=value option chooses the layout of the pages\n  on each output page:\n-o number-up-layout=btlr\nBottom to top, left to right\n-o number-up-layout=btrl\nBottom to top, right to left\n-o number-up-layout=lrbt\nLeft to right, bottom to top\n-o number-up-layout=lrtb\nLeft to right, top to bottom (default)\n-o number-up-layout=rlbt\nRight to left, bottom to top\n-o number-up-layout=rltb\nRight to left, top to bottom\n-o number-up-layout=tblr\nTop to bottom, left to right\n-o number-up-layout=tbrl\nTop to bottom, right to left\n\n\n\nSo I assume it will be something like this: \nlp -o number-up=4 number-up-layout=lrtb -d {printer} {filename} -n {copies} \n\nAnd it should print 4 images from left to right, top to bottom per page for the amount of {copies}. The numbers you can use seems fixed... \n\nIf this does not work please leave a comment. \n\nA: install gThumb (sudo apt-get install gthumb)\nexecute gThumb\nselect several image\nright-click and select print\n\nselect image tab\nincrease Rows and Coulms\n\nA: It is possible and convenient with PhotoPrint.\nInstall the app in the Terminal:\nsudo apt-get update\nsudo apt-get install photoprint\n\nWhen you open the image in the app, click it and choose from the menu Image > Duplicate Image. (also available via rightclick on the image)\nNext you choose the amount of columns and/or rows you want to produce under Layout  and adjust the other settings like margins and  distances between the images.\nYou can save your settings as default under File in the menu.\n\nA: You can use ImageMagick's montage tool.\n\n\n*\n\n*Install the imagemagic tools\nsudo apt-get install imagemagick\n\n\n*Combine your images. I have created this image, called foo.png as a demonstration:\n\nRun montage, telling it to make 3 rows of 5 images each (-tile 3x5), keeping the original size of the image (-geometry 300x400  and give it the same image 15 times as input:\nmontage -geometry 300x400 -tile 3x5 foo.png foo.png foo.png foo.png foo.png foo.png foo.png foo.png \\\n foo.png foo.png foo.png foo.png foo.png foo.png foo.png  montage.ps\n\nThe result is:\n\n\n*Since that creates a postscript file (the language printers speak), you can print it directly from the command line using tools like lp or enscript. I don't have a printer at the moment so I can't check but this should work\nlp montage.ps\n\nor\nenscript montage.ps\n\n\nA: I was not satisfied with the answers so I came up with my own solution to print an image sixteen times on one sheet of paper:\n# Append vertically.\nconvert Image.png Image.png Image.png Image.png -append Image_4_1.png\n# Append horizontally.\nconvert Image_4_1.png Image_4_1.png Image_4_1.png Image_4_1.png +append Image_4_4.png\n\nNow you can go ahead and print Image_4_4.png. You may want to delete Image_4_1.png afterwards. Works nicely with flashcards.\n", "Q: atheros AR9285 compatibility with wpa2 enterprise I have a asus u32u and just install the ubuntu 13.10. I'm new working with linux and need a little help.\nMy pc has a Qualcomm Atheros AR9285 and I can connect to my Wi-Fi, my problem is in my college, where i can connect via cable but not via Wi-Fi.\nMy college Wi-Fi:\n\n\n*\n\n*security: WPA2 Enterprise\n\n*authentication: Protected EAP (PEAP)\n\n*inner authentication: MSCHAPv2\n\n\nAny question, just ask. If you need me to put some information about my pc, please leave the respective code.\n\nA: I have this problem all the time with Linux-based OS's.\nsudo gedit /etc/NetworkManager/system-connections/'name of SSID'\n\nThe problem is that it's looking for a certificate on the PC to validate the connection.\nGo in and find:\nsystem-ca-certs=true\n\nand change it to:\nsystem-ca-certs=false\n\nAnd then try reconnecting. Hope that helps.\n", "Q: browser compositor issues - chromium versus chrome Chrome browser beta release 34 includes the google 'Aura' compositor that caused lots of issues on my env using 12.04 with GPU = intel HD4000. \nSo, i went back to the 'Chrome-browser' general release and stopped using 'chrome-beta' which i always liked.\nPrior to chrome-beta 34 everything with the GPU with WebGL with the GPU drivers was fine. \nI do not understand the implications of Google's move to 'aura' compositor on my choice of browser ( chrome or chromium ) for my ubuntu system. \nI can just install Chromium browser and try it for awhile and see whether i like it better than chrome browser. \nBut i am interested in this source divergence around the google 'Aura' compositor and what actually would work better on my linux system?? \nIf google are doing something (fundamental in the aura compositor) with the way that their browser interacts with X  or with GTK i have no idea what i should check in my system to make sure that i have not gummed something up. \nI did originally have to twiddle some hardware driver things in Ubuntu in order to get WebGL to work with my GPU (intel HD4000 drivers). \n--EDIT-- google-chrome-unstable (M35 including aura) is running fine detls below:\nremove older package (stable or beta)\ninstall google-chrome-unstable using apt\nopen broswer to \"chrome://flags\" changing first option to \"ignore blacklist\"\neverything looks OK in \"chrome://gpu\" following tweek above\n\nA: Aura hasn't been push to beta. M34 initially was planned to have Aura, but it was decided that there were too many bugs (most likely among other reasons). M35 (currently on dev) does have Aura enabled.\nPart of the reason that they are switching to Aura is so that they have less code to maintain, fewer #ifdef's (code to compile on one OS, but not on the other), and the ability to push out new features at around the same time as Windows. This does mean that there is probably less reliance on GTK, and the looks of menu entries will be slightly different.\nWhich one works better? Hopefully, by the time Aura is pushed to beta and stable, Aura will be nearly equivalent in terms of functionality and looks as GTK (note that not everything will be the same; the omnibox drop down menu fills the whole width of the browser rather than just the width of the omnibox, and this is intentional). In terms of performance, Aura seems to be a little smoother for me (I'm currently on Chromium Dev), but that's completely unscientific and possibly just a placebo effect. There are one or two major bugs where the rendering is messed up when you exit full screen or shrink the browser window, but I work only in maximized mode and don't see these bugs. On my Intel i3 and HD Graphcs 3000, I don't see any major bugs in Aura.\nNote that M34 did suffer from a major rendering bug that affected Intel GPUs where pages would be frozen. The most recent beta release (34.0.1847.60) should have fixed that.\nIf you want, you can try Chromium Aura from my PPA, and report any major bugs you see to Chromium.\n", "Q: Check dependencies and generate download script before installing by dpkg I used to install packages with dpkg -i *.deb command for off-line installation. Because all deb files are in one folder.\nI want to avoid dependency error and stop installing packages as broken. \n\nUltimately my aim is to check dependencies and generate download script (if all dependencies are not satisfied) for only those package\n  which is missing in mentioned folder. so-that I can first download missing packages and Then confidently \n  install package by dpkg -i *.deb\n\napt-cache showpkg $(find -iname '*.deb' -exec dpkg --info '{}' \\; | awk '/Package:/ {print $2}') shows dependencies but long list and not helpful to check whethter it is satisfied (exist) in mentioned folder or not. Also dpkg -I *.deb errors following: \n   dpkg-deb: 'cabextract_1.4-4_i386.deb' contains no control component 'chromium-codecs-ffmpeg-extra_34.0.1847.116-0ubuntu2_i386.deb'\n   dpkg-deb: 'cabextract_1.4-4_i386.deb' contains no control component 'flashplugin-installer_11.2.202.350ubuntu1_i386.deb'\n..\n..\nso on for each deb\n\nHence, That commands are not useful for me.\nFurther Clarification:\n\n\n*\n\n*First check all deb dependencies in my folder.\n\n*according to package already installed, check this deb's are able to installed without dependency error or not.\n\n*if yes then execute dpkg -i *.deb\n\n*else list missing package which not fond installed or in mentioned folder\nThanks.\n\nA: You can always try a dry run before the install,\ndpkg --dry-run -i *.deb\n\n\nA: You can get a list of the packages dependencies with:\nfind *deb -exec dpkg -f {} Depends \\;\n\n\nA: You can also try one of these\n dpkg -I package\n apt-cache rdepends package.deb\n apt-cache showpkg package-name\n\nthis one is a combination of steps incase it's just a .deb file\n ar -x <package-name>.deb\n tar -xzf control.tar.gz\n grep Depends control\n\nor \n apt-cache depends package-name\n\nfor example\n apt-cache depends mplayer\n\nbut i think the last option is what might serve you best\n", "Q: How do I get the two external monitors connected to my laptop to stop mirroring each other? I have a Lenovo T440 laptop on 12.04 with two external monitors attached (running through one VGA port that goes to this splitter). Right now Ubuntu is counting the two external monitors as one (they mirror each other). It seems like 3 monitors is a bit tricky. For now, how do I get my laptop screen to mirror one (but not the other) monitor. That way my laptop and one external monitor will show one picture and the other external monitors will show the other. Thanks.\n\nA: The specifications on the link which you provided for your splitter says:\n\n\"provides an inexpensive solution for displaying a mirror image on 2\n  monitors at the same time\"\n\nWhat you want is not possible with this equipment.\n\nA: I believe one is connected to HDMi. I don't know your laptop specs but without the necessary drivers the HDMi would either not work or act like a VGA out. So the easiest solution would be to install latest closed-source drivers for your GPU.\nI am pretty sure there could be open-sourced and code-based solutions too but I have no idea about them...\n", "Q: How to do-release-upgrade with automatic yes to all continue and disable reboot after upgrade completion How do I disable reboot after do-release-upgrade? Is that even possible?\nHow do I automatically answer y to all continue during do-release-upgrade`?\n\nA: There's an app for that! Well, for answering y automatically anyway:\nNAME\n       yes - output a string repeatedly until killed\n\nSo, you could do \nyes | do-release-upgrade\n\n", "Q: 403 forbidden access apache on ubuntu full access we had an issue with our sites on our Ubuntu server.\nbasically we did a chmod -R 777 on the var folder to grant full permissions. Is that ok to do?\nlrwxrwxrwx  1 ftpuser ecoftpgroup   30 2011-06-03 15:37 mywebsite.co.uk -> /var/www/clients/client5/web6/\n\nHow can i also find info about the user and group as stated in the line above?\nIt was working fine yesterday and today we got the 403 forbidden error.\n\nA: Check the permission of parent folders. All the folders in the chain must have +x (execute privileges) available to the www-data user (usually via other permission).\n", "Q: copying the contents of a directory from Downloads to /etc I want to copy the contents of a folder colors from ~/Downloads/vim-colorschemes-master to /etc/vim/colors. I tried this as instructed:\ncp colors/* ~/etc/.vim/colors\n\nBut I am getting the error:\ncp: target ‘/home/advenio/etc/.vim/colors’ is not a directory\n\nHow do I do this correctly?\n\nA: ~ refers to the home directory (in your case /home/advenio/). The place you want to copy it to is /etc/vim/colors\nTry the command sudo cp ~/Downloads/path_to_colors/colors/* /etc/vim/colors\n\nA: Try the following command:\nsudo mkdir -p /etc/vim/colors && sudo cp ~/Downloads/vim-colorschemes*/colors/* /etc/vim/colors\n\n\nA: The command for copying a directory including all of its contents is:\nme@linuxbox:~$ cp -R location_of_source_directory location_of_destination_directory\n\nThis command will create the destination directory at the new location.\nFor example, here I copied a folder from one destination to another destination. I used cd and ls to make sure the files were copied and didn't exist before.\n\nBy the way, as you are trying to copy the folder to /etc/... you need to use sudo like:\nme@linuxbox:~$ sudo cp -R location_of_source_directory location_of_destination_directory\n\nBecause that location is owned by root and you don't have permission to add/remove files/folders in there.\n\nA: When copying folders using the cp tool, use the recursive option. This copies the contents of the colors folder:\nsudo cp  ~/Downloads/colors/* /etc/vim/\n\nor copy the entire folder\nsudo cp -r ~/Downloads/colors/ /etc/vim/\n\nwhere the ~ sign represents the home directory.\nBy the way it's not .vim but vim.\n\nA: First make sure the target directory (here ~/etc/.vim/colors) exists.\nIf it does not, create it with:\nmkdir -p ~/etc/.vim/colors\n\nTo copy the contents of a source directory to some other location:\ncp -rvt destination-directory source-directory/*\n\n(this will copy all contents, both files and directories within source-directory to destination-directory.)\ncp -vt destination-directory source-directory/*\n\n(this will copy the files within source-directory to destination-directory.)\nExample:\ncp -rvt ~/etc/.vim/colors ~/Downloads/vim-colorschemes-master/colors/*\n\nHere, the contents of ~/Downloads/vim-colorschemes-master/colors directory will be copied to ~/etc/.vim/colors.\nIf you want to copy the source-directory itself use:\ncp -rvt destination-directory source-directory\n\n(where v in -rvt is for verbose output, r for recursive used when copying directories, t to specify the destination.)\nExample:\ncp -rvt ~/etc/.vim/colors ~/Downloads/vim-colorschemes-master/colors\n\nHere, the source ~/Downloads/vim-colorschemes-master/colors directory will be copied to ~/etc/.vim/colors.\n\nA: Here's how to copy a folder in Ubuntu terminal.\nAt the upper most part of your terminal window you will know what user or directory you are.\nNote: you won't be able to run the cp command if you are in the wrong directory.\nTerminal command:\ncp -R /home/user/directory /destination\n\nYou'll get it to work soon, just continue thinking hard. Me, it took about 3 hours before I understand the command.\n", "Q: Should I use MAAS and Juju if I only intent to use a single PC? I am planing to setup a local server at my home that I will use for various entertainment/work tasks. Do you think that installing MAAS and juju is an overkill if I intent to use only one pc? \n\nA: Yes, for one machine MAAS is absolutely overkill.\nHowever Juju can (as of version 1.18) deploy to any Ubuntu Server with OpenSSH via manual provisioning, we designed this feature for cases like yours where you want to deploy services quickly without needing a cloud:\n\n\n*\n\n*https://jujucharms.com/docs/stable/clouds-manual\nThe basic process is you register your machine(s) with Juju via: juju add-machine ssh:10.1.1.2 for example. And then you can deploy services to your one server (preferably in LXC containers to keep them isolated).\nIf you had racks and racks of machines then MAAS makes sense, if you have one box or a handful of machines then the manual provider is much simpler to get up and running. \nSee also:\n\n\n*\n\n*Is juju only for cloud usage?\n", "Q: How to open GTK apps at center of screen? \n*\n\n*How to code this using Quickly?\n\n*Will frameless GTK apps work the same?\n\n\nA: Type quickly design when you are in the application's directory. This should open up glade which gives you a GUI to design your application.\nWhen you click on the top-level window, you will see the Window Properties. In this you will find an option for \"Window position\", assign \"center\" to this field.\n\nThis will open the main window of your application in center.\n", "Q: UbuntuOne Auth failed I have a dual boot notebook (windows 7 and Xubuntu 12.04).\nThe Ubuntu one client is installed on both systems, each one with a different sync folder (c:\\user\\a\\ubuntu one, home/b/ubuntu one) \nUbuntuOne client was running fine until I booted Windows where I got an error from UbuntuOne client. So I upgraded UbuntuOne client, started the synch process and it worked.\nWhen I booted Ubuntu again I get a \"File Sync error. (auth failed (AUTH_FAILED))\". \nI read this question but I can't find the 'Passwords and Keys application' in Xubuntu both from the Accessory or from System Settings.\nI have tried a completely re-install of the UbuntuOne client but it was unsuccessful.\nI think that the issue might be due to a different user files owner (a on windows7, b on Ubuntu).\nHow can I fix it?\nShould I remove the UbuntuOne client for Windows7 and get only the Ubuntu version?\n\nA: I experienced something very similar on Ubuntu 13.10 when adding new devices which is logged at https://bugs.launchpad.net/ubuntuone-client/+bug/1253728\nFor me the workaround was really odd but consistant on 3 different computers as I was doing some moving, adding, and re-installing on several (only two as of the writing of that post).  I found that I had to click some things that seemed contrary to logic but everthing worked fine every time.\n\n\n*\n\n*Started the client and it seemed frozen at \"Getting information,\nplease wait...\"     \n\n*Killed the client and restarted it.\n\n*This time it asked me to log in so I did so with my existing account (as\nif it were new).\n\n*It displayed \"Getting information\" but I just\nclicked next anyway.\n\n*Confirmed the folder selections.\n\n*After this it displayed the authentication error but after I clicked restart\neverything was fine and it has been working since then.\n\n", "Q: Run .bash_profile script at login i'm working on a deb package that allows the administrator to create another account and run that account automatically in kiosk mode. I created the user, specified a shortkey and put that in a hidden file, and created a .bash_profile script on the admin account that i copy to the new user's home folder.\nThis is the script i'm running to create the files and specify the shortkey:\n#!/bin/bash\nbasis=\"Primary + Alt + \"\nshortkey=`zenity --entry --text \"Your shortkey will be a combination of <Primary> + <Alt> + a letter\\n\\n Specify your letter!\"`\n\nwhile [[ $shortkey = *[^A-Z]* ]];\n        do\n                zenity --warning --text \"Input incorrect\\n\\nTry again\"\n                shortkey=`zenity --entry --text \"Your shortkey will be a combination of <Primary> + <Alt> + a letter\\n\\n Specify your letter!\"`\n\ndone\n        basis=\"$basis$shortkey\"\nzenity --info --text \"$basis\" --title=\"Your shortkey\"\n\ntouch kiosk/kiosk-0.1/.mykey\necho \"gsettings set org.gnome.desktop.wm.keybindings close [$basis]\" > kiosk/kiosk-0.1/.mykey\n\nuser=$(cat kiosk/kiosk-0.1/.username)\nkeys=$(cat kiosk/kiosk-0.1/keys)\ncontent=$(cat kiosk/kiosk-0.1/.mykey)\n\ntouch kiosk/kiosk-0.1/.bash_profile\necho \"#!/bin/bash\" >> .bash_profile\necho \"\" >> .bash_profile\necho $keys >> .bash_profile\necho $content >> .bash_profile\nchmod +x .bash_profile\nchown $user .bash_profile\nmv '.bash_profile' /home/$user\n\nThat content that is copied to .bash_profile contains code to disable all the keys from the interface like:\ngsettings set org.gnome.desktop.wm.keybindings begin-move []\n\nNow I only added a line to start the chromium browser to the right website\n/usr/bin/chromium-browser www.google.be --kiosk --no-default-browser-check --disable-translate\n\nI also changed the owner of the .bash_profile script to the account user and made it executable before I copied it to the new users home folder. \nNow when i login on the new user, this script does nothing. Can anyone see where i'm wrong of help me finding the solution?\n\nA: The main issue here is that .bash_profile is not read when you do a graphical login. It is a bash-specific file, it's read when you start a login shell and I very much doubt it will ever be read on graphical login. \nYou would have a better chance using ~/.profile instead which is i) read by most login shells, not only bash, so you're not limiting your user to a specific shell and ii) far more likely to be read by a graphical login.\nI just checked this and .profile is indeed read on Ubuntu 13.04 when you log in graphically. However, you cannot assume that will always be the case. For more details see Gilles's excellent answer here.\nNow, a couple of minor points. There is no need for touch, echo \"foo\" >> bar will create the file bar if it doesn't exist and append to it if it does. Also, there is no need for .bash_profile to be executable, the file is sourced, not run. I don't know if that would cause problems but it might.\nFinally, the file's group will be root, not the user's. Again, not sure if this is a problem but you may as well add this to your script:\nchown $user:$user .profile\n\nNote that .profile is ignored by bash if a file called ~/.bash_profile exists. This should not affect graphical logins but may cause unexpected behavior when logging in from the command line. \n", "Q: Black Screen appear after set default display manager gdm Yesterday i install gdm and set it default display manager then l notice ubuntu is running but there is several lines appear on desktop when i want to shutdown system after i powered off system and start Grub Menu appear and normal boot system but nothing is appear and black screen is regularly appear even after several restart.\n\nA: Try this:\non that black screen click Ctrl+Alt+f1\nenter your user-name\n\npassword:your password\n\n$ sudo su\n\nenter your password\n\nrun\n# dpkg-reconfigure gdm\n\nor\n# dpkg-reconfigure lightdm\n\nand choose lightdm\nreboot\n(sorry for my bad English)\n", "Q: find/tar combination to backup certain files at one level, and all files in one subdirectory Our server's directory structure is like this\n\n\n*\n\n*/home/site1/public_html\n\n*/home/site1/logs\n\n*/home/site1/cgi-bin\n\n*etc...(it's the standard when using virtualmin)\n\n\nWhat I want to schedule backups for is the public_html directories + some files at the site1/ level (there are often some handy scripts written in those levels, but also there are inevitably a bunch of bloat files there too like temp db dumps that I don't want filling up the backup server every job)\nHere's what I would like to do if possible (from /home/):\ntar -cz --include=\"*.sh\" --include=\"*.php\" --include=\"public_html/*\" ./site1/ | ssh backupserver ...\n\nBut, tar doesn't have an include option, only exclude.\nI've tried\nfind ./site1/ -type f -name \"*.sh\" -or -name \"*.php\" -or -wholename \"./site1/public_html/*\" | xargs tar -cz | ssh backupserver ...\n\nBut that doesn't work either because xargs breaks a large list of files into chunks, causing every restart of the tar -c command to overwrite the previous file (and if I don't use xargs, then there is an error for the list being too long).\nI can't use the -r option to append to the backup because 1) it doesn't work on compressed archives and 2) I don't think that could work across ssh anyway.\nThe only solution I can think of is to break it into steps creating a temporary tar file locally (one to tar ./site1/public_html/ and another to append ./site1/*.[sh|php]), then zipping, then ssh, then delete the local file.  But that seems almost ridiculous on linux.\nIs there some format to the tar command that I can use that I'm missing?\n\nA: globstar to the rescue?\nshopt -s globstar\ntar -cz archive.tar.gz file1 file2 subdir/**\n\n\nA: pax, this is your time to shine!\nfind ./site1/ \\( -path \"./site1/public_html\" -prune -o -name \"*.sh\" -o -name \"*.php\" \\) -print |\n    pax -x ustar -wf archive.tar\n\nOr when you have a find and pax that both support NUL delimited data:\nfind ./site1/ \\( -path \"./site1/public_html\" -prune -o -name \"*.sh\" -o -name \"*.php\" \\) -print0 |\n    pax -x ustar -0wf archive.tar\n\n", "Q: booting issues booting windows XP after installing ubuntu 12.04 After installing Ubuntu 12.04 on my system, Windows XP won't boot any more. Ubuntu starts ok however. \nWhen starting Windows in the Grub menu, it give's an error:\nERROR: UNKNOWN FILESYSTEM.\nGRUB RESCUE\n\nI've tried to resolve it using boot-repair but with no result. Also tried the booterrorfix as suggested but no result.\nBoot-repairs logs the following info:\nhttp://paste.ubuntu.com/7079160/ \nYour support is much appreciated.\n\nA: From the boot-repair log,\n\nGrub2 (v1.99) is installed in the boot sector of sda1 \nand looks at sector 128708312 of the same hard drive \nfor core.img. core.img is at this location and looks \nfor (,msdos5)/boot/grub on this drive. No errors found \nin the Boot Parameter Block.\n\nGrub installed in the boot sector of dev/sda1 Windows Xp partition.So you have to repair your windows boot files and then you have to run boot-repair again.\nSee this to repair your Windows boot files and  reinstall grub on /dev/sda disk. \n", "Q: After 13.10 install none of my apps appear in the Dashboard, only social network apps (of which I have none) After 13.10 installation none of my apps appear on the Dashboard so effectively I cannot launch any apps from the Dash only through the terminal.\n\nAny advice?\n\nA: I would ensure all of these were installed:\nsudo apt-get install unity-lens-applications unity-lens-files unity-lens-music unity-lens-video\n\nif that works, great. Otherwise also try:\nrm ~/.cache/software-center -R\n\nand\nunity --reset &\n\nEdit: it as pointed out in the comments:\nsudo apt-get install unity-scope-home\n\nmay also solve the issue. Thanks\n", "Q: Broken packages from versions mismatch I've been trying to fix some dependencies to install cinelerra, and stupidly install libvpx1:amd64 for Sid and it casued a broken package. Synaptic could not fix it. I tried apt-get install -f and it gave me the following:\nZHD ~ # apt-get install -f\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nCorrecting dependencies... failed.\nThe following packages have unmet dependencies:\n libvpx1 : Breaks: libvpx1:i386 (!= 1.3.0-2) but 1.2.0-2 is installed\n libvpx1:i386 : Breaks: libvpx1 (!= 1.2.0-2) but 1.3.0-2 is installed\nE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.\nE: Unable to correct dependencies\n\nI've tried removing libvpx1:amd64, and it says it cannot because libvpx1:i386 is a different version. I've tried the other way round by removing libvpx1:i386, and it says it cannot because libvpx1:amd64 is a different version. I cannot downgrade or upgrade either of these packages to try and make them the same version.\nIf anyone has some suggestions I'd be glad to hear!\nAptitude gives some solutions, but involves uninstalling half of my software.... \n\nA: You installed mismatching versions of the same library in different architectures (amd64, i386). This isn't allowed.\nTo fix this, either run sudo apt-get install -f libvpx1:i386=1.3.0-2 or sudo apt-get install -f libvpx1=1.2.0-2. The former command will bump up libvpx1:i386 to the version in Sid, and the latter command will bump down libvpx1:amd64 to the i386 version (Wheezy? Jessie?).\n\nA: I found the answer on this page:\nhttp://www.iasptk.com/ubuntu-fix-broken-package-best-solution\nAfter trying\nsudo dpkg --configure -a\n\nand\nsudo apt-get install -f\n\nthe problem of a broken package still exist the solution is to edit the dpkg status file manually.\nsudo nano /var/lib/dpkg/status    (you can use vi or gedit instead of nano)\nLocate the corrupt package, and remove the whole block of information about it and save the file.\nI then ran sudo apt-get update && upgrade\nand it asked to install the missing package. \nEverything is running good now, and I've learnt not to so boldy install packages from other releases....\n\nA: It happened because probably you installed two separate versions of apt out of which one was incompatible. Hence find out which is the architecture version of your system and remove the other package using the folowing steps:\nYou'll need to edit the dpkg file status manually.\n\n\n*\n\n*Execute the following command :\n\n\n\n$ sudo nano/var/lib/dpkg/status\n\n(You can use any other editor instead of nano(like gedit,vi, etc...)\n\n\n*Search for \"Package: libapt-pkg\" in the file that opens up.\n\n*if you find multiple segments with the same name, cut all of it out,store it in file and leave the appropriate one .\n\n*Save the file there itself and proceed with casual aptcommands.\n\n*If the error persists, Go for exchanging the \"Package: libapt-pkg\" block with another one from the file you've copied.\n\n", "Q: How to prevent other hosts on the same network from cutting of my internet connection? Recently, I've noticed that my Internet connection -- wireless on a public WiFi network -- has been cut off many times, and I think this may have been done maliciously or deliberately (for example, by users running Netcut on different systems).  \nHow can I accomplish this? \n\nA: This is a problem;  let's act immediately!\nYou need (and should) to use a configured arpON daemon in all your personal computers and, if you are the network administrator, you can (and should) upgrade to a router with Internal Firewall and Peer Isolation.\nNOTE: Always use encrypted (at least WPA) networks to have a layer of extra protection and privacy; public networks are very often insecure and you should warn immediately the administrator if you find vulnerabilities & problems, also in institutional networks.\nPlease note that arpON is very heavy and must be configured and tested: follow only the official guide and the man pages in your Ubuntu distribution!\nAsk by commenting down here if you need more help (safety & privacy are very important) and don't forget to press the UP arrow and set as favorite if I'm of any help. ;-)\nHave a nice experience,\ngood evening!\n", "Q: Wifi not responding on Lenovo Z710 I have installed Ubuntu 12.04 LTS on my new Lenovo Z710. It connects with the wifi but mozilla does not show the home page (google.com).\nKindly suggest a solution.\nwarm regards,\nAmit.\n\nA: Go to the link below and set the home page\nhttp://support.mozilla.org/en-US/kb/How%20to%20set%20the%20home%20page\n", "Q: How to remove a path from system path(`$PATH`) using terminal commands? I added a directory path to system path($PATH) by running,\nexport PATH=$PATH:/home/avinash/Desktop/raj\n\nNow my path look like this,\n\n$ echo $PATH\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/avinash/Desktop/raj\n\nI want to remove /home/avinash/Desktop/raj from system path variable by using command(like export command does on adding path).\n\nA: If you put the export statement in any shell initiation file like ~/.bashrc, you can use the following commands in terminal,\n#remove the export statement from the file.\nsed -i 's#export PATH=$PATH:/home/avinash/Desktop/raj##g' ~/.bashrc\n#source ~/.bashrc\n. ~/.bashrc\n\nIt will remove the folder from path.\nIf you have exported the path from a terminal\nThe folder will be in path as long as you are in that shell. To overwrite the path you have to assign new path. As oli already mentioned in the other answer.\nYou can use the following command to set old path\nexport PATH=`echo ${PATH/\\:\\/home\\/avinash\\/Desktop\\/raj/}`\n\nOr, simply\nexport PATH=${PATH/':/home/avinash/Desktop/raj'/}\n\nThis is Substring Replacement,\n${string/substring/replacement}\n\n\nA: If you want use it as a command, here is a little script:\n#!/bin/bash\n\n# This script removes folder from PATH variable\n# Folders to remove reading as arguments\n\nif [ $# -lt 1 ]; then\n    echo \"You should give at least one argument\"\n    echo \"For example\"\n    echo \"$0 /usr/local/bin\"\nelse\n    FOLDERS_TO_REMOVE=`echo $@ | sed 's/ /|/g'`\n\n    echo \"You actually PATH variable is:\"\n    echo $PATH\n    echo \"###\"\n\n    PATH=$( echo ${PATH} | tr -s \":\" \"\\n\" | grep -vwE \"(${FOLDERS_TO_REMOVE})\" | tr -s \"\\n\" \":\" | sed \"s/:$//\" )\n\n    echo \"Now you need to run\"\n    echo \"export PATH=$PATH\"\nfi\n\nName it unexport, and add it to your PATH.\nUsage:\nunexport /usr/local/bin /bin /sbin\nThis script does not change your actually PATH. If you want script to do it, you should change last line. Substitute echo \"export PATH=$PATH\" to export PATH=$PATH\n\nA: One dirty hack is \nexport PATH=\"$( echo $PATH| tr : '\\n' |grep -v raj | paste -s -d: )\"\n\n\n\n*\n\n*separate each dir in your PATH by line using tr\n\n*remove what you don't want (path matching \"raj\") using grep -v, and\n\n*collapse back into a long \":\" delimited string using paste.\n\n\nthis probably wont work well if any dir in PATH has : or a new line \nif you find yourself doing this a lot, consider making it a function and saving in your shell profile (e.g. .bashrc,.zshrc)\n# use like: rminpath \"raj\"\nrminpath(){ export PATH=\"$( echo $PATH| tr : '\\n' |grep -v \"$1\" | paste -sd: )\"; }\n\n\nA: In your current shell (your current session of gnome-terminal) you can do this using:\nexport PATH=${PATH%:/home/avinash/Desktop/raj}\n\nIn general:\n${string%substring}\n\ndeletes shortest match of $substring from back of $string.\nCheck out String manipulation for more info.\n\nA: Running export PATH=$PATH:/... doesn't set your PATH system-wide. It's just a shell variable. Start a new shell and BOOM, it's gone. Obviously if you've added that to ~/.bashrc (or another environment bootstrap file) you'll have to revert that change but it doesn't sound like your problem here.\nIf you're desperate not to start a new shell, you could set it by removing it manually, with: \nexport PATH=/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\n\n\nA: export PATH=$PATH:/home/avinash/Desktop/raj (Here you have added the file to the path variable.)\necho $PATH\nIf you execute this command, This is the output:\n/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/avinash/Desktop/raj\n\nHow do you remove it from the path?\njust execute\n$ export PATH=${PATH/'/home/avinash/Desktop/raj'/}\n\nIt is a concept of string replacement.\n$ export PATH=${string/substring/replacement}\n\n\nA: The shell builtin command export Doesn't determine whether or not a variable is set, it determines if the variable and its value are also set in sub-processes.\nChanging a variable, exported or not, does not affect the parent process or above, so changing it in a script has no effect unless that script is run with source.\nA shell function:\nfunction trimpath {\n    PATH=${PATH%:*}\n}\n\nwill trim off the last component of the PATH variable. Its export status is unaffected.\n\nA: declare -x PATH=\"/desired/path/you_want\" if I'm not mistaken that itself will update what you want and it's completely at your behest what it will be. [Make sure you run as root AND as the desired user for which you want this change to affect] To be double sure, run ENV afterwards to make sure that the $PATH was effectively altered as you want. (This is usable for altering any of the output you will get when you run '/usr/bin/env'. Although I dont know whether or not it is permanent. In that respect do as stated above and alter ~/.bashrc for it to stick) \n\nA: I simply use sed, like this\nPATH=$(sed \"s/\\/home\\/avinash\\/Desktop\\/raj//\" <<< $PATH)\n\nthis should do the trick.\nA little explain how this will work:\nFirst we define the variable value setting PATH=, then we must say to use the result value of next command as the value of this variable just using $(command), after came the SED command sed \"s///\", the / will be the separators for this command, by default we use / but you can set anything like - or _. The first s is for replace, then came the first separator, after came the expression you look for, then another separator, then the expression you want to replace the first one (that you look for), then another separator (the last one) and you can use some argument like g, for a global replace. The \\ is a scape character that used for make sed understand that next / is a literal and not the separator. The <<< is for drop the variable at the command sed.\n", "Q: gksudo from a non sudoer? I want to run gui applications that require admin privileges from gksudo/gksu on a non-sudoer account.  Currently, I can just run sudo guiapplication from a sudoer tty, and will be able to display/use the application as a sudoer  most of the time.  There are times when this causes conflicts.  To get around this, I've been trying to use gksu and gksudo.\nBoth commands\n    gksudo -slu sudoerusername guiapplication\n    gksu -slu sudoerusername guiapplication\n\ndon't seem to work from the non-sudoer's tty (it says its asking for the sudoer's password, but will only use the non-sudoer's password and says that sudo doesn't allow me to run the command).  I don't really want to use xnest/xhost as it's a pain to limit who can use the xhost.  Anyone know of a way to run gksudo or gksu from a non-sudoer terminal?\nEDIT: I've also tried running\n    export DISPLAY=:0\n\non both the sudoer's and non-sudoer's terminal, and then running gksu/do from the sudoer's terminal, but it says it cannot display on :0.\n\nA: If you can edit your /etc/sudoers with visudo add to it:\nnon-sudoer-username localhost=/foo/bar/guiapplication\n\nThen gksudo should work for that non-sudoer user and that guiapplication.\n", "Q: What does this (root) CMD line in system.log mean? Why is it there? What does it mean?\n(root) CMD (  [ -x /usr/lib/php5/maxlifetime ] && [ -d /var/lib/php5 ] && find /var/lib/php5/ -depth -mindepth 1 -maxdepth 1 -type f -cmin +$(/usr/lib/php5/maxlifetime) ! -execdir fuser -s {} 2>/dev/null \\; -delete)\n\nFound it in system.log.\n\nA: This cron job is scheduled in /etc/cron.d/php5 file.\n\nA: You chopped up part of the log line, which would provide more context about what this means.\nIt would be something like:\nsyslog:Mar 12 10:17:01 hostname CRON[4154]: (root) CMD (  [ -x /usr/lib/php5/maxlifetime ] && [ -d /var/lib/php5 ] && find /var/lib/php5/ -depth -mindepth 1 -maxdepth 1 -type f -cmin +$(/usr/lib/php5/maxlifetime) ! -execdir fuser -s {} 2>/dev/null \\; -delete)\n\nThe fact that it says CRON indicates it was generated by the cron periodic execution daemon. After the colon, you see it executed a command as the root user. The command was the thing in the parentheses after CMD.\nWhen you install PHP it adds a crontab entry to clean up stale sessions, which is run by the crontab daemon. Other than the cron-related information I mentioned, the command itself verifies that /usr/lib/php5/maxlifetime and /var/lib/php5 exist, then uses the find command to locate session files under /var/lib/php5 older than the number contained in /usr/lib/php5/maxlifetime, which it then deletes.\nThis is the command itself:\n[ -x /usr/lib/php5/maxlifetime ] && [ -d /var/lib/php5 ] && find /var/lib/php5/ -depth -mindepth 1 -maxdepth 1 -type f -cmin +$(/usr/lib/php5/maxlifetime) ! -execdir fuser -s {} 2>/dev/null \\; -delete\n\nIf you want to understand it better, I suggest reading this for the conditions at the beginning:\nhttp://tldp.org/HOWTO/Bash-Prog-Intro-HOWTO.html\nthen this answer for basics of find:\nHow can I use find command more efficiently?\nIf your question is about whether this command is safe, then yes, it's not a security risk of any kind and is perfectly safe to see this run periodically.\n", "Q: Ubuntu software store not working i try to install or un-install some think and i get this:\n\ninstallArchives() failed: (Reading database ... \n(Reading database ... 5%\n(Reading database ... 10%\n(Reading database ... 15%\n(Reading database ... 20%\n(Reading database ... 25%\n(Reading database ... 30%\n(Reading database ... 35%\n(Reading database ... 40%\n(Reading database ... 45%\n(Reading database ... 50%\n(Reading database ... 55%\n(Reading database ... 60%\n(Reading database ... 65%\n(Reading database ... 70%\n(Reading database ... 75%\n(Reading database ... 80%\n(Reading database ... 85%\n(Reading database ... 90%\n(Reading database ... 95%\n(Reading database ... 100%\n(Reading database ... 222127 files and directories currently installed.)\nRemoving vlc ...\nProcessing triggers for desktop-file-utils ...\nProcessing triggers for gnome-menus ...\nProcessing triggers for bamfdaemon ...\nRebuilding /usr/share/applications/bamf-2.index...\nProcessing triggers for mime-support ...\nProcessing triggers for man-db ...\nProcessing triggers for vlc-nox ...\ndpkg: error processing python-wxgtk2.8 (--configure):\n Package is in a very bad inconsistent state - you should\n reinstall it before attempting configuration.\ndpkg: dependency problems prevent configuration of playonlinux:\n playonlinux depends on python-wxgtk2.8; however:\n  Package python-wxgtk2.8 is not configured yet.\n\nNo apport report written because the error message indicates its a followup error from a previous failure.\ndpkg: error processing playonlinux (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n python-wxgtk2.8\n playonlinux\nError in function: \ndpkg: error processing python-wxgtk2.8 (--configure):\n Package is in a very bad inconsistent state - you should\n reinstall it before attempting configuration.\ndpkg: dependency problems prevent configuration of playonlinux:\n playonlinux depends on python-wxgtk2.8; however:\n  Package python-wxgtk2.8 is not configured yet.\n\ndpkg: error processing playonlinux (--configure):\n dependency problems - leaving unconfigured\n\n\nA: Try the below commands on terminal to reinstall the above mentioned packages,\nsudo apt-get install --reinstall python-wxgtk2.8\nsudo apt-get install --reinstall playonlinux\n\nBecause the error report clearly says,\n\nPackage is in a very bad inconsistent state - you should\n reinstall it before attempting configuration\n\n", "Q: Copy text from LibreOffice Writer to text file using terminal I am connecting to my Ubuntu 12.04.4 LTS Server via ssh.\nAnd I want to view my LibreOffice Writer Notes remotely.\nI need a way to copy text paragraphs from .odt files to a normal text file.\nThis way I can read customer reports uploaded via our support web application without the need to download all the .odt files\n\nA: Here is a tip that will fits your needs  :\nFirst : \nInstall abiword.\nsudo apt-get install abiword\n\nSecond  the following command:\nabiword --to=txt /pathofyour/file.odt\n\nThis command will copy all the text from file.odt, and create automaticallyfile.txt` file in the same directory then paste this text.\nIf you want to view reports, then just use cat file.txt.\n\nA: You can use unoconv. To install via apt use,\nsudo apt-get install unoconv\n\nTo convert a .odt file to .txt file use in terminal,\nunoconv --format=txt file.odt\n\nYour converted txt file name will be file.txt at the same location.\n", "Q: shell script + mutt: mutt terminating while loop I am having a problem with mutt exiting my while loop prematurely in my shell script.\nThe while read MAILTO loop of my function sendFiles will only process (send) the first file and then returns. However, if I comment-out '/usr/bin/mutt' from the function all the files in the directory are processed properly.\nAnyone know why this behaviour is occurring and how to fix it?\n#!/bin/sh\n# sendReports.sh\n\n# sendFiles function    \nsendFiles ()\n{\n  cd $1\n  ls -1 *@* | while read MAILTO\n  do\n    echo \"Emailing file: $MAILTO\"\n    /usr/bin/mutt -s \"Your file\" -a $MAILTO -- $MAILTO\n    rm -f $MAILTO\n  done\n}\n\n# .... later in the life of this script ....\nsendFiles /tmp/reports\n\n# (end of file)\n\n\nA: Mutt goes into interactive mode after sending an Email, this breaks you out of the loop add < /dev/null at the end of your mutt request \nExample:\n/usr/bin/mutt -s \"Your file\" -a $MAILTO -- $MAILTO < /dev/null\n", "Q: How to install Unity3d game engine on Ubuntu I downloaded unity 3d game engine from the official website.\nI tried to install using this command:\nwine unity*.exe\n\nDone.\nThen trying to open I get the following error:\nerror initializing license system\n\n\n\nA: Add the following key to your wine registry:\nwine reg add 'HKLM\\Software\\Microsoft\\Windows NT\\CurrentVersion' /v ProductId /t REG_SZ /d 12345-oem-0000001-54321\n\n\nA: In my case, I just installed a 32 bit version of Unity3D, even though my system was x64, it fixed the problem.\n", "Q: Is there any light user interface or gtk package for Gstreamer 1.0? I have just installed package gstreamer 1.0, and I use as executable the file located in\n ~/usr/bin/gst-play-1.0 .\nAll is fine, I can play local files, and also I can use 'gst-play-1.0' in TV-MAXE to watch live video streams. I was wondering if there is some GUI or a gtk package in a repository out there to make gstreamer work with the keyboard so I be able to see videos in fullscreen, and maybe pause the video or even change brightness and so on. Fulscreen feature would be nice to have for Gstreamer.\nI have read lots of tutorials on the Internet but they are all for developers, and advanced Linux users, I can't understand nothing from those scripts and suggestions.\nFor the moment I can watch videos and live streams adjusting the screen size manually, it is not that bad, image and sound are great, but maybe someone knows a package that works for Gstreamer, and includes a very useful interface for the average user?\n\nA: I'd say that the default package in Ubuntu answering your question is Totem:\n   Totem - GNOME desktop movie player based on GStreamer\n\n\nA: I am not sure what happened since I first posted my question, but I recently tested again  gstreamer 1.0 and it goes fullscreen now (using the  menu button in the upper-left section of player's window to enter fullscreen), I can pause video with the space key and I suppose there are also other useful commands available that I haven't tried yet.\nI followed a guide from this page, installed gstreamer 1.0 with all its dependencies, and it worked just fine for streaming videos at least. I use it to watch tv-maxe channels, and I have no complaints so far. Basically, all I had to do was to run this commands in a terminal window:\n         sudo add-apt-repository ppa:gstreamer-developers/ppa\n         sudo apt-get update\n         sudo apt-get install gstreamer1.0*\n\nI tested this on Xubuntu 12.04.5 so I can't promise it works for Ubuntu 14.04 or Xubuntu 14.04.\n", "Q: How can I get a DVD to play? When I insert a DVD, videos said it cant be played. so i go into the disc and select a VOB file and that does not work.I’ve tried VLC and it still does not work. Please HELP!\n\nA: Look for and install the following packages using Synaptic Package Manager:\n\n\n*\n\n*libdvdcss2\n\n*libdvdread4\n\n*libdvdnav4\n\n*and any dependancies\n\n", "Q: Unable to unlock after locking when VirtualBox is in full screen mode I'm running 13.10 as host, with a VirtualBox 4.2.16_Ubuntu running Windows 8.1 as guest.  I had the virtual machine in full screen mode when Ubuntu locked due to inactivity.\nI tried to wake the machine and discovered the standard unlock screen, where I could move the mouse pointer but could not type any characters into the password box.\nI switched terminals, logged in, and shutdown the virtual machine programatically.  However, I was still unable to type in the password box on the lock screen.\nI ended up just rebooting the real (host) machine, which worked fine I guess :-/\nTwo questions:\n\n\n*\n\n*Any idea what happened here?\n\n*Is there a way to resolve this without rebooting the whole computer?\n\n\nA: I have had the same problem on 14.04. I usually run 2 Virtualbox VMs (Windows 8.1 and CentOS 6.5). I've been running both in full screen mode on separate workspaces and my lock screen was preventing me from unlocking my computer. I found this post, so instead of running my VMs in full screen using the Virtualbox menus, I just maximized them. It's not the same VM experience (lost a little screen real estate), but I haven't had a problem with my lock screen all morning.\nFYI, it also fixed my problem where VMs would move to a different workspace after waking the screens from sleep.\n\nA: I've just experienced this issue on 14.04, locked for inactivity while the Windows 8.1 VirtualBox VM was on full-screen mode. Keyboard is not working on login screen; mouse cursor moves but cannot interact.\nAnd just found a workaround: \n\n\n*\n\n*Alt+F2 to a terminal and type: unity --replace\n\n*Hit Enter, and the keyboard is working on the lock-screen again.\n\n\nA: I've had similar issues happen to me as well. What most likely happened is your host hardware replaced the ram back to the host operating system and caused a programing glitch/error in the virtual machine. You may want to reduce the amount of ram that is allocated to the the VM, that may help!\n\nA: Another alternative if Guest account is enabled is to just login and logout from the Guest account from the top right corner menu there.\nAfter logout from Guest account, you would be at the login screen again and be able to enter the password into the lock screen to login with Virtualbox still in full screen mode.\nAfter you login back, you would see whatever you type while you tried to login on the unresponsive login inside the virtual box application if it is an editor :) Probably your password too!\nAt least it works for me.\n\nA: I am running Ubuntu 18.04 in Virtualbox on my Windows 7 Professional PC, and although I am not running Virtualbox in full screen mode, I sometimes get the same problem.  I happen to stumble upon an easy workaround, which may or may not work for others.  I press my scrollbar wheel, which seems to trigger some event and provides me with the password prompt window.  My keyboard then works again.  \n\nA: I've encountered this several times today, and I realized that it is because the virtual machine still had my keyboard/mouse captured.  I had to press the \"HOST key\" to release them; for me, the host key is the right-CTRL key (default).\nThis did not always work on the first try, sometimes had to click around and mash the keyboard, then press the HOST key again.  In the end, it always worked without having to force a reboot; and if I had Notepad open in the virtual machine I could even see the keys I pressed.\n\n\n*\n\n*I was using seamless mode, not full screen.  Hopefully the work around will still work for you.\n\n\nA: I had the same problem and the solution was obvious. Disable the screensaver/locking of the guest machines. Really, if you have the screensaver enabled for the host, that also applies to all guest displays.\n\nA: For me ubuntu 18.04 LTS and before 16.04 LTS had the same issue *(host machine), where I would be able to unlock once I had unlocked the locker, .. the screen stays black and numlock won't respond. The only option then is either reset or force power off.\n", "Q: How to vertical scale a juju service unit? Suppose I deploy a PostgreSQL charm with 3 units. When I deploy, I will use a EC2 small instance. How can I change the instance type of those units after those 3 units are already running? Is this handled automatically?\nThanks!\n\nA: You aren't able to change the instance type of already running units. You can however create new units with different constraints and then destroy your smaller ones. For more information check out juju help constraints and juju help deploy.\nThis is very easy to do using the Juju GUI: https://jujucharms.com/juju-gui/\nJuju 2.x: \nThe GUI is included by default in Juju 2, you can access it by running juju gui --show-credentials which will open up the GUI in a new browser window with your credentials outputted in the console.\nJuju 1.x:\nYou can deploy the Juju GUI to your bootstrap node using juju deploy juju-gui --to 0 assuming that your bootstrap node is machine 0\nSee also:\n\n\n*\n\n*https://jujucharms.com/docs/stable/charms-deploying\n\n*https://jujucharms.com/docs/stable/reference-constraints\n\n*https://jujucharms.com/docs/stable/charms-constraints\n", "Q: Split VPN (PPTP) in Ubuntu 13.10 not working -- Router problem? I can't setup successfully a split-VPN on Ubuntu 13.10. I followed this guide, or this or this. Adding a route manually for the VPN-secured part allows successful ping's to VPN-resources as well as standard internet domains (like google.com). ssh into a remote machine works, too. Also, syslog reports the correct nameservers. But after 1 minute or so, the VPN part stops working. ping reports unknown hosts for the private resources, ssh freezes. route still shows all correct routes, though. Looking into syslog, no error messages are available. Trying to stop/restart the VPN client does usually not help. The standard VPN setup (not trying to split the tunnel) works without problems, but does not allow any external internet addresses, of course. Any ideas?\nUpdate: Using one of the above guides and running in a different wlan network, no problems seem to occur. So could that problem be connected to my router (a fritzbox in my case)?\nUpdate 2: In order to check the router, I connected via a Windows machine to the VPN. The same behavour as described above can be observed -- this seems to be a problem with my router, then.\n\nA: Do you have PPTP Passthrough, or something like it, enabled on your router? If not, I suspect that your router might be blocking proxy traffic.\n\nA: As indicated in my updates, this seems to be a problem with my router, a Fritz!Box (though I might have missed something). After some emails with the nice customer support at AVM, no resolution could be found. To get a working 'split'-VPN setup anyway, I decided to use SSTP instead of PPTP. Adding the necessary repo to 13.10 according to this link. Note that I had to change the repository name to precise in sources.list.d. Set up the connection according to this guide. This setup worked without problems for several hours from two computers behind the above router.\n", "Q: Get Workrave to treat video watching as \"work\", not rest I use workrave not just to avoid RSI, but also as a tool to save my eyes.\nI only have the rest break set up every 70 minutes.\nThe problem is that it treats events like video-watching as inactivity and resets, then stop the timer till I'm done watching the video, which can be hours if I'm watching something engrossing (I generally use VLC for playback).\nThe inactivity reset is great when I'm working, because it treats periods I spend away from my computer (walking around or answering a phone call) as breaks. The only qualm I have is with video playback being counted as idle time.\nHow do I solve this?\nSuggestions for other software that meet my criteria are most welcome.\nSpecifications: Ubuntu 13.10 64bit, Workrave-1.10.1\n\nA: I think if you turn on \"reading mode\" in workrave, it will always count down the time, regardless of how much keyboard/mouse usage you do.\nWorkrave documentation says:\n\nWorkrave has a special mode for reading. While reading, you usually do not use the keyboard and mouse. Therefore, Workrave would normally not ask you to take breaks. When the reading mode is active, Workrave will also remind you to take breaks while reading.\n\n\nIn reading mode, Workrave will start the break timers as soon as you start using keyboard or mouse. The timers will keep running until the first rest break, even if you stop using the keyboard and mouse. During this time you will be reminded to take microbreaks. After the first restbreak, the break timers stop until you start using keyboard and mouse again. Then it all starts over.\n\n", "Q: how can I get into my ubuntu server with my mobile? I know how to see/login trought a computer, but how do I view them from my mobile. I have a samsung galaxy s3. Android.\n\nA: For login via SSH: ConnectBot or JuiceSSH\nFor login via VNC: android-vnc-viewer\n\nA: For desktop remote control\nuse \"x11vnc\" on your Ubuntu machine,\nvnc viewer is available for mobile ( android, windows phone ). I use \"tiny vnc\" on my windows phone, it should be also available for android.\nother than vnc, you can also use \"splashtop\"\nfor desktop sharing. (Splashtop is available for android).\nyou can download splashtop for ubuntu from link http://www.splashtop.com/linux\nif you want to control your desktop through internet connection, \"teamviewer\" is the best.\n( teamviewer is available for android )\napart from these if you want to share files only,\ninstall \"vsftpd\" on your Ubuntu machine.\nand connect through file manager ( ftp option is available on some file manager eg. FILE MANAGER by Rythm Software) on your android phone.\n", "Q: Windows 7 hangs at grub's purple screen when dual booting I have installed a new laptop (Lenovo Z510) for dual boot Ubuntu 12.04 and Windows 7 64 bit. After several trials it now works, but I have a strange effect.\nI always enter the Grub purple screen fine. Ubuntu always works. When I want to boot Windows however windows boots fine (I hear the Windows start sound) but I only see a blank, purple Grub like screen. I can operate Windows though, pressing three times the tab key and then enter shuts the PC down successfully.\nSometime a trick works like that: I press just the power key and the PC hibernates. When I switch on the PC afterward and choose Win7 in Grub again everything is working fine, this time with working screen. However I had to find the trick does not always work - maybe whether it works or not is just random :-(\nThe workaround is quite dirty, what can I do to get rid of it?\nThanks for your help!\n\nA: I had the exact same problem (I was able to listen to the windows login sound even when the only think I saw was the grub purple screen).\nLuckily I found a workaround:\n\n\n*\n\n*move the file 30_os-prober to 06_os-prober (because I wanted the windows entries to be listed first)\n\n*run sudo upgrade-grub\nAnd now it works fine every time... I do not not understand why and I have not tried to isolate if update-grub is enough or not.\n\nA: So this sort of worked for me. I moved the /etc/grub.d/30_os-prober file to /etc/grub.d/06_os-prober, then ran update-grub.\nThis puts windows on the top of the grub boot screen. Then I tried many different options to start, restart from windows and ubuntu and what I have noticed so far is if I let the boot via grub,  proceed by it self with no manual intervention and let the default 10s pass, it will boot into windows with no issues.\nHowever if I manually select the \"Windows 7\" option in the grub boot screen using my cursor and then hit enter, I get the dreaded purple screen in windows.\n\nA: In my experience,  this issue can appears if Video card drivers were not installed into the Windows system properly  (Win 7 in my case).\nThe steps which helped me :\n\n\n*\n\n*Boot into Ubuntu\n\n*Edit /etc/default/grub and uncomment the line GRUB_TERMINAL=console, then execute sudo update-grub\n\n*Restart and boot into Windows\n\n*Install / Reinstall Video card drivers (Intel HD + nVidia in my case)\n\n*Restart and boot into Ubuntu again\n\n*Restore /etc/default/grub to the previous state (comment GRUB_TERMINAL=console), execute sudo update-grub again.\nDone.\nTested on:\nDell Inspiron 15 3000 Series, Os: Windows 7 x64, Ubuntu 16.04 LTS x64\n\nA: I had the same problem\nI noticed I was booting to the 1st partition, the windows boot partition ~200mb\nWhen I instead selected the partition with Windows system installed on it, the boot proceeded normally\n\nA: I had a similar problem when upgrading my dual boot Lenovo T440s from Windows 7 to Windows 10. It always worked fine with Win7 until the upgrade rebooted to start Win10. I then only saw the purple screen.\nI booted into Ubuntu 14.04 and modified /etc/default/grub to uncomment GRUB_TERMINAL=console to disable graphical mode and changed GRUB_DEFAULT=0 to 3. After I ran sudo update-grub and rebooting, Win10 booted just fine. However, I then re-enabled graphical mode, changed default back to 0, ran sudo update-grub, and Win10 still booted fine. \nSo I think just running sudo update-grub solved my problem.\n\nA: Had the same issue. It's more to do with Legacy v/s UEFI Boot mode.\n Win 7 is installed in Legacy mode while it's other way round for win 8.1 and above. If both win 10 and Ubuntu are installed in Legacy mode (for eg. if win 7 upgraded to 10). This issue may come.\nFor me just disabling legacy mode from BIOS and enabling it again worked fine. \n\nA: Well I have found a temporary solution to the problem... just go into your BIOS settings and set Windows bootloader to boot first (before Ubuntu)...\n", "Q: how to install nmap in ubuntu 12;04 Hi every one I am new to Ubuntu before I was using the backtrack 5 r3 in which every thing was installed but when I came to Ubuntu I get confused every thing is change please some body give me little description about how to install nmap in Ubuntu with some useful link if you people can.\n\nA: Open a terminal by either pressing CTRL + ALT + T or by pressing your windows(super) key and searching for terminal. Then simply use this to install: sudo apt-get install nmap\n", "Q: Trailing mouse and other small graphical glitches, unable to install proprietary drivers in 14.04 So I've been trying to get various distros Ubuntu running on my PC for a few months now, on and off. I recently had success with 14.04 on my Laptop so I decided to give it a go on my PC, especially because my PC is running fairly new hardware.\nAs it says in the title it doesn't quite work, it's a little laggy and there are a few graphical glitches. I tried to install nvidia-current and it seems as though the module causes everything to break. When I say everything, I mean I just get a blank screen with a blinking cursor. I can't even switch to a TTY, it doesn't seem to get that far. I can't even uninstall the module, I have to reinstall everything.\nHere's the output of lspci | grep VGA\n00:02.0 VGA compatible controller: Intel Corporation Xeon E3-1200 v3/4th Gen Core Processor Integrated Graphics Controller (rev 06)\n01:00.0 VGA compatible controller: NVIDIA Corporation GK106 [GeForce GTX 660] (rev a1)\n\nSo as you can see, it seems to think I have two graphics controllers? Here are my machine specs:\nMotherboard: Gigabyte Z87-HD3\nProcessor: Intel Core i5-4430 (Haswell)\nVideo: GeForce GTX 660 Windforce\n\nIs this a switchable graphics type deal? I tried installing the Intel graphics bundle but it's not supported on 14.04 yet so I tried installing individually and it didn't seem to have any effect. It shouldn't anyway because my video output is going though my nVidia card. I've had a look at the UEFI settings screen but I can't see anything of relevance.\n\nA: I think your computer has Optimus technology.\nThere are two solutions: \n\n\n*\n\n*Nvidia prime\nThe binary Nvidia driver added partial Optimus support in the 319.17 update.\nYou can install this by typing\nsudo apt-get install nvidia-319 nvidia-settings-319 nvidia-prime\n\nin the terminal to install the binary Nvidia driver. Prime will disable the Intel card, so you will only be using Nvidia. Nvidia prime is still work in progress and changing will be added. This works perfectly for me, and I have Ubuntu 14.04 with Optimus technology. \n\n*Bumblebee\nThe open-source project Bumblebee  tries to provide support for graphics-chip switching. \nTo install it, type\nsudo add-apt-repository ppa:bumblebee/stable\nsudo apt-get update\nsudo apt-get install bumblebee bumblebee-nvidia primus\n\nin the terminal. This works also very well. Before prime, I used this.\nI hope this will fix the issue. If not, you can report this as a bug. Remember that Ubuntu 14.04 still is in beta stage.\nEDIT:\nA flickering mouse: Mouse cursor flickering and disappearing\n", "Q: My netbeans is not working after I deleted the jvm folder My netbeans is not starting since I deleted the /usr/lib/jvm folder. But I have installed java jdk 1.7.0_51.deb debian file and the file dir is /usr/java.\nWhen I tried to start the netbeans using terminal the following message came out:\n***Error occurred during initialization of VM\njava/lang/NoClassDefFoundError: java/lang/Object***\n\nWhat should i do?\n\nA: Open netbeans.conf file available under etc folder.\nModify the netbeans_jdkhome variable to point to new JDK path, then restart your Netbeans.\n", "Q: Backslash not working I am facing a problem with my backslash. whenever i press control backslash this (#) comes out. I tried to press alt right that doesn't work as well. Initially everything was working perfect this happened after removing the debug port. If anyone knows the solution please try to help me as i am writing my dissertation  on latex and this key is really crucial. \nThanks\n\nA: It's just a keyboard configuration issue. Your computer assumes your keyboard is American but it's actually British (or something else with that crossover). It's fairly simlpe to fix from a terminal:\nsudo dpkg-reconfigure keyboard-configuration\n\nAs stolen from this question.\n", "Q: Crosshair as standard mouse pointer. But how? All I want is to change the default mouse cursor (the upward pointing arrow) into a crosshair. I don't need instructions on how to download a cursor theme, I just want a crosshair as the standard pointer. That's all. But I can't get it done. Can't find a theme with a crosshair as default cursor, either. I do have a Windows .cur file with the perfect crosshair pointer. Can that be imported, perhaps? Whatever is possible to get me that crosshair, please provide extensive instructions because I'm new to this. Thanks.\n\nA: http://gursormaker.sourceforge.net/ allows for importing and creating of X11 cursors. Probably .curs too.\n", "Q: Wireless doesn't work ( hp635 notebook pc ) (ubuntu 12.04 ) I installed ubuntu 12.04 most everything is working except the wireless. I have tried many solutions but none of them worked.\nThe original issue before complicating it by installing several drivers for different devices is rfkill list all shows a hardblock.\nCan anyone help resolve this issue?\nAs requested:\nwget -N -t 5 -T 10 http://dl.dropbox.com/u/57264241/wireless_script && chmod +x wireless_script && ./wireless_script\n\nOutput (wireless-info.txt):\nhttp://pastebin.com/5CmCpCu0\n(Some Changes)\nhttp://pastebin.com/awK8wniD\n\nA: Please run the following commands in the terminal by copying and pasting for accuracy:\nsudo apt-get purge --remove bcmwl-kernel-source b43-fwcutter firmware-b43-installer \n\nreboot, then post a new file so we can see what other drivers are still loaded.\nEDIT: \nPlease copy and paste the following code:\necho \"blacklist bcma b43 ssb 8192cu\" | sudo tee -a /etc/modprobe.d/blacklist.conf \n\nReboot   \nEdit:\nPost the contents of:\ncat /etc/modules\n\nEdit:\nPlease run the following command in the terminal:\ngksudo gedit /etc/modules\n\na small window will open type in your user password and the /etc/modules file will open, then remove:\n8192cu and b43\n\nfrom the file then save and close gedit then reboot.\nEDIT:\nPlease run the following command in the terminal:\ngksudo gedit /etc/modprobe.d/blacklist.conf\n\na small window will open type in your user password a file will open, then remove:\nhp-wmi\n\nboth instances of it from the file then save and close gedit then reboot.\nNow hopefully your wifi button will turn wifi on and off.\nEDIT:\nRun this command \necho \"blacklist hp-wmi\" | sudo tee -a /etc/modprobe.d/blacklist.conf\n\nThen reset your bios, you need to be careful doing this:\n1.\nTurn on or restart the computer, and then press \nesc\nwhile the “Press the ESC key for Startup Menu”\nmessage is displayed at the bottom of the screen.\n2.\nPress f10 to enter Setup Utility.\n3.\nUse the arrow keys to select Exit > Load Setup Defaults.\n4.\nFollow the on-screen instructions.\n5.\nTo save your changes and exit, press \nf10, and then follow the on-screen instructions.\n", "Q: Scratch 1.4 not available on Ubuntu 13 anymore? I used to run older versions of Ubuntu that included Scratch 1.4.\nI have a fresh Ubuntu 13.10 (installed today) and Scratch is just not there anymore. The Software center does NOT show any Scratch in its search results, plus the link to the debian/ubuntu installation here  fails to work.\nIs this because we are expected to use Scratch 2.0? Scratch 1.4 is useful to us in a number of situations. I would only like to understand if there is a way to get it back on the new Ubuntu. Many thanks in advance.  \n\nA: You can easily just do this(I don't think there us a problem in software center). You just seem that you are not enabling the universe repoisoty.\nBut please be sure you enable the universe repository(if it's enabled skip this step). To enable universe repository do this\n sudo add-apt-repository \"deb http://archive.ubuntu.com/ubuntu $(lsb_release -sc) universe\"\n\nUpdate the package index:\nsudo apt-get update\n\nInstall scratch:\nsudo apt-get install scratch\n\nAnyway if you like to install the binary(.deb) directly you can download:\nscratch1.4 32bit or scratch1.4 64bit according to your needs.\nNow you have the .deb file you can install by the command:\nsudo dpkg -i ~/Downloads/scratch*.deb\n\n", "Q: 13.10 Ubuntu mouse problem I have upgraded from Ubuntu 12.04 to 13.10 and I'm currently experiencing a mouse problem. The pointer blinks very fast and most of the time is not even visible.\nI've tried the solution given in a different post, which was to change something on the display settings, but without any outcome.\nOn 12.04 there was no such a problem.\n\nA: Try this:\n\n\n*\n\n*Open a terminal an run\ngsettings set org.gnome.settings-daemon.plugins.cursor active false\n\n\n*OR run dconf-editor\nNavigate to org.gnome.settings-daemon.plugins.cursor and set the key active to false.\n\nA: I have had the same problem you can push ctrl + alt + f6 goes to tty, and then type.\n  sudo apt-get update\n  sudo apt-get install --reinstall ubuntu-desktop\n  sudo shutdown -r now\n\nOr change mouse curser theme.\nIt will might work, and you can also disable mouse in settings, and then enable it again it works in kubuntu.\n", "Q: Cannot flash Galaxy Nexus ('maguro') device I've got a problem when tried to flash my android.\nMy phone was already unlocked. I performed factory reset and after enable developer mode.\nHere code from terminal:\nmikalai@mikalai-HP-Compaq-6000-Pro-SFF-PC:~$ sudo ubuntu-device-flash --channel=trusty\n2014/03/12 18:36:23 Expecting the device to expose an adb interface...\n2014/03/12 18:36:23 Device is |maguro|\n2014/03/12 18:36:24 Flashing version 188 from trusty channel and server https://system-image.ubuntu.com to device maguro\n2014/03/12 18:36:25 Start pushing /home/mikalai/.cache/ubuntuimages/gpg/image-signing.tar.xz to device\n2014/03/12 18:36:25 Start pushing /home/mikalai/.cache/ubuntuimages/gpg/image-master.tar.xz to device\n2014/03/12 18:36:25 Start pushing /home/mikalai/.cache/ubuntuimages/trusty/maguro/version-188.tar.xz to device\n2014/03/12 18:36:25 Cannot push /home/mikalai/.cache/ubuntuimages/gpg/image-master.tar.xz to device\n\nIf anybody know what I did wrong, please advise. Thank you for any help.\n\nA: What device do you have?\n(a.) Samsung Galaxy Nexus ('maguro')\n(b.) LG Nexus 4 ('mako')\n\nAssuming that does NOT matter ..\nYou should verify device is 'online', with\nadb devices\n\nThen Try:\nubuntu-device-flash --channel=trusty --bootstrap\n\n\nA: Im wondering you flash the device in ADB while your device is on android. The best way turn device to bootloader, connect to pc via usb and bootstraping:\nubuntu-device-flash --bootstrap --device=maguro #or other nexus device unless nexus one and nexus s\n\nThis you will get live \"stable\" ubuntu touch for your device. After device have ubuntu touch live. It's easy to change channels:\nubuntu-device-flash --list-channels \nubuntu-device-flash --device=maguro --channel=saucy-custoized --bootstrap\n\nNote: bootstrap command usable only on booatloader / fastboot mode.\n", "Q: How to disable GRUB installation on my hard drive, I have Archlinux with fully customized GRUB. I want to install Xubuntu 14.04 on other partition. How to disable GRUB installation during Xubuntu installation process?\n\nA: I think you can install Xubuntu with a Live CD/DVD, and choose to place bootloader on your Xubuntu partition and not where your grub is so grub stays as it is. After you finish installing Xubuntu, you can boot into Archlinux and play with update-grub or better use another Live CD or some USB pendrive with Boot Repair on it to fix your dual-boot configuration. Boot Repair can be written on USB with Unetbootin tool. But you need to make sure you can boot into Archlinux after first reboot when finished with installing Xubuntu.\nOh, also make sure you download the right iso image for Boot Repair, they have iso images for both 32bit and 64bit machines.\n\nA: Run ubiquity -b or ubiquity --no-bootloader to skip the grub installation step. See ubiquity --help for more details.\n\nA: My solution is:\nInstall Xubuntu with GRUB on sda.\nBoot Archlinux from Xubuntu's GRUB.\nRun\n# grub-install --recheck --target=i386-pc /devsda\n# grub-mkconfig -o /boot/grub/grub.cfg\n\nAfter that, I have Archlinux's GRUB.\n\nA: Wanted to do the same, I decided to add this answer with captures.\n\n\n*\n\n*Open a terminal\n\n*tape the following command:\nubiquity -b\n\nThis will open the ubuntu installer program after a few seconds.\nDon't close the terminal though.\n\nNow assuming you selected the Something Else option (see below image)\n\nNow, you won't have the option to chose where to install GRUB. Like in this following image.\n\nInstead, that options is removed Like in this next image.  So GRUB won't be installed.\n\n", "Q: Why is my SD card not transferring files to SSD? I have a memory card reader, and when I insert a sd card and began to copy pictures or vidioes from the sd card to my ssd(hard disk) after one or two files the error appears:\nError splicing file: Input/output error\nand the sd card disappeared from the computer and I need to restart the computer to see here again ,and the all things again and again until I finish \n\nA: troylatroy is likely correct. It could also be your card reader is failing. It's possible that not all the files are lost. Use ddrescue from the terminal to attempt recovery. Use a log file so that ddrescue can work as intended.\nThe manual can be found here: https://www.gnu.org/software/ddrescue/manual/ddrescue_manual.html\nExample 9 in the manual specifically mentions your problem..\nI have successfully used ddrescue many times to recover data from failing storage devices.\n", "Q: Overlapping line from smaller disaply in dualhead mode I have a problem on both gnome shell and unity that is best described with the following photo:\nhttp://i.imgur.com/JQwr3Rh.jpg\nThis is my external monitor. It's a FHD monitor and my laptop monitor is 1366x768 px The white line on the left side pointed to by the green arrow is supposed to be on the laptop screen but is instead showing up on the external monitor. They overlap so to say (It's a maximized application on laptop monitor). Like I said... the problem exists on both unity and gnome shell (I had regular ubuntu installed before today, now it's \"Ubuntu Gnome\"). My graphics card is amd radeon 7670m or 7770m not sure right now. The drivers are open source one I have some problems with the proprietary ones so I could not test what happens with them. Also, my external monitor is set to primary... but it also happens when the laptop display is primary.\nAny ideas on how to fix this?\n\nA: The problem goes away when I use proprietary amd drivers. Which do not cause some other issues anymore so I can use them now instead of the open source ones.\n", "Q: How to close/end/terminate an accidental \"if\" in the terminal? So tab completion is great... unless you're a n00b... and you type the first part of ifconfig and then hit tabenter real quick... in which case you end up with:\n(not actual terminal input)\n~$ if\n> \n> \n>'\n> \"\n> end\n> ^C\n> \n> )\n> ()\n> ]\n> \n> []\n> ]\n> ;\n> \n> \n> []\n> ;aognf'\n> \n> \n\nWhat's really weird is ctrlc didn't even work. I know about quotation marks (which is why that's what I tried first), but that knowledge didn't help.\nHow can I break out of one of these fat-fingered mistakes next time, without closing the terminal?\nBonus point for answering what is this thing that I've accidentally started doing?\n\nA: Use Control-D in cases like this.  \nYou've gotten stuck in a bash shell if conditional control structure. \nThis is the output I see:\n$ if\n> \n> '\n> \"\n> sdf\n> )\n> []\n\nControl-D \n\nbash: syntax error: unexpected end of file\n\n\nA: You have started an if statement.  The next command is run, and only if it returns a zero exit status (success) are the following commands executed, from the then keyword up until the fi keyword (\"if\" backwards).  Like:\nif true\nthen\n    echo yes\nfi\n\nTypically one uses the test program (AKA [) to test various things such as:\nif [ $somevariable = someword ]\n\nor\nif [ -f /some/file/exists ]\n\nA Ctrl-C aborts it fine for me.\n\nA: Use stty -a to be sure that intr = ^C. If it isn't, ^C is just another character. stty sane helps me out of terminal confusion. See man stty. Here is the first few lines of mine (where ^C does interrupt if....):  \nwalt@spong:~(0)$ stty -a\nspeed 38400 baud; rows 24; columns 80; line = 0;\nintr = ^C; quit = ^\\; erase = ^?; kill = ^U; eof = ^D; eol = M-^?; eol2 = M-^?;\nswtch = M-^?; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W;\n...\n\n", "Q: Move audio stream from OpenAL application to different audio device I have two different audio output devices: an internal sound card and an external DAC/amp.\nWhen starting an OpenAL application (I first observed the issue with Minecraft, but I suspect it affects all applications that use OpenAL for audio playback), the internal sound card is selected for output, and I cannot change the device using pavucontrol (or KMixer on Kubuntu). The option to select an alternate device is present, but choosing the device has no effect.\nHow can I select an alternate audio playback device for OpenAL applications?\n\nA: The solution is to add the option allow-moves = true to the OpenAL configuration file (the per-user file is located at ~/.alsoftrc).\nIf you don't already have this file (it doesn't exist by default), you can copy it from /etc/openal/alsoft.conf or use this sample default configuration.\n", "Q: How to show the full path of a file or directory in the terminal? I need to know how the directory name in order to type it out in the terminal. How do I access the names of directories? \nWindows Explorer used to have a title bar with the full path. Can someone please help me figure out how to see the full path of a certain file? \n\nA: find can do this quite handily from the terminal. Here's an example in which I'm looking for the full path of the file Taxes-2013.pdf:\nsudo find / -name Taxes-2013.pdf\nProvides the output:\n/home/me/Documents/Taxes-2013.pdf\n\nI'm using sudo so that I can avoid all the permission denied output that I would otherwise get with find when searching from the root of the tree.\nIf you just want the pathname and want the filename stripped off you can use\nsudo find / -name Taxes-2013.pdf | xargs -n1 dirname\nNote: If you are in the habit of putting spaces in names this is relevant to you.\nSome sources:\nhttps://www.unixtutorial.org/commands/dirname/\nhttp://www.commandlinefu.com/commands/using/dirname\nhttp://man7.org/linux/man-pages/man1/xargs.1.html\nTested on Ubuntu 14.04\n\nA: If you are using nautilus to browse your files, you can toggle the navigation bar by pressing Ctrl + L.\nIf you are using the terminal, just use pwd to know the absolute path of your current location.\n\nA: To display the full path of a file in the terminal just drag the file's icon into the terminal, and the full path of the file will be displayed enclosed by two apostrophes (single quotation mark characters). It's that simple.\nIn Ubuntu 20.04 and later drag and drop of files or directories doesn't work from the desktop, but does work in other locations including dragging from the desktop in Files file manager.\n", "Q: Every time I try to upgrade from Ubuntu 13.04 to 13.10, it fails How do I add space to my /boot directory? Every time I try to  upgrade I am told that I need 20MB more space (for a total of about 80MB), and I have already run commands to free up all unused kernels and headers. I have 60MB free, and am currently using 40MB. I am really stuck. Please help.\n\nA: You can always use gparted to extend your /boot partition. \nFor more information refer this question \nHow do I resize my /boot partition?\n", "Q: How to set a default file manager for qt's app? I am running on ubuntu with awesomeWM which does not have specific file manager. When I launch vlc or any other Qt app and try to open a file from there, it does segfault after the following error message :\n<application_name>/kdeui (KIconLoader): Error: standard icon theme \"oxygen\" not found!\n\nDo you know how to set a specific file manager for Qt apps and why it's expecting a kde part one ?\nBasically, how does it work ? Why are only GTK's app able to open a file manager ? Is there a lib missing for Qt ? Do they both have their own default file manager ?\n\nA: Problem solved by uninstalling the following packages : kdelibs5-data kde-style-qtcurve\nsudo apt-get remove kdelibs5-data kde-style-qtcurve\n\n", "Q: Touchpad not working after a while I keep having trouble with my 12.04LTS install!\nI now have everything working fine the way I want but the touchpad does not work anymore... It was not working at first during the install and the first boot. It started working after installing the Nvidia driver 331-update and after reboot it stopped working again...\nI would like to know if someone know a work around for this.\nI already tried the :\nsudo modprobe -r psmouse\n sudo modprobe psmouse proto=imps\nsolution, and it is not working for me.\nMy computer is a Gigabyte P35K, with a Nvidia GTX 765M.\n\nA: ok, this might be stupid, but have you made sure you haven't accidentally hit the FN+ what ever Fkey turns off your touch pad? \ntry pressing it a few times and see what happens\n", "Q: Access Windows XP files from Ubuntu 12.04 I've just installed Ubuntu 12.04, dual boot with Windows XP, and I would now like to access my Windows XP files from Ubuntu. How do I do so?\nMy Ubuntu desktop menu does not have 'Applications', 'Places', or 'System', as seen on one or two websites that I've investigated.\nI've installed 'gparted' and managed to open the terminal window, type sudo -s,..., /mnt/windows\nI cannot find a folder called 'windows'.\nThis is day 2 of my entire Ubuntu experience, so I've a lot to learn.\nAny assistance will be much appreciated! Thanks\n\nA: Open a file browser (called Nautilus) by clicking on the folder icon in the Unity Launcher (the vertical bar on the left of your screen). The icon should look like a folder with a darker house printed on it.\nA Nautilus window opens up. In the left column you should find your windows partition. It should be called \"OSDisk\" or something like that. Click on the link and you will be able to browse the files of your windows installation.\n\n", "Q: How to find name of the virtual machine Ubuntu server is being hosted on? Is it possible to find out what version and what type of virtual machine is my ubuntu server being hosted on its on a remote server?-Thanks in advance.\n\nA: You can give virt-what a try. It is a shell script that can detect most common VMs types. It's avaliable in the official repos, just an apt-get away.\nsudo apt-get install virt-what\nsudo virt-what\n\n", "Q: Installing Ubuntu 12.10 Downloads How do I fix The following: The upgrade needs a total of 76.2 M free space on disk '/boot'. Please free at least an additional 76.2 M of disk space on '/boot'. Empty your trash and remove temporary packages of former installations using 'sudo apt-get clean'.\n\nA: From the error report, it clearly says that you have to free up some space around 80 MB on your /boot partition or you have to increase the size of /boot partition.\nMainly /boot partition contains old(unused) kernals.Removing all of them will give you some space.See this question for how to free up some space in your /boot partition.\nIf you want to increase the size of /boot partition, then you have to boot from Ubuntu live disk or gparted live disk.Freeup some space from other partition and add it to your /boot partition.\n", "Q: Wondering if I could use Ubuntu Server as a backup server for my windows? I'm planning to install Ubuntu as a WindowsDualBoot and the WindowsDualBoot guide says that I need to do a backup. I was thinking of using the Ubuntu Server as a backup hosting but I'm not so sure. I don't have much knowledge in the Linux OS let alone Ubuntu as I'm only going to use Ubuntu for my coding os and as a separation from my misc stuff on my windows 7. I'm thinking of using Amanda as well but I have absolutely no idea what they are.\n\nA: If you are going to install a dual boot system for the first time make sure you have the windows install disk for your machine.  Use the windows built in backup system (I think it saves things to DVD).  Although it has been a good few moons since my first install of a dual boot system here is my method:\nGo down to the local village computer shop and buy a hard drive.  It's worth it for the extra space, drives get bigger all the time.\nRemove your old hard drive (this is now a windows backup) and fit the new one in its place.  Install windows on it and THEN Linux.\nCheck this works as a dual boot system.\nDo it again because you made a mess of things, drink coffee/red bull, try again.\nInstall your old drive as a second hard drive and copy across any of the required old windows files.\nIf anything goes wrong, you make a mistake or want to change something you can disconnect your old drive, scrub the new drive and start again.  \nIf you do not like Ubuntu you can just put the old drive back and format the new one as drive D:\nIf you are thinking of installing for the first time on a laptop DONT! Use a USB drive.\nI know people will be shouting that Ubuntu is easy to install but I SNAFUed so many machines when I started that this is the method I now use if the machine is important.\nHugs.\nMandy\n\nA: for this purpose I think Amanda is a bit overkill. Amanda is a tool for taking automatic backups of 1 or 100+ servers daily. what you need for this purpose is simply a backup of the files you can not replace.\nso, if you have files in dropbox, or if you email yourself files, or if you copy it to a USB drive, does not matter.. the point is that if you totally break your windows install by mistake, then you want to get the files back that you can not simply download. (so no need to backup firefox, and windows and such), but DO back up your own home made files such as word files, pictures, videos etc. \nyou said that you would like to use a linux box to backup, and that is possible, the quickest way is probably to install Samba on linux, that way you can share a disk that windows can easily see.. then you can copy all the files you want to backup to this Samba shared folder.\nto install Samba on a ubuntu (and probably debian) do following:\nsudo apt-get install samba smbfs\n\nThen setup the smb.conf file like this: (assuming desktop, if a server use pico or vi instead of gedit).\nsudo gedit /etc/samba/smb.conf\n\nfind this part:\n####### Authentication #######\n\n# “security = user” is always a good idea. This will require a Unix account\n# in this server for every user accessing the server. See\n# /usr/share/doc/samba-doc/htmldocs/Samba-HOWTO-Collection/ServerType.html\n# in the samba-doc package for details.\n;  security = user\n\nuncomment the security line like this\nsecurity = user\n\nand below that add a line like this:\nusername map = /etc/samba/smbusers\n\nthen crete a user for samba\nsudo smbpasswd -a <username>\n\nthen add a user to smbuser file (again use favorite editor)\nsudo gedit /etc/samba/smbusers\n\nadd a line with format =\"\"\n<username> = “<username>”\n\nthen you must setup a shared folder (using your fav editor)\nsudo gedit /etc/samba/smb.conf\n\nfind and edit like this:\n#======================= Share Definitions =======================\n\n# Un-comment the following (and tweak the other settings below to suit)\n# to enable the default home directory shares. This will share each\n# user’s home directory as \\\\server\\username\n[homes]\ncomment = Home Directories\nbrowseable = yes\n\n# By default, \\\\server\\username shares can be connected to by anyone\n# with access to the samba server. Un-comment the following parameter\n# to make sure that only “username” can connect to \\\\server\\username\nvalid users = %S\n\n# By default, the home directories are exported read-only. Change next\n# parameter to ‘yes’ if you want to be able to write to them.\nwritable = yes\n\nNow that your home folder is mapped to samba, it is time to go to windows, and map this shared folder so you can use it in windows.\n\\\\ubuntumachine\\username\n\ntypically an ip address such like this:\n\\\\192.168.1.23\\username\n\n(replace with your own ip (of the ubuntu server) and your username that you created earlier.\n\nA: I think I understand the confusion.\nYou must back up BEFORE installing Ubuntu.  As Ubuntu is not installed then the answer is no, you can not back up windows to it as Ubuntu is not there yet.\nAs a dual boot system has windows and Ubuntu on the same drive (once you have installed it) your backup files will be on the same drive as your original files.  If the drive fails then you lose everything.  Backups must be to another drive/CD and then put away, that way if your computer catches fire or gets hit by a truck you still have the data.\nI hope that helps.\nHugs\nMandy\n", "Q: installing ubuntu and windows 8 dual boot so i have windows 8 pre installed i have shrunk my original c: which was 700 gb in two equal halfs. i have also disabled the secure boot and enabled legacy support. now when i boot into ubuntu and select the partition which i want to install to the only partition that shows up is the total 700 gb not the two separate ones that i created earlier. so my question is how do get ubuntu to recognize the second partition do i dont install ubuntu over my windows 8 partition.\n\nA: On Windows, set a FAT32/NTFS Partition in the unpartitioned space.\nYou could then see it from Ubuntu, delete it, and create the needed partitions for the install.\nAlthough the unpartitioned space should also show up anyway.\nI am running Ubuntu 13.10 x64 and Windows 8.1 Pro in perfect Dual-Boot on an Acer Aspire V5.\n\nNote that to achieve this I had to create all of the Linux partitions manually for the Ubuntu to install and run properly.\n\nI created the following:\n\n*\n\n*/boot (238MB) ext2\n\n*/home (15GB)  ext4\n\n*/     (80GB)  ext4\n\n*swap  (4GB)   swap\n\n\n\nThe size of the /boot partition should be around 200-250MB, the rest are up to you.\n\nA: First, if Windows 8 or 8.1 came pre-installed on the computer, and if you've not re-installed Windows, it's almost certainly booting in EFI/UEFI mode. On such a computer, you SHOULD NOT ATTEMPT TO INSTALL LINUX IN BIOS/CSM/LEGACY MODE!!!!!! The advice to do so is running rampant on the Internet, I suspect because this approach solves certain rare problems; however, it creates many more problems than it solves, and so is bad advice. To learn how to install on such a computer in a sane way, read one or more of the following:\n\n\n*\n\n*My page on EFI-mode Linux installations\n\n*The Ubuntu community wiki on the topic\n\n*Adam Williamson's blog post about UEFI\nThat last one probably has the least practical advice, but it's got a good theoretical background that will be helpful.\nSecond, if the partitioning tool is showing a blank disk with no partitions, then that indicates a defective partition table, or at least one that libparted doesn't like. This is more common on MBR disks than on GPT disks, and in fact if you re-installed Windows, you might have done so in BIOS/CSM/legacy mode, which could produce this symptom and which would negate my earlier advice to install Linux in EFI/UEFI mode. Thus, it's imperative that you discover whether you're using MBR or GPT on your disk. You can do this with gdisk:\n$ sudo gdisk -l /dev/sda\nGPT fdisk (gdisk) version 0.8.10\n\nPartition table scan:\n  MBR: protective\n  BSD: not present\n  APM: not present\n  GPT: present\n\nThe four lines following Partition table scan identify the presence of, and in some cases some basic health information on, various types of partition tables. The GPT: present line indicates a GPT with no immediately-obvious problems (but it could still have more subtle problems to which libparted might object). The MBR: protective line should also be present on a GPT disk. If you see MBR: MBR only and GPT: damaged, then that explains the problem you're seeing, and suggests you've re-installed Windows in BIOS/CSM/legacy mode. If you see MBR: MBR only and GPT: not present, then you've got a straight-up MBR partition table, which might have more subtle problems.\nDepending on what you discover, one or another repair solution may be advisable, but without further data, I can't offer a sure-fire solution to your problem.\n", "Q: dns is fine but www don't work I currently have a server with a static IP address and setup DNS on it.  I have my DNS server working correctly for my domain.  I can create an A or CNAME record, restart BInd9 and it works. I have only had a problem with my \"www\" record.  I have changed my zone file tons of times and it doesn't seem to work if I ping or go to www.mydomain.com.\nHere is my zone file:\n\n$TTL 14400\nmydomain.com.      IN      SOA     mydomain.com.      randy.mydomain.com. (\n        2013032600 ;Serial Number\n        86400 ;refresh\n        7200 ;retry\n        3600000 ;expire\n        86400 ;minimum\n)\n\nmydomain.com.      86400   IN      NS      ns1.mydomain.com.\nmydomain.com.      86400   IN      NS      ns2.mydomain.com.\nmydomain.com.      14400   IN      A       1.2.3.4\nro1                     14400   IN      A       1.2.3.4\nns1                     14400   IN      A       1.2.3.4\nns2                     14400   IN      A       1.2.3.4\ndev                     14400   IN      A       1.2.3.4\nrandy                   14400   IN      A       1.2.3.4\ntest1                           IN      CNAME   mydomain.com.\nwww                     14400   IN      A       1.2.3.4\n\nI'm new at Bind but looked at a lot of what was in the DNS at my current webhost.\nThe records dev, test1, and randy I created and they worked as soon as I restarted Bind9.  I can ping \"www.mydomain.com\" from the server.  But not from outside.  \nAny ideas?\n\nA: Have you told the outside machines to use the 1.2.3.4 machine as the nameserver?  If your outside machines are still using DHCP then they will be looking to your router/hub for a DNS machine.\nHugs\nMandy\n", "Q: Why am I unable to update from Software Updater? I am unable to update through software updater. After clicking install now, it shows \"requires installation from untrusted package\". \nThen there is two options: Settings and OK. \nI click OK but the software updater window closes and stops.\n\nA: might be useful to look at your sources file you can get it like this:\ncat /etc/apt/sources.list\n\nbut you might try this:\nsudo apt-get clean\ncd /var/lib/apt\nsudo mv lists lists.old\nsudo mkdir -p lists/partial\nsudo apt-get clean \nsudo apt-get update\n\nsource\n", "Q: How can I launch a specific application bypassing the global menu in Unity? So, trying to get up to speed with LaTex in vim/gvim... problem is the beginners tutorial for vim-latexsuite assumes gvim and the gui menus. Okay, got gvim right here. Problem is, under Unity and the global app menu, the menus are truncated and don't show the keyboard shortcuts that they should for most entries, or in the case of the TeX-Suite menus, entries like '2: Article' are simply truncated to '2: '. Not helpful at all!\nI know the menus themselves work - starting gvim using sudo gvim, which does not use the global app menu but the local menus, looks just fine - like gvim on any other platform or desktop, i.e. like it should.\nHow do I force that behaviour under Unity for a regular user (i.e. not using sudo)?\n\nA: This should work (thanks @Braiam):\n UBUNTU_MENUPROXY=0 gvim\n\nRunning the above command from a terminal will launch a gvim instance with its own menus. So, to create a launcher on your desktop, open a file called ~/Desktop/gvim.desktop with the following contents:\n    [Desktop Entry]\n    Name=gvim\n    Comment=Run gvim with menus\n    Exec=env UBUNTU_MENUPROXY=0 gvim\n    Type=Application\n    Icon=/usr/share/icons/HighContrast/48x48/apps/vim.png\n    StartupNotify=true\n    Categories=Utility;Editor;\n\nThe env command allows you to run a specific command in a temporarily modified environment and is needed to pass the variable when you launch a program using a .desktop file.\nIf you prefer the command line way, you now make an alias for the command above by adding this line to your ~/.bashrc:\nalias gvim=\"UBUNTU_MENUPROXY=0 gvim\"\n\nNow, open a new terminal, run gvim and you'll have it menu free. \n", "Q: q4wine: Cannot find or execute the 'wine' binary i tried to download q4wine and everything went well but when i tried to open the software it gave me this:\n\nCannot find or execute the 'wine' binary. Make sure that this binary is available by search PATH variable and see also INSTALL file for application depends\n\n\nA: Use sudo apt-get install wine.\nWINE is a Windows API implementation on Linux which q4wine depends on.\nLook into Wikipedia article for more information.\nIf you need to set up your $PATH, you can set it inside /etc/environment. It should look like:\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games\"\n\n\nA: You can install q4wine using:\nsudo apt-get install q4wine\n\nThis may need wine, and would be installed as a dependency if not previously installed. The wine binary should be in /usr/bin, if it is not in your $PATH variable, refer to this answer to add /usr/bin to your $PATH variable.\n", "Q: Is there a way to force Ubuntu to install in BIOS mode? I'm currently trying to triple boot OSX, WIndows 8.1, and Ubuntu on my macbook pro 5,3. I have 2 hard drives. One only has OSX on it and the other has Windows 8.1 and Ubuntu. That hard drive uses an mbr partition table. \nI installed Windows 8.1 first and then tried to install Ubuntu 12.04.4, however it said it was unable to install grub to the target and wouldn't be able to boot. I tried both installing it to the root partition, and creating a separate /boot partition, but neither worked. I then tried installing Ubuntu 13.10 and that installed successfully, however it wouldn't boot. I can get to the grub menu, but when I select Ubuntu, it just gets stuck on a blank purple screen.\nI believe the problem is it's booting using EFI mode. I'm using a USB stick to install Ubuntu and when I boot off of it all I see if EFI boot. Also during the installation, when I'm choosing partitions, there's an efigrub format, but no biosgrub. \nThere are 3 solutions I could think of:\n\n\n*\n\n*Find a way to install Ubuntu in BIOS mode\n\n*Install grub separately from Ubuntu using Boot-Repair or something similiar\n\n*Install Ubuntu on my other hard drive that contains OSX\nI'm not exactly sure how to do the first 2, so if anyone thinks it would work and knows what to do, some help would be well appreciated. \n\nA: Firstly: your boot issue that hangs on a purple screen is not necessarily corrupt.  It sounds like an issue with graphic drivers. \nTry including nomodeset as a boot option in grub. From the main grub bootloader press 'e' to edit the boot parameters. Find where it reads:\nquiet splash\n\nEdit to look like this:\nquiet splash nomodeset\n\nHopefully this will solve your boot issue. If so, try changing your graphics driver from the 'Additional Software' app.\nThis is probably the simplest solution. This should allow you to boot into ubuntu in order to select the correct drivers for your system.  If that fails try removing 'quiet' and 'splash' completely and report back where your boot hangs. \n\nA: Manually installing grub-pc worked. First I had to boot onto a LiveUSB/CD. I was having trouble with my gpu again though so I had to boot using nomodeset, which only allowed me to use a terminal. I follow the guide here. They list the terminal commands needed so it was pretty straight forward. On the first boot, I also had to use nomodeset so I could install the nVidia drivers. Everything is working great now.\n", "Q: Intel 7260 works during installation but not after reboot Before you hit dupe: I've already attempted the steps listed in No wireless for Intel Corporation 7260 version 63 question.  I have the proper microcode loaded into /lib/firmware and I'm running kernel version 3.11.\nI'm having some issues with a completely fresh install of Kubuntu 13.10: my wireless card works on the live USB (created with unetbootin) but on the installed system the driver fails to load and gives a backtrace with error failed to probe (hw address?) with error -12. Does anyone have any ideas or suggestions? Google is coming up dry.\nFrom kern.log (10 finger interface, so some information omitted):\n---[ cut here]---\nWARNING CPU: 10 PID: 302 at /build/buildd/linux-3.11.0/drivers/net/wireless/iwlwifi/pcie/rc.x:1059 iwl_pcie_alloc_ict+0x1cb/0x210 [iwlwifi]()\nModules linked in: iwlwifi(+) parport_pc psmouse cfg80211 ppdev serio_raw snd_hda_codec_realtek snd_hda_intel(+) bnep rfcomm snd_hda_codec bluetooth snd_hwdep     lpc_ich snd_pcm snd_page_alloc snd_seq_midi (and many others)\nCPU: 10 PID: 302 Comm: kworker/10:1 Tainted: GF 3.11.0-18-generic #32-Ubuntu\nHardware name: ASUSTeK COMPUTER INC. Z9PE-D8 WS/Z9PE-D8 WS, BIOS 5304 11/18/2013\nWorkqueue: events work_for_cpu_fn\n(12 memory addresses here, 1st, 4th and 10th are very small, 4th is nil)\nCall Trace:\n[address] dump_stack+0x45/0x56\n[address] warn_slowpath_common+0x7d/0xa0\n[address] warn_slowpath_null+0x1a/0x20\n[address] iwl_pcie_alloc_ict+0x1cb/0x210\n[address] iwl_trans_pcie_alloc+0x26a/0x400\n[address] iwl_pci_probe+0x1d/0xc0\n(9 trace entries omitted)\n---[ end trace (address) ]---\niwlwifi:probe of 0000:84:00.0 failed with error -12\n\nlspci:\n84:00.0 Network controller: Intel Corporation Wireless 7260 (rev 04)\n\nlsmod:\niwlwifi   165636 0\ncfg 80211 480503 1 iwlwifi\n\ndmesg | grep 84:00\npci 0000:84:00.0: [8086:08b1] type 00 class 0x028000\npci 0000:84:00.0: reg 0x10: [mem 0xfb100000-0xfb101fff 64bit]\npci 0000:84:00.0: PME# supportd from D0 D3hot D3cold\npci 0000:84:00.0: Signaling PME through PCIe PME interrupt\niwlwifi 0000:84:00.0: can't disable ASPM; OS doesn't have ASPM control\niwlwifi 0000:84:00.0: irq 133 for MSI/MSI-X\niwlwifi: probe of 0000:84:00.0 failed with error -12\n\ndmesg | grep iwl\niwlwifi 0000:84:00.0: can't disable ASPM; OS doesn't have ASPM control\niwlwifi 0000:84:00.0: irq 133 for MSI/MSI-X\nWARNING CPU: 10 PID: 302 at /build/buildd/linux-3.11.0/drivers/net/wireless/iwlwifi/pcie/rc.x:1059 iwl_pcie_alloc_ict+0x1cb/0x210 [iwlwifi]()\nModules linked in: iwlwifi(+) parport_pc psmouse cfg80211 ppdev serio_raw snd_hda_codec_realtek snd_hda_intel(+) bnep rfcomm snd_hda_codec bluetooth snd_hwdep     lpc_ich snd_pcm snd_page_alloc snd_seq_midi (and many others)\n[address] iwl_pcie_alloc_ict+0x1cb/0x210\n[address] iwl_trans_pcie_alloc+0x26a/0x400\n[address] iwl_pci_probe+0x1d/0xc0\niwlwifi: probe of 0000:84:00.0 failed with error -12\n\ndmesg | grep -i error\nioapic: probe of 0000:00:05.4 failed with error -22\nioapic: probe of 0000:80:05.4 failed with error -22\nERST: Error Record Serialization Table (ERST) support is initialized.\nnouveau: probe of 0000:04:00.0 failed with error -22\nnouveau: probe of 0000:83:00.0 failed with error -22\niwlwifi: probe of 0000:84:00.0 failed with error -12\nEXT4-fs (sda1): re-mounted. Opts: errors=remount-ro\n\nlsmod | grep iwl\niwlwifi 165636 0\ncfg80211 480503 1 iwlwifi\n\nSame command after modprobeing iwlmvm:\niwlmvm 161339 0\nmac80211 597268 1 iwlmvm\niwlwifi 165636 1 iwlmvm\ncfg80211 480503 3 iwlwifi,mac80211,iwlmvm\n\nHowever, I still don't have wlan0 if my ifconfig and iwconfig returns nothing interesting after modprobe\ncat /etc/modprobe.d/iwlwifi.conf matches the version pasted in Chili555's answer below.\nBelow this line are samples of it working within the installer.\ndmesg | grep iwl\niwlwifi 0000:84:00.0: can't disable ASPM; OS doesn't have ASPM control\niwlwifi 0000:84:00.0: irq 132 for MSI/MSI-X\niwlwifi 0000:84:00.0: loaded firmware version 22.0.7.0 op_mode iwlmvm\niwlwifi 0000:84:00.0: Detected Intel(R) Dual Band Wireless AC 7260, REV=0x144\niwlwifi 0000:84:00.0: L1 Disabled; Enabling L0S\niwlwifi 0000:84:00.0: L1 Disabled; Enabling L0S\niwlwifi 0000:84:00.0: ieee80211 phy0: Selected rate control algorithm 'iwl-mvm-rs'\niwlwifi 0000:84:00.0: L1 Disabled; Enabling L0S\niwlwifi 0000:84:00.0: L1 Disabled; Enabling L0S\n\nlspci | grep 84:00:\n84:00.0 Network controller: Intel corporation Wireless 7260 (rev 73)\n\n(Detected different revision(?!))\nInstaller is using Kernel 3.11.0-12-generic, Installed system is running Kernel 3.11.0-18-generic\nThanks in advance for your time.\n\nA: First of all, I'd get a temporary wired ethernet connection and fully update your system, if not already:\nsudo apt-get update && sudo apt-get -y upgrade\nsudo reboot \n\nCheck the log to see if the problem persists:\ndmesg | grep iwl\n\nNext, in your lsmod, we don't see iwlmvm. Is it loading correctly?\nlsmod | grep iwl\n\nIf not, try loading it:\nsudo modprobe iwlmvm\n\nIs your /etc/modprobe.d/iwlwifi.conf file properly completed? Mine reads:\n# /etc/modprobe.d/iwlwifi.conf\n# iwlwifi will dyamically load either iwldvm or iwlmvm depending on the\n# microcode file installed on the system.  When removing iwlwifi, first\n# remove the iwl?vm module and then iwlwifi.\nremove iwlwifi \\\n(/sbin/lsmod | grep -o -e ^iwlmvm -e ^iwldvm -e ^iwlwifi | xargs /sbin/rmmod) \\\n&& /sbin/modprobe -r mac80211\n\nIf it is not correct you will need to restore it. Let us know if you need guidance.\nFinally, are there any interesting messages here?\ndmesg | grep 84:00\ndmesg | grep -i error\n\n84:00 is the PCI bus for your wireless card. If there are ACPI or IRQ errors, you might try resetting the BIOS to Defaults.\nOnce we find some clues, I'll edit my answer as needed.\n\nA: I eventually fixed it by installing the 14.04 beta from scratch and then running an update before rebooting:\n$ sudo su\n# mount /dev/sda1 /target\n# mount -o bind /dev /target/dev\n# mount -o bind /sys /target/sys\n# mount -o bind /tmp /target/tmp\n# mount -o bind /proc /target/proc\n# mount -o bind /etc/resolv.conf /target/etc/resolv.conf\n# chroot /target\n# apt-get update\n# apt-get dist-upgrade\n\n", "Q: how to display quota info on lock screen? Is it possible to display user quota info on lock screen or any message at least?\nbecause every time user lock in or unlock the first window he/she will look at is going to be lock screen.\n\nA: Till now there is no option to do that. If you wish you can download the source code of the unity-greeter and lightdm and try to do it yourself. But This is not a valid option right now.\n", "Q: Referring a source pydev project to another pydev project fails in eclipse How to give reference from one source pydev project to another destination pydev project. I tried to remove the .pyc files from the referring project, it also fails. Later i tried after giving the reference i restarted the eclipse, this also fails.\nCan any one solve this issue?\n\nA: Just keep unique names for root packages in both referred and referring projects. Dont keep same package names for root packages, then it works properly.\n", "Q: How to block facebook for particular time intervals in ubuntu server? How can i  block facebook for particular time intervals in Ubuntu server?\nCan anyone help me.\n\nA: If you like to do it command line:\nsudo iptables -A OUTPUT -p tcp --dport 80 -d ipaddress_here -m time --timestart 09:00 --timeend 22:00 -j ACCEPT\nsudo iptables -A OUTPUT -p tcp --dport 80 -d ipaddress_here -j REJECT\n\nThose are two rules for your iptable allow to use port 80 for specificIP in a specific time and reject in other times.\nAll you have is to replace the ip-address of facebook letus say and put the timestart and timeend \nBut this is great IF you know the IP's.\nFor that I provide you other ways: \nIf you use Google Chrome, I strongly recommend the StayFocusd \nextension. It takes a second to install and 30 seconds to configure the options - choose how much time you want to allow yourself to be on Facebook and other sites that you class as time-wasting.\nIf you're a Firefox user, consider LeechBlock.\n", "Q: How to use my 6GB of free ram to optimize ubuntu12.04? I also want to load faster on boot. If possible, can I shift all temp file hard disk operation to RAM?\n\nA: do you mean that not all your RAM is recognized? the only reason I can think of that could happen is that you might be using the 32 bit version of Ubuntu, if so use the 64 bit.\nIf you want a faster boot time you are talking about read speeds of the hard drives. I would advise a SSD that will make a big difference in boot time. but I cannot imagine that you can do something with your ram to speed up boot since everything stored on ram is lost when you power off.\nmaybe there is a way to store temp files in ram, I have never heard about it. but I wonder whether the read speed of the temp files is limiting your system. \n\nA: I think that Ubuntu already does a great job with RAM management. I only have 1024 RAM memory, not very fast RAM too, but my swap space is rarely used for system operations, and I do not have issues with a faster boot or usual system operations. The problems I have are generated by my CPU, which is kind of ancient, but even so it gets the job done with honor :) .\nIf you really want to optimize Ubuntu for speed and RAM management you could install first a few extra packages with Synaptic Package Manager or in the terminal emulator:\n\n\n*\n\n*Preload is one of them, faster boot, better service management:\n      sudo apt-get install preload\n\n\n*Bum is another package that you can use to get rid of all the services that you do not need at startup, services and daemons that you do not use at all. Use BUM with extreme care, it can have a negative impact on your system if you disable wrong services. Test BUM first by disabling services one by one, I mean all those system services that you don't use at all! Install BUM with this code:\n      sudo apt-get install bum\n\n\n*You can also disable graphical boot which adds a few extra seconds to total boot time. To do that you need to edit the grub file located in /etc/default/grub:\n      gksu leafpad /etc/default/grub\n\nGo to the line saying:\n         # Uncomment to disable graphical terminal (grub-pc only)\n         #GRUB_TERMINAL=console\n\nOnce there, remove the '#' to uncomment line GRUB_TERMINAL=console and get a faster boot in  a non-graphical console. The result should look like this:\n         # Uncomment to disable graphical terminal (grub-pc only)\n         GRUB_TERMINAL=console\n\nSave the file located in /etc/default/grub and close it. Very important, update grub immediately after that using this code:\n         sudo update-grub\n\nFinally, change your swappiness value from 60 to 10 as follows:\nEdit sysctl.conf file by typing in the terminal this code:\n gksu leafpad /etc/sysctl.conf\n\nOnce the file is opened, go right to the end of the file and add your swappiness and cache parameters. If there are similar lines in there and vm.swappiness is already 10, you don't need to do anything, otherwise you have to add the following lines right at the end of the file:\n# Decrease swap usage to a workable level\nvm.swappiness=10\n# Improve cache management\nvm.vfs_cache_pressure=50\n\n", "Q: Unable to complete sudo apt-get update I have just installed Ubuntu 12.0.4 LTS (Precise Pangolin). I tried to run sudo apt-get update on shell and it ends up with following errors after couple of seconds:\nErr http://pk.archive.ubuntu.com precise Release.gpg\nCould not connect to pk.archive.ubuntu.com:80 (58.65.218.244), connection timed out\n\nW: Failed to fetch http://pk.archive.ubuntu.com/ubuntu/dists/precise-backports/Release.gpg Unable to connect to pk.archive.ubuntu.com:http:\n\nW: Some index files failed to download. They have been ignored, or old ones used instead.\n\n\nA: Open /etc/apt/sources.list and replace pk.archive.ubuntu.com with archive.ubuntu.com, after that save the file and run sudo apt-get update\n", "Q: Mysql data provider for TORA I was a MySQL query browser user in Windows. I switched to Ubuntu 13.10 and now I can't get MySQL query browser so I tried TORA referenced from MySQL GUI Tools\nNow I could not get any option in connection provider: it's like disabled not showing MySQL db\nWhen I hit New Connection it says\nno available connection provider\n\nHow to get connection provider in TORA?\n\nA: Need to install and it's ready\nsudo apt-get install libqt4-sql-mysql  #for mysql\nsudo apt-get install libqt4-sql-psql   #for postgresql\nsudo apt-get install libqt4-sql-sqlite #sqlite\n\n", "Q: How can I access Windows files from Ubuntu Is it possible to get the files I had on Windows onto my Ubuntu desktop?\nHow can I connect to my Windows partition from Ubuntu?\n\nA: Yes, just mount the windows partition from which you want to copy files. Drag and drop the files on to your Ubuntu desktop. That's all.\nMounting a partition can be done manually or automatically,\nsudo mkdir /media/windows\nsudo mount /dev/sdaX /media/windows\n    # X = partition number\n\nNow your windows partition should be mounted inside /media/windows directory.\nAfter you clicked on the corresponding partition icon(which was on the unity), it get automatically mounted inside /media/$USER directory. To copy files from windows partition to Ubuntu desktop, you have to run these command,\ncp /media/$USER/xxxxxxx/folder ~/Desktop\n    # To copy a folder to your Ubuntu desktop\n\ncp /media/$USER/xxxxxxx/folder/* ~/Desktop\n    # To copy all the files inside that folder to Ubuntu desktop\n\ncp /media/$USER/xxxxxxx/folder/filename ~/Desktop\n    # To copy specific file to your Ubuntu desktop\n\nxxxxxxx - label name of the Windows partition.\n\nA: yes of course you can acccess windows NTFS/FAT32 partitions from Ubuntu\nFrom help.ubuntu.com:\n\nUsing the File Manager For those using a desktop version of Ubuntu, or\n  one of its offical derivatives, the easiest and quickest way of\n  mounting NTFS or FAT32 partitions is from the file manager: Nautilus\n  in Ubuntu, Thunar in Xubuntu, Dolphin in Kubuntu and PCManFM in\n  Lubuntu. Simply look in the left pane of the file manager for the\n  partition you wish to mount and click on it - it will be mounted and\n  its contents will show up in the main pane. Partitions show with their\n  labels if labelled, or their size if not.\nUnless you require your Windows partition - or a NTFS/FAT32 partition\n  for data shared with Windows - mounted every time you boot up for one\n  of the reasons given below, mounting from the file manager in this way\n  should suffice.\nIf you are using a Wubi version of Ubuntu and you wish to browse the\n  host partition, you do not need to mount it - it is mounted already in\n  the \"host\" folder. Click on \"File System\" in the left pane of the\n  Nautilus file browser and then open the host folder which you will see\n  in the main pane.\n\nJust Open Home folder from your Dash menu and you can see all partitions mounted under Devices:\n\nClick on the needed drive and copy files/folders thw way you want to your Ubuntu drive\n\nA: From the default file browser in Ubuntu, you can find other locations, by pressing it you can navigate to disk partitions, you can find a partition that looks something like: /dev/nvme... or /dev/sata... according to your disk type.\nBy mounting this directory you can access all your windows files.\nN.B.: this is valid for any operating system other than windows.\n\n\nA: Press Ctrl+Alt+T to open a terminal and enter the two commands below:\ncd /media/$USER/\nls\n\nThe folders you get correspond usually (windows 10) for g drive, f drive and c drive. Navigate to either of these and access your files.\n", "Q: How does linux handle a move command How does linux handle a move command under the hood?\nLet's say I move my home dir\n/home/me\n\nand I move this into another directory\n/home/foo/me\n\nHow are all the files and directories paths under me changed?  I know my Desktop dir under  me is now /home/foo/me/Desktop as well as Documents /home/foo/me/Documents but does the file system explicitly update every path under me to to reflect the change?  That doesn't sound very efficient and it's probably not this.  \nWhere can I get more information on this? \n\nA: If you're interested in how programs such as mv and cp work, remember that they're open source and you can get the most accurate explanation by reading through the code. Here has links to all the core utilities. Specifically, you can find mv here\n\nA: To understand how it move folders you may need to understand a bit about file system under linux.  Every files and folders are stored as part of a data structure called an \"inode\".  Each file has an inode number, so does folders.\nTo view the inode of your folder, use the command ls -ial foldername.  The first column shows the inode number of the file.  For each folder there are two unique names . and .., representing the directory of its own, and the parent directory respectively.\nYou can try doing an experiment to move a directory (say, /home/me/source) with sub-directories and files to another directory (e.g. /home/me/somewhere/else).  The inode number of /home/me/source and all its contents remains the same before and after moving.  The only difference is the inode number of .., which originally shares the inode number of /home/me and now becomes the inode number of /home/me/somewhere/else.  In simple wording, Linux update the link to directory source and then it's done.\nThe contents on the hard disk are not modified anyway, only the inode index is updated when the folder is moved.  This is, of course, not the case if you move the folder to a different physical location.\n", "Q: Can't \"compile\" the makefile This is the make file:\nobj-m += hello_pass_arg.o\n\nKDIR = /lib/modules/$(shell uname -r)/build\n\nall:\n    $(MAKE) -C $(KDIR) SUBDIRS=$(PWD) modules\nclean:  \n    rm -rf *.o *.ko *.mod.* *.symvers *.order\n\nWhen i execute the command \"make\" i shows the following error:\nmake -C /lib/modules/3.8.13.14-qd/build SUBDIRS=/usr/src/linux-headers-3.8.13.14-qd/drivers/hello modules\nmake[1]: Entering directory `/root/source/linux-lts-raring-3.8.0'\nmake[2]: *** No rule to make target `/usr/src/linux-headers-3.8.13.14-qd/drivers/hello/hello_pass_arg.c', needed by `/usr/src/linux-headers-3.8.13.14-qd/drivers/hello/hello_pass_arg.o'.  Stop.\nmake[1]: *** [_module_/usr/src/linux-headers-3.8.13.14-qd/drivers/hello] Error 2\nmake[1]: Leaving directory `/root/source/linux-lts-raring-3.8.0'\nmake: *** [all] Error 2\n\nI dont understand why does it enter linux-lts-raring-3.8.0!\n\nA: Move your hello_pass_arg.c file to a location other than the source code of your linux kernel and it should work.\n", "Q: Can I Install Ubuntu in sd3? I was using Windows 7 some days ago. Accidentally, a magnet touched the HDD of my laptop. After few seconds, I got blue screen saying crash dumping bla bla. I shutdown my computer and when I started it, it says automatic repair... and the there was nothing.\nI put my ubuntu live CD to see if I could format the HDD, Under Devices, I could only open the Z drive (/dev/sda3) and the System Reserved. I think, the magnet has deleted the files from sda2.\nSo, I just want to know if it's possible to install ubuntu in sd3 and make it bootable. \n\nA: It might be possible to re-format the entire disk, provided no physical damage was done when you wiped it. \nFirst start up the installer and see if you can create a new partition table. If this works you can continue to install as normal. \nWith regards to your question about installing to a single partition, yes you can. You will need to create a swap file instead of dedicating a partition. Read the Swap FAQ here\n", "Q: How can I list all applications installed in my system? I know, I just can hit Super+A to see all installed apps in Ubuntu, but I need a command to list their names. The command\ndpkg --get-selections | awk '{print $1}'\n\nis also not an option because it shows all installed packages and it contains drivers, kernels and libraries.\n\nA: To get the list of all your installed applications with their names, the easiest way is to do:\nsudo apt-get install aptitude\naptitude -F' * %p -> %d ' --no-gui --disable-columns search '?and(~i,!?section(libs), !?section(kernel), !?section(devel))'\n\nIt will get you a nice list of all installed packages that are not libraries, not kernels, not development package like this:\n* zip -> Archiver for .zip files \n* zlib1g -> compression library - runtime \n* zlib1g-dev -> compression library - development \n* zsh -> shell with lots of features \n* zsh-common -> architecture independent files for Zsh \n\nIt's more complete since it also lists non-GUI applications that won't appear in the .desktop files\n\nA: Run the below command to see all the installed applications,\nls /usr/share/applications | awk -F '.desktop' ' { print $1}' -\n\nIf you want to get the list of all installed applications, then run the below command,\nls /usr/share/applications | awk -F '.desktop' ' { print $1}' - > ~/Desktop/applications.txt\n\nIt will stores the above command output to applications.txt file inside your ~/Desktop directory.\nOR\nAlso run the below command on terminal to list the installed applications,\nfind /usr/share/applications -maxdepth 1 -type f -exec basename {} .desktop \\; | sort\n\nTo get the list in text file, run the below command\nfind /usr/share/applications -maxdepth 1 -type f -exec basename {} .desktop \\; | sort > ~/Desktop/applications.txt\n\nDesktop entries for all the installed applications are stored inside /usr/share/applications directory, where file names are in the format of application-name.desktop.Removing the .desktop part from the file names will give you the total list of installed applications.\nUpdate:\nAs @Radu suggested, you can also find desktop entries for your additional installed applications inside ~/.local/share/applications directory.\nfind /usr/share/applications ~/.local/share/applications -maxdepth 1 -type f -exec basename {} .desktop \\;\n\n\nA: I came up with this answer for people who wants to use bash in a good way. It's clear that the answer of the question is related to the listing of the files from /usr/share/applications, but the problem is that ls command shouldn't be parsed ever. In the past, I was doing the same mistake, but now I learned that the best way is to use a for loop to iterate over the files, even if I must use some more keys from my precious keyboard:\nfor app in /usr/share/applications/*.desktop; do echo \"${app:24:-8}\"; done\n\nI also used in the previous command string manipulation operations: removed from app first 24 characters which are /usr/share/applications/ and last 8 characters which are .desktop.\n\nUpdate:\nAnother place where you can find applications shown by the Dash is ~/.local/share/applications/*.desktop. So you need to run the following command as well:\nfor app in ~/.local/share/applications/*.desktop; do echo \"${app:37:-8}\"; done\n\nTo unify the previous two commands, you can use:\nfor app in /usr/share/applications/*.desktop ~/.local/share/applications/*.desktop; do app=\"${app##/*/}\"; echo \"${app::-8}\"; done\n\n\nA: Not sure why most of the answers posted involves extracting the filename of .desktop shortcuts. Your .desktop shortcut filename can be anything but what matters is the Name field inside the shortcut file. If you want to build the list of installed application names showing in Dash, just \"grep\" that field under [Desktop Entry]\nRudimental code, with bash\n#!/bin/bash\n\nfor file in /usr/share/applications/*.desktop;\ndo\n    while IFS== read -r key val\n    do\n        if [[ -z $key ]]; then\n            continue\n        else\n            if [[ $key =~ ^\\[Desktop\\ Entry ]]; then\n                interesting_field=1\n            elif [[ $key =~ ^\\[ ]]; then\n                interesting_field=0\n            fi\n        fi\n        [[ $interesting_field -eq 1 ]] && [[ $key == \"Name\" ]] && echo $val\n    done < $file\ndone\n\nBut this does not take into account shortcuts that are hidden from being showed in Dash. Someone with better understand of .desktop spec might want to further expand this code to exclude those kinda of shortcuts\nEdit : another attempt, with Python\n#!/usr/bin/python\n\nfrom os import listdir\nfrom os.path import isfile, join\nimport ConfigParser\n\nSHORTCUTDIR = \"/usr/share/applications/\"\n\nshortcuts = [ file for file in listdir(SHORTCUTDIR) if isfile(join(SHORTCUTDIR, file)) and file.endswith(\".desktop\") ]\ndash_shortcuts = []\n\nfor f in shortcuts:\n    c = ConfigParser.SafeConfigParser()\n    c.read(SHORTCUTDIR + f)\n\n    try:\n        if c.getboolean('Desktop Entry', 'NoDisplay') is True:\n            continue\n    except ConfigParser.NoOptionError:\n        pass\n\n    try:\n        if \"unity\" in c.get('Desktop Entry', 'NotShowIn').lower():\n            continue\n    except ConfigParser.NoOptionError:\n        pass\n\n    try:\n        if \"unity\" not in c.get('Desktop Entry', 'OnlyShowIn').lower():\n            continue\n    except ConfigParser.NoOptionError:\n        pass\n\n    dash_shortcuts += [ c.get(\"Desktop Entry\", \"Name\") ]\n\nfor s in sorted(dash_shortcuts, key=str.lower):\n    print s\n\n\nA: If you need list of applications shown when you hit Super+A, you can use ls /usr/share/applications. The only thing you should do is replace .desktop ending which is quite simple task. I do it with sed:\nls /usr/share/applications | sed s/.desktop// - > installed-apps.txt\n\nBut you can do it after you received the list using the text editor. \n\nA: The questioner wants to list the names of all installed \"apps\".\nRegarding apps with .desktop files:  \n\n\n*\n\n*the answer by Danatela deals with apps that have .desktop files in /usr/share/applications\n\n*as pointed out by Radu, apps with .desktop files may also be found in ~/.local/share/applications\n\n*at this point, it may be noted that apps with .desktop files can have two names\n\n\n*\n\n*one \"name\" is available by querying the Dash in Unity or from menus in Xubuntu (for example). This name is derived from the Name= line in the respective .desktop file. One example is \"Character Map\".\n\n*the other \"name\" is the one to be used when running the app from the terminal and is the first word after Exec=. In the case of \"Character Map\", that would be gucharmap.\n\n\n*the two names (and the .desktop file) could be related using:  \n\n\n*\n\n*sed -ns '1F;/^\\[Desktop Entry\\]/,/^\\[/{/^Name=/p;/^Exec=/h};${z;x;G;p}' /usr/share/applications/*.desktop\n\n*and\n\n*sed -ns '1F;/^\\[Desktop Entry\\]/,/^\\[/{/^Name=/p;/^Exec=/h};${z;x;G;p}' $HOME/.local/share/applications/*.desktop\nRegarding apps without .desktop files:  \nDepending on how one defines \"app\", some don't have .desktop files.  \n\n\n*\n\n*would something like conky, poppler-utils, qpdf,  xdotool and wmctrl be considered \"apps\"? How are these to be identified and listed by their names (assuming one has installed them)? \n\n*What about awk, find, grep, ls and sed to name some more? Are they apps or are they not?\n\n\nIf anything that has a command is thought of as an app, then Linux command to list all available commands and aliases and this answer there will help identify them.\n", "Q: ubuntu 13.10 doesn't boot up I have downloaded the ISO file and copied on a usb drive\nI have made a live usb\nI have changed the boot order\nubuntu loads but after loading system stucks on a blank screen(on both trying and installing)\nmd5sum has verified the hash key\nWhat should I do now?\n\nA: Try including nomodeset as a boot option in grub. From the main grub bootloader press 'e' to edit the boot parameters. Find where it reads:\nquiet splash \nEdit to look like this:\nquiet splash nomodeset\n\nHopefully this will solve your boot issue. If so, try changing your graphics driver from the 'Additional Software' app.\n", "Q: gedit:3457 Error: Not using units is deprecated. Assuming 'px' I have an error with my first application which I don't understand :\n(gedit:3457): Gtk-WARNING **: Theme parsing error: gtk-widgets.css:1971:11: Not using units is deprecated. Assuming 'px'.  (gedit:3457): Gtk-WARNING **: \nFailed to parse /usr/share/themes/mac-os-lion-theme-v2/gtk-3.0/settings.ini: \n\n\nA: Graphical sudo\n\nYou should never use normal sudo to start graphical applications as\n  Root. You should use gksudo (kdesudo on Kubuntu) to run such programs.\n  gksudo sets HOME=~root, and copies .Xauthority to a tmp directory.\n  This prevents files in your home directory becoming owned by Root.\n\nyou must use this way\ngksudo gedit /path-to-file\n\n", "Q: How to create a Kconfig file So i have a hello world module and a Makefile for it. I want the module to be shown in the make menuconfig window! How do i do that? By creating a new Kconfig file or something? If so, how to create a new Kconfig file?\n\nA: First create a \"Kconfig\" file in the same directory and edit the file as follows:\nex:\n menu \"Networking\"\n config NET\n tristate \"my network driver\" # --> this line gives the desc of the ko.\n depends on <ARCH>\n default y if <ARCH>\n help\n   <Text displayed when help is selected for your driver>.\n\nYou can also create multi level menus, for more details refer to Kconfig\n", "Q: How to share VirtualBox Windows XP Guest's Internet Connection with Ubuntu 13.10 Host? I'm using Ubuntu 13.10 with Windows XP SP3 Installed as a Virtual Machine, the only way for me to access the internet is using a PPP broadband USB Modem (DWM-156) I am not able to run it in Ubuntu, I managed to install it on XP and get it to work but I don't know how to share that connection with Ubuntu. I googled it and not found any working workaround for me. I tried all types of \"Attached to:\" settings on my guest OS, but no success (perhaps there is more settings that I did not).\nI'm not an expert, so please explain your answer in step-by-step approach.\nCould someone shows me an easy way to do that? Thanks!\n\nA: First Step\n\n\n*\n\n*Select your guest virtual machine in the VirtualBox Manager then\nclick on Settings.\n\n*Select the Network category\n\n*Select \"Bridged Adapter\" in the \"Attached to\" drop-down list.\n\n*Boot your VM normally\n\n\n\nSecond Step\nThis post should help you too:\n\nAdd a NIC to the VM if you haven't attached one already and set it to\n  Host-Only. In the general VB settings, DISABLE the DHCP service for\n  the host-only interface and configure it with the following IP, the\n  last number can be anything between 2 and 254: IP: 192.168.0.2 Mask:\n  255.255.255.0\nThat is everything you can configure there, but your Host needs a\n  gateway too, and that will be 192.168.0.1. DNS servers can be whatever\n  the Host gets, but you can also use the OpenDNS servers.\nIn the Guest, right click on the interface that provides internet and\n  click on Properties. Go to the Advanced tab and share the connection.\n  This should set the other interface with the IP of 192.168.0.1 and\n  enable a DHCP server on it. It's a bit of a shame that it can't be set\n  on the Host side to use DHCP, but you can do that manually. Using the\n  DHCP option means that the above steps to set a static IP are not\n  needed, they will be overwritten by DHCP. You have to run the dhcp\n  client from a terminal in order to get the complete configuration for\n  use on the Host.\nHope it makes sense.\n\n", "Q: How to add shortcut onto Wine desktop? Wine has a \"desktop mode\" where it renders a virtual desktop in a window and renders all its windows within that desktop. You can access it through:\nwine explorer /desktop=arbname,1920x1200 \"C:\\...\\...\\application.exe\"\n\nI used it and some applications have installed icons on the virtual desktop:\n\nThose shortcuts (.lnk files) are located in ~/.wine/drive_c/users/Public/Desktop/, but are binary files.\nHow can I create a custom one?\nNote: I am not asking how to create a shortcut to a Wine app on my Ubuntu desktop.\n\nA: With an amount of pain and suffering, fossfreedom's suggestion paid off. I didn't try the VBScript method, mainly because I didn't know how much of that is actually implemented in Wine. There was also mention of add-on packs that don't seem to be present in Wine.\nSo that left me with the Shortcut.exe method from alfasin.\n\n\n*\n\n*Download Shortcut.exe from its creator\n\n*Unzip it and make it available somewhere under your WINEPREFIX (I used ~/.wine/drive_c/)\n\n*Run wineconsole to get a cmd.exe-like environment\n\n*From there, cd to whereever your shortcut.exe live and use it. Here's what I ran:\nShortcut /a:c /f:\"%ALLUSERSPROFILE%\\Desktop\\Borderlands2.lnk\" /t:\"C:\\Program Files\\Steam\\steamapps\\common\\Borderlands 2\\Binaries\\Win32\\Borderlands2.exe\"\n\nIf nothing else it has provided me with a renewed (and thoroughly deserved) hatred towards Windows.\n\nA: Go to your user folder in ~/.wine/drive_c/users/ and to \"Start Menu\", \"Programs\" and copy the shortcut you want and paste it in ~/.wine/drive_c/users/Public/Desktop/\nYou can create a launch shortcut in your linux with for example this command line:\nwine explorer /desktop=arbname,1920x1080 \"C:/Program Files/Windows NT/Accessories/wordpad.exe\"\nThe wine window close when you close this wordpad but, if you reduce it, all the other wine software is accessible from the desktop.\n", "Q: How to purge my deleted files I had un-installed a package and deleted all of its files/directories. But still when I locate the package, i can find the deleted files in list while in actual they are not present. I cant access those deleted directories nor can access its config files in /etc.\nI gave my server a restart but didn't helped.\n\nA: First you should always uninstall package with apt-get purge packagename if you what to completely remove them from your system.\nDon't use locate to actually find deleted files, it does not work this way:\nlocate reads one or more databases prepared by updatedb and writes file names matching at least one of the PATTERNs to standard output, one per line.\nBy default, locate does not check whether files found in database still exist.\nRun sudo updatedb and check again with your locate command, deleted files should not be listed.\n", "Q: nVidia 331.49 Installaton on P151EM1 Clevo (with dual-boot Ubuntu 13.10) (apologies for the possibly confusing title)\nHere is the situation:\nI have Ubuntu 13.10 installed on my P151EM1 Clevo laptop (GTX670MX) (dual boot with W7).\nI'm trying to update the drivers to version 311.49, but I am constantly running into strange issues.\nInstalled manually (via .run download from nVidia's site), ended up with a black screen and a black \"X\" as a cursor, AFTER the \"Ubuntu\" loading screen appears. (installing via the Ctrl+Alt+F1 Terminal).\nInstalled via the xorg-edgers ppa, ended up with the same issue (black screen and black \"X\" as cursor).\nMy Ubuntu 13.10 is pretty much a new installation, it is fully updated too. Only additional thing I have installed is OpenJDK 7 JRE.\nNOTE: I'm new at trying to do this (first time seriously considering using Ubuntu for any of my games that support it, example: Minecraft. Which runs perfectly fine yet it uses the onboard HD4000 which isn't ideal. Making it run worse than in Windows 7).\n\nA: Try removing bumblebee, as this seems to have helped many others with the latest nvidia drivers. \nBoot into the command line then run:\n$  sudo apt-get remove --purge bumblebee\nReboot and you should have a working X\n", "Q: How can I view file header information? I looked at this question Mark PDF as Adobe PDF and one of the answers says: \n\nIn my document headers created with LibreOffice, the version 1.4 is having fewer header information.\n\nWhat header information is this and how can I view it? For all type of files if possible.\n\nA: you can use some command that read the hexadecimal of a file like hexdump and then read  the header from the right panel example:\nhexdump -C  Desktop/somefile | head\n\nThe output is:\n00000000  ff d8 ff e0 00 10 4a 46  49 46 00 01 01 00 00 01  |......JFIF......|\n00000010  00 01 00 00 ff fe 00 3b  43 52 45 41 54 4f 52 3a  |.......;CREATOR:|\n00000020  20 67 64 2d 6a 70 65 67  20 76 31 2e 30 20 28 75  | gd-jpeg v1.0 (u|\n00000030  73 69 6e 67 20 49 4a 47  20 4a 50 45 47 20 76 38  |sing IJG JPEG v8|\n00000040  30 29 2c 20 71 75 61 6c  69 74 79 20 3d 20 39 30  |0), quality = 90|\n00000050  0a ff db 00 43 00 03 02  02 03 02 02 03 03 03 03  |....C...........|\n00000060  04 03 03 04 05 08 05 05  04 04 05 0a 07 07 06 08  |................|\n00000070  0c 0a 0c 0c 0b 0a 0b 0b  0d 0e 12 10 0d 0e 11 0e  |................|\n00000080  0b 0b 10 16 10 11 13 14  15 15 15 0c 0f 17 18 16  |................|\n00000090  14 18 12 14 15 14 ff db  00 43 01 03 04 04 05 04  |.........C......|\n\nas you see this show me that this file is a jpeg image.\nAnother option is xxd\nxxd Desktop/somefile | head\n\ngives same output of above.\n", "Q: Forgot to add swap memory during installation In my ignorance I didn't add swap memory to my install. So my question is, can I work without it and if not how can I add it to my existing install?\nLove to get some feedback!\n\nA: \nCan i work whitout swap?\n\nIt depends on your RAM size.If your RAM size is too low, you have to create swap otherwise you won't.\nSee this page for how much swap space do you really need, according to you RAM size.\n\nHow can i add it to my excisting install?\n\nYou can create a new swap partition using Gparted Utility.And don't forget to create a new fstab entry for your created swap partition.See this page for how to create swap partition and add it to the existing Ubuntu installation.\n", "Q: Connecting Ubuntu Server 12.04 to public network (internet access) I have installed Ubuntu Server 12.04 on my computer. I want to setup my dedicated server for web server and also I already have my own domain for web hosting company. \nI followed these instructions to install Ubuntu Server 12.04. \nI just setup my server connect with a router and the router connect to Internet. That problem is I can't access my server from a public network. I already tried this way, and made forward port 80 in my router but it's still not working.\nOutput ifconfig \n[eth0      Link encap:Ethernet  HWaddr 00:1f:29:d8:ab:e4\n          inet addr:192.168.0.117  Bcast:192.168.0.255  Mask:255.255.255.0]\nIs there any way to connect my server to the internet?\n\nA: OP's own answer:\nI found the anwers for my problem. So I just need to forward port 80 in my routers. Now I can access my server using internet network.\n", "Q: Camera movies will not play I have recoded video footage on my Fuji X-S1 camera, which plays back fine on the actual camera, but when transferred to my computer, running Ubuntu 12.04, the movie files will not play. Photographs taken on the same camera view fine, it is just the movies. Can anyone assist in this please?\n\nA: As vlc has built-in decoders I would recommend to install it instead of installing by hand the missing plugins for Totem (the default media player).\nfrom a terminal: sudo apt-get install vlc\nUsing the Software Center, just search for vlc and click on install\n\nA: Fujifilm X-S1 can save video files in H.264 MOV format. The default media player Totem should tell you which codec is missing and try to install it (package x264).\nIf you use another media player or Totem is not able to find out which codec is missing, you can install the package ubuntu-restricted-extras package: \n\nAfterwards you should be able to play those video files.\n", "Q: Increase space for Ubuntu Server on VirtualBox I am running Ubuntu Server in VirtualBox (I am on a Mac) as a web development server. My Mysql server has stopped starting (and wont start) and I highly suspect it is because I have no disk space left so I am trying to increase the space available.\nI used the disk resizer utility (VBoxManage modifyhd Ubuntu\\ Server.vdi  --resize 80000) to increase the disk size and then I booted into Ubuntu live and, using GParted, created a new 30gb partition. I made it an ext2 filesystem. \nBut when I boot I first see that this hasn't helped:\n\nAnd here is the output from fdisk -l:\n\nI am stuck at this part - how do I now tell my machine that it can use the new space so I don't get disk space errors?\nUPDATE:\nI deleted the 30gb partition I made and tried to just resize but I am unable to use Gparted to resize the partition because Gparted says lvm2 is not supported(?):\n\n\nA: You made the wrong decision. You have to resize the partition instead of creating a new partition.\n\n\n*\n\n*Now boot from Gparted and delete the newly created 30Gb partition\n\n*Resize the old partition and get the space you need\nTo resize it, click ‘Resize/Move’ button\n\n\n*Next, use the slider to drag the line to the left to repartition the free space. The available free space is the area with the white background. Ubuntu is installed in the area with the yellow background.  When you’re done, click ‘Resize/Move’ button to apply the changes.\n\n\n*Finally, review the changes and click ‘Apply’ to save.\n\n", "Q: How can I uninstall oracle java 8 and install oracle java 7 instead with webupd8 installer? I installed oracle java 8 by typing in terminal:\nsudo add-apt-repository ppa:webupd8team/java  \nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n\nbut now I want to uninstall oracle java 8 and install oracle java 7 instead with sudo apt-get install oracle-java7-installer\nhow can I uninstall java 8? which commands should I type in terminal? \n\nA: First, you should not need to uninstall Java 8 to switch to Java 7, due to the alternatives system.  Merely installing oracle-java7-installer will make Java 7 the preferred JVM/JDK.  If you ever do need Java 8:\n$ sudo update-java-alternatives --set java-8-oracle\n\nNote that this changes /usr/bin/java, thus affecting everything on that system that relies on the default java.  You may want to set JAVA_HOME (to, e.g., /usr/lib/jvm/java-8-oracle) if there is a single app that needs a different java.\nWARNING:  This works only for Oracle Java installed via webupd8 packages!  Adding any OpenJDK package has undefined results!\nIf you really do need to get rid of Java8, the removal scripts for oracle-java8-installer will remove the JDK as well as the installer.\n\nA: You can remove packages with aptitude by entering apt-get --purge remove <package> into a terminal.\nI recommended the --purge option since apt-get remove may sometimes leave behind configuration files and those may cause conflicts if your plan is to install an older version.\n\nA: Try with this code in terminal to remove java 8:\nsudo apt-get purge oracle-java8-installer\n\nThen type:\njavac -version\n\nThe output should be:\njavac: command not found\n\nand to install java 7 in Ubuntu I use this code in terminal:\nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java7-installer\n\nAfter that type the following to see if there is java installed:\njava -version\n\nThe output should be:\njava version \"1.7.0_80\"\n\n\nA: I am guessing that most of it lives here:\n$ du -h -d 1 /usr/lib/jvm\n363M    /usr/lib/jvm/java-8-oracle\n\nUsing which and then ls -l on the result, I found that there is a chain of links that point all the way to the above folder, for various java executables (java, javac, etc.), so you might want to delete/unlink these as well.\n$ which java\n/usr/bin/java\n$ ls -l /usr/bin/java\nlrwxrwxrwx 1 root root 22 Apr  5  2015 /usr/bin/java -> /etc/alternatives/java\n$ ls -l /etc/alternatives/java\nlrwxrwxrwx 1 root root 39 May  3  2015 /etc/alternatives/java -> /usr/lib/jvm/java-8-oracle/jre/bin/java\n\nThere also seems to be some documentation in /usr/share/doc/java-common/ and user preferences in ~/.java\n", "Q: Where does the command make search for libraries I wonder if you can tell me the path make command uses to search for libraries and header files, I'm getting these errors posted in my question and I wanna check the path manually.\nI have Ubuntu 12.04 LTS, 2.6.38-16 kernel and gcc version 4.6.3 and I'm trying to compile this package:\nhttp://nrg.cs.ucl.ac.uk/mptcp/mptcp_userland_0.1.tar.gz\nThank you.\n\nA: The make command itself does not search for libraries or header files - instead it looks for a Makefile in the current directory (unless an alternative file is specified on the command line using the -f option) and executes the instructions inside. Those are usually instructions to specific compilers such as gcc and/or g++.\nThe Makefile may add search paths for specific compilation commands using -I (for include files) and/or -L (for libraries) directives. You can find the default search paths in your compiler documentation e.g. GNU gcc: Search Paths or you can list them directly by processing an empty file with compiler verbosity turned up e.g. to see what the gcc include path is\necho | `gcc -print-prog-name=cc1` -v\n\nor to see both include and library path information echo | gcc -xc -E -v - (for C) or echo | gcc -xc++ -E -v - (for C++). \n\nHowever the question you linked to looks like the output from a ./configure script rather than from a make command. A ./configure script is part of the GNU automake system and is used to create a 'custom' Makefile for the local build environment by figuring out where various components are located on your system. If you have libraries located in non-standard locations, such as other build dependencies that you have also built from source, and installed somewhere like /usr/local/, then it may be necessary to pass those locations to the ./configure script e.g.\n./configure --with-foo=/usr/local --with-bar=/opt/bar_3.14\n\nFor specific instructions you will need to refer to the README or similar documentation for the package you are trying to build.\n", "Q: LAN network won't work in Linux but works on windows I have a question. Please forgive if this has already been answered:\nI am trying to connect some computers to the LAN of my office and I found out that the Ubuntu 13.10 computers won't connect to the LAN unless I manually setup a fixed IP number for them. If I connect a windows computer to the same wired network, works with no problems. \nDo you have any idea what this could be happening? Why the automatic DHCP seems to work fine in windows but no in linux?\nThe computers I'm using are Lenovo ThinkCentre Edge 72 with Ubuntu 13.04\nEthernet Controler: Realtek Semiconductor Co., Ltd. RT8111/8168 PCI Express Gigabit Ethernet Controler (rev 06)\nIntel Pentium Dual-Core G2030( 3.00GHz )\nIntel Integrated HD Graphics\n4.0GB PC3-12800 DDR3 SDRAM 1600 MHz\n500GB 7200 rpm\n\nA: The linux kernel uses \"generic drivers\" for your computer. Where as Windows requires explicit installation of your drivers. Hence some of the functionality that you get in windows might not be available in ubuntu.\nYou can go to the website of your NIC card vendor and check for drivers that can be installed in ubuntu. Reinstall the driver. All will be fixed.\nI had faced this problem with my laptop which used \"Realtek\" NIC card. When I reinstalled the driver with my kernel everything worked.\n", "Q: howto link / execute / add to $PATH: python3.3.5 after manual installation in 12.04 LTS I'm trying to install python3.3.5 on /home/myUser/XX, where home is located on a separate partition.\nI'm relatively new to Linux and have only basic knowledge about installing packages on my own, without the synaptic package Manager.\nHere is what I did:\nI followed the instructions from Sergey in this thread. I also used the similar explanation from James Nichsolson at this webpage\nEverything worked fine so far except this part:\n\nSome nice touches to install a py command by creating a symlink:\nmkdir ~/bin\nln -s /opt/python3.3/bin/python3.3 ~/bin/py\n\n\nAs I understand it, this is to make python3.3 execuable via the terminal at any place? So if I write python3.3 it opens.\nmy paths are bit different from the ones in Sergeys description:\npath of python installation:\n/home/metin/python/python3.3.5\n\nmy ./configure command was therefore:\n./configure --prefix=/home/metin/python/python3.3.5\n\nmy command to create the link was:\n ln -s /home/metin/python/python3.3.5/bin/python3.3\n\nProblem:\nafter I do this and when I type python3 in my terminal it says this programm is not installed, so something went wrong with creating the link?\nFurther Question:\nWhere is the difference between creating such a link and adding entries to $PATH? As I understand it Ubuntu can access all programs stored in $PATH, right? Why should'nt I just ad .../python3.3.5 to $PATH? So when do I use ln(links) and when do I add stuff to $PATH.\nIf I want to add dirs to $PATH how do I do that easy? I found some explanations on the internet but I'm confused. There is the file .bashrc in my /home dir. Is that the one were I add such dirs? Because there is also /etc/bash.bashrc and I remember adding\nPATH=/home/metin/texlive/2012/bin/x86_64-linux:$PATH; export PATH\nMANPATH=/home/metin/texlive/2012/texmf/doc/man:$MANPATH; export MANPATH\nINFOPATH=/home/metin/texlive/2012/texmf/doc/info:$INFOPATH; export INFOPATH\n\nwhen I installed texlive\nsince this questions are related I found it logic to put it all in one thread. Please let me know if I should rather make more than one post.\n\nA: Try this:\nsudo ln -s /home/metin/python/python3.3.5/bin/python3.3 /usr/bin/python3.3.5\n\nNot sure if your home path is correct, so if the command above fails you must symlink the binary located in your home folder to /usr/bin.\n", "Q: How to change Gedit embeded terminal plugin colors? I am trying to use Gedit as an IDE for learning C. So far everything is working great but i have this problem: when using ls in its embedded terminal I am unable to see all the files and directories in my workspace directory (only shows .c files but not the .out and other directories), yet when i run terminal from CTRL+ALT+T all the files in the current directory show.\nI can't seem to figure out why this is happening, so any ideas would be greatly appreciated. it seems to me that only the colored files aren't showing in the embedded terminal and i need them to show.\nthank you!\n\nA: The OP is asking about a problem in Gedit embedded terminal plugin. \nThe only problem here is that the colour scheme is not good i.e., white prompt on light grey background makes it almost impossible to work. To change the colour scheme follow the next series of steps:\n\n\n*\n\n*Open dconf-editor. If it is not installed, install it through the following command :\nsudo apt-get install dconf-tools\n\n\n*Once installed, execute it using the following command :\ndconf-editor\n\n\n*In the dconf editor window, go to org->gnome->gedit->plugins->terminal \n\n\n*\n\n*deselect the use-theme-colors option.\n\n*clear palette settings\n\n*set foreground color: #FFFFFF \n\n*set background color: #000000\n\n\n\n\n*Now restart the gedit program.\n\nObserve that a colour scheme of black prompt over light background is now active.\n\nA: Verify your .bashrc file, and see if it contains the following:\nalias ls='ls --color=auto'\n\nIf it doesn't have, add it. It must help to show dotfiles too.\n", "Q: Configure rsnapshot to keep initial(first) backup forever? How could I tell rsnapshot to keep the initial (ie., the very first backup) backup of my server forever, incase I may need it in some rare time (like for some files in /etc directory ) ?\n\nA: There is a utility called rsnaptar which can be found in the utils folder located in /usr/share/doc/rsnapshot-*/ area depending on your rsnpashot installation. From the rsnaptar file itself is a brief description:\n\nA quick hack of a shell script to tar up backup points from the\n  rsnapshot snapshot root. Sends an e-mail to an address specified on\n  the command line when finished.\n\nSo you can use this script utility to tar up your initial backup and keep it handy.  \n", "Q: /dev/mapper/ubuntu--vg-root is full I have just successfully increased my disk size having had help with this question. My set up is Ubuntu Server running in VirtualBox as a web development server. I now have this space:\n\nAs you can see /dev/mapper/ubuntu--vg-root is full but I have a a lot more space. How do I go about using the new space to stop disk full errors? I am not even sure where to start looking so any help is great.\n\nA: /dev/mapper indicates that you're using LVM; so resizing the physical volume is not enough to resize the logical volume contained within, let alone the filesystem.\nTo increase the filesystem size, I followed these instructions from ServerFault with success:\n\n*\n\n*First, I increased the physical partition using gparted. This was straightforward, and I assume you've already done that. If you don't have access to a LiveCD, you can increase the size of the physical disk while online, via pvresize, as shown in the linked instructions.\n\n\n*Then I used lvresize to grow the logical volume to fill the physical volume. I used pvdisplay to verify the size of the physical volume, and tried using that size.\n sudo lvresize -L 28.82G /dev/ubuntu-tt-vg/root\n\nHowever, it was too large, so I started with 27G, and kept resizing my partition bigger until I hit the max.\n\n\n*Then, I used resize2fs to grow the filesystem inside the logical volume.\n sudo resize2fs /dev/ubuntu-tt-vg/root 7290881\n\nFinding the max here was much easier. If you try a number bigger than the max, it will tell you exactly what the max is.\n\n\n*At this point, df -h should show that your filesystem has grown to the new size.\n\n", "Q: Two gateways and two interfaces I wan't to configure my ubuntu server as shown below.\n\nI need the clients in the 192.168.3.0 network to access internet through gateway 192.168.0.14, but at the same time i need 192.168.0.13 router to communicate with the server for vpn/apache access (rules are defined in the router) from the \"outside world\".\ninterfaces file:\nauto lo\niface lo inet loopback\n\nauto eth0\niface eth0 inet static\n        address 192.168.0.5\n        netmask 255.255.255.240\n        network 192.168.0.0\n        broadcast 192.168.0.15\n        up ip route add default via 192.168.0.13 dev eth0  metric 100\n\nauto eth1\niface eth1 inet static\n        address 192.168.3.250\n        netmask 255.255.255.0\n        network 192.168.3.0\n        broadcast 192.168.3.255\n\nrouting table:\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         192.168.0.13    0.0.0.0         UG    100    0        0 eth0\n192.168.0.0     0.0.0.0         255.255.255.240 U     0      0        0 eth0\n192.168.3.0     0.0.0.0         255.255.255.0   U     0      0        0 eth1\n\nThis way clients are using only router1 for web access.\nI've tried several things, like iproute2 tables...but with no success.\nIf i change the default gateway to 192.168.0.14 internet access works fine on the clients (through router 2), but vpn/apache2 access from the web won't.\nThanks\n\nA: If router2 is connected to an ethernet network ( hub / switch ) that is also connected to the dhcp clients, then they all need to be configured using a common IP address block. In this case 192.168.3.x \nWhat is router2 ? ( cisco / juniper / linksys / openwrt ?? )\n\nA: \nI need the clients in the 192.168.3.0 network to access internet through gateway 192.168.0.14, but at the same time i need 192.168.0.13 router to communicate with the server for vpn/apache access (rules are defined in the router) from the \"outside world\".\n\nWhit that description i think you can make a few things, identify the problems and isolate them:\n1º One server for 2 Gateways -> Ubuntu server 16.04 to 2 gateway at same time.\n2º 2 network address on same adapter. 2 networks Fisical and Vlan (192.168.0.0/24 and 192.168.3.0/24) ->How to setup and save vlans on ethernet\n3º Dhcp server over Vlan and routing petitions to 192.168.0.14. ->How do I install and configure a DHCP server?\n4º Valorate if you want to create a security Proxy/gateway/firewall for your client lan (192.168.3.0/24) or only a neutral server.  This is convert your server in a router and may be its more easy to buy a network switch/router/firewall with administrative capabilitys.  \nThis can be very complex, you need to touch iptables and stablish rules for port fordwarding. If you make this with using eth1 for the tow networks, a trained/Experienced user can jump your security and directly use any 192.168.0.XX/24 ip to use 192.168.0.14 as gateway. The recomended way to make this its adding another fisical adapter (like eth2) and this is the only fisical conection to 192.168.0.14 ip, fisical isolating the networks. \n", "Q: Do modifications to sysctl.conf take effect in openVZ container? I'm following a security guide(http://www.thefanclub.co.za/how-to/how-secure-ubuntu-1204-lts-server-part-1-basics) to strengthen my OpenVZ based VPS webserver running Ubuntu 12.04 , a part of that asks to make some modifications to sysctl.conf. But I am not sure if all that really makes sense in an openVZ container, as it is a shared kernel. \nHere are the edits that are suggested for sysctl.conf\n# IP Spoofing protection\nnet.ipv4.conf.all.rp_filter = 1\nnet.ipv4.conf.default.rp_filter = 1\n\n# Ignore ICMP broadcast requests\nnet.ipv4.icmp_echo_ignore_broadcasts = 1\n\n# Disable source packet routing\nnet.ipv4.conf.all.accept_source_route = 0\nnet.ipv6.conf.all.accept_source_route = 0 \nnet.ipv4.conf.default.accept_source_route = 0\nnet.ipv6.conf.default.accept_source_route = 0\n\n# Ignore send redirects\nnet.ipv4.conf.all.send_redirects = 0\nnet.ipv4.conf.default.send_redirects = 0\n\n# Block SYN attacks\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 2048\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv4.tcp_syn_retries = 5\n\n# Log Martians\nnet.ipv4.conf.all.log_martians = 1\nnet.ipv4.icmp_ignore_bogus_error_responses = 1\n\n# Ignore ICMP redirects\nnet.ipv4.conf.all.accept_redirects = 0\nnet.ipv6.conf.all.accept_redirects = 0\nnet.ipv4.conf.default.accept_redirects = 0 \nnet.ipv6.conf.default.accept_redirects = 0\n\n# Ignore Directed pings\nnet.ipv4.icmp_echo_ignore_all = 1\n\nWhen I tried to test these with my OpenVZ container I got permission denied for 3 of these entries which probably have been locked down by my host.\nerror: permission denied on key 'net.ipv4.tcp_max_syn_backlog'\nerror: permission denied on key 'net.ipv4.tcp_synack_retries'\nerror: permission denied on key 'net.ipv4.tcp_syn_retries'\n\nNow my question is: Does it really make sense to include these to my sysctl.conf in an openVZ container environment ? I want to tighten security on my server but I am not really sure if they would take effect in my openVZ container.\n\nA: Already answered on superuser.com:\n\nthere is only a single kernel running for both the host and all \"VPS\"es\n\nFor security reasons the openVZ container will not allow you to change any shared setting that may impact the host server, but the settings in the host server - at least many of them - will affect all containers.\nIf you receive access denied your settings are ignored for security reasons.\nA good host server will have security measures that will prevent common kernel level vulnerabilities from affecting your container; in a shared enviroment, always notify the admin if you find bad or not safe settings (he will be happy, don't worry)!\nYou are still allowed to configure iptables firewall (official guide) in your container: it will block a good range of attacks!\nIf you have other questions feel free to answer by commenting under here and don't forget to press the UP arrow and set as favorite if I'm of any help.\n\nGood afternoon.\n", "Q: Compiling a C file through Gedit external tools Is there any way to compile and run .c files by using a shortcut key using gedit? I know its possible for java and C++, and I read somewhere that it is possible to do so using scripts in external tools. I'm currently compiling my files by gcc -Wall name name.c then ./name, but i would like to make this process faster\nI already tried the below script for my shortcut but it generates an error saying \n\nfatal error: no input files\n\n#!/bin/sh\necho \"$GEDIT_CURRENT_DOCUMENT_NAME\"\ngcc  \"$GEDIT_CURRENT_CODUMENT_NAME\"\n\n\nA: The default build command of the gedit external tools works perfectly for me (run using Ctrl+F8):\n\n", "Q: Advice for troubleshooting a (url) preseed file? I'm working on my first preseed file, and to avoid having to re-burn a DVD every time I make a change, I'm hosting it on a webserver and loading it with preseed/url=... \nTo load the preseed, I'm booting a virtual machine from an edubuntu 12.04 LTS DVD, selecting the Install Edubuntu option, pressing F6, and replacing the file=... with auto  url=...\nAccording to the logs on my webserver, the preseed file is getting downloaded by the installer, but then... as far as I can tell, it isn't being used. For example, I get prompted to select a language even though d-i debian-installer/locale string en_US is right there at the top of the preseed. I also tried this \"100% automated\" preseed with the same results. \nSo, apparently something is going wrong between the installer retrieving my preseed and the contents thereof actually getting used, and I'm at a loss for how to troubleshoot this further. \nIf I do a Ctrl+Alt+F2 while the installer starts, I can see a bunch of stuff happening, including several \"Authentication Failed\" messages that may or may not mean anything, but if that output gets saved in any way that lets me do a meaningful examination of it I haven't found it. \nI'm sure I can't be the first person to have this problem, but I didn't find much when I searched for \"preseed troubleshooting\" here or on the Ubuntu forums, so perhaps this would be a good thread to start. Any advice would be greatly appreciated!\n\nA: Found the solution. \nShort version: Live ISOs use a different installer (Ubiquity) than the one on the \"alternate\" ISO (d-i), which ignores many of the standard d-i preseed keywords.\nI'd seen docs that recommended using the alt ISO for custom installers, but nothing explaining why, or saying what to do if you want to customize a live environment from which you can install.\nI'd been thrown off by the fact that installing from a live environment undoes changes to certain config files by default, which led me to conclude that I had less control over the install than I did. It's actually pretty simple, just very, very different from a d-i install.\nThe best documentation I've found for this is actually not on the Internet, it's right on your system if you have the ubiquity package installed. Just do:\nzcat /usr/share/doc/ubiquity/README.gz | less\n\nAnd you're off. \nYou can also find it online in some source code repositories.\n\nA: You can also use debconf-get-selections from the debconf-utils package.\nAfter you've created a preseed file you can test with debconf-set-selections -c preseed-file. It won't actually exit with a failure code unless you really messed something up, but it will give warnings for incomplete answers.\nFrom the Ubuntu example preseed:\n### Preseeding other packages\n# Depending on what software you choose to install, or if things go wrong\n# during the installation process, it's possible that other questions may\n# be asked. You can preseed those too, of course. To get a list of every\n# possible question that could be asked during an install, do an\n# installation, and then run these commands:\n#   debconf-get-selections --installer > file\n#   debconf-get-selections >> file\n\n", "Q: How can I get Firefox to use the KDE style? There are some problems using Firefox in Kubuntu.\n\n\n*\n\n*The menus are ugly and do not use the KDE style.\n\n*The file browser for uploading or opening files is also ugly, and is not the default KDE mini-file-browser.\n\n*The filetype icons are not shown correctly in the Downloads window.\n\n*In the small Downloads window, if I right-click a file and select \"Open Containing Folder\", nothing happens.\n\n\ngtk3-engines-oxygen is installed and \"oxygen-gtk\" is the default GTK style in System Settings > Application Appearance > GTK.\nHere's an example of what it looks like:\n\nSomething tells me I am missing something to integrate Firefox into KDE. What can I do to get Flamewolf - ahem Firefox to integrate nicely with KDE?\n\nA: The first thing when you install KDE Distro is to install gtk3-engines-oxygen.\nsudo apt-get install gtk3-engines-oxygen\n\nThen re-apply gtk settings in System Settings/Application Appearance/GTK\nre-select a GTK2 Theme:  oxygen-gtk\nre-select a GTK3 Theme:  oxygen-gtk\nand click apply...\nThen every program include Firefox should appear correctly.\n\nA: I would add the Blue System's PPA for Firefox integration, as recommended straight from MMartin Gräßlin, KWin's main developer. Link: Firefox KDE integration in Debian Testing\nThe Launchpad PPA page for Blue Shell's Firefox can be found here: firefox-kde\nNote that two packages need to be installed: firefox, and firefox-kde-suport\nThis will lead to a better experience, as shown in the picture from Martin's blog post. The reason this is not installed by default in Kubuntu is that Kubuntu tries to maintain a \"pure\" KDE experience, and therefore rarely alters upstream packages. And since Firefox is not a KDE application, upstream (KDE) would have no interest in supporting Firefox. This is the best answer for how to handle integration with Firefox + KDE in Kubuntu. \nEditorial: If more people file bugs on the matter, maybe it can be addressed. Esp. since Firefox is the default browser now for Kubuntu 14.04, which is a LTS. \n", "Q: how to Check the IP address of the Ethernet interface on the target device? I am new in embeddedlinux ,, also I want guidelines about how to run my first application on target ?\n\nA: I can update this if you give more information but the basic command to check network configuration is ifconfig:\n$ /sbin/ifconfig wlan0\nwlan0     Link encap:Ethernet  HWaddr c4:46:19:5f:dc:f5  \n          inet addr:192.168.0.21  Bcast:192.168.255.255  Mask:255.255.0.0\n          inet6 addr: fe80::c646:19ff:fe5f:dcf5/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:361918 errors:0 dropped:38 overruns:0 frame:0\n          TX packets:259496 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:213916434 (204.0 MiB)  TX bytes:59886866 (57.1 MiB)\n\n", "Q: Clipboard syncronization between wine and X11 I installed Lingoes dictionary in Wine. It has a popup translator that is triggered by clipboard change. When I copy or select an item it must translate the word, but in Wine, when I copy or select a word, Lingoes dictionary remains unresponsive as if nothing has been copied.  I can paste into Lingoes dictionary through right click context menu then it translates.\nHow can I enable auto clipboard sync between Wine and X11?\n\nA: The solution is listed in this thread, namely you need to create registry entry\n[HKEY_CURRENT_USER\\Software\\Wine\\X11 Driver]\n\"UsePrimarySelection\"=\"1\"\n\n(some sources suggest \"UsePrimarySelection\"=\"y\" but that has the same effect).\nFor more information refer this post. In particular if you want to copy text from VNC server (e.g. Linux) to VNC client (e.g. Windows), you need to install additionally autocutsel and add to ~/.vnc/xstartup something like this:\nautocutsel -s PRIMARY -fork\n\nThis is needed because historically VNC protocol uses old and deprecated CUTBUFFER (legendary applications like xterm support it from those ancient times out of the box), while new applications like Wine use CLIPBOARD by default (switched to PRIMARY with registry option above). autocutsel should be used to synchronize all these types of buffers.\n\nA: Thanks to dma_ks answer I found a variant that worked for me.\n\n*\n\n*Open a terminal window Ctrl+Alt+t\n\n*export WINEPREFIX=~/.wine32/ use your defined WINEPREFIX\n\n*(optional) export WINEDEBUG=fixme-all\n\n*(optional) Query if you have it already set\n\n:~$ wine reg query \"HKLM\\Software\\Wine\\X11 Driver\"\nreg: The system was unable to find the specified registry key or value\n:~$ wine reg query \"HKCU\\Software\\Wine\\X11 Driver\"\nreg: The system was unable to find the specified registry key or value\n\n\n\n*ADD the registry key to Current User (HKCU) and Local Machine (HKLM), what I have read in the source code doesn't seem to check HKLM but I could have missed it somewhere, probably doesn't hurt to have them both set.\n:~$ wine reg add \"HKCU\\Software\\Wine\\X11 Driver\" /v UsePrimarySelection /t REG_SZ /d 1\nThe operation completed successfully\n:~$ wine reg add \"HKLM\\Software\\Wine\\X11 Driver\" /v UsePrimarySelection /t REG_SZ /d 1\nThe operation completed successfully\n\nIn the example I have set it to 1 which defines TRUE. Other valid options, as defined in the source files, are\n\n*\n\n*TRUE : y Y t T 1\n\n*FALSE : n N f F 0\n\n\n*You can now close the terminal window and start your wine app\n\nNote1: WINEPREFIX must be set to and coincide with the wineprefix on which your application runs, if each app runs on a different prefix you will probably need to modify each one\nNote2: HKLM and HKCU are registry key shortcuts for HKEY_LOCAL_MACHINE and HKEY_CURRENT_USER respectively\nNote3: You can perform all of this aswell by using the GUI app regedit. You can launch it with wine regedit.\nDetails:\nHaving a look through the source code it appears as wine\n\n*\n\n*First checks the application specific value HKCU\\Software\\Wine\\AppDefaults\\app.exe\\X11 Driver\\UsePrimarySelection and returns its assigned value if it exists\n\n*if it did not find an application specific value it checks the current user \"general\" value HKCU\\Software\\Wine\\X11 Driver\\UsePrimarySelection and returns its assigned value if it exists\n\nRelated:\n\n*\n\n*Bug 31216 in WineHQ\n\n*Bug 47344 in WineHQ\n\n*Bug 50598 in WineHQ\n\n*WineHq Forums discussion on Copy/Paste\n\n*CMDLine Windows Registry Edit Article\n", "Q: Start \"chrome\" with certain command line parameters? unfortunately, we have some intranet sites that \"insecure\" content; thus I really really want to start chrome with \"--allow-running-insecure-content\".\nI \"locked\" chrome to the unity launcher, later on, I edited \n/usr/share/applications/google-chrome.desktop and added this parameter.\nBut when starting chrome using the unity launcher ... it doesn't start in that mode.\nI had a closer look and saw that the .desktop file even says \"--incognito\", and no, chrome does start in normal mode. \nLong story short: why is the desktop file content not relevant when starting chrome using the unity launcher panel?\n\nA: you will probably have a local desktop file of chrome in /home/yourname/.local/share/applications that overrules the global one.\nIf you edit that one, it should work.\n", "Q: Intel wireless 7260 (rev 73) / NUC N2820: OK during install, failed after install I have a new mini-PC Intel NUC N2820 and it has a fairly new wireless controller Intel 7260 (rev 73). \nI downloaded the source, compiled and installed it.  \nBut the problem is that during the installation I connected to wireless (in the beginning), entered the password for the wifi, and it even updated during the installation, but failed after the install was complete.  \n\nA: Is the driver loading? Check from the terminal:\nlsmod | grep iwl\n\nIf not, load it and see if the problem is fixed:\nsudo modprobe iwlwifi\n\nIf that fixes it, let's get iwlwifi to load on boot.\nsudo -i\necho iwlwifi >> /etc/modules\nexit\n\nDo you have the latest firmware?\nls -al /lib/firmware | grep 7260\n\nThe newest is 683236 iwlwifi-7260-7.ucode; the older is smaller,  682892. If you have the older firmware, update it: Intel wireless 7260 driver crashes, how do I work around it?\nFinally, look for clues:\ndmesg | grep iwl\n\n\nA: Had the same problem on a Toshiba Portege R30 (with intel wireless 7260, hence requiring the iwlwifi-7260-7.ucode firmware file).\nSymptoms: Wifi ok during install of Ubuntu 12.4 from USB stick (alongside and already installed Windows 8.1), but afterwards, when using the installed Ubuntu, no Wifi servers were detected, and hence no wireless internet was available.\nlsmod | grep iwl \n\nshowed that the firmware file was not there while:\ndmesg | grep iwl\n\nshowed also an error message that the firmware could not be found.\nI downloaded the required firmware via:\nsudo apt-get install linux-firmare\n\nafter which the required firmware file \"iwlwifi-7260-7.ucode\" was now present in: /lib/firmware\nRebooted and the Wifi worked fine.\n", "Q: Problem with Broadcom BCM4312 on Ubuntu 13.10 Desktop I'm new in Ubuntu and I have a problem with my Wireless card Broadcom BCM 4312...\nI have installed Ubuntu 13.10 Desktop on my netbook with USB, because i haven't got CD/DVD-ROM....Installation looks fine, Ubuntu works fine, too, but I cant connect to the internet by Wi-Fi. I don't know, what should I do with it..:( ... BTW: I can connect to Internet via LAN, but at my home I can't connect by LAN, because we have Internet developer, which banned connecting from other IP....but that's not problem...\nCan anyone help me, please? :)\n...and I connect there some print screens of PCI list, iwconfig and Installing bcmwl-kernel-source (this language is Slovakian, but it says, that you must insert install CD into media/cdrom, but I haven't got CD-ROM -_-...\n\nThank you in advance for every answer :)\ndomosino@domosinoPC:~$ lspci -nn -d : | grep 14e4\n02:00.0 Ethernet controller [0200]: Broadcom Corporation NetLink BCM5906M Fast Ethernet PCI Express [14e4:1713] (rev 02)\n05:00.0 Network controller [0280]: Broadcom Corporation BCM4312 802.11b/g LP-PHY [14e4:4315] (rev 01)\n\nI tried sudo apt-get update and Broadcom driver install in setting, but it no work :/...\n\nA: Use either a wired or bluetooth tethered connection to get wifi temporarily up and running, then run:\n$ sudo apt-get update\n\nThen open 'Software and Updates'  and select the proprietary Broadcom driver.\n", "Q: How to install OneDrive on ubuntu 13.10 x64 I have Ubuntu 13.10 and I don't know how to install OneDrive on ubuntu 13.10 x64.\n\nA: @terdon is right , you can use some alternatives to google drive like :\nDropbox\nDropbox was the first popular cloud storage service, and its client ecosystem is much more mature than Google Drive’s. Dropbox offers clients for every platform, including Linux. Download and install the Dropbox package for your distribution to get started Download .\nIt also offers client for microsoft , mac Link \nSpiderOak\nSpiderOak’s distinguishing feature is its support for encryption. Unlike Google Drive, Dropbox, and Ubuntu One, all files you upload to SpiderOak are encrypted on your computer before they’re uploaded. SpiderOak advertises that they’re stored in an encrypted form where not even SpiderOak’s employees can view them.\nWuala\nWuala, owned by external storage manufacturer LaCie, is another cloud storage service that offers a Linux client in addition to clients for other platforms. Like SpiderOak, Wuala distinguishes itself by offering local encryption of your files – they’re uploaded to and stored on Wuala’s servers in an encrypted form.\nWuala also offers 5 GB of storage for free. Another 3 GB is available through a referral system.\nCopied from Site\n\nA: You can't. One drive is a Microsoft service and, oddly enough, they don't support Linux but only Windows and OSX. Apparently, there is a project to port it to Linux which looks like it's worth trying, but it is still under development.\nIn the meantime, I recommend you use another cloud storage service, there are various that have Linux versions. See, for example, here and here.\n\nA: I run 3 machines, 2 running Windows with only one running Ubuntu 12.04.4 LTS.  Although it is not perfect, I simply make it a routine to log into outlook.com or onedrive.com to access files on the Ubuntu machine.  It is necessary when creating links to sharing files with the public anyway, which I do periodically.  So it's a small effort to log in for me.\n\nA: I've found a solution, but it's in dev. Pls keep to follow this topic: To Install OneDrive on Ubuntu\n\nA: The Microsoft OneDrive website allows access to onedrive content. Documents can be edited with office online. I like this approach best since office online is 100% compatible with paid versions of Office. \n", "Q: Grub menu won't show up after updating Ubuntu, can boot only into Windows I recently installed Ubuntu 13.10 on my Toshiba P55 A5200 and everything was working perfectly. After I updated Ubuntu and installed a few applications GRUB menu won't show up and my computer only boots directly into Windows.\nYour help is appreciated.\n\nA: You can try reinstalling grub from within the live cd. Remember to replace 'sdX' with your desired boot disk/partition.\n$    sudo grub-install /dev/sdX\n$    sudo update-grub\nIf that fails try using boot-repair by following the steps below:\n\n\n*\n\n*Boot into your live cd.\n\n*Download and install boot-repair (instructions here).\n\n*Run from terminal: $ sudo boot-repair\n\n*Select 'fix recommended'\n\n*Reboot.\n\n", "Q: Can Partition images (.img), directly mounted under Linux Can partition images like nandc.img uImage are file system, can this mounted directly in Linux? \nmount command?\nData inside image file can be viewed?\nAppreciated Thanks,\n\nA: mount -o ro,loop,offset=32256 nandc.img nandc\n\n\nA: If it's a raw partition image like dd then mounting is simple, basically\n# mount -t fstype -o loop,ro image.dd /mntpoint\nThe -t fstype may be optional, it'll be vfat or ext3 or whatever the partition is, sometimes mount can figure it out on it's own so try leaving it out first. And ro means read-only.\nIf it's a multi-partition disk image that's a little trickier, then use kpartx and it creates mappings for each partition which you then mount.\nSee http://www.forensicswiki.org/wiki/Mounting_Disk_Images for more info, examples, etc.\nBut, if you're referring to something like a Das U-Boot bootloader embedded system image, that might need tools like dd and the u-boot-tools package's mkimage to extract the filesystem (if there is one) and then mount it. It's rather involved, see this link for info: http://www.isysop.com/unpacking-and-repacking-u-boot-uimage-files/\n", "Q: How much disk space does a clean Ubuntu Studio installation need? I'm considering installing Ubuntu Studio. I can't decide whether to make a clean installation or to install its programs on my existing Ubuntu to save disk space. I'm currently low on free disk space.\nI just want to know About how much disk space would Ubuntu studio take? Just like Ubuntu maybe? Or less?\n\nA: A minimum of 7.6 GB are required for a clean ubuntu-studio-12.04 install:\n\n", "Q: Ubuntu 13.10 failed NVIDIA drivers install (no bumblebee) Thinkpad W520 with Quadro 1000m, optimus disabled.\nReading a little bit about the topic, I thought I was well prepared and did the following:\nsudo apt-get remove --purge nvidia*\nsudo add-apt-repository ppa:xorg-edgers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-331\nsudo apt-get --purge remove bumblebee\nsudo reboot\n\nAlas, despite the bumblebee precaution, next boot takes me to X-mode. I purged the nvidia and after reboot I was back in Unity mode. Is the official driver from nvidia a better idea?\n\nA: The official drivers are generally considered to have better compatibility for your hardware. You should really stick to the ones found in the ubuntu repositories as these have been tested with your distribution. Nvidia 331 is the latest but you can expect to run into bugs. I think 319-updates is the most up to date supported driver for 13.10.\n\nA: After lots of digging, I found that it's hardware specific. W520 + 64 bits linux = trouble. But there is some hope. The version of the driver doesn't seem to matter. What did the trick for me in the end? Adding those 2 elements to the boot configuration (I use Grub Customizer for this).\nOn the line that starts with linux /boot..., adding acpi_backlight=vendor made my system boot normally again (it would most times hang otherwise).\nOn the same line, adding nox2apic made it possible to adjust brightness without freezing (when I say troubles, I mean troubles.)\nSee here for more details.\nGood luck and patience to other W520 owners.\n", "Q: problem with installing ubuntu along with windows 7 while installing from an  usb,the process is continuing till i get an option of \"Install ubuntu inside windows\".When i click ok the process get stuck and windows is getting started.how can i resolve this?\n\nA: Do you want to install alongside windows or whave ubuntu contained within? I don't believe wubi is supported any longer for 13.10 and up, however you may get it to work with some tinkering.\nYou can try:\n\n\n*\n\n*Installing ubuntu alongside windows to a seperate partition.\n\n*Running ubuntu from a virtual drive within windows using software such as virtualbox.\n\n\nGood luck.\n", "Q: question about Ubuntu for Smart Phones I have the Samsung Galaxy S4 Mini, if i use Ubuntu on my phone, will I lose features such as SBeam? and will it be compatible with US Cellular Network?\n\nA: Check out the wiki for the latest touch FAQ here\n", "Q: Has anyone successfully installed ubuntu on a Lenovo Y410P I see lots of posts on here about folks having major issues with installing Ubuntu on a Lenovo Y410P. Has anyone successfully installed Ubuntu with no major issues?\n\nA: I have! I decided to go ahead and do it today before waiting on an answer to this question.\nI used the top answer to this post: Unable to install Ubuntu on Lenovo Y500. \nIt's for a Y500 but it applies to the Y410P. \n\nA: Yes. I succeeded in installing 13.10, there were some issues with dual-booting with Windows 8 but grub was able to fix it once I can boot into Ubuntu.\nI am going to upgrade my 13.10 to 14.04 now. Hope it works out for me!\n\nA: I've been successful with Kubuntu 14.04.4 LTS installation in dual boot configuration as of 29 Feb 2016 with nothing more than a 2 GB USB stick that was turned into bootable Kubuntu Live/Install medium using 'UNetbootin'\n", "Q: Is it possible to install two kernels and choose one on startup? I want to install Ubuntu Studio and I'm aware that it uses a different Linux kernel than normal Ubuntu. Is it possible to install both kernels and chose which one to use on every startup? And if yes, how do I do that?\nI'm not very experienced. Also tell me if there are other more differences between Ubuntu and Ubuntu Studio other than the Linux kernel and the preinstalled software they have. Thanks in advance :)\n\nA: You can install both kernels :Generic Ubuntu kernel linux-generic and Low Latency Ubuntu Studio kernel linux-lowlatency. On boot press Shift, to get Grub boot menu, then choose advanced.\n\n\n*\n\n*If you have installed Ubuntu Studio, install generic kernel:\nsudo apt-get install linux-generic\n\n\n*If you have installed Ubuntu Desktop, then convert it to Ubuntu Studio if you like (skip it if you don't want, you can install just the kernel)\nsudo apt-get install ubuntustudio-*\n\nInstall low latency kernal:\nsudo apt-get install linux-lowlatency\n\n\nA: You can safely install both Ubuntu and Ubuntu studio on the same system but I would not use Ubuntu kernels with Ubuntu studio. \nEspecially if you're interested in video/audio editing where those studio kernels have specific timings adjustments to fit application needs. \n", "Q: Accessibility bus warning when opening files in Eclipse from command line (Ubuntu 13.10) Similar to closed issue Gnome Menu Broken?\nWhen opening a file from the command line for edits in Eclipse , I get this warning:\n** (eclipse:nnnn): WARNING **: Couldn't register with accessibility bus: \nDid not receive a reply. Possible causes include: the remote application \ndid not send a reply, the message bus security policy blocked the reply, \nthe reply timeout expired, or the network connection was broken.\n\nThe 4-digit number at (eclipse:nnnn) changes each time I issue an 'eclipse some/file.ext' command. The file opens but the warning is an annoyance that shouldn't be happening, it may be indicative of some other problem. Updated Ubuntu 13.10 64-bit, updated Eclipse Luna.\n\nA: Summary of workaround: Add \"export NO_AT_BRIDGE=1\" to your .bashrc/.bash_profile/etc.\nDetails: I have this annoying issue too. Obviously, it's a bug that needs to be fixed, but as an end user, I found a workaround at a Fedora bug thread: https://bugzilla.redhat.com/show_bug.cgi?id=1056820. The workaround is to add \"export NO_AT_BRIDGE=1\" to my environment (via .bashrc/.bash_profile/etc, or similar equivalent command if you're not using bash). Hope that helps.\n", "Q: Why ping -f command needs sudo privileges? When i tried to use ping -f ipaddress command in Ubuntu for testing my system , It fails with a message : \n ping: cannot flood; minimal interval, allowed for user, is 200ms\n\nWhen i type man ping and see -f option , it state \nOnly the super-user may use this option with zero interval.\n\nWhy does it need that privilege   ?\n\nA: from man ping \n\n-f\n  Flood ping. For  every  ECHO_REQUEST  sent  a  period  ``.''\n  is\n                printed,  while  for  ever  ECHO_REPLY  received  a backspace is\n                printed.  This provides a rapid display of how many packets  are\n                being  dropped.   If  interval is not given, it sets interval to\n                zero and outputs packets as fast as they come back or  one  hun‐\n                dred  times  per second, whichever is more.  Only the super-user\n                may use this option with zero interval.\n\nIt's obvious clear that the it's forbidden for lowering the network traffic and thus get lowering the threat of DDOS due to large replies for every arrived packet.\n\nA: It is because only super user can specify interval less than 0.2 seconds. And -f is like very very little interval.\nP.S. Since commit https://github.com/iputils/iputils/commit/0ccdbb9937a90f4c765fe9ab94d1441dd8680f45 it is now 0.002 seconds. So yeah, that is just a fake protection.\n\nA: There is no point in comparing it with the Windows ping, because they basically came from  two different origins.\nLong ago when nets were congested easily, this was used to prevent users from casually running the command and making the net useless. You can see the source code of original traceroute command, which says something like\n\nThis command must be run by root or be setuid (I suggest you don't make it setuid -- casual use could result in a lot of unnecessary traffic on our poor, congested nets).\n\nSo even till now, this is more like a reminder or preventive measure, than a security feature\nQuoting the commit message of https://github.com/iputils/iputils/commit/0ccdbb9937a90f4c765fe9ab94d1441dd8680f45\n\nNOTE: we keep minimal limit just to make sure people don't\naccidentally DoS themselves. It's not that much about security\n(there are other tools to allow DoS if user wants).\n\n", "Q: missing squid in /etc/init.d I installed squid v3 on ubuntu 13.  Running squid3 -v responds with version 3.3.8 (yet I cannot find any squid script in /etc/init.d).  I am able to run \nservice squid3 restart\n\n(process shows as running).  Any insight as to what I might have configured incorrectly?  I noticed the missing squid after I made a change to the squid.conf file.\nThanks in advance.\n\nI realized that squid was generating the squid.conf file in /etc/init & not /etc/init.d - I had installed squid via sudo apt-get install squid.\n\nA: Your Ubuntu release uses already Upstart for starting services.  That's why you can't find the init script for squid anymore in /etc/init.d/.  Instead, you have to start squid via\nsudo service squid3 start\n\nBTW, you cannot use su here to become root and then call service squid3 start. For more information see Ubuntu bug #1303769.\nThe script /etc/init/squid3.conf is the init script used by upstart and nothing we should normally edit.\nInstead, use /etc/squid3/squid.conf for setting your configuration options.\n\nA: Service startup file for squid is /etc/init/squid.conf \n this services run as upstart which is very good to restart them use this \ncommands \nTo stop\n\nsudo stop squid3\n\nTo start\n\nsudo start squid3\n\nTo check status\n\ninitctl list\n\nmain advantage here is system boots faster and also if some kills the pid of squid3 kernel automatically restarts squid3 services in fraction of seconds with new pid.\nfor more information about upstart services\nBelow you will see in the /var/log/syslog messages \nApr 22 12:00:48 proxy02 kernel: [5864996.503368] init: squid3 main process (318) killed by KILL signal\nApr 22 12:00:48 proxy02 kernel: [5864996.503379] init: squid3 main process ended, respawning\n\nA: Squid Installation generates the squid.conf file in /etc/init & not /etc/init.d on ubuntu - I had installed squid via sudo apt-get install squid.  \n\nA: Try looking in /etc/rc.d/init.d/\nYour .conf file should be located in /etc/squid/squid.conf \n", "Q: Getting black screen in 13.10 i recently install Nvidia  drivers through terminal using the command \"sudo apt-get install Nvidia-323.86 after complete installation i upgrade packages using upgrade command.\nafter that i shutdown it. later after enter password only black screen shown. by enter terminal shortcut key i can open my terminal.. from terminal i also open some software's like vlc. i tried my things like rm some config file and auto remove and and install upgrade and update install nvidia. remove -- purgge nvidia.*.  but  did't solve this problem.. plz give me perfect solution..  thanks in advance \n\nA: Try removing bumblebee:\nsudo apt-get remove --purge bumblebee\n\nIf that doesnt work then try including nomodeset as a boot option in grub. From the main grub bootloader press 'e' to edit the boot parameters. Find where it reads:\nquiet splash\n\nEdit to look like this:\nquiet splash nomodeset\n\nHopefully this will solve your boot issue.\n", "Q: What is a easy way to view texi files? I am reading some files for a library I plan on using and the files are of extension '.texi' and although I can open the files in gedit, all the syntax and markups make it difficult to read. Also, I cant use the embedded links within the document. Is there an go-to program for reading .texi files? I am using Ubuntu 13.10 btw. Thx!\n\nA: You can use texiinfo : \nTexinfo uses a single source file to produce output in a number of formats, both online and printed (dvi, html, info, pdf, xml, etc.). This means that instead of writing different documents for online information and another for a printed manual, you need write only one document. And when the work is revised, you need revise only that one document. The Texinfo system is well-integrated with GNU Emacs. \nYou can downlod it from here, eg:\ncd\nwget http://ftp.gnu.org/gnu/texinfo/texinfo-6.0.tar.xz\ntar xf texinfo-6.0.tar.xz\n\nCompile and install:\ncd texiinfo-6.0\n./configure\nmake\nsudo make install\n\nAfter installation use man texiinfo and learn how to convert it .\nMore info Here\n\nA: makeinfo from the texinfo package\nsudo apt install texinfo\nmakeinfo --html --no-split -o a.html a.texi\nfirefox a.html\n\nYou can also convert to many other formats if you prefer:\n\n*\n\n*makeinfo a.texi.\nGenerates an a.info file which can be opened with:\ninfo -f a.info\n\nThis is the most \"native\" local GNU documentation format.\n\n\n*makeinfo --pdf a.info\nRequires LaTeX.\ntexi2html appears to have been deprecated in 2011: http://www.nongnu.org/texi2html/\n\ndevelopment of Texi2HTML and of the Texi2HTML based makeinfo implementation stopped in 2011.\n\nTested on Ubuntu 20.04.\nBinutils docs\nHere is how you can build the Binutils docs like GDB and GAS, which are in texinfo format, to a single HTML page nirvana: https://unix.stackexchange.com/questions/477303/how-to-build-the-gdb-documentation-from-source/477309#477309\n\nA: Install texi2html to convert Texinfo files to HTML:\nsudo apt-get install texi2html\n\nMan page of texi2html:\n\nSYNOPSIS\n   texi2html [options] file\n\nDESCRIPTION\n   Texi2html  converts  the  given Texinfo file to a set of HTML files. It\n   tries to handle most of the  Texinfo  commands.  It  creates  hypertext\n   links for cross-references, footnotes...\n\n   Texi2html  may furthermore use latex2html to generate HTML (code and/or\n   images) for @math and @iftex tags (see the --l2h option).\n\n   Texi2html creates several files depending on the contents of  the  Tex‐\n   info file and on the chosen options (see FILES).\n\n   The  HTML  files created by texi2html are in general closer to TeX than\n   to Info. Using init files (see the --init-file option), other styles or\n   output formats may be selected.\n\n[...]\n\n", "Q: What's the equivalent of rpm -qc PACKAGE_NAME in Ubuntu? # rpm -qc PACKAGE_NAME  \n\nlists the configuration files contained in that RPM package, in a Red Hat-like OS. What's it's equivalent command in an Ubuntu/Debian-based OS?\n\nA: Edit:\nYou can use the following command: \ndpkg-query --show -f '${Conffile}\\n' package.rpm\n\nAlternatively you can convert the .rpm to a .deb file. You will need to run this command to install alien and other necessary packages:\nsudo apt-get install alien dpkg-dev debhelper build-essential\n\nTo convert a package from rpm to debian format, use:\nsudo alien packagename.rpm\n\nOnce in .deb format you should be able to open/extract with archive utility. If you want to install the newly converted .deb to your system run:\nsudo dpkg -i packagename.deb\n\n\nA: If you want to use the output for a script and need this to output just the configuration files, I'd try dpkg-query like in the answer from bleeves.\nIf you don't mind if there's extra information however, dpkg --status PACKAGE_NAME is a simpler choice. It will print pretty much all the information there is about an installed package. (The exception is the complete list of installed files for that package. But that is available via dpkg --listfiles PACKAGE_NAME.) So it's an equivalent to most rpm -q commands for an installed package, at least when meant for human consumption. In this case, you're looking for the conffiles section.\nExample output:\n$ dpkg --status base-files\nPackage: base-files\nEssential: yes\nStatus: install ok installed\nPriority: required\nSection: admin\nInstalled-Size: 433\nMaintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\nArchitecture: i386\nMulti-Arch: foreign\nVersion: 7.2ubuntu5.1\nReplaces: base, dpkg (<= 1.15.0), miscutils\nProvides: base\nPre-Depends: awk\nBreaks: initscripts (<< 2.88dsf-13.3), sendfile (<< 2.1b.20080616-5.2~)\nConffiles:\n /etc/debian_version 142012ca081ab0981cdcc1ac6db77c34\n /etc/dpkg/origins/debian 731423fa8ba067262f8ef37882d1e742\n /etc/dpkg/origins/ubuntu ea35901c45553c3451f60476be94d2d8\n /etc/host.conf 89408008f2585c957c031716600d5a80\n /etc/issue 46f9e5ee59e4c34c7e0fa6038d081966\n /etc/issue.net 44eb23df696ad5ef26a2f3836671c14a\n /etc/legal 0110925f6e068836ef2e09356e3651d9\n /etc/lsb-release 30c373a51f59c87d55f6e03c946d2962\n /etc/os-release 3ce55484c383d7de3862bf2f2f2f6490\n /etc/update-motd.d/00-header 4a1e6eed7a59f200b4267085721750a3\n /etc/update-motd.d/10-help-text 5064fb57493325202dded183ab0c4ebd\nDescription: Debian base system miscellaneous files\n This package contains the basic filesystem hierarchy of a Debian system, and\n several important miscellaneous files, such as /etc/debian_version,\n /etc/host.conf, /etc/issue, /etc/motd, /etc/profile, and others,\n and the text of several common licenses in use on Debian systems.\nOriginal-Maintainer: Santiago Vila <sanvila@debian.org>\n\n", "Q: Unable to change brightness using keys after recent 13.10 update I have been using Ubuntu 13.10 for months now without too many hassles. But a couple of days back, my system offered to install this major update and of the many things that have gone wrong, the most prominent one is I am unable to change the brightness of my laptop (Dell Inspiron 15R) using my brightness hotkeys and as far as my knowledge goes, you can't do this graphically using Ubuntu's settings (please correct me if I am mistaken).\nHow can I rectify this? Please help my poor eyes!\n\nA: Are you running nvidia drivers per chance? This seems to be a common issue. Try installing the xbacklight package as a workaround. It won't fix your function keys but at least you can look for an answer without melting your retina's.\n$ Sudo apt-get install xbacklight\n\nYou can then adjust the settings from a terminal using commands found here.\nTo increase brightness by 20%:\n$ sudo xbacklight -inc 20\n\nAlternatively to decrease:\n$ sudo xbacklight -dec 20\n\nOr use the -set parameter to define the exact level:\n$ sudo xbacklight -set 50\n\nIf this works for you may want to add a new startup entry so it runs on boot. Open \"Startup Applications\" and add the following details:\nName: Brightness\nCommand: xbacklight -set 60\nClick add and you are done! Hope this helps.\n\nA: I have Dell Inspiron 15 and in a fresh ubuntu installation I always do the following to fix the brightness \nEdit the grub configuration file by running in terminal : \ngksu gedit /etc/default/grub\n\nChange this line:\nGRUB_CMDLINE_LINUX=\"\"\nTo:\nGRUB_CMDLINE_LINUX=\"acpi_osi=\\\"!Windows 2012\\\"\"\n\nSave the file And Update Grub:\nsudo update-grub\n\nReboot and test.\n", "Q: Rootkit on port 60001 !? Tiger says so - how do I verify? My system is an up-to-date Ubuntu 13.10\nI've installed Tiger and I'm getting this\n# Running chkrootkit (/usr/sbin/chkrootkit) to perform further checks...\nOLD: --ALERT-- [rootkit005a] Chkrootkit has found a file which seems to be infected because of a rootkit\nOLD: --ALERT-- [rootkit009a] A rootkit seems to be installed in the system\nOLD: INFECTED (PORTS: 60001)\n\nWhat?!\nI've also tried rkhunter: doesn't really find anything directly, here's the assorted warnings\n/usr/bin/unhide.rb                                       [ Warning ]\nChecking for passwd file changes                         [ Warning ]\nChecking for group file changes                          [ Warning ]\nChecking /dev for suspicious file types                  [ Warning ]\nChecking for hidden files and directories                [ Warning ]\n\nThere's also the suckit thing (described in another thread here http://ubuntuforums.org/showthread.php?t=1680428), but that's been ruled out as a bug.\nLooking at\nnetstat -ltnp\n\nThere's nothing on this port there, well not now anyway.\nHow do I verify this? How do I go about it??\n\nA: Whenever you want to see what process is holding a port open, use the lsof command. For a tcp port use lsof -i tcp:80 and for a udp port use lsof -i udp:53. The info will provide all the info you require as to process name, pid, and ownership. For example:\ncyberfarer@Quadraphenia:~$ sudo lsof -i tcp:80\n[sudo] password for cyberfarer: \nCOMMAND  PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\napache2 2723     root    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\napache2 2751 www-data    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\napache2 2752 www-data    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\napache2 2753 www-data    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\napache2 2754 www-data    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\napache2 2755 www-data    3u  IPv4  16241      0t0  TCP *:http (LISTEN)\n\nFast, easy, and without needless scrolling and deciphering.\n", "Q: Used dd to backup a disk, now want to look at the filesystem I dd copied /dev/sdd\nsudo dd if=/dev/sdd of=backup.img\nsudo fdisk backup.img\nCommand (m for help): p\n\nDisk backup.img: 143.3 GB, 143274860544 bytes\n61 heads, 35 sectors/track, 131069 cylinders, total 279833712 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x0003c0d1\n\n\n\n      Device Boot      Start         End      Blocks   Id  System\n    backup.img1            2048   286747999   143372976    5  Extended\n    backup.img5            4096   286746623   143371264   83  Linux\n\nCommand (m for help):q\n\nsudo mount backup.img /mnt/disk3\ndoesn't work.\nNot sure what to do now.\nAny suggestions?\n\nTime to start over:\nSounds like I should run dd on the partition, not the entire disk.\nHere's the output of fdisk:\nsreeve@cebuild:~$ sudo fdisk /dev/sdd\n\nCommand (m for help): p\n\nDisk /dev/sdd: 146.8 GB, 146814976000 bytes\n\n61 heads, 35 sectors/track, 134308 cylinders, total 286748000 sectors\n\nUnits = sectors of 1 * 512 = 512 bytes\n\nSector size (logical/physical): 512 bytes / 512 bytes\n\nI/O size (minimum/optimal): 512 bytes / 512 bytes\n\nDisk identifier: 0x0003c0d1\n\n   Device Boot      Start         End      Blocks   Id  System\n\n/dev/sdd1            2048   286747999   143372976    5  Extended\n\n/dev/sdd5            4096   286746623   143371264   83  Linux\n\nCommand (m for help):\n\nSo should I do this:\nsudo dd if=/dev/sdd1 of=/home/sreeve/backup.img\n\nor this:\nsudo dd if=/dev/sdd5 of=/home/sreeve/backup.img\n\n\nA: You need the loop option to mount:\nsudo mount -o loop backup.img /mnt/disk3\n\nI am not sure how this will work on an image of an entire disk as opposed to a single partition, I have never tried it. The above works to mount partition images though. \n\nA: Download AcetoneISO from the ubuntu software center. This has the ability to mount and convert .img files.\n", "Q: Newbie problem: Black screen from live cd; old PC Equipment: 12 year old Sony VAIO PCV-RX741 desktop; AMD Athlon @ 1.53 GHz; 1 GB RAM; AwardBIOS 1003VX. Used daily for the last 5 years as my principle business machine.\nBackground: Have used XP on this machine since new, very few problems to date. Tried DSL years ago mainly because it was the only distro I could download by dial up. About 4 years ago I installed a dual boot setup w/OpenSUSE, no installation problems, I just didn't like the distro, could not see a benefit for me over XP. I later wiped it out with the only necessary re-installation of windows on this machine.\nObjective: I am trying to try or install Lubuntu 13.10 from a live cd. Yesterday I was trying with Xubuntu 13.10 with similar results. Also tried Peppermint 4 from a USB with worse results.\nProblem: During boot, blue \"Lubuntu\" screen is present for an extended period of time, then is replaced by a black \"Lubuntu\" screen for a shorter time. Screen then goes completely black, followed by the mouse pointer appearing (and functioning [USB mouse]).\nThen screen goes black again, and the following message appears: \"Starting mount network filesystems [OK] Stopping mount network filesystems [OK]\" Once the message disappears the screen begins alternating between a non working mouse pointer, a black screen, and a rapid spasm of 2 rows of forward slashes.\nI have tried all of the F6 boot options in various combinations to no avail. This live CD functions flawlessly on my 5 year old Sony Windows 7 laptop, as did the Xubuntu live CD and various and sundry Unetbootin USB distros I have tried with the exception of Manjaro.\nThank you for your time.\n\nA: Try including nomodeset as a boot option in grub. From the main grub bootloader press 'e' to edit the boot parameters. Find where it reads:\n  quiet splash\n\nEdit to look like this:\n   quiet splash nomodeset\n\nIf that does not work try without the 'quiet splash' and see if there are any errors displayed on the screen, then post back here.\n", "Q: How do I change the font colours for grub? I managed to change the background on the boot screen and now I need to set the font colours to something I can read. I've been lurking around the Ubuntu Forums and the Ask site and I've also tried with the grub-customizer with no luck. All I need is the right code for grub file.\nHere's a copy of my current grub:\nGRUB_DEFAULT=\"saved\"\nGRUB_SAVEDEFAULT=\"true\"\n#GRUB_HIDDEN_TIMEOUT=\"0\"\nGRUB_HIDDEN_TIMEOUT_QUIET=\"true\"\nGRUB_TIMEOUT=\"10\"\nGRUB_DISTRIBUTOR=\"`lsb_release -i -s 2> /dev/null || echo Debian`\"\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nGRUB_CMDLINE_LINUX=\"\"\nGRUB_BACKGROUND=\"/home/autumn/Pictures/grub/suckng.jpg\"\n\nmenu_color_normal=black/black\nmenu_color_highlight=yellow/dark-gray\ncolor_normal=black/black\ncolor_higlight=black/black\n\n\nA: I had this problem in ubuntu 13.10 with grub-customizer.  In my case it was caused by reverting to the default debian theme, which made the image appear in the background, but all text was grey.  I solved it by editing the 05_debian_theme file found in /etc/grub.d/\n$    sudo gedit /etc/grub.d/05_debian_theme\nFind where it reads:\nif [ -z \"${2}\" ] && [ -z \"${3}\" ]; then\n        echo \"  true\"\nfi\n\nChange to:\nif [ -z \"${2}\" ] && [ -z \"${3}\" ]; then\n    echo \"  true\"\n    echo \"    set color_highlight=light-blue/black\"\n    echo \"    set color_normal=white/black\"\nfi\n\nReplace the colours with that of your choosing, remembering grub treats 'black' as transparent.  Then run the following and reboot:\nsudo update-grub\n\nIf that does not solve it for you go go back and edit the theme as mentioned above. You will see a section:\nset_default_theme(){\ncase $GRUB_DISTRIBUTOR in\n    Ubuntu|Kubuntu)\n        # Set a monochromatic theme for Ubuntu.\n        echo \"${1}set menu_color_normal=white/black\"\n        echo \"${1}set menu_color_highlight=light-blue/black\"\n\n        if [ -e /lib/plymouth/themes/default.grub ]; then\n            sed \"s/^/${1}/\" /lib/plymouth/themes/default.grub\n        fi\n        ;;\n    *)\n        # Set the traditional Debian blue theme.\n        echo \"${1}set menu_color_normal=white/black\"\n        echo \"${1}set menu_color_highlight=light-blue/black\"\n        ;;\n\nChange the colours to what you require then update-grub, reboot.\nGood luck, I hope this helps.\n\nA: Solution: /etc/grub.d/06_local_colors\nThe problem is that update-grub recreates your grub.cfg. The usual way to configure update-grub in Ubuntu is to edit /etc/default/grub, but unfortunately text colors are not yet supported.\nWe will use a lower level method: create a script in /etc/grub.d/ which will output the lines we want in the grub.cfg files. We use the name 06_local_colors so that it will run after 05_debian_theme and override the color choices.\nThere are three easy steps.\nStep 1. sudo editor /etc/grub.d/06_local_colors\nPaste in this script:\n#!/bin/sh\n# /etc/grub.d/06_local_colors\n# Override foreground/background colors with local admin's choices.  \n#\n# Note: be sure to chmod +x this file or it will not be used.\n# After editing this file, run update-grub.\nset -e\necho \"Overriding foreground/background text colors ($0)\" >&2\n\necho \"${1}set color_normal=light-gray/black\"\necho \"${1}set color_highlight=black/light-gray\"\n\n# Set these if you'd like the menu options to be different than other text\necho \"${1}set menu_color_normal=light-gray/black\"\necho \"${1}set menu_color_highlight=black/light-gray\"\n\n# NOTES\n\n# Colors: red, green, blue, cyan, magenta, brown, light-gray, black\n#\n# Foreground has additional colors available:\n#\n#         light-red, light-green, light-blue\n#         light-cyan, light-magenta, yellow, white, dark-gray\n\n# Text background of \"black\" is transparent when a background image exists.\n# (GRUB_BACKGROUND in /etc/default/grub).\n\n# To change the font face and size, set GRUB_FONT in /etc/default/grub \n# to point to a .pf2 file crated by grub-mkfont.\n# \n# sudo grub-mkfont --output=/boot/grub/fonts/DejaVuSansMono24.pf2 --size=24 \\\n#           /usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf \n\nThe script contains abundant notes so it should be quite simple to tweak.\nStep 2: sudo chmod +x /etc/grub.d/06_local_colors\nThe file needs to be executable or it will not be used.\nStep 3: sudo update-grub\nAfter update completes successfully, simply reboot to see what your new colors look like in GRUB.\n\nFurther reading\n\n*\n\n*GNU GRUB Manual (PDF)\n\n*\n\n*color_normal (PDF)\n, color_highlight (PDF)\n\n\n*menu_color_normal (PDF)\n, menu_color_highlight (PDF)\n\n\n*GRUB Configuration (PDF)\n\n\n\n\n*Man update-grub\nSide note: Why not 05_debian_themes?\nWhile it is possible to edit the system file 05_debian_theme, as described in other answers, it is a bad idea. That file can may need to be overwritten when the system is updated.\n", "Q: How to resolve \"ERROR machine is already provisioned\" in manual provision set up? I set up a manually provisioned environment successfully (in local network among x3 12.04 ubuntu servers.) However adding the second machine failed twice. After the third try (installed missing dependency) their remained x2 'pending' machines. \nI tried destroy-machines on those, than used destroy-environment to try and start over. Now when I add machine I get:\nERROR machine is already provisioned. \nI have tried uninstalling/re-installing along with removing all juju files in ~/.juju.\nAny ideas on how to start over or remove the provisioning?\nThanks!\n\nA: Per documentation on https://jujucharms.com/docs/stable/clouds-manual:\nNote: If you have an existing configuration, you can use juju generate-config --show to output the new config file, then copy and paste relevant areas in a text editor etc.\nOn each failing node: \nsudo rm -rf /etc/init/juju*\nsudo rm -rf /var/lib/juju\n\nNow kill all Juju processes and run\nsudo apt-get remove juju-mongodb landscape-common\nsudo rm -rf /var/lib/juju\nsudo rm -rf /usr/lib/juju\nsudo rm /tmp/pprof.jujud.* /usr/bin/juju-run\nsudo rm -r /etc/juju\n\nThis will allow a normal add-machine.\n\nA: Ubuntu 18.04 with juju 2.6.8\nClean up the machine-node.\nsudo rm -rf /var/lib/juju\nsudo rm -rf /lib/systemd/system/juju*\nsudo rm -rf /run/systemd/units/invocation:juju*\nsudo rm -rf /etc/systemd/system/juju*\n\n\nA: Also, for newer systemd based distros:  rm /etc/systemd/system/jujud*\n", "Q: How to install rt73usb in Ubuntu Server 12.04.4? How can I install rt73 on Ubuntu Server 12.04.4 LTS?\nI have installed Ubuntu Server on an old Laptop (Advent 7109B) and wireless is not working by default due to missing drivers.\nI found online I needed rt73.\nlsmod | grep rt gives me this:\nrt73usb                31360  0 \nrt2x00usb              20161  1 rt73usb\nrt2x00lib              53673  2 rt73usb,rt2x00usb\nmac80211              534884  2 rt2x00usb,rt2x00lib\ncfg80211              416271  2 rt2x00lib,mac80211\nparport                40930  1 lp\ncrc_itu_t              12627  2 rt73usb,firewire_core\n\nI have SSH access to it by having the laptop plugging in via ehternet.\nAny ideas how I can get Wifi working?\nEDIT: Here are results from terdon's comment:\niwconfig:\nwlan0     IEEE 802.11bg  ESSID:off/any  \n          Mode:Managed  Access Point: Not-Associated   Tx-Power=0 dBm   \n          Retry  long limit:7   RTS thr:off   Fragment thr:off\n          Power Management:on\n\nlo        no wireless extensions.\n\neth0      no wireless extensions.\n\n/sbin/iwlist wlan0 scan:\nwlan0     Failed to read scan data : Network is down\n\nlspci | grep Net returns nothing.\n\nA: In a server, without a desktop environment and therefor without Network Manager, wireless is not going to connect to any old possibly insecure network. You must specify the network you want and supply a password. I suggest you amend your /etc/network/interfaces file so as to add the wireless details at the end:\n#auto eth0\niface eth0 dhcp <--or however it reads now\n#Do NOT comment out eth0 until wireless is working reliably and double-checked\n\nauto wlan0\niface wlan0 inet static\naddress 192.168.1.150\nnetmask 255.255.255.0\ngateway 192.168.1.1\ndns-nameservers 8.8.8.8 192.168.1.1\nwpa-ssid <your_network>\nwpa-psk <your_password>\n\nI suggest a static IP for a server so you can easily ssh and ftp into it. Of course, select an address outside the range used by the DHCP server in the router, switch, or access point. Substitute your details here.\nGet the system to re-read and use the changes:\nsudo ifdown wlan0 && sudo ifup -v wlan0\n\nCheck to see if you connected:\nping -c3 www.google.com\n\n", "Q: After partitioning space to my ubuntu partition, nothing updates Right now, I have Ubuntu 13.04, and using sudo-apt-get dist-upgrade does not get me the 13.10 update. \nWhenever I sudo-apt-update or upgrade lately, I get:\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. \nIt has been for a couple of months (I'm not actually sure, but it has been a long time), and I want to fix this somehow.\nEdit: from sudo cat /etc/apt/sources.list\nEdit 2: from sudo vim /etc/apt/sources.list to comment out the last two lines\nEdit 3: I found out the problem on my own.\n# deb cdrom:[Ubuntu 12.10 _Quantal Quetzal_ - Release amd64 (20121017.5)]/ quantal main restricted\n\n# See http://help.ubuntu.com/community/UpgradeNotes for how to upgrade to\n# newer versions of the distribution.\ndeb http://us.archive.ubuntu.com/ubuntu/ raring main multiverse restricted\n\n## Major bug fix updates produced after the final release of the\n## distribution.\ndeb http://us.archive.ubuntu.com/ubuntu/ raring-updates main multiverse restricted\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu\n## team. Also, please note that software in universe WILL NOT receive any\n## review or updates from the Ubuntu security team.\ndeb http://us.archive.ubuntu.com/ubuntu/ raring universe\ndeb http://us.archive.ubuntu.com/ubuntu/ raring-updates universe\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu \n## team, and may not be under a free licence. Please satisfy yourself as to \n## your rights to use the software. Also, please note that software in \n## multiverse WILL NOT receive any review or updates from the Ubuntu\n## security team.\n\n## N.B. software from this repository may not have been tested as\n## extensively as that contained in the main release, although it includes\n## newer versions of some applications which may provide useful features.\n## Also, please note that software in backports WILL NOT receive any review\n## or updates from the Ubuntu security team.\ndeb http://us.archive.ubuntu.com/ubuntu/ raring-backports main universe multiverse restricted\n\ndeb http://security.ubuntu.com/ubuntu raring-security main multiverse restricted\ndeb http://security.ubuntu.com/ubuntu raring-security universe\n\n## Uncomment the following two lines to add software from Canonical's\n## 'partner' repository.\n## This software is not part of Ubuntu, but is offered by Canonical and the\n## respective vendors as a service to Ubuntu users.\ndeb http://archive.canonical.com/ubuntu raring partner\n# deb-src http://archive.canonical.com/ubuntu quantal partner\n\n## This software is not part of Ubuntu, but is offered by third-party\n## developers who want to ship their latest software.\ndeb http://extras.ubuntu.com/ubuntu raring main\ndeb-src http://extras.ubuntu.com/ubuntu raring main\n## deb http://www.duinsoft.nl/pkg debs all\n## deb http://ppa.launchpad.net/person/ppa/ubuntu karmic main\n\n\nA: Contrary to what it seems, sudo apt-get dist-upgrade does not upgrade to the new version if you do not changes the sources before. \nThe correct command is sudo update-manager or sudo update-manager -d.\nMore info in http://www.unixmen.com/upgrade-ubuntu-13-04-raring-ubuntu-13-10-saucy-salamander/ \n\nA: apt-get dist-upgrade does not perform a distribution upgrade to the next release as it sounds. \nFrom the man page : \n\ndist-upgrade in addition to performing the function of upgrade,also intelligently handles changing\n  dependencies with new versions of packages; apt-get has a \"smart\" conflict resolution >system, and it will attempt to upgrade the most important packages at the expense of less >important ones if necessary.\n\nIf you want to upgrade to the next available release of Ubuntu, you can do this by using the do-release-upgrade at the command line.\nThis command will automatically generate the required /etc/apt/sources.list file for the next release.\n\nA: Open the software and updates application and tab to updates. Ensure you have option 'Notify me of a new ubuntu version' set to 'For any new version'. It may be that you have updates set to only download LTS versions, which is the default option.\n\nA: I have found the answer to my question. I ran the command of sudo apt-get remove xserver-xorg-video-* which means that there are other third-party software I did not remove for the upgrade of 13.04 to 13.10.\nsource: http://ubuntuforums.org/showthread.php?t=2181779\n", "Q: Flash player is not working probably Am new at ubuntu. I downloaded flash plugin for my ubuntu, and install it from the terminal but it does not play the movie on YouTube it seams installed, and there is sound and the first picture is there. and when I installed the libflashplayer.so, and in terminal i type:\n          # rah -Uvh libflashplayer.so. \n\nI tried several times and it seems installed but those are  not working probably. \nCan some one please help me?\n\nA: Try this\nsudo apt-get install flashplugin-installer\n", "Q: How to make custom refresh rate stay saved? I'm testing out 14.04 on a partition to see if I want to use it as my main desktop for when it's fully released, but I've encountered some problems.\nI have a 144Hz monitor, so in the the Nvidia X Server Settings window I set the refresh rate to 144Hz and it works just fine. However, when I restart my computer those settings revert back to \"auto\" and I have to reset the refresh rate back to 144Hz each time I log into Ubuntu. How do I make the Nvidia settings stay set to 144Hz?\nThe refresh rate settings also revert back to auto every time I go into full screen in Minecraft.\nI've searched Google and can't seem to find any solution to these problems.\nI'm not open to any lectures about how 144Hz is pointless because the eye supposedly can't see a difference beyond a certain refresh rate, so if you intend to lecture me on that incorrect knowledge then please be gone.\n\nA: To complement previous answers, if monitors.xml does not exist, set the refresh rate temporarily using xrandr, then enter the \"Displays\" configuration window and click \"apply\" to create the file with the correct refresh rate (no need to modify the settings).\n\nA: After reading 113 blog posts, SO questions, and other attempts at solving this problem, my refresh rate was still lost on reboot.\nFrom there I combed through man pages and played with dozens of utilities. During that process I discovered the following one-liner works on my 64 bit machine with a GTX 760.\nxrandr --output DVI-D-0 --mode 1920x1080 --rate 144\n\nThis targets the device connected via DVI-D-0, sets the resolution to 1920W by 1080H, and forces a refresh rate of 144 Hz.\nTo determine the value for --output, run the following command\nxrandr -q\n\nWhich will display information like the following.\n\nYou can see the second to last entry is where I found the device name, as well as supported settings.\nI call this script from \"Startup Applications\" to ensure that it runs immediately following log in. I'm not 100% happy with that solution, because the screens flickers immediately after entering my password. If you can live with that (I can), then this solves the issue.  \n\nA: To set refresh rate permanently (tested with Ubuntu 16.04):\n\n\n*\n\n*Open ~/.config/monitors.xml.\n\n*File may have multiple configuration sections which seems to be for different monitor setups there have been. I had most recent setup at most bottom.\n\n*If you have multiple displays make sure to edit correct output. Write xrandr to terminal and check by name of output that edited output really support wanted mode.\n\n*Insert refresh rate to rate element.\n\n\nThis method was found from a comment of Kaspar but I think this should be raised as answer.\n\nA: Run nvidia-xconfig as root and save the configuration:\n\n\n*\n\n*Open a terminal and run\nsudo nvidia-xconfig \n\n\n*On the tab where you set up your screen, choose your settings and then hit save:\n\n\n*That should pop out a new window with the location to save to. The default should already be /etc/X11/xorg.conf, hit OK and that should be it.\n", "Q: Windows 7 Install USB won't boot after installing Ubuntu I have replaced Windows 8 with Ubuntu 13.10 and now I am trying to install Windows 7 from a USB but it won't boot. When I choose to boot from my USB it gives an error:\nThis is not a bootable device. Insert a bootable floppy and press any key.\n\nThe USB was made in the built-in Startup Disk Creator in Ubuntu.\n\nA: I think that Startup Disk Creator doesn't work well with Windows. \nYou can try creating the usb via winusb as instructed here : How can I create a Windows bootable USB stick using Ubuntu?\n\nA: Startup Disk Creator will not work for this purpose; it creates only Ubuntu USB Boot keys.\nTo create a Windows USB Boot you can follow steps listed here\n", "Q: lshw not showing individual memory bank info This is all I get:\nsudo lshw -C memory\n  *-memory                \n       description: System memory\n       physical id: 0\n       size: 7981MiB\n\nsudo lshw doesn't give any more info. lshw used to show individual memory banks.\nWhat am I doing wrong?\n\nA: use :\n lshw -class memory\n\ntry it without sudo .\nor use sudo dmidecode --type 17\n\nA: You can type this at terminal\ndmidecode\n\nA: This is yet another regression bug of 16.04.\nSee this bug report:\nhttps://bugs.launchpad.net/ubuntu/+source/lshw/+bug/1586473\nAs you can see in the link if you build lshw from source it works properly.\nsudo apt-get source lshw\nsudo checkinstall\n\nhttp://wyldeplayground.net/ubuntu-ubuntu-16-04-aarch64-lshw-c-memory-did-not-show-memory-banks-info-correctly/\n\nA: Indeed this seems to be a bug with the lshw shipped with Ubuntu 15.10 and 16.04.\nSimilar to Kat Amsteram's answer, I fixed the issue by running:\nsudo apt-get source lshw\nsudo make\nsudo make install\n\n", "Q: Command with percent symbols not running in crontab The following crontab does not work:\n# TEST LINE DOES DOT RUN\n*/1 * * * * /bin/echo 'test '`/bin/date +%Y-%m-%d` >> /tmp/test\n\nI also tried starting it with:\nSHELL=/bin/bash\n\nUpdate: I thought the backtick characters ` were the villains, but as the answer below clarifies the percentage % was the culprit!\n\nA: In /bin/date +%Y-%m-%d, you need to escape each % with \\ according to this man page:\n\nThe \"sixth\" field (the rest of the line) specifies the command to be run. The entire command portion of the line, up to a newline or % character, will be executed by /bin/sh or by the shell specified in the SHELL variable of the cronfile. Percent-signs (%) in the command, unless escaped with backslash (), will be changed into newline characters, and all data after the first % will be sent to the command as standard input. \n\n", "Q: My laptop won't boot after fresh-install After a fresh install of Ubuntu 12.04 (or any other version of Ubuntu), my laptop never boot\nI tried to fix boot with boot repair but nothing fix my problem. After having run boot repair, I got this LOG. Please help me.\n\nA: Using an Ubuntu Live CD/USB, open terminal and type:\nsudo fdisk -l\n\nYou'll see something like this:\nDisco /dev/sda: 160.0 GB, 160041885696 bytes\n255 heads, 63 sectors/track, 19457 cylinders\nUnidades = cilindros de 16065 * 512 = 8225280 bytes\nIdentificador do disco: 0x7402e25b\nDispositivo Boot Início Fim Blocos Id Sistema\n/dev/sda1   *           1        4649    37343061    7  HPFS ou NTFS\n/dev/sda2            4650        5683     8305605   83  Linux`\n\nMount the linux partition (change /dev/sda2 according to your partition)\nsudo mount /dev/sda2 /mnt\n\nReinstall GRUB 2:\nsudo grub-install --root-directory=/mnt /dev/sda\n\nReboot your PC\n", "Q: I just installed Ubuntu on my Yoga 2 pro and I am looking to manually adjust the screen resolution This was my installation method. Strung together from various sources.\nSteps I followed to install Ubuntu on my Lenovo Yoga 2 pro\n\nA: The package you are looking for is xrandr (should be installed by default).\nTo see the help :\nxrandr --help\n\nTo read the manual :\nman xrandr\n\n\nYou can change your screen resolution with : \nxrandr --fb <width>x<height>\n\n", "Q: Not yet another question about truecrypt on usb! everybody,\nAfter reading a few topics on this forum, and the Truecrypt documentation, I still can't understand how to achieve my objective: \nTo encrypt data on a usb device and use it on any computer where: \n\n\n*\n\n*they don't have Truecrypt installed \n\n*I don't have admin privileges (I do have admin privileges on my own computer, which I am trying to use to create such volume/file).\nAfter creating an encrypted file container on the usb, I have copied the Truecrypt executable file on it. Of course, I cannot run it from another computer, as I do not have admin privileges.\nOn the Truecrypt documentation they talk about using Tools --> Traveler Disk Setup which I do not seem able to find anywhere when launching the program.\nIs there any way to achieve my objective?\nThanks,\nMax\n\nA: Truecrypt handles the mounting of encrypted/hidden volumes using its own executable program.  If you do not have sufficient privileges on the computer, and truecrypt is not installed, it is not possible to decrypt the drive within that environment. \nQuick workaround would be to boot the target computer with another live usb containing pre-installed truecrypt. That way you could decrypt your encrypted usb drive and copy any files over to the target system and vice-versa. \nThis truecrypt website has information regarding why it can not run without administrator privileges. You can run the program in portable mode (meaning no installation is necessary) however you will not be able to run it without being an administrator, as documented here. \n", "Q: How to install CPU-G on Ubuntu How to install CPU-G on Ubuntu , so i can use it to view information about my desktop hardware .\n\nA: To install Cpu-G , useful utility to show hardware information. It detects hardware and display details about everything, it shows information about CPU(Processor), RAM(Active/Inactive, Free, Used and cached), Motherboard and Chipset, Bios Details, Graphic card details .\nIn Terminal :\nsudo add-apt-repository ppa:cpug-devs/ppa\nsudo apt-get update\nsudo apt-get install cpu-g\n\nOpen it :\n\nYou can view information about :\n\n\nReference\n\nA: In newest versions of Ubuntu (mine Linux Mint 18), try this:\nsudo add-apt-repository ppa:atareao/atareao\nsudo apt-get update\nsudo apt-get install cpu-g\n\nA: Although i find that @nux gave the good answer, i have to indicate a simple way  to install CPU-G for people  without use of add-apt-repository  utility. In that case  the   CPU-G sourceforge   tarball or  CPU-G deb download is a convenient way\n", "Q: How to recover data lost when connecting a USB drive to a VirtualBox VM I have just installed/configured my machine to run Ubuntu 13.10, with Windows 8 running in a virtual machine on VirtualBox 4.2.16_Ubuntu r86992.\nI was just experimenting with mounting and unmounting an external hard drive which has a FAT32 filesystem.\nEverything seemed to work...  The drive could be mounted and unmounted in the VM, and I could see on Ubuntu that it was also mounting and unmounting.\nHowever, then I tried to access a folder in Ubuntu, and it appeared empty.\nSo I clicked on another folder, to see if it was also empty, and it was.\nI tried a couple more, and they appeared empty.  None of these should have been empty.\nThen I tried to connect the drive to a different physical Windows laptop.\nIt appeared that every folder that I had clicked on in Ubuntu was empty!\nI'm scared to try access this drive from Ubuntu again, and I don't know what could have caused this to happen.  (The drive is FAT32.)\nIs there any way to recover my data?\nIs there any way to prevent this happening again?\nAny advice would be greatly appreciated.\n\nA: Please consult this help page for information regarding data recovery on failed or formatted drives from within ubuntu. It is possible to recover lost data but it is worth you reading the help page to avoid me repeating it here.  Tread carefully, and if in doubt take it to a store that offers data recovery. \n", "Q: install the drivers for the built in blueray /dvd drive and other such hardware on my laptop? If I install ubuntu will I need to install the drivers for the built in blueray /dvd drive and other such hardware on my laptop?\n\nA: Playback should be supported for most DVD types by enabling the ubuntu-restricted-extras package. \nsudo apt-get install ubuntu-restricted-extras\n\nYou may also need to install libdvdcss.\nsudo apt-get install libdvdread4\n sudo /usr/share/doc/libdvdread4/install-css.sh\n\n", "Q: gnome crashed on ubuntu while updating After I've installed openCV and after updating/upgrading apt-get, gnome crashed. \nI was wondering how can I fix/reinstall/repair gnome.\nbest regards\n\nA: You should be able to use this,\nsudo apt-get install --reinstall gnome-shell\n\nIf not, then I would try\nsudo apt-get install --reinstall ubuntu-desktop\n\n", "Q: Cant get ubuntu usb to boot I recently had Linux Mint installed on my new laptop with windows 8.1.\nI had problems booting to Mint so i installed rEFInd and managed to get Windows and L+Mint to boot correctly.\nI decided i wanted to install Ubuntu instead of Mint so i deleted the partition with Mint and tried to install Ubuntu but everytime i try to boot ubuntu from my usb it sends me to busybox saying:\nmount: mounting dev/loop0 on //filesytem.squashfs ...\nI read that it was probably a bad download and redownloaded again, but im still getting the same error.\n\nA: Make a new USB boot using Unetbootin or LiLiUSB, both for Windows. Your USB media is corrupted.\n", "Q: Bootstrapping Juju gives \"\"ERROR could not access file '*-provider-state' gomaasapi: got error back from server: 403 forbidden.\" We are trying to bootstrap Juju onto another machine in the MAAS cloud but are getting a \"ERROR could not access file *-provider-state gomaasapi: got error back from server: 403 forbidden.\" error. \nWhen we run juju bootstrap a .jenv file is created and this error is returned with the * in the '*-provider-state'  replaced by the Juju Agent Name of the MAAS node. When we delete the environment (by deleting the .jenv file), the same error is returned but filename just listed jsut as 'provider-state'. The node does not move into Allocated state even if the .jenv file is created. Running anything - juju bootstrap, juju status, juju destroy-environment, gives the same error.\nBackstory: There used to be a bootstrapped Juju environment existing on this MAAS server previously. We had to change our network configurations, and couldn't get the allocated node to be deleted. So, we thought we could unistall juju and start over. Clearly, it didn't work and there are some links left of it still on our server. How do we get rid of it? We did get the allocated node deleted using the maas shell but this error still persists.\nWe are running MAAS 12.04 LTS, Juju 1.16. \n\nA: First off, deleting the .jenv file does not destroy the environment, it just makes it impossible to connect to it from you juju client. The .jenv file contains all the necessary information to connect to the environment, including juju API server addresses, SSL certificates, etc.\nTo destroy a juju environment, use:\n$ juju destroy-environment my-maas-env-name -y\nThis will properly deallocate the MAAS nodes, delete the storage entries, including the provider-state file. \nAlso, reinstalling juju on your client machine cannot solve your issue, because the environment and its allocated nodes are still there and to MAAS it appears as you're still using the environment.\nTo solve your specific issue, I'd do the following:\n\n\n*\n\n*Your environment is no longer accessible because the .jenv file is gone, and since it's auto-generated you cannot regain access to the environment just by creating an empty .jenv file.\n\n*Delete the .jenv file if it's still there.\n\n*Login as the MAAS administrator in the MAAS web UI, go to \"Nodes\" and for each allocated node, click on the node and click \"Stop node\" on the node page. This will deallocate the node and bring it back to Ready.\n\n*Using the MAAS CLI, you can list all files in the environment storage: $ maas my-maas-session files list, and delete the provider-storage file: $ maas my-maas-session file delete XXXX-provider-storage (the exact file name you get from the files list, it will look like c4ba50c2-268c-4cf4-8be1-c0903982c8a8-provider-state; and my-maas-session corresponds to your CLI user session - it can be any string, created with e.g. $ maas login my-session-name http://192.168.50.2/MAAS/ <maas-api-key> - use the same key you specify with \"maas-oauth\" in environments.yaml)\n\n*Bootstrap again, once it's done it should work.\n\n\nHope this helps,\n", "Q: unable to connect to the internet through my Ubuntu 13.10 unable to connect to the Internet through my Ubuntu 13.10\nlspci -nn\n\n00:00.0 Host bridge [0600]: Intel Corporation Mobile PM965/GM965/GL960 Memory Controller Hub \n[8086:2a00] (rev 03) 00:02.0 VGA compatible controller [0300]: Intel Corporation Mobile GM965/GL960 Integrated Graphics Controller (primary) \n[8086:2a02] (rev 03) 00:02.1 Display controller [0380]: Intel Corporation Mobile GM965/GL960 Integrated Graphics Controller (secondary) \n[8086:2a03] (rev 03) 00:1a.0 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #4 \n[8086:2834] (rev 03) 00:1a.1 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #5 \n[8086:2835] (rev 03) 00:1a.7 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB2 EHCI Controller #2 \n[8086:283a] (rev 03) 00:1b.0 Audio device [0403]: Intel Corporation 82801H (ICH8 Family) HD Audio Controller \n[8086:284b] (rev 03) 00:1c.0 PCI bridge [0604]: Intel Corporation 82801H (ICH8 Family) PCI Express Port 1 \n[8086:283f] (rev 03) 00:1c.1 PCI bridge [0604]: Intel Corporation 82801H (ICH8 Family) PCI Express Port 2 \n[8086:2841] (rev 03) 00:1c.2 PCI bridge [0604]: Intel Corporation 82801H (ICH8 Family) PCI Express Port 3 \n[8086:2843] (rev 03) 00:1d.0 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #1 \n[8086:2830] (rev 03) 00:1d.1 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #2 \n[8086:2831] (rev 03) 00:1d.2 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB UHCI Controller #3 \n[8086:2832] (rev 03) 00:1d.7 USB controller [0c03]: Intel Corporation 82801H (ICH8 Family) USB2 EHCI Controller #1 \n[8086:2836] (rev 03) 00:1e.0 PCI bridge [0604]: Intel Corporation 82801 Mobile PCI Bridge \n[8086:2448] (rev f3) 00:1f.0 ISA bridge [0601]: Intel Corporation 82801HM (ICH8M) LPC Interface Controller \n[8086:2815] (rev 03) 00:1f.1 IDE interface [0101]: Intel Corporation 82801HM/HEM (ICH8M/ICH8M-E) IDE Controller \n[8086:2850] (rev 03) 00:1f.2 IDE interface [0101]: Intel Corporation 82801HM/HEM (ICH8M/ICH8M-E) SATA Controller [IDE mode] \n[8086:2828] (rev 03) 00:1f.3 SMBus [0c05]: Intel Corporation 82801H (ICH8 Family) SMBus Controller \n[8086:283e] (rev 03) 02:00.0 Ethernet controller [0200]: Marvell Technology Group Ltd. 88E8039 PCI-E Fast Ethernet Controller [11ab:4353] (rev 15) 04:00.0 Network controller [0280]: Broadcom Corporation BCM4312 802.11b/g LP-PHY [14e4:4315] (rev 01)\n\n\nA: Your Broadcom Corporation BCM4312 wireless uses proprietary drivers. Temporarily connect your system to the internet using an Ethernet cable. You should have the opportunity to install it by using the additional drivers application. Once installed your wireless connection should function normally.\n", "Q: How to change the permission on a single file? I need to change the permission on a couple of files in the /usr/share/backgrounds/. I've been lurking around forums but no one will give me a straight answer. Rather, they just keep warning me against it. \nThe files in question are two images, lets say, img1.jpg and img2.jpg. All I want to do is set their \"Other\" permission from \"None\" to \"Read-only\". \n\nA: Type in a terminal:\nsudo chmod o+r /usr/share/backgrounds/img1.jpg\n\n\nA: as owner or user with write permissions on the file:\nchmod o+r filename\n\n\nA: sudo chmod 444 /usr/share/backgrounds/img1.jpg \n\n444 Allow read permission to owner, group and world.\n", "Q: remember wireless password in kde I've got kubuntu 12.04.3 LTS installed. Don't know why - whether it's a default option or I've made this - but KDE always keeps asking me for the wireless connection password and it's annoying a little bit. Each time I reboot I have to enter kde wallet password.\nWhat can I do to grant access to the kde wallet for the wireless network manager?\n\nA: I know this thread is a wee-bit old, but if someone else has the same issue these days, here is how it worked for me under KDE Neon 5.10 (Ubuntu 16.04 LTS):\nSetting up the system I must have disabled a feature called KWallet (probably thinking it had something to do with online payment). Thereafter, it would always ask me for the password again, and I didn t pay it any mind as I rebooted only a few times since then. \nEnabling the Kwallet again under \"Settings->User Accounts->Kwallet\"\nresolved this issue for me.\n\nA: If that version of KDE has Network manager try opening network connections, go to the wireless tab and edit (or add) your wireless network info, making sure to check the box \"available to all users.\" It won't ask for the wireless password again.\n\nA: There's a small spanner icon in the top right hand cornor of the popup window when you click on the wifi connection icon in the task bar.\nThis opens the Connection Editor, where you can edit the wifi connection and allow all users to use the connection.\n\nA: Following @elder-geek's suggestion, I noticed that my connection didn't have the password saved. (Connection editor -> Edit Connection 'X' -> Wireless Security). If you put the password in this tab and hit OK, it should save it.\n\nA: From system setting go to connections. Under Known Wi-Fi's find your  connection. In the Wi-Fi security tab type Wi-Fi password in field. Also check connect automatically with priority and set priority (probably you want to be 0) in general tab.\n\nA: Even after disabling  Kwallet it prompting for password then go to Setting->connections->Your_wifi_name Then go to WiFi tab and check whether there is password stored or not.If not then Enter your password there and click on OK.\n", "Q: Why can't I see eth0 on my ubuntu 12.04 server in virtualbox? I've just install ubuntu 12.04 server on virtualbox through my windows 7 pc. When I try to give my server an ip address through /etc/network/inferfaces, I first to need make sure eth0 is there correct? And when I check for eth0, I don't have one when I go through ifconfig. I only see lo and virbr0. Commands like auto eth0 doesn't work. I'm a total newb to linux command system. Someone please enlighten me. \n\nA: The virbr0, or \"Virtual Bridge 0\" interface is used for NAT (Network Address Translation). This is the default network interface automatically set up by VirtualBox.\nIn order to have eth0 available in your guest OS please follow this procedure:\n\n\n*\n\n*Select your guest virtual machine in the VirtualBox Manager then click on Settings.\n\n*Select the Network category\n\n*Select \"Bridged Adapter\" in the \"Attached to\" drop-down list.\n\n*Boot your VM normally\n\n\n\n", "Q: Enable alt-drag I am very used to alt-drag for moving and resizing windows.  \nHowever, I can't get it to work in xubuntu 13.10.  (I just recently installed it in a virtual box machine).  If I change it to a different key (shift for example), shift-drag works as expected.   When it is set up to use alt, and I press the alt key, it activates the menu shortcuts, but doesn't drag or resize windows if I click.\nEDIT:\nYes, that sounds like exactly the setting I need to change.  However, when I pull up the keyboard settings, that tab isn't there.  I'm using xubuntu 13.10.\n\nSo where else might that setting live?\n\nA: Found the problem:\nI am running inside a virtual box, and had Alt-dragging turned on in the host system.  Even though Alt-drag didn't drag the whole VB window, it disabled it in the guest OS.  If I turned it off in the host, it works as expected in the guest.\n\nA: Open the System Settings application, then go to Keyboard -> Shortcuts -> Launchers. You can disable the \"Key to show the HUD\" which seems to prevent you to use the alt-drag:\n\n", "Q: where does the shell fall into the process hierarchy? When you open a new terminal, it becomes the parent process of all processes forked within it. But where does the bash shell, for example, fall into this process chain? Is its parent the terminal? Are all processes forked within the shell children of the shell? If so, then when I change shells, why do the processes still remain running? In short, where does the shell fall in the process hierarchy?\n\nA: Indeed the parent of the bash process is the terminal. You can see the process hierarchy using the ps -aef command:\n$ ps -aef\nUID        PID  PPID  C STIME TTY          TIME CMD\n[...]\nsylvain   3510  1862  2 22:02 ?        00:00:01 gnome-terminal\n[...]\nsylvain   3520  3510  0 22:02 pts/1    00:00:00 bash\nsylvain   3587  3520  0 22:03 pts/1    00:00:00 sh\n\n\n\n*\n\n*PID: Process ID\n\n*PPID: Parent Process ID\n\n\nIn this example I started a sh process (3587) from the bash shell (3520)\n\nA: There is nice commands that can help you to understand things here: pstree. \nShow the process tree of the current process (in a shell, $$ is substituted with the PID of the shell): \n(0)samsung-rmano:~% pstree -s $$\ninit───gdm───gdm-simple-slav───gdm-session-wor───init───gnome-terminal-───zsh───pstree\n\nShowing PIDs: \n(0)samsung-rmano:~% pstree -s -p $$\ninit(1)───gdm(1128)───gdm-simple-slav(1203)───gdm-session-wor(1933)───init(1955)───gnome-terminal-(2340)───zsh(23005)───pstree(23044)\n\nThe whole system process tree, with the current shell highlighted (open a very big terminal! --- the higlight is not visible here):\n (0)samsung-rmano:~% pstree -h \n ...\n ├─gdm─┬─gdm-simple-slav─┬─Xorg───4*[{Xorg}]\n │     │                 ├─gdm-session-wor─┬─init─┬─Notifications_h\n │     │                 │                 │      ├─Translator\n │     │                 │                 │      ├─at-spi-bus-laun─┬─dbus-daemon\n │     │                 │                 │      │                 └─3*[{at-spi-bus-laun}]\n │     │                 │                 │      ├─at-spi2-registr───{at-spi2-registr}\n │     │                 │                 │      ├─darktable───47*[{darktable}]\n │     │                 │                 │      ├─dbus-daemon\n │     │                 │                 │      ├─dconf-service───2*[{dconf-service}]\n │     │                 │                 │      ├─dropbox───30*[{dropbox}]\n │     │                 │                 │      ├─evolution-calen───4*[{evolution-calen}]\n │     │                 │                 │      ├─evolution-sourc───2*[{evolution-sourc}]\n │     │                 │                 │      ├─firefox─┬─plugin-containe───10*[{plugin-containe}]\n │     │                 │                 │      │         └─43*[{firefox}]\n │     │                 │                 │      ├─gconfd-2\n │     │                 │                 │      ├─gnome-session─┬─deja-dup-monito───2*[{deja-dup-monito}]\n │     │                 │                 │      │               ├─gnome-shell─┬─alarmclock───3*[{alarmclock}]\n │     │                 │                 │      │               │             ├─cairo-dock───3*[{cairo-dock}]\n │     │                 │                 │      │               │             └─6*[{gnome-shell}]\n │     │                 │                 │      │               ├─tracker-miner-f───3*[{tracker-miner-f}]\n │     │                 │                 │      │               ├─tracker-store───7*[{tracker-store}]\n │     │                 │                 │      │               ├─update-notifier───3*[{update-notifier}]\n │     │                 │                 │      │               ├─vino-server───2*[{vino-server}]\n │     │                 │                 │      │               ├─zeitgeist-datah───10*[{zeitgeist-datah}]\n │     │                 │                 │      │               └─3*[{gnome-session}]\n │     │                 │                 │      ├─gnome-settings-─┬─syndaemon\n │     │                 │                 │      │                 └─4*[{gnome-settings-}]\n │     │                 │                 │      ├─gnome-shell-cal───4*[{gnome-shell-cal}]\n │     │                 │                 │      ├─gnome-terminal-─┬─gnome-pty-helpe\n │     │                 │                 │      │                 ├─slogger\n │     │                 │                 │      │                 ├─3*[zsh]\n │     │                 │                 │      │                 ├─zsh───man───pager\n │     │                 │                 │      │                 ├─zsh───python3\n │     │                 │                 │      │                 ├─zsh───pstree\n │     │                 │                 │      │                 └─3*[{gnome-terminal-}]\n...\n\n", "Q: Package denyhosts in Ubuntu Trusty Tahr is deleted: temporary or forever? While doing a test-upgrade of our Ubuntu server to 14.04, I found that the package DenyHosts is no longer available. Installing it gives following error:\napt-get install denyhosts\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package denyhosts\n\nApparently it has been deleted, according to launchpad.\nWill Denyhosts be available in the final release of Ubuntu 14.04?\n\nA: No, it's not comming back. bodhi offers some good suggestion on how you can replace it, but it's also worth explaining why it was remove.\nIt was removed in Debian at the request of the Debian Security Team:\n\n  \n*\n  \n*There are unaddressed security issues (e.g. #692229).\n  \n*The tool is dead upstream (last release 2008).\n  \n*There is a viable alternative, fail2ban, that provides the same or\n  increased feature set.\n  \n\nYou might also want to check out this question on ServerFault:\nDenyhosts vs fail2ban vs iptables- best way to prevent brute force logons?\n\nA: While DenyHosts is not available as a package in Ubuntu, there is a fork of the upstream project here: http://denyhost.sf.net\nThe fork includes security patches and better supports Ubuntu. You can install it by downloading the tarball and running\ntar xzf denyhost-2.7.tar.gz\ncd DenyHosts-2.7\nsudo python setup.py install\n\n\nA: I am sorry denyhosts has reached this stage, but I think you answered your own question : \n\ndead upstream; unmaintained; dysfunctional in sid\n\nUnmaintained upstream projects will reside in the repos, with patches, until the packages can no longer patch, so looks like the end for denyhosts.\nMy best advice is to look for alternates.\nPersonally I harden my ssh server\nAnd use iptables\nsudo iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH --rsource -j ACCEPT\nsudo iptables -A INPUT -m recent --update --seconds 600 --hitcount 8 --rttl --name SSH --rsource -j DROP \n\nSee http://bodhizazen.com/Tutorials/iptables\nall the links in this post are from my LUG ;)\n\nA: It is unmaintained, but issue #692229 is fixed, as noted here https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=692229\nFail2ban isn't really an alternative if you want to use a sync server. I haven't seen other systems than denyhosts that support this.\nSo, as long as it works, why not use it?\n\nA: It appears that a fork is now being maintained at https://github.com/denyhosts/denyhosts and the current version is 2.9.\n", "Q: Cannot get wireless to work after installing Ubuntu 12.04 My hard drive crashed that was running Win8 so I installed Ubuntu 12.4 on my HDD. I can connect to wired connection but no wireless. I have checked drivers and they seem good. Can anyone tell me what I'm missing here?\ndamulag@damulag-Satellite-S55-A:~$ sudo lshw -class network\n[sudo] password for damulag: \n  *-network UNCLAIMED     \n       description: Network controller\n       product: RTL8188EE Wireless Network Adapter\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:02:00.0\n       version: 01\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list\n       configuration: latency=0\n       resources: ioport:3000(size=256) memory:c2400000-c2403fff\n  *-network\n       description: Ethernet interface\n       product: QCA8171 Gigabit Ethernet\n       vendor: Qualcomm Atheros\n       physical id: 0\n       bus info: pci@0000:03:00.0\n       logical name: eth0\n       version: 10\n       serial: 54:be:f7:49:db:2b\n       size: 1Gbit/s\n       capacity: 1Gbit/s\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm pciexpress msi msix bus_master cap_list ethernet physical tp 10bt 10bt-fd 100bt 100bt-fd 1000bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=alx driverversion=1.2.3 duplex=full firmware=N/A ip=10.0.0.6 latency=0 link=yes multicast=yes port=twisted pair speed=1Gbit/s\n       resources: irq:18 memory:c1000000-c103ffff ioport:2000(size=128)\ndamulag@damulag-Satellite-S55-A:~$ ifconfig eth0 up\nSIOCSIFFLAGS: Operation not permitted\ndamulag@damulag-Satellite-S55-A:~$ sudo lshw -class network\n  *-network UNCLAIMED     \n       description: Network controller\n       product: RTL8188EE Wireless Network Adapter\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:02:00.0\n       version: 01\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm msi pciexpress bus_master cap_list\n       configuration: latency=0\n       resources: ioport:3000(size=256) memory:c2400000-c2403fff\n  *-network\n       description: Ethernet interface\n       product: QCA8171 Gigabit Ethernet\n       vendor: Qualcomm Atheros\n       physical id: 0\n       bus info: pci@0000:03:00.0\n       logical name: eth0\n       version: 10\n       serial: 54:be:f7:49:db:2b\n       size: 1Gbit/s\n       capacity: 1Gbit/s\n       width: 64 bits\n       clock: 33MHz\n       capabilities: pm pciexpress msi msix bus_master cap_list ethernet physical tp 10bt 10bt-fd 100bt 100bt-fd 1000bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=alx driverversion=1.2.3 duplex=full firmware=N/A ip=10.0.0.6 latency=0 link=yes multicast=yes port=twisted pair speed=1Gbit/s\n       resources: irq:18 memory:c1000000-c103ffff ioport:2000(size=128)\ndamulag@damulag-Satellite-S55-A:~$ \n\n\nA: \"UNCLAIMED\" means there are no drivers attached to your card. Since there are no drivers attached to your card you wifi will not work.\nTry this solution, it is marked as solved so it should work for you:\nhttp://ubuntuforums.org/showthread.php?t=2162026\n", "Q: Cannot write bytes broken pipe I can't seem to boot Ubuntu 12.04 on my t-61 Thinkpad. I get the splash screen, then a black screen that reads: \nCannot write bytes: broken pipe.\n\nLet me first say that originally I had removed xserver-xorg-video-mach64(because I have an Intel video card) xserver-xorg-core, and other similar packages that I thought were extraneous. After doing this, I would get the black screen but it would say something about Plymouth and freeze. So then I reinstalled all the xserver packages I removed by installing xserver-xorg-video-all. \nThis is when I got the current error message: \ncannot write bytes: broken pipe\n\nPlease be verbose with your answers, as I am not that knowledgeable about Linux\nThanks for the help\n\nA: Reinstalled the ubuntu desktop, fixed it. It was still a driver issue though, even though I said I reinstalled xserver-xorg-video-all. It had something to do with the dependencies.\n", "Q: Tab doesn't auto complete on user \"minecraft\" but completes with root On my user \"minecraft\" whenever I hit the tab key it just indents instead of auto completing. It works fine on root though.\nOutput of getent passwd minecraft:\nminecraft:x:1001:1001::/home/minecraft:/bin/sh\n\n\nA: It will work if you change your shell from sh to bash:\nsudo chsh -s /bin/bash $USER\n\nAlso, make sure you have the default initialization files in your home directory:\ncp /etc/skel/{.bash*,.profile} $HOME\n\n", "Q: How to clean executable using make clean? After compiling several *.c and *.h files using make, I cleaned up the object files using make clean. However I don't know how to remove the executable.\nmy makefile code -->\n    CC=gcc\n    CFLAGS=-I.\n    mp1: main.o downloader.o json.o\n            $(CC) -o mp1 main.o downloader.o json.o -I.\n    .PHONY : clean\n    clean :\n           -rm *.o $(objects)                              \n\n\nA: Your executable seems to be the file mp1. Add this file to the rm command in the clean target:\nclean :\n       -rm *.o $(objects) mp1\n\n\nA: $ sudo make clean\n\nThe above mentioned command will clean all the .o files \n\nA: This command is useful when make is not available in your system.\n$ find coding/ -type f -executable | xargs rm\nThis command removes all executable files in the coding directory.\nThe first part of the command, the find part lists all the files which are executable.\nThe second part of the command takes the input from 1st part and gives it to rm command.\nxargs - a command that converts its standard input into arguments of another program, look the man page for more info\n", "Q: Xbmcbuntu install won't proceed This question is about xbmcbuntu, hope that's ok. I'm trying to install it on my computer now for a while (hope to make it a HTPC/server) but I just can't get it to work. Here's my hardware configuration:\nMotherboard MSI FM2-A75MA-E35\nCPU: AMD A6 5600K\n8 GB of memory\nOnboard video\nCrucial 64 GB SSD (formatted in FAT)\nWD RED 3 TB Harddrive (want to run windows home server in virtualbox)\n350 Watt PSU\nNow I've been trying to install it using USB using Linuxlive USB creator, Unetbootin, Universial USB installer, YUMI and regular dvd with ISO but all don't work. (I set the bootorder configuration right) My motherboard boots properly, displaying the usual stuff and after that I get to the installmenu of xmbcbuntu. Here I can choose whatever I want but all I get after selecting an option is a white screen. I tried to adjust the installation using TAB with removing quiet splash and adding nomodeset (I guess in case my onboard video driver doesn't get supported). All i get is a long list with all kids of information ending with ACPI: core revision 20120320. Also tried all of the options above with the regular version of Ubuntu (12.04) but face the same problem.\nDoes anyone know what I am doing wrong and how to proceed? \nThanks!\n\nA: Update your BIOS to the latest version. Follow the manufacturers recommendations for doing so. This will typically resolve problems.\n", "Q: What is the recommended release of Ubuntu for 32-bit Intel based Macs? What is the recommended release of Ubuntu for 32-bit Intel based Macs?\nI see for 13.10 that there are specialised images for macs, (e.g. ubuntu-13.10-desktop-amd64+mac.iso).  These only support 64-bit, and there is nothing similar for the i386 images.  Looking at older versions such as 12.04 LTS, there are no mac variants at all.\nI have tried using the regular 12.04 i386 image to create a bootable USB stick, but I was not able to boot the MacBook using this.  Only the Macintosh hard disk appeared in the boot menu options.\nI do not need to keep Mac OS X on the MacBook and would be happy single booting Ubuntu.  Not sure if that makes things easier or harder.\n\nA: I figured out how to do this and am now dual booting OS X and Ubuntu 12.04, so here's the solution...\n\n\n*\n\n*Prepare a USB stick for installing Ubuntu from.  I downloaded 12.04.4 i386, and created a bootable USB stick using the instructions here.\n\n*Shrink the Mac OS X volume to make space for Linux.  I executed sudo diskutil resizevolume disk0s2 250G.  The exact size you need will depend on how large your hard disk is and how much space you intent to reserve for Linux.  Reboot, and confirm you have some unused space by using Disk Utility.\n\n*Install rEFIt from inside Mac OS X.  I installed v0.14.  Note the installation docs say you may need to reboot twice after installing.\n\n*Reboot and use the rEFIt menu to sync partition tables.  For me MBR was out of date with respect to GPT.\n\n*Boot with the USB stick inserted, and use rEFIt to boot from the USB stick.  For me rEFIt showed the USB stick as an external hard disk.\n\n*Install Ubuntu normally.  I selected the option to install Ubuntu alongside Mac OS X.\n\n*After the install completes you can reboot.  Use the rEFIt menu to sync partition tables again.  I don't recall if this had any effect at this point.\n\n*You will find that the Linux option in the rEFIt menu doesn't work yet.  You can select it but you just get a blank screen.\n\n*Boot from the USB stick again and use the \"Try Ubuntu\" option.\n\n*Open a terminal and mount the Ubuntu partition installed to the hard disk.\nsudo mkdir /target\nsudo mount /dev/sda4 /target\nsudo mount -o bind /proc /target/proc\nsudo mount -o bind /dev /target/dev\nsudo mount -o bind /dev/pts /target/dev/pts\n\n\n*Chroot into this, with sudo chroot /target.\n\n*From inside the chroot shell install refit and grub packages with sudo apt-get install refit grub.  Note this will remove grub-pc, this is fine.\n\n*From inside the chroot shell resync the partition tables with sudo gptsync /dev/sda.  For me this updated the MBR tables. (gptsync should have been installed as one of the dependencies of refit.)\n\n*From inside the chroot shell update grub with sudo update-grub.\n\n*Reboot and remove the USB stick.  You will find the Linux option in the rEFIt menu now works just fine.  The option for Mac OS X should also still work.\nThis method was mostly deduced by taking hints from the Debian wiki about MacBooks.  I had no trouble with this, but you may find additional troubleshooting tips there.\n", "Q: 13.10 Fully installed reset and operating system does not boot My system boots and searches for my operating system and nothing happens. I can run it from a CD just fine. I have tried loading it twice and once on a clean hard drive.\n\nA: That is some very basic information. I would like to help you but I need some information.\n\n\n*\n\n*What hardware are you running?\n\n*Did you try to enter the bios and run hardware tests?\n\n*Also this could be a problem with the boot loader. \n\n*I mentioned Bios but do you have UEFI instead? If so try https://help.ubuntu.com/community/UEFI\nI hope this helps, best I could do with the information you provided.\n", "Q: Cursor positioning using mouse in bash possible? In Vim I can actually position the cursor in insert-mode using the mouse. So I assume this should (technically) also be enable-able for the bash. Is it possible? This would be quite useful at times when small changes have to be made to very long commands.\n(I am using fish actually, but I guess referring to bash I reach a wider audience.)\n\nA: Does that work ? It should print escaped sequences on your terminal when using the mouse\necho -e \"\\e[?1000;1006;1015h\" # Enable tracking\n\nIf it works : test my script on github\nDetails : Read my answer in another post\n", "Q: Can not enter password Am new at ubuntu i tried to install a kdeplasmadesktop addons, and by typing su -c 'yum update kdeplasma-addons' from the terminal it ask for password but can not type any in.\nThanks.\n\nA: Ubuntu doesn't show you the password for security reasons. So just type it in as normal and hit enter. \n", "Q: Installing Nvidia drivers on ThinkPad w530 I am on a ThinkPad W530 and have just installed Ubuntu. Which one of these drivers do I install? \nDoes the command sudo apt-get install nvidia-current install current drivers? \n\nEDIT: I used sudo apt-get install nvidia-current and now there is a nvidia_304 driver activated in Additional Drivers:\nIf you have Optimus enabled in the BIOS, you either have to disable it or install Bumblebee\n\n\nA: I used sudo apt-get install nvidia-current. There should be a new driver that appears in the Additional Drivers GUI. Restart your computer. \nIf you have Optimus enabled in the BIOS, you either have to disable it or install Bumblebee. Otherwise, you will have grey icons on the dashboard. \n", "Q: How to install ubuntu on separated flash drives? I need to install a single version of Ubuntu on 2 USB flash drives, what is the best partitioning scheme to use for this situation? All I want to do on the flash drives are play minecraft, and use for minimal everyday things.\nThe current on I want to use is\n/dev/sda = / 8 GB  (My root)\n/dev/sdb = /usr 8 GB (For my programs to install)\n\nA: If you only want to play Minecraft and browse the web, this partitioning will do:\n/dev/sda = /\n/dev/sdb = unused\n\nAlternatively, you could make a RAID 1 volume of the two disks to protect against the failure of one drive. A RAID 1 volume uses two (or more) disks with identical contents, so if one disk fails, you still have a working system. Or you could use the second drive to back up your data.\nSeparating /usr is not useful. On a typical desktop machine, /usr makes up the bulk of what is not /home. If you have little data on /home, with your scheme, you'd end up with /dev/sda almost empty. If you have a lot of data in /home, make it /dev/sdb.\nIf you need more than 8GB for the system, there's no particularly meaningful place to break it up. /usr/lib would be a good bet. Anyway, you can mount /dev/sdb wherever you like, and move one or more directories there and create a symbolic link.\nRather than pick a mount point, there's a simpler approach to splitting your system between two drives: make it a RAID 0 volume. RAID 0 combines two or more disks into one, in an arrangement that tries to spread the load evenly between the disks. The advantages of RAID 0 over a mount point is that you don't have to worry at all about choosing the mount point right for splitting the space evenly, and that it's a bit faster. The downside of RAID 0 is that if one of the disks fails, the whole filesystem will be unusable.\nTo install Ubuntu on a RAID volume, you'll need to use the server (alternate) installation media and do manual partitioning.\n", "Q: How can I have multiple apache sites under the same domain? I have a single IP that is external - say xx.xx.xx.xx. Currently, I have 2 urls that resolve to the IP address. I use virtual hosts within Apache to make sure that the right requests go to the site:\nwww.mysite1.com --> /home/mysite1\nwww.mysite2.com --> /home/mysite2\n\nWorks great. However ...\nI want to add a 3rd (and then 4th and 5th, etc) site to this IP. The sites are temporary and thus won't get domain names. I was hoping to access them by using:\nhttp://xx.xx.xx.xx/mysite3 where mysite3 --> /home/mysite3\n\nbut it seems that the virtual host from site1 catches these requests and routes the request to www.mysite1.com which struggles finding the files (mysite3) so I get the www.mysite1.com with 404 page (They are all Wordpress sites).\nI am sure that this can be done but I am just as sure I can't figure it out.\nDoes anyone have an idea of how I need to configure \"things\"?\n\nA: You have 2 solutions\n1. Creating a Virtual Host for each site\nIn my opinion, I would recommend this solution if it's a possibility.\nIn this step, you would need need to create a site just as you did for your previous ones. But you will need to give them a domain like www.site3.temp even if it won't have a dns record. (notice the .tmp TLD)\nNext, for each user that will open that site, they would need to edit their hosts file and add a line which points that temp url to your IP. Like so:\nxx.xx.xx.xx      www.site3.tmp\n\n\n\n*\n\n*In Linux and Mac OS the hosts file is located at /etc/hosts\n\n*In Windows it's located in <Windows Installation>/system32/drivers/etc/hosts\nBy default, <Windows Installation> is in C:/Windows\n2. Creating an Alias\nIf editing of the hosts file is not a solution, then this is you only other option\nThis would require you to edit your default virtual host file. It's the virtual host of www.mysite1.com, since it's the one that is opening when you go to http://xx.xx.xx.xx/mysite3.\nThis is the reason I don't like this solution since it makes stuff ugly and cluttered. And I only use it as a last resort.\nIn the Virtual Host configuration, add the following line (Changing the paths as required of course):\nAlias /mysite3 /home/mysite3/\n# Notice that there isn't a trailing slash\n# So this won't work: Alias /mysite3/ /home/mysite3/\n\nOf course, if you need to add some apache configuration to the directory, the also need to be done in the same host file.\n<Directory /home/site3/>\n    AllowOverride All # Just an example\n</Directory>\n\n3. (Bonus) Combining both solution\nThis is better then the second solution, but not as good as the first one\nThe default Virtual Host file is the first one loaded by apache. And by default, apache loads them alphabetically. So, what you can do, you can create a new virtual host file which would precede all your other virtual hosts files.\nFor example, 000-default (Which is now done in the default configuration of apache2.4).\nThen create all your Aliases in that Host file, and the default URL of this virtual host would go to a 403 page. So in the end, you would get this:\nwww.mysite1.com   --> /home/mysite1\nwww.mysite2.com   --> /home/mysite2\nxx.xx.xx.xx       --> 403 Error\nxx.xx.xx.xx/site3 --> /home/site3\nxx.xx.xx.xx/site4 --> /home/site4\n\nThis is preferred over the second solution, since that one might conflict with your other sites. For example, it might get messed up with your URL rewrites.\n", "Q: No keyboard response in applications due to permissions of /.config/ibus/bus I was running into an error using the Android SDK-- the error message was:\nThe owner of /home/[username]/.config/ibus/bus is not root!\n\nSo, like a moron I did a sudo chown root:root /bus command.\nNow, I can type in the search bar, but not in any application (including terminal).  Any way to fix this permission?\n\nA: Press Ctrl+Alt+F1, log in then run:\nsudo chown -R $USER: $HOME\n\n", "Q: ISC-DHCP-SERVER (primary/secondary) - Can Load Balancing Be Disabled? When I was hired at my company, I quickly determined that one of my highest priority projects would be to improve our ancient DNS/DHCP setup. It was running on an Ubuntu-based workstation-grade server that was more than 7 years old, and was in serious danger of keeling over. So, I started researching options for adding fault tolerance. I ended up building a standard Ubuntu Server 12.04.3 LTS 64-bit ISC DHCP failover cluster with a primary and secondary server, utilizing load balancing. The way things currently work, if my DHCP range consists of 54 IPs, the 2 servers split the IP pool evenly (27 each) while remaining in constant communication with one another. If one of the servers goes down for more than an hour without getting put into a partner-down state, my life then becomes hell.\nI've since come to realize that the load balancing aspect is overly complex, and VERY unnecessary for our small shop. Unfortunately, I've been unable to find any documentation on how to create a simple primary/secondary relationship, whereby the secondary will take over all responsibilities in the event the primary experiences a failure (it would ideally function as a hotspare). Does this functionality exist within ISC-DHCP-SERVER v4.1.ESV-R4-0ubuntu5.6? If so, how in the world is it configured? I've seen mention of things such as \"split 256\" (as opposed to the \"split 128\" I'm currently using), but I can't find anything to definitively confirm this. If the convoluted load balancing feature is a requirement for fault tolerance, then so be it. Also, a quick note that I'm more of a Windows Admin than a Linux Admin, so please be gentle :P\nThanks,\n-Snipe\n\nA: https://kb.isc.org/article/AA-00502/0/A-Basic-Guide-to-Configuring-DHCP-Failover.html\nthe first comment answers this i Think:\n\n[Michael McNally]: Re: Failover without load balancing2014-03-04 00:01 That's what the \"split\" or \"hba\" values are for -- you can read\n  more about them in the dhcpd.conf man page.\nSetting a split value of 128 divides responsibility for the clients\n  between the two failover partners. But if you want one partner to be\n  principally responsible for all clients and the other partner to only\n  grant leases if the client has been retrying for more than a certain\n  number of seconds or if the peer is in partner-down state, you can set\n  the split to 0 (secondary is chiefly responsible for answering) or 255\n  (primary is chiefly responsible for answering.)\n\"split\" and \"hba\" are mutually exclusive -- you can use one or the\n  other but never both.\nYou may also want to read about the \"load balance max seconds\"\n  setting, which tells how long a client is expected to retry before the\n  peer will answer even for clients for which it is not principally\n  responsible.\n\n", "Q: Computer missing firmware? I have an iMac G5 that I'm looking to install Ubuntu, Kubuntu, etc, and release of Ubuntu on to. Whenever I try to install any version (I've only tried 12.04 and above), I install the OS without errors, but when I restart after installation, I get an error that told me to go to wireless.kernel.org/en/users/Drivers/b34#devicefirmware. Again, this works with every Ubuntu release I've tried on this specific computer.\nI have, although, successfully installed Ubuntu 12.04 on a Mac mini G4, which works entirely fine, which is confusing, because I had no need to install firmware on that, yet I have to install seemingly new firmware on a computer that is older.\nThis iMac runs on a PPC processor, so it's probably no longer supported. \nBy the way, I'm completely and totally new to Ubuntu, and I probably have no idea what I'm doing. I needed to switch to something other than OS X because neither of my 2 semi-old macs seem to co-operate with OS X very well. My Mac mini is fine, but this iMac G5 will not stop giving me issues.\nI'd really appericate any help that anyone out there might have.\nThanks in advance.\n\nA: The firmware referred to is proprietary firmware for the specific wireless device in the machine. With a temporary wired ethernet connection, it can be installed with:\nsudo apt-get install firmware-b43-installer\n\nReboot and the message will be gone and the wireless present.\n", "Q: apache 2 not restarting Hi I am having trouble restarting Apache, I get the error\n(99)Cannot assign requested address: make_sock: could not bind to address 58.108.248.95:80\nno listening sockets available, shutting down\nUnable to open logs\nAction 'start' failed.\nThe Apache error log may have more information.\n\nwhen I run the command \nsudo netstat -ltnp | grep ':80'\n\nthis is what I get:\ntcp   0  0 127.0.0.1:8080  0.0.0.0:*    LISTEN      2320/python\n\nif I clear the port using \nsudo kill -9 2320\n\nand then restart apache2 I still get the same error\nif anyone has any info it would be greatly appreciated !!!\n\nA: Assuming you installed from a standard package, you should be able to use \nsudo service apache2 restart\n\nYou might also try the older\nsudo /etc/init.d/apache2 restart\n\n\nA: As looking into your netstat output it seems like yout default port 80 is not listening . first try to open port 80 then try restarting apache service\n", "Q: Change Default Scale Method Setting for KDE Wallpapers I wish to change the default scaling method for the desktop wallpaper in KDE(more specifically Kubuntu) by editing the configuration file KDE uses to fill in those defaults on a fresh install.  So that, when any new account is created, or someone is installing the OS, it is set to Scaled & Cropped instead of zoomed or scaled.\nI know that gnome has this default setting stored in, \n/usr/share/gnome-background-properties/ubuntu-wallpapers.xml\n\nor in,\n/usr/share/gconf/schemas/desktop_gnome_background.schemas\n\nI have been searching the linux filesystem for a couple days know to find the KDE equivalent of the files listed above, but with no luck.\nI have thoroughly search '/usr/share/kununtu-default-settings' but there doesn't seem to be any configuration file for the wallpaper settings listed there.  At this point I am assuming another program, not built into KDE, is handling the wallpaper, I don't know how to determine this though.\n\nA: KDE Plasma desktop\nThe KDE configuration files: http://techbase.kde.org/KDE_System_Administration/Configuration_Files\nThe KDE is using the plasma desktop and the wallpaper is an applet/widget. The plasma desktop applet configuration file is: plasma-desktop-appletsrc.\nThe wallpaper setting can be set for the each activity/desktop.\nThe positioning information is saved to the 'wallpaperposition=X'\nwallpaperposition=0 is 'Scaled'\nwallpaperposition=1 is 'Centered'\nwallpaperposition=2 is 'Scaled & Cropped'\nwallpaperposition=3 is 'Tiled'\nwallpaperposition=4 is 'Center Tiled'\nwallpaperposition=5 is 'Scaled, keep proportions'\nkde4rc\nThe default configuration profile path is read from the /etc/kde4rc. The information is used when the new user default configuration files are made.\nThe Kubuntu is using: \n[Directories-default]\nprefixes=/usr/share/kubuntu-default-settings/kde4-profile/default/\n\nthe user can change this - as example at here\n[Directories-default]\nprefixes=/usr/share/my-default-settings/kde4-profile/default/\n\nThe Kubuntu has in the /usr/share/kubuntu-default-settings/kde4-profile/default/share/config/plasma-desktop-appletsrc:\n[AppletGlobals][plasma_applet_launcher]\nSwitchTabsOnHover=false\naskBeforeRemoval=true\n\nYou could edit your plasma desktop and then copy your ~/.kde/share/config/plasma-desktop-appletsrc to the /usr/share/my-default-settings/kde4-profile/default/share/config/plasma-desktop-appletsrc. The new user will then has your plasma applet settings as start default.\n", "Q: Unable to see my windows drives blkid shows the following\nswethamadhu@MyPC:~$ sudo blkid\n/dev/sda1: LABEL=\"System Reserved\" UUID=\"8E82D4C182D4AF49\" TYPE=\"ntfs\"\n/dev/sda2: LABEL=\"MyOS\" UUID=\"9812314912312E1E\" TYPE=\"ntfs\" \n/dev/sda3: LABEL=\"MyData\" UUID=\"0C76D84876D833E4\" TYPE=\"ntfs\" \n/dev/sda5: UUID=\"0bac628e-f3a7-4b01-a2d3-e93504d3b5bb\" TYPE=\"ext4\" \n/dev/sda6: UUID=\"d9fcd4e0-54db-46f5-9fc1-b7dd3326c2a9\" TYPE=\"swap\" \n\nand\nswethamadhu@MyPC:~$ sudo vol_id --uuid /dev/sda3\nsudo: vol_id: command not found\n\nDo suggest me what next?\nThe problem is I am unable to see my windows drives which were shown in Home earlier before some auto updates.\nThanks\n\nA: To view the contents of your ntfs partitions, you have to mount it on a specific directory.\nsudo mkdir /media/Myos /media/Mydata\nsudo chmod a+rwx /media/Myos \nsudo chmod a+rwx /media/Mydata\n\nNow mount /dev/sda2 to /media/Myos and /dev/sda3 to /Mydata\nsudo mount /dev/sda2 /media/Myos\nsudo mount /dev/sda3 /media/Mydata\n\nNow your ntfs partitions are mounted and you can view it's contents on /media/Myos and /media/Mydata directories.\nTo make your ntfs partitions  automatically mounted on boot, then you have to add the following lines on /etc/fstab file.\n# /dev/sda2\nUUID=9812314912312E1E  /media/Myos  ntfs  defaults  0  0\n# /dev/sda3\nUUID=0C76D84876D833E4  /media/Mydata  ntfs  defaults 0  0\n\nAnd you won't need to mount an system reserved ntfs partition(/dev/sda1)\n", "Q: How good is linux encrypted file system? I am using xubuntu 12 . I just used palimpsest to encrypt my external harddisk and it seems cool. But I am wondering how easy it is for someone to crack my harddisk using any tools available. And one more thing, https://help.ubuntu.com/community/EncryptedFilesystemsOnRemovableStorage asks us to do the following commands to make cracking difficult.\n sudo dd if=/dev/zero of=/dev/sdb bs=4K\n OR\n sudo badblocks -c 10240 -s -w -t random -v /dev/sdb\n OR\n sudo dd if=/dev/urandom of=/dev/sdb bs=4K\n\nSo can this be done after I have created the encrypted partition. Like My device is sdb and the encrypted partition is sdb1.\nso how should I go about these commands. \nsudo dd if=/dev/zero of=/dev/sdb1 bs=4K\n\nAnd how does random, or adding zero makes it difficult to crack.\n\nA: The zero and then random is to make it more difficult to determine where there is data, since the encrypted filesystem (if working correctly) is indistinguishable from noise. No, you cannot run those commands after you have the filesystem created (unless you will then re-install); if you do, then the system is slightly more secure then it is currently.\n\nA: You ask \"But I am wondering how easy it is for someone to crack my harddisk using any tools available.\"  I remember reading about someone who refused to hand over their password to a court and got locked up for contempt.  The police decrypted the drives not long after.  From that press report I assume no encryption is foolproof.\nYou have to think about what you are protecting and from what.  Protecting your bank details from a thief who will sell your computer for drugs, then any simple encryption will do the job.  If you are working for Mr. Al Kieda or you are another Terry Wrist then I doubt the encryption methods available will do any good when you get a knock on the door.\nNo one is going to tell you what encryption methods they can or can not crack.\n", "Q: Recovering Windows Files Through Ubuntu I am using Ubuntu after my windows 7 has crashed. Can I recover all of my files by navigating to the \"Windows 7 OS\" tab under devices and just moving everything over to the external? Which folders and files am I looking to move to get all of them? Thanks.\n\nA: I will suppose you didn't overwrite your Windows installation to install Ubuntu. If that's the case I have some bad news for you. Other than that, which files you want is irrelevant. Check out This link which uses gparted to access your windows partitions :) \nAnd to answer your question: Yes, whichever file you move to your external drive will be available.\n", "Q: how to i connect huawei dongle to my ubuntu 12.4 version? i have purchased HP pavilion laptop.Then i bought HUAWEI vodafone dongle and connect to my laptop it would not connected to my laptop.i had installed Ubuntu 12.4 version.How to i will connect this dongle to my laptop?\n\nA: Ideally once you insert your dongle; in the Network Manager Application Indicator list (on the top bar of your screen), you should now have an option something like \"Create new CDMA connection\". Click that and the setup wizard should open.\n\nA: Press Network Button in Unity panel\nPress Last Edit Option > Press Add Button > Select Mobile Broadband Press create\nThen select County, Providers and Plan.\nMethod 2\nYou can install Mobile partner software for Linux Download Here\nInstallation instruction is here in the answer of question\n", "Q: Chromium 32.0.1700.107 Ubuntu 12.04, sqlite3 database? In Chromium 32.0.1700.107 Ubuntu 12.04, I can't locate the directory in sqlite3 database? Any one can help me.\n\nA: On Ubuntu all the Chromium related database are stored under location directory\n~/.config/chromium/Default/databases\n\nYou can use \nSQLite  database Browser to view the contents of the db\n\nA: The SQLite databases are located in ~/.config/chromium.\n", "Q: How I can reset all of desktop configuration without reinstall it? Excuse me, I have some duty from my teachers to make tutorial video by records how to change and setting desktop configuration. The problem is, I have been setting all my desktop configuration. Is that any way to reset it without reinstall?\nThanks before \n\nA: The command\nunity --reset \n\nreverts your desktop settings back to default. Also, \nsudo dpkg-reconfigure unity\n\nmay help.\n", "Q: Buzzing from my speakers when idle Lenovo Y410P I have a buzzing constantly from my speakers when no sound is being played.\nIf I open sound settings, the speakers POP and then they are silent. (I don't even have to mess with any of the settings.) Once I exit, the speakers POP again and then the buzzing comes back. If I have anything that plays sound on, the buzzing goes away. \nI know others have tried turning off automute. I have tried turning off automute in alsamixer but the buzzing does not go away. \nI am using a lenovo y410p. Two sound cards show up in alsa mixer: HDA Intel MID and HDA Intel PCH:\nEDIT:\nI should also note that in alsamixer, for sound card 0[MID] I do not have any options for volume control. I only have these in alsamixer for sound card 1[PCH]. \nAudio Devices:\ncat /proc/asound/cards\n0 [MID            ]: HDA-Intel - HDA Intel MID\n                     HDA Intel MID at 0xc2610000 irq 49\n1 [PCH            ]: HDA-Intel - HDA Intel PCH\n                      HDA Intel PCH at 0xc2614000 irq 50\nSound card information from the terminal can be found here: my google doc\nNew discovery:\nWhen my computer is plugged in and I adjust any setting of the volume (mute, unmute, volume up, volume down), the buzzing goes away. As soon as I unplug my computer, the speakers POP and the buzzing comes back. \nWhen I plug the computer in, with the speakers buzzing, the buzzing continues until I adjust any setting of the volume (mute, unmute, volume up, volume down). Then the buzzing goes away. \nThis suggests to me that \"auto-mute disabled\" is being overridden on battery power. It seems like auto-mute is activating on battery power regardless of whether or not I have auto-mute disabled. Am I off-base for thinking this?\nI don't think this is an electrical issue, since I am dual booting windows and have no such problem with windows. \nEDIT: Sunday March 16, 2014\nThanks to onecoder4u for pointing out that the buzzing only happens when the keyboard back-lighting is on dim, but not when keyboard back-lighting is off or on high. \nOk, I can live with not having my keyboard on dim. This solves the buzzing but not the popping issue. I still get a loud pop from my speakers whenever the computer switches between playing sound and not playing sound. I have no issues at all when my computer is plugged in. \nI would mark this question as answered, but I am still having part of the problem.  \n\nA: Not sure if this is your issue, but my Y410p with ubuntu 13.10 has this issue.\nI get a high pitch noise if I have my keyboard backlight on low brightness.  If the keyboard backlight is off or on high no noise.   I use the fn+space to toggle it.\n\nA: I had similar problem, and it was caused by skype.\ndo you have skype installed? in my case I simply turned off ALL notification sounds on skype and this fixed the problem.\n\nA: I followed the steps on this post and it completely solved the problem: Popping noise from laptop speakers\nThe issue was the power save mode on the audio cards. Note, I used nano instead of gedit make changes to the configuration files. \n\nA: Same exact thing happened to me, with Ubuntu (technically Mint) and a Y410P. If other solutions work for you please use them instead, because mine is a really backhanded, last-resort fix. I disabled my speakers and then bought a USB to stereo audio adapter and I plug my headphones into that instead of the regular jack. It works, and there is another way to get your speakers working again if absolutely necessary, but if you do this then do not forget to write down everything you do. It will save your life one day in the future, I'm sure.\n", "Q: Ubuntu 12.04 LTS always stuck in Login First time, but to recovery screen second time Presently Installed Ubuntu 12.04 LTS as stand alone through USB overwriting older linux versions option. Previously installed as dual with Windows XP. Then for about 7 times as stand alone with custom partitions. Used all space for partitions. Missing swap problem occurred. Once Nvidia driver update showed up. When updated screen went reso wrong. So I always avoid nvidia driver update. Lastly allowed a lot of free space to avoid bad sectors and installation successful. This time the missing swap area problem is not arising.\nProblem:\nBut always when boot for first time, Both mouse and keyboard inactive in Login screen. \nI have to switch off directly and reboot.\nAlways for the second time - Ubuntu leads to GNU GRUB recovery option screen. When I choose (recovery option) everything properly recovers to a working Login screen with activated mouse and keyboard.\nI am very new to Linux and Ubuntu, but can follow instructions both terminal and desktop based. I am planning for a big UBUNTU awareness program in my area and need help to make myself professional. Please do Help.\n\nA: I had a similar problem once, and what I noticed in my case was that it was user-dependant. so I simply created a new user for the staff, and used that to log in, and it was fine with the new user. I then deleted the offending user account.  from your information it is a bit hard to tell what is going on, but if you show some log files we can have some better ideas, /var/log/syslog, /var/log/dmesg, and /var/log/auth.log would be a good start.\n\nA: I overlooked the Hard Disk Bad Sectors When I do Custom Partition. So the swap cannot mount properly. So I found out size of my hard disk  Badsectors. Then I minus them from my total hard disk space and minus again with some extra space and then made the custom partition. Now the problem solved and Ubuntu began to load excellently.\n", "Q: how to encapsulate HTTP in a HTTPS session Team, hi, \nI'm looking for a solution that would allow me encapsulate incoming HTTP traffic, with HTTPS traffic from my application (HTTP in an iFrame), and deliver both as HTTPS.\nCan Squid proxy do that?\nThanks\nEtai\n\nA: You should be able to use STunnel to do that.\nhttps://www.stunnel.org\n", "Q: Can't access BIOS for USB install I am trying to install Ubuntu on my second machine now from a USB startup disk. The disk works fine as I used it yesterday to install on another machine. \nThe problem is on this second IBM machine: when I go to BOOT menu (by pressing F12) I do not see boot from USB. The only other option that might be similar is REMOVABLE DEVICE. When I select this option and hit Enter nothing happens. The light on the USB stick doesn't even flash, just my old Windows boots up normally.\nI have been attempting to access the BIOS, but the only thing I can seem to get access to is the IBM Setup Utility which seems like the BIOS, but isn't that blue screen like on my other machine. Can anyone please help me figure out how to get this going so I can install Ubuntu again?\n\nA: ploplinux is a bootable iso that will allow a machine to boot from USB or CDROM if it is not supported.\n\nA: Install PLoP using EasyBCD on Windows\nCLICK Here\nDownload EasyBCD [Just type any name or email-id and click \"Download!\"]\n\nA: i don't have much experience with ibm brand machines,   are you able to find anything that represents a boot device order?  on one of my pc's the usb stick appears in the list of connected hard drives and i have to move it to the top of the list for my computer to attempt to boot from it.\n\nA: I don't know if it's the same for you, but my IBM Thinkpad registers my live USB on the boot menu as a USB hard disk.\n\nA: If the BIOS/UEFI setup utility on your computer is not accessible, then it is possible that your computer's firmware is preconfigured to boot from bootable USB drives automatically, and the problem is that the bootable USB drive has not been created correctly, not that the BIOS/UEFI setup utility is not accessible.\nDid you create your Ubuntu installation media correctly? There are instructions for creating a bootable Ubuntu live USB at: What is the proper way of creating installation media from an Ubuntu iso?.\n\nA: ANSWER: CD was not bootable. WHen burned form windows the disk was not being read as an image. In windows the ISO file is read as a winrar archive which was not readable. I simply burned the CD on my other UBUNTU machine as DISK IMAGE and set the BOOT sequence to boot from CD, and it worked. \n", "Q: Gnome-Terminal stretch background image to fit window size Is there a way to stretch the selected image in my gnome terminal to fit the current window size?\nUsing\ngnome-session 3.2.1\n\nA: I don't think that there is a specific option to fit the image according to the window size.\nThe only options supported by gnome-terminal to modify the background are listed below:\n$ gconftool-2 --recursive-list /apps/gnome-terminal/profiles/Default | grep background\nscroll_background = false\nbackground_darkness = 0.58315799999999995\nbackground_image = /usr/share/backgrounds/Forever_by_Shady_S.jpg\nbackground_color = #000000000000\nbackground_type = image\n\nWhen I set /usr/share/backgrounds/Forever_by_Shady_S.jpg I get the following gnome-terminal window:\n\nIn order to have a background image automatically resized/adjusted to your terminal window size you could try urxvt:\nsudo apt-get install rxvt-unicode\n\nand run your terminal this way:\nurxvt -pixmap /usr/share/backgrounds/Forever_by_Shady_S.jpg -fg white\n\nThe result will automatically resize the background image when you resize the window:\n\n", "Q: How to replace a string on the 5th line of multiple text files? I want to replace the 5th line of multiple text files (file1.txt,file2.txt,file3.txt,file4.txt) with the string \" Good Morning \" using a single terminal command.\nAll the text files are located on my ~/Desktop.\nNote: My desktop consists of 6 .txt files.I want to apply the change to above mentioned 4 text files only.\n\nA: Here are a few approaches. I am using brace expansion (file{1..4}.txt) which means file1.txt file2.txt file3.txt file4.txt\n\n\n*\n\n*Perl \nperl -i -pe 's/.*/ Good Morning / if $.==5' file{1..4}.txt\n\nExplanation:\n\n\n*\n\n*-i: causes perl to edit the files in place, changing the original file.\nIf -i is followed with a file extension suffix, then a backup is created for every file that is modified. Ex: -i.bak creates a file1.txt.bak if file1.txt is modified during the execution.\n\n*-p: means read the input file line by line, apply the script and print it.\n\n*-e: allows you to pass a script from the command line.\n\n*s/.*/ Good Morning /: That will replace the text in the current line (.*) with Good Morning.\n\n*$. is a special Perl variable that holds the current line number of the input file. So, s/foo/bar/ if $.==5, means replace foo with bar only on the 5th line.\n\n\n*sed\nsed -i '5s/.*/ Good Morning /' file{1..4}.txt\n\nExplanation:\n\n\n*\n\n*-i: Like for perl, edit file in place.\n\n\nBy default, sed prints each line of the input file. The 5s/pattern/replacement/ means substitute pattern with replacement on the 5th line. \n\n*Awk\nfor f in file{1..4}.txt; do \n    awk 'NR==5{$0=\" Good Morning \"}1;' \"$f\" > foobar && mv foobar \"$f\"; \ndone\n\nExplanation:\nawk has no equivalent to the -i option¹ which means that we need to create a temporary file (foobar) which is then renamed to overwrite the original. The bash loop for f in file{1..4}.txt; do ... ; done simply goes through each of file{1..4}.txt, saving the current file name as $f. In awk, NR is the current line number and $0 is the content of the current line. So, the script will replace the line ($0) with \" Good Morning \" only on the 5th line. 1; is awk for \"print the line\".\n¹Newer versions do as devnull showed in his answer.\n\n*coreutils\nfor f in file{1..4}.txt; do \n    (head -4 \"$f\"; echo \" Good Morning \"; tail -n +6 \"$f\") > foobar && \n    mv foobar \"$f\"; \ndone \n\nExplanation:\nThe loop is explained in the previous section.\n\n\n*\n\n*head -4: print the first 4 lines\n\n*echo  \" Good Morning \": print \" Good Morning \"\n\n*tail -n +6: print everything from the 6th line to the end of the file\nThe parentheses ( ) around those three commands allow you to capture the output of all three (so, 1st 4 lines, then \" Good morning \", then the rest of the lines) and redirect them to a file. \n\nA: You could use sed:\nsed '5s/^/Good morning /' file\n\nwould append Good morning on the fifth line of a file.\nIf you want to replace the contents on line 5 instead, say:\nsed '5s/.*/Good morning/' file\n\nIf you wanted to save the changes to the file in-place, use the -i option:\nsed -i '5s/.*/Good morning/' file\n\nsed can handle more than one file at a time. You can just add more filenames onto the end of the command. You can also use bash expansions to match particular files:\n# manually specified\nsed -i '5s/.*/Good morning/' file1.txt file2.txt file3.txt file4.txt\n\n# wildcard: all files on the desktop\nsed -i '5s/.*/Good morning/' ~/Desktop/*\n\n# brace expansion: file1.txt, file2.txt, file3.txt, file4.txt\nsed -i '5s/.*/Good morning/' file{1..4}.txt\n\nYou can read more about brace expansions here.\n\nGNU awk versions 4.1.0 and higher come with an extension that enable in-place editing.  So you could say:\ngawk -i inplace 'NR==5{$0=\"Good morning\"}7' file\n\nto replace line #5 in the file with Good morning!\n\nA: I didn't see python solution so here it is:\nimport sys\nimport os\ndef open_and_replace(filename):\n\n    with open(filename) as read_file:\n        temp = open(\"/tmp/temp.txt\",\"w\")\n        for index,line in enumerate(read_file,1):\n            if  index == 5:\n                temp.write(\"NEW STRING\\n\")\n            else:\n                temp.write(line.strip() + \"\\n\")\n        temp.close()\n    os.rename(\"/tmp/temp.txt\",filename)\n\nfor file_name in sys.argv[1:]:\n    open_and_replace(file_name)\n\nBasic idea is that for each file provided on command-line as argument, we write out a temporary file and enumerate each line in the original file. If index of the line is 5, we write out line that is different. The rest is just replacing old file with temp file\nDemo:\n$> ls\nfile1.txt  file2.txt  file3.txt\n$> cat file1.txt                                                               \nline 1\nline 2\nline 3\nline 4\nGOOD MORNING\nline 6\n$> python ~/replace_5th_line.py file1.txt file2.txt  file3.txt                 \n$> cat file1.txt                                                               \nline 1\nline 2\nline 3\nline 4\nNEW STRING\nline 6\n$> cat file2.txt                                                               \nline 1\nline 2\nline 3\nline 4\nNEW STRING\nline 6\n\nThe same can be achieved with list comprehension. Below is a one-liner of the same script:\ncat /etc/passwd | python -c 'import sys; print \"\\n\".join([\"CUSTOM\"  if index == 5 else line.strip() for index,line in enumerate(sys.stdin,1)])'\n\nor without cat\npython -c 'import sys; print \"\\n\".join([\"CUSTOM\"  if index == 5 else line.strip() for index,line in enumerate(sys.stdin,1)])' < /etc/passwd\n\nWhat is left there is to simply redirect output of edited contents into another file with > output.txt \n\nA: You can use Vim in Ex mode:\nfor b in 1 2 3 4\ndo\n  ex -sc '5c|Good Morning' -cx file\"$b\".txt\ndone\n\n\n\n*\n\n*5 select 5th line\n\n*c replace text\n\n*x write if changes have been made (they have) and quit\n\nA: The following is a bash script which wraps up the perl process suggested in this answer\nExample:\n/tmp/it\nconsole:\n  enabled:false\n\nThen run the following:\n$ search_and_replace_on_line_of_file.sh false true 2 /tmp/it\n\nand the file now contains\n/tmp/it\nconsole:\n  enabled:true\n\nsearch_and_replace_on_line_of_file.sh\nfunction show_help()\n{\n  IT=$(CAT <<EOF\n\n  usage: SEARCH REPLACE LINE_NUM FILE\n\n  e.g. \n\n  false true 52 /tmp/it  -> replaces false with true on line 52 of file /tmp/it\n\n  )\n  echo \"$IT\"\n  exit\n}\n\nif [ \"$1\" == \"help\" ]\nthen\n  show_help\nfi\nif [ -z \"$4\" ]\nthen\n  show_help\nfi\n\nSEARCH_FOR=$1\nREPLACE_WITH=$2\nLINE_NO=$3\nFILE_NAME=$4\nperl -i -pe \"s/$SEARCH_FOR/$REPLACE_WITH/ if $.==$LINE_NO\" $FILE_NAME \n\n", "Q: Cannot detect 'Mobilelink ML27 Telkomsel Flash' modem in ubuntu 12.04 I am now using the USB modem 'Mobilelink HSUPA 7.2 Mbps Model ML27' to try to connect to internet in ubuntu 12.04. However, it cannot detect my USB modem and I cannot install it following Network Connections > Mobile Broadband > Add. Anyone has the experience using this USB modem?\n(This is brought in Indonesia) \n\nA: After a little bit of searching, I am able to detect the 'Mobilelink HSUPA 7.2 Mbps Model ML27' USB modem, it is in this thread (3G USB Modem Not Working in 12.04). The product key 20a6:f00e is found by lsusb and usb-devices.\n\n\n*\n\n*sudu do\n\n*nano /usr/bin/usbModemScript and type\n#!/bin/bash\necho 20a6 f00e > /sys/bus/usb-serial/drivers/option1/new_id\nThen save and exit.  \n\n*chmod +x /usr/bin/usbModemScript\n\n*nano /etc/udev/rules.d/option.rules and type\nATTRS{idVendor}==\"20a6\", ATTRS{idProduct}==\"f00e\", RUN+=\"/usr/bin/usbModemScript\"\nATTRS{idVendor}==\"20a6\", ATTRS{idProduct}==\"f00e\", RUN+=\"/sbin/modprobe option\"\nThen save and exit.\n\n*sudo reboot\nAfter reboot, it can be detected by Network Manager. I add it in the Mobile Broadband, with the following setting:\nCountry: Indonesia\nProvider: Telkomsel\nPlan: Volume-based\nNumber: *99#\nUsername: empty \nPassword: empty \nAPN: internet\nNetwork ID: empty \nType: Any\nPIN: empty\nAnd I select the option 'Connect Automatically' \n", "Q: How to provide GUI interface to all users of Ubuntu? I have \"Ubuntu Desktop\" installed in VirtualBox in a Windows 7 PC.\nHow can I configure it to provide a GUI interface to every user I create in the Ubuntu?  \nShould I install \"Ubuntu Server\" to accomplish this?  \nCan this be done in Ubuntu? I remember working in a place where solaris was installed in a server and every user used to login using cygwin and get a solaris GUI desktop.   \nCan this be done? And what is this feature called?   \nI am asking this for an event for the following purpose.  \nI want to install ruby on rails in an ubuntu machine and create 5 users in the ubuntu.  \nThese 5 users will have their own Windows 7 laptops.   \nThese 5 users should be able to get their own GUI desktop on their Windows 7 laptop.\nAnd can this be done by installing Ubuntu in Virtual Box in a Windows 7 PC? Please help.\n\nA: So, if I understand you well, you want that the users you are going to create in Ubuntu to be able to be able to access the Ubuntu desktop from their Windows PC.\nTo accomplish that, you will need to have on each Windows PC of the users a running X Server. Indeed in the Cygwin tools family there is one.\nPersonally, I use MobaXterm which provides a SSH, FTP, ... client, a local X Server and many other features.\nOnce the users are defined on the Ubuntu server, you will have to create a XDMCP sessions in this application. \nRemark: by default the XDMCP protocol is not enabled in Ubuntu. To enable the XDMCP server in LightDM edit /etc/lightdm/lightdm.conf and add the following section:\n    [XDMCPServer]\n    enabled=true\n\nThen restart LightDM : sudo restart lightdm\n", "Q: huwai 1731 ( mobile broadband ) not working with dell inspiron 3521 Please help, one of my friend shared this note ( enclosed below), I used these codes and my laptop is able open the data card but I am not getting any signals.\nI am able to work with wired connection, but wi-fi and mobile broad band are not working. Please help.\nsudo apt-get purge usb-modeswitch\nsudo apt-get update\nsudo spt-get install usb-modeswitch\nsudo apt-get update\ngksudo gedit /lib/udev/rules.d/40-usb_modeswitch.rules\n\nOnce you enter these above commands 40-usb_modeswitch.rules text file will open.\nThen, copy below mentioned lines into  40-usb_modeswitch.rules text file.\n#Huawei E1731\nATTRS{idVendor}==\"12d1\", ATTRS{idProduct}==\"1446\", RUN+=\"usb_modeswitch '%b/%k'\"\n\nSave the file\nThen type : sudo apt-get update\nThen restart the machine.\n\nA: It works for me when i plugged it into USB 2.0 port.But if its connected to USB 3.0 port it doesn't recognized as modem.\n\nA: I just did execute....\ngksudo gedit /lib/udev/rules.d/40-usb_modeswitch.rules\n\nand added the following lines (before the last line) end of file.\nSaved the file and closed it.\nRestarted the machine - That's all.\nMy Airtel 3G USB Modem HUAWEI E1731 got automatically detected. \nInternet worked like a charm.\n", "Q: Loaded Ubuntu 13.10 on Mac I've installed Ubuntu 13.10 both on a seperate partition and alongside osx on my mac and whenever I have to restart at the end of the installation, it get:\nGNU GRUB version 2.00-19ubuntu2.1\n\nMinimal BASH-like line editing is supported. For the first word, TAB lists possible command completions. Anywhere else TAB lists possible device or file completions.\n\ngrub>\n\nWhat now?!\n\nA: Boot back into your live cd and run boot-repair (instructions here) to update your grub EFI.  Provided the installation did not fail this should get your mac booting into ubuntu. \n", "Q: How to transfer music and files from Ubuntu 13.10 to Android 4.3? I'm trying to transfer files and music from my computer with Ubuntu 13.10 to my Samsung smartphone S3 Android version 4.3 with no success. Can someone please help me and guide me through the steps to do so?\n\nA: Install Rhythmbox or Banshee from Software Center and when the phone is plugged in via USB they should detect the device and allow you to directly drag and drop music into the device from within the application.\nNOTE: You may need to place your device in USB Mass Storage Mode first. When you connect the cable you should have a tick box or menu item that allows you to do this.\n\nA: Another good solution is to use google play music. I've found it to be pretty seamless. You can simply upload your music to the cloud and stream it from the Internet remotely. You may want to check it out. \n", "Q: Is there any free or paid version of Photoshop available for Ubuntu? Is there any free or paid version of Photoshop available for Linux? I'm not familiar with GIMP like software.\n\nA: There isn't a paid or free version of Photoshop for Linux you may get some success running it under WINE but an alternative would be to make GIMP look like Photoshop which is possible if your running version 2.8+. First download the latest GIMP offering 2.8+, enter Terminal and add this PPA, update your repository cache and then install GIMP.\nsudo add-apt-repository ppa:otto-kesselgulasch/gimp\nsudo apt-get update\nsudo apt-get install gimp\n\nNow you need to download the icon set. Here's the download link for the icon set: GIMP toolbox like Photoshop - Gnome-look.org\nAs Photoshop has icons In the Tool Panel that can change if you hold them down, you'll have to approximate the layout to your taste in Gimp. Here's my Layout that I chose:\n\nThe '.gimp-2.8' directory is located in your Home folder, but it's hidden, so just press Ctrl+H to toggle the hidden folders.\nYou'll place the new icon theme in the folder titled \"themes\", and if you wish you can also copy the other files that came with the set to alter the shortcuts etc. (they will overwrite the old ones, so back them up if you need to).\nChanging the UI:\n\n\n*\n\n*If you prefer Single-Window mode, select it now in the menu \"Windows\".\n\n*To get the Tool Palette narrower you'll need to drag the Brushes away from the panel. If you prefer a minimal layout and really only use the Layer and History Palette, but feel free to add/remove what you like. This is one of the big annoyances with Gimp's default layout – there's just too much on show at once and those brushes take up way too much space!\n\n*The Canvas colour also needs to be adjusted as it's not dark gray, to change this, head into 'Preferences' under the \"Edit\" menu and change Appearance →Custom padding colour and also 'Custom Padding Mode' Having a dark canvas is easier on the eyes after you've been playing with GIMP for several hours. Plus it makes it less distracting when working with photos or images.\n\n*Play around with other preferences as you wish Preferences→Toolbox→Tool Configuration to suit.\n\n*Increased the Layer Thumbnail size in here if you wish.\nAnd that's it GIMP should now look more like Photoshop and be a little more user friendly for those unfamiliar with GIMP.\n\nA: \nIs photoshop free for linux?\n\nNo Photoshop is not free for linux\n\nor any payable version of photoshop available for linux? \n\nStill No unfortunately\n\nBecause I'm not familiar with GIMP like software.\n\nI have the same problem. So my only alternative is to use photoshop cs2 which runs pretty well on wine. You can follow this tutorial to install it http://www.omgubuntu.co.uk/2013/01/photoshop-cs2-available-for-free-works-fine-in-wine\n", "Q: Trendnet TEW-664UB Not recognized in Ubuntu I just installed a Ubuntu system on my computer and its not working with my TrendNet TEW 664-UB (the device works fine in Windows 7). At first I thought this was a driver issue so I tried ndiswrapper, however, when I type in lsusb in terminal it doesn't show a Trendnet USB, it only shows the keyboard and mouse attached to it. So what can I do to get my wireless adapter working on Ubuntu?\n\nA: You can get the wireless card to work using the new rt8192cu driver created by Larry Finger:\nsudo apt-get install build-essential linux-headers-generic git\ngit clone https://github.com/lwfinger/rtl8192du.git\ncd rtl8192du\nmake\nsudo make install\nsudo modprobe 8192du\n\nEvery time you upgrade the kernel, run these commands again:\ncd rtl8192du\nmake\nsudo make install\nsudo modprobe 8192du\n\nSource: The Ubuntu Forums\n", "Q: How to change window opacity dynamically in Python and Quickly? The app is written in HTML and is running using webkit and Quickly.\nThe opacity can be changed using Glade.\nI want to add a slider functionality in HTML which will change the title of the HTML document according to the opacity.\nHow to code the main app/AppWindow.py so that it will change the opacity dynamically according to the HTML document title?\n\nA: You can use the set_opacity() method of GtkWindow object.\nIt will expect a float, so you should do a type conversion before.\ntry:\n    self.set_opacity(float(title))\nexcept ValueError:\n    pass  # Do something with the invalid value here.\n\n\nA: Glade doesn't add any magic function or properties to the widgets, it just uses what GTK provides.\nLooking at the docs, I can find that GtkWidget has a set_opacity() method. This only works since 3.8 and is the preferred way to do it. If your code also has to support GTK 3.6 and lower, use GtkWindow.set_opacity()\n", "Q: Error writing on apache2 I've problem when I want to write on apache2\n$ nano /etc/apache2/sites-available/default  \nError writing /etc/apache2/sites-available/default: Permission denied\n\nI've installed \nsudo a2enmod rewrite ; sudo a2enmod headers\n\nbut the result still error: permission denied.\nanyone have trouble same with me, can share to fix it.\nthanks advanced.\n\nA: You should use sudo command, for example sudo nano, when you want to change something in /etc directory, because it is system directory. This is default security measure in Ubuntu.\nUse\nsudo nano /etc/apache2/sites-available/default\n\nor\nsudoedit /etc/apache2/sites-available/default \n\n\nAlso, you can check permissions of the file using ls -l:\n$ ls -l /etc/apache2/sites-available/default\n-r-------- 1 root root 1411 march 11 11:41 /etc/apache2/sites-available/default\n\nIn the above example file permissions are set not allowing for writing. Let's fix it:\n$ sudo chmod u+w /etc/apache2/sites-available/default\n$ ls -l /etc/apache2/sites-available/default\n-rw------- 1 root root 1411 march 11 11:41 /etc/apache2/sites-available/default\n\nHowever, it's just a dirty example of using chmod, because root does not need the w flag to be able to write to a file, he doesn't even need to be an owner.\n", "Q: Using an already setup RAID 1 array on Ubuntu 12.04 I have just installed Ubuntu 12.04LTS on a separate HDD to dual boot with Window 7 x64. My Windows install is on an SSD and my system includes two 3TB Seagate drives in Raid 1. Raid is provided by the motherboard's Intel chipset.  The SSD is on a different Sata chip by AsMedia. The mobo is an AsRock Z77-Pro4.\nIn Windows, I have the Intel Storage software that checks the Raid array for synch problems and any other issues.  This works fine.\nWhat I would like to ask is whether that same Raid array can be seen as one drive from Ubuntu. As it stands, Ubuntu recognises that I have TWO separate 3TB HDD, named /sda and /sdb.\nIs there a way for Ubuntu to recognise that both these drives are in fact supposed to be seen as one and keep them in sync if I change or update something in one of them?  Will the change be reflected in both of them once the array is accessed through Windows?  \nThank you for any help.\n\nA: What you have is known as a Fake Raid.  If you install the dmraid package, it will recognize the array and create a device in /dev/mapper/ that you can use to access it correctly.  Be sure to use that device, and not the individual disks.\n", "Q: How to keep a maximum of 79 characters per line in case of Python list comprehensions? I have function which consists of 1 line. It is something like:\nreturn [item for item in list if something_very_long and something_else_very_long] == []\n\nHow is it most appropriate to separate this statement to adhere to PEP-8 guidelines of keeping a maximum of 79 characters per line? I couldn't find an example like this in PEP-8 documentation.\n\nA: The other answers say you should rewrite your list comprehension to a normal loop. It's much easier than that, and you can keep your list comprehension.\nYou can split wherever you want, it's the same as a statement with parentheses.\n# Splitting too much just for the sake of example\nreturn [item for item in list if \n        something_very_long and \n        something_else_very_long] == []\n\n\nA: I voted to close. This is really not about Ubuntu. Just in case you need an answer quickly: don't use a list comprehension if it is too complex. Just try.\noriginal_li = [1,2,3,4,5]\nnew_li = []\nfor itm in original_li:\n     if condition1 and condition2:\n         new_li.append(itm)\n\nor if the conditions are still too long:\noriginal_li = [1,2,3,4,5]\nnew_li = []\nfor itm in original_li:\n     if condition1:\n         if condition2:\n             new_li.append(itm)\n\nNow you have the list you need. You could wrap this up in a function of course.\n\nA: It is same as\n   var1=[]    \n    for item in list:\n        if something_very_long and something_else_very_long:\n            var1.append(item)\n    if var1: return var1\n\n", "Q: how to create a domain with apache2 lamp I want to create a mail server for which a domain is required. I want to access a particular directory in WWW folder with a domain name instead of writing www/foldername. can I do this??\nI tried this:-\n        # Setup \"foldername.tld\" Virtual Host\n <VirtualHost *:80>\n ServerName foldername.tld\n  DocumentRoot /home/user/var/www/foldername\n\n <Directory /home/user/var/www/foldername>\n    Options Indexes FollowSymLinks Includes\n    AllowOverride All\n    Order allow,deny\n    Allow from all\n </Directory>\n </VirtualHost>\n\nI created a file called foldername.tld in /etc/apache2/sites-available/.\nI am using ubuntu 12.04 lts.\nplease help me out.\n\nA: Your config file looks correct.\nI would have started it by :\n    <VirtualHost foldername.tld:80>\n    (...)\n\nThis way, you can later create other virtual hosts (if needed).\nUsing '*:80' will catch all requests going to this server on port 80 to the virtual host only.\nThen at DNS level you just have to let foldername.tld point to the address of your web server (via an A record or via a CNAME to an already defined A record).\n", "Q: How to know if the OS is desktop or server version We have both Ubuntu 12.04 LTS server and desktop editions installed in office. How do I know if the installed ubuntu was server or desktop edition (forget GUI as all are CLI).\nUname -a and lsb-release or os-release just don't help you identify it.\nI have seen a post on this forum but its 3 years old which tell you to identify from kernel but as far as I remember, from 12.04 edition onwards ubuntu used same kernel for both desktop and server editions so whats left to identify.\n\nA: It does not matter, there is no difference in kernels any more.\nThe only differences is the installer and the default packages.\nOnce installed you can have exactly the same OS configured, no matter if you start from the server or desktop installer.\n\nWhat's the difference between desktop and server?\nThe first difference is in the CD contents. The \"Server\" CD avoids including what Ubuntu considers desktop packages (packages like X,\n  Gnome or KDE), but does include server related packages (Apache2,\n  Bind9 and so on). Using a Desktop CD with a minimal installation and\n  installing, for example, apache2 from the network, one can obtain the\n  exact same result that can be obtained by inserting the Server CD and\n  installing apache2 from the CD-ROM.\n      The Ubuntu Server Edition installation process is slightly different from the Desktop Edition. Since by default Ubuntu Server\n  doesn't have a GUI, the process is menu driven, very similar to the\n  Alternate CD installation process.\nBefore 12.04, Ubuntu server installs a server-optimized kernel by default. Since 12.04, there is no difference in kernel between Ubuntu\n  Desktop and Ubuntu Server since linux-image-server is merged into\n  linux-image-generic.\nFor Ubuntu LTS releases before 12.04, the Ubuntu Desktop Edition only receives 3 years of support. This was increased to 5 years in\n  Ubuntu LTS 12.04 In contrast, all Ubuntu LTS Server Edition releases\n  are supported for 5 years.\n\nhttps://help.ubuntu.com/community/ServerFaq#What.27s_the_difference_between_desktop_and_server.3F\n", "Q: How to know the time/date of when the packages are installed? I installed and removed so many packages on my system.But it don't know when it was installed and when it was removed.\nI want to know when the packages are installed on my PC.\n\nA: I'd improve on things simply with:\n$ zgrep -sh ' install iperf' /var/log/dpkg*\n2013-02-21 14:07:46 install iperf:amd64 <none> 2.0.5-3\n\nzgrep doesn't care if you hand it uncompressed data so it's just easiest to use that. Obviously if you need every install you could remove iperf and see everything, but it seems more logical to search down on that at the same time.\n", "Q: What command is Thunar using to mount USB device? I set up rsync as an hourly cron job to back up data to an external USB device which is always plugged into my machine.\nI see that Thunar (version 1.6.3 / Xubuntu 13.10) can mount this device when I just click on it in the left pane of the file manager under Devices. I can also right-click to \"eject\" it.\nI want to know the actual command Thunar uses to mount/unmount the device without needing sudo. Then I can put the same command in autostart so that rsync can do its work. Now, if I forget to mount the USB device, rsync won't do the backup.\n\nA: Thunar, in xubuntu, uses udisks for it's volume management. Having said so, once thunar-volman is notified about a new device from udev, it does:\nudisksctl mount -b /dev/$block\n\nIt just replaces block with whatever is being mounted, and throws it in /media, depending on the label in the filesystem. Some file managers use a dbus call to org.freedesktop to access the udisk mount methods, but whether it's the dbus call or the udisksctrl command, as long as there is a rule in your policy kit config, the command will run.\nRef: http://ubuntuforums.org/showthread.php?t=2204350&page=2&p=12925064#post12925064\n", "Q: How can you make the system print dialogue default in chrome? Chrome has its custom feature-limited print dialogue which i always skip in order to use the system print dialogue.\nIs it possible to make the system print dialogue default?\n\nA: You could use Control+Shift+P.\nChrome also supports a --disable-print-preview mode where the dialogue is completely removed.\ngoogle-chrome --disable-print-preview\n\nTo persist this, you'll need to hack around the existing launcher. The easiest way is with alacarte (the menu editor). Just add the flag before the %U so you're left with something like this as the command:\n/usr/bin/google-chrome --disable-print-preview %U\n\n", "Q: Is there an exposé like window overview feature in xubuntu? Using Ubuntu with unity and compiz it was possible for me to create a hot corner which triggered all (in-)active windows to be shown in an overview.\nIs it possible to create something similar in xubuntu?\n\n\nA: skippy-xd is the closest thing I can see.\n\n\n*\n\n*Code and bug tracker: https://github.com/richardgv/skippy-xd/\n\n*PPA: https://launchpad.net/~landronimirc/+archive/skippy-xd-daily/\nI'd check the bug tracker because this doesn't come without issues.\nYou can install the PPA with:\nsudo add-apt-repository ppa:landronimirc/skippy-xd-daily\nsudo apt-get install skippy-xd\nmkdir -p ~/.config/skippy-xd\nwget -qO ~/.config/skippy-xd/skippy-xd.rc https://raw.github.com/richardgv/skippy-xd/master/skippy-xd.sample.rc\n\nThen you just need to run skippy-xd to see the windows laid out. You can set a keyboard binding for that to make things easier.\n", "Q: Processing - /usr/lib/cups/filter/hpcups failed I am running ubuntu 13.10 on my laptop at work and cannot manage to have our printer to work.\nSetting up the printer either with the GUI or with cups (webbrowser) is working fine but no chance with printing anything since I get the error message \n\"Processing - /usr/lib/cups/filter/hpcups failed\"\nBackground:\nThe print server we have is running openSuse with CUPS 1.5.4\nmy saucy ubuntu has cups 1.7rc1\nThe IT here want to mess with my computer and downgrade cups to 1.5.4 ... :-/\nI already tried to reinstall all cups, hplip, and various dependencies with no luck ... and tried using different driver versions\nAny suggestions ?\nThanks a lot\n\nA: I meet this weird problem, too. After trying all kinds of methods, the problem is finally resolved by using latest hplip. You can download 3.14.4 from http://hplipopensource.com/hplip-web/gethplip.html and then execute the .run file.\n", "Q: Is lsblk not available for Ubuntu10.04? I tried to install lsblk, but I got this error message:\n# apt-get install lsblk\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Couldn't find package lsblk\n\nI am using Ubuntu Server 10.04 64-bit.\nIf lsblk is not available then what is the best substitution for it?\n\nA: Use blkid from the util-linux package instead:\nsudo apt-get update\nsudo apt-get install util-linux\n\nblkid\n\n\nA: From the @Oli's comment , lsblk was not included in the util-linux package for  Ubuntu 10.04 LTS versions.  \nSee this Ubuntu 10.04's util-linux package file list.So you can't able to run lsblk command on Ubuntu 10.04 LTS.\n", "Q: Echo command with color option in script and command works differently If I run echo -e \"\\e[1;31mThis is red text\\e[0m\" in comand line, It prints out red text. \nHowever, if I use write it in script file test.sh\n#! /bin/bash\necho -e \"\\e[1;31mThis is red text\\e[0m\"\n\nrun $ sh test.sh \nIt prints out \n-e \\e[1;31mThis is red text\\e[0m\nWhy they act differntly?\n\nA: echo is a shell builtin in Bash and dash (/bin/sh). If you run echo from the command line you are using the Bash builtin, if you are running your shell script with sh you are using the Dash builtin.\nThe dash version of echo doesn't know the -e option but just outputs anything verbatim without any special handling for \\ sequences.\nEither use Bash to run your shell script, or use /bin/echo instead of echo:\n/bin/echo -e \"\\e[1;31mThis is red text\\e[0m\"\n\nTo avoid the problems with different versions of echo you may want to use printf instead. In contrast to echo printf always interprets \\ sequences but doesn't automatically add a linefeed at the end so you have to append \\n at the end if you want one.\nAs some versions of printf don't understand \\e you should use \\033 instead:\nprintf \"\\033[1;31mThis is red text\\033[0m\\n\"\n\n\nA: This needs the correct command in the correct format is all. \nProper echo statement: echo \"Hello World!\"\nProper echo statement with color: echo \"\\e[1;31mHello World!\\e[0m\"\nAdding color to a bash script is one of those very simple but easily confusing things.  =)\nThis site could help explain it all clearly to you. I often use it as reference because, who can remember all the correct color codes right? LOL\n\nA: Don't run it with sh test.sh, it prints the text in white colour like you said..After creating the script, make it executable by running,\nsudo chmod +x /path/test.sh\n\n\nRun the script with sudo,like sudo ./test.sh or ./test.sh both will works.\nOr\nRun the script with bash,\nbash /path/test.sh\n\n", "Q: How to get the list of installed library packages only? I want to get the list of installed library packages only from terminal.\nIs there any command for that?\n\nA: /sbin/ldconfig -p\n\nThe -v option will show the libraries version.\nResult:\n267 libs found in cache `/etc/ld.so.cache'\n        libz.so.1 (libc6) => /usr/lib/libz.so.1\n        libz.so (libc6) => /usr/lib/libz.so\n        libxslt.so.1 (libc6) => /usr/lib/libxslt.so.1\n        libxml2.so.2 (libc6) => /usr/lib/libxml2.so.2\n        libxcb.so.1 (libc6) => /usr/lib/libxcb.so.1\n        libxcb-xlib.so.0 (libc6) => /usr/lib/libxcb-xlib.so.0\n        libwrap.so.0 (libc6) => /lib/libwrap.so.0\n        libvolume_id.so.0 (libc6) => /lib/libvolume_id.so.0\n        libuuid.so.1 (libc6) => /lib/libuuid.so.1\n        libutil.so.1 (libc6, hwcap: 0x8008000000008000, OS ABI: Linux 2.6.8) => /lib/tls/i686/cmov/libutil.so.1\n        libutil.so.1 (libc6, OS ABI: Linux 2.6.8) => /lib/libutil.so.1\n        libutil.so (libc6, OS ABI: Linux 2.6.8) => /usr/lib/libutil.so\n        libusb-0.1.so.4 (libc6) => /lib/libusb-0.1.so.4\n        libusb-0.1.so.4 (libc6) => /usr/lib/libusb-0.1.so.4\n        libulockmgr.so.1 (libc6) => /lib/libulockmgr.so.1\n        libt1x.so.5 (libc6) => /usr/lib/libt1x.so.5\n        libt1.so.5 (libc6) => /usr/lib/libt1.so.5\n        libtiff.so.4 (libc6) => /usr/lib/libtiff.so.4\n        libticw.so.5 (libc6) => /lib/libticw.so.5\n\nIf you want to turn that list into a list of packages, you can do something like this:\ndpkg -S $(/sbin/ldconfig -p | awk 'NR>1 { print $NF }')\n\nAnd you can further massage that to cut out errors, unneeded components and duplicates:\n$ dpkg -S $(/sbin/ldconfig -p | awk 'NR>1 { print $NF }') 2>/dev/null | sed 's/\\: .*$//' | sort -u\nakregator\nark\nbinutils\ncalligra-libs\ncomerr-dev\ncompiz-core\ndolphin\ne2fslibs:amd64\nfreeglut3:amd64\ngettext\n...\n\n\nA: I'm not sure there's a guaranteed way to know from a package name that a package is a \"library\" (if that's even a solid definition in itself) but you can find installed packages that start and end with lib fairly easily:\ndpkg -l | awk '($1 == \"ii\") && ($2 ~ /^lib|lib$/) { print $2 }'\n\nSome packages contain \"lib\" that aren't libraries. You'll probably need to exclude librarian and libreoffice from those:\ndpkg -l | awk '($1 == \"ii\") && ($2 ~ /^lib|lib$/) && ($2 !~ /^(libreoffice|librarian)/) { print $2 }'\n\nThis is still going to miss out a dearth of python-... libraries.\n\nA: And aptitude came to the rescue:\naptitude search '?and(?section(libs), ~i)'\n\nIt reads: looks for packages that contains libs in their ?section and that are installed (~i).\nYou can use this to look for just all libraries in your repository:\naptitude search '?section(libs)'\n\nThis method obviously need of aptitude.\n\nA: You can use the following command for finding all installed packages in Ubuntu:\napt list --installed\n\nYou can search for a specific package using:\napt list --installed <package_name>\n\nIn case the above commands are not be permitted to be run by the user, then add sudo in front of them.\n", "Q: How do I make the shell to recognize the file names returned by a `ls -A` command, and these names contain spaces? This is the part of the script I am using to rename the files returned by ls -A:\nfor FILE in `ls -A`\ndo\n        ext=${FILE##*.}\n        NUM=$(($NUM+1))\n        NEWFILE=`echo $2_$NUM.$ext | sed 's/ /_/g'`\n\n        mv \"$FILE\" \"$NEWFILE\"\ndone\n\nBut can not find names with space!\nThe $2 parameter can not be the cause of the error why I ever step a name without a space as a parameter, and this script takes that name and rename all files in the folder so to let them numbered and does not modify the file extension.\nUnfortunately it does not rename files with spaces in the name.\nCan someone help me?\n\nA: You can include hidden files ('dot files') in the bash '*' shell glob by setting the dotglob shell option\nshopt -s dotglob\nfor file in *\ndo \n  echo \"$file\"\ndone\n\ne.g. for a directory that contains file, file with spaces and .hidden file (the last of which is hidden and has a space) this produces \nfile\nfile with spaces\n.hidden file\n\nYou may want to add the nullglob option as well to prevent an error condition in the case that the directory is empty - see the excellent BashFAQ/004 . Remember to quote the variable \"$file\" and also it's best practice not to use all-caps for your variable names. \n\nA: ls -A for me writes multiple filenames on one line, separated by white space. If you tried adding -1 as in ls -A1 that would output one filename per line, and might work better for you.\nI've run into the same problems with spaces in filename, espeically when using find, but separating names with a null character handles spaces & newlines in filenames: find (...) -print0 | xargs -0 (do stuff here)\nBut, if you just want to rename files you might consider man rename it can do things like:\nFor example, to rename all files matching \"*.bak\" to strip the extension,\nyou might say\n     rename 's/\\.bak$//' *.bak\nTo translate uppercase names to lower, you'd use\n     rename 'y/A-Z/a-z/' *\n\nOr for a gui solution for a few directories Thunar has a nice Rename Multiple Files interface that can do numbering how you're describing too. I just tried some filenames with spaces combined with find to Thunar and it seems to work:\nfind . -type f -print0 | xargs -0 thunar -B\n\nA: In case you haven't figured out yet, parsing ls is a Bad Idea®. Unless you can know that your file names will always be sane (you usually can't), you need to be able to deal with file names containing:\n\n\n*\n\n*spaces and tabs\n\n*consecutive spaces or tabs\n\n*newlines (\\n)\n\n*carriage returns (\\r)\n\n*backslashes (\\)\n\n\nAll of the above are allowed by the Linux kernel (and are guaranteed to drive your sysadmin mad). The following two methods can deal with any combination of the above. I am using cp file directory/ as an example command):\n\n\n*\n\n*Use find and its -exec option, the {} will be replaced by each file or directory found.\nfind . -exec cp {} directory/\n\n\n*Pipe find's results to xargs as null separated strings (-print0), tell xargs to read null separated (-0) and tell it to replace {} with each file/directory name (-I {}).\nfind . -print0 | xargs -0 -I {} cp {} directory/\n\n\n*Use the shell alone, to match dotfiles as well, activate dotglob \n shopt -s dotglob\n for i in *; do cp -v \"$i\" directory/; done\n\n\n*Combine the power of find and the versatility of the shell\nfind . -print0 | while IFS= read -r -d '' i; do cp \"$i\" directory/; done\n\nThe IFS= disables splitting at spaces, the -r disables backslash escapes (allows backslashes to be treated literally), the -d '' sets the record separator (lines if you like) to null.\n\nA: for iterates over words, words are delimited by whitespace. You should not iterate over the output of ls, you should use * .*:\nfor file in * .* ; do\n    if [[ $file = . || $file = .. ]] ; then\n        continue\n    fi\n    # ...\ndone\n\n\nA: How about:\nls -A | while read fname\ndo\n    echo \"$fname\" # your code goes here\ndone\n\nPiping ls forces it to send 1 filename per line, read then accepts the line into the variable fname.  \n", "Q: How to download file on Ubuntu server I want to download files from torrent to my ubuntu server. I want to install utorrent and download files using torrent. I wanna know if it is possible? I want to download that files on my server directly so I can share them with download link directly. \nIf it is possible then how will I be able ti get link for that file to share it for downlaod? \nCan we do the same using any contropanel? Don't think so. I just want to save those file downloaded from torrent to my server and share their download link to people. Please tell me ow is it possible. I am asking this because I don't want to download the files first on my computer than upload it to server.  \n\nA: I would suggest installing deluge, specifically deluged (deluge daemon) and deluge-web (web control panel).\nComprehensive instructions can be found here:\nhttp://dev.deluge-torrent.org/wiki/UserGuide/InitScript/Ubuntu%2011.04%2B%20(Upstart%20Job)\n", "Q: How to mount novell share? I would like to mount netWare service on my linux.\nCould someone give me example how such a line should looks like in fstab?\n\nA: From the directions here,\nEXAMPLE:\n1) Verify the installation of ncpfs:\nlinux~# rpm -q\nncpfs-2.6.6-7\n\n2) Create a mountpoint for the server\nlinux~# mkdir /mnt/myserver\n\n3) Create a group to assign the filerights to\nlinux~# groupadd nwaccess\n\n4) Assign users to the defined group\nlinux~# usermod -G nwaccess veerh01\n\n5) Create a password file\nlinux~# echo myserver/myuser.location.nds:mypassword >/etc/ncp-pass\nlinux~# chmod 600 /etc/ncp-pass\n\n6) create a mount line in /etc/fstab - that is edit /etc/fstab with your favorite editor and add a line to it with the following definitions:\n<server/user> <mountpoint> ncp uid=root,gid=<group>,mode=660,owner=root,A=<server>,passwdfile=/etc/ncp-pass     0 0\n\nFor the example described above it becomes:\nmyserver/myuser.location.nds /mnt/myserver ncp uid=root,group=nwaccess,mode=660,owner=root,A=myserver,passwdfile=/etc/ncp-pass 0 0\n\n\nA: We (still) run a mixed back of netware and OES servers.\nTo attach to the netware servers we tell our users to use the following cifs command:\nsudo mount -t cifs //NETWARESERVER/VOLUMENAME /mount/point/ -o username=USERNAME,file_mode=0777,dir_mode=0777,sec=ntlm\n\nThe most important part in that is the sec=ntlm since netware is running an earlier version of cifs.\nTo attach to OES servers we tell the users to run the same command, but without the sec-ntlm option.\nIf you're adding this to fstab  I think you would need to also add a password=PASSWORD to the options too.\nHope that helps.\n", "Q: When/why do I need to make/install linux headers? The use case is installing Ubuntu Core to run as an appliance. The machine:\n\n\n*\n\n*will run a single task,\n\n*is preferably slimmed down to have low disk space consumption,\n\n*has the (custom) kernel installed via a .deb file (not the \"linux\" meta package)\n\n\nThe kernel compile make-kpkg command suggest to include kernel_headers.\nBut why and/or when do I really need (or is it wise) to make and/or install linux headers (package)?\n\nA: You need the linux headers when you plan to develop and compile on the machine where you've installed Ubuntu.\nIf you build an appliance dedicated to a specific task, you are certainly not willing to compile on it.\nIf you need to compile your own application, you will do this on an different system. A development one and copy the compiled code to the appliance.\n\nA: I have never heard of this tool and suggest you follow the\nKernel Team documentation for building a kernel from source.\nInstalling kernel-headers never hurts and is required for any build\nfrom source driver provided by a dkms package.\n", "Q: Moving files from several subdirs to a main dir So I recovered all the files that were still available on a corrupted external drive using testdisk. Now I want to sort out the different file extensions and copy them to their respective newly created main directories (.jpg / .doc / .xls etc...)\nAfter some looking around I found that the following entry in the commandline should do the trick, however I get a message stating there is a missing argument for -exec, meaning I am actually stuck. Any input?\nfind /media/DRIVE-N-GO/Backup\\ Wiebe/ -type f -name *.jpg -exec cp {} /media/Elements/jpgs/ \\\n\n\nA: find /media/DRIVE-N-GO/Backup\\ Wiebe/ -type f -name \"*.jpg\" -exec cp \"{}\" /media/Elements/jpgs/ \\;\n\nYou were missing a ;.\nThe quotes are around the search term for preventing bash from expanding the asterisk\nThe quotes around the parameter of cp are when some files with spaces in the name are hit - because then cp would fail\n\nA: You have to finish the command with an escaped semicolon:\n... -exec cp {} directory \\;\n\n", "Q: Can I configure Ubuntu to remove apt-get and dpkg? I need to completely remove any methods for making changes to my system. Is there a way to remove apt-get and dpkg? Is it possible to also disallow changing executable bit to any files copied into my system? Can this be done with a mask? \n\nA: You could remove the execute bit from apt-get and dpkg; \nchmod -x $(which apt-get)\nchmod -x $(which dpkg)\n\nBe aware that this will disable updates. Also, you could mount the drive read-only. \n\nA: I think with the advent of functional \"micro\" deployments using LXC and Docker that this might become increasingly relevant. \nI can think of reasons why I would create a bash environment in a container, put utilities in it that require to be run as root, make a variety of devices available to the container by having it launch in privileged mode, but NOT want the user of that container to add any new software.  \nWith the layered revisions of containers - then \"once removed you can't go back\" is not true. I can iterate on my docker utility container - but deliver it in \"final\" form. \nUSE AT YOUR OWN RISK (and I wouldn't recommend this other than in docker style work):\nAt least in Precise you can apt-get remove apt leading to this interaction below:\napt-get remove apt \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages will be REMOVED:\n  apt ubuntu-minimal\nWARNING: The following essential packages will be removed.\nThis should NOT be done unless you know exactly what you are doing!\n  apt\n0 upgraded, 0 newly installed, 2 to remove and 57 not upgraded.\nAfter this operation, 3300 kB disk space will be freed.\nYou are about to do something potentially harmful.\nTo continue type in the phrase 'Yes, do as I say!'\n ?] Yes, do as I say!\n\n(now of course if scp or other file transfer programs are available to the container, someone can fiddle this all back in.)\n", "Q: Cannot acess my own Username directory My directory root is: $home/pk\nThe problem is that I'm unable to enter into home directory. When I type commend cd /pk, it gives an error, saying file or directory not found. When i type -ls command on terminal, it shows pk directory.   \nHow can I access my home directory?\n\nA: To enter in your home folder, just type cd without parameters.\n\nA: You can also run the full path:\ncd /home/pk/\n\nMostly, your home directory is located inside /home.\n\nA: You have to run,\ncd pk\n\nnot,\ncd /pk\n\ncd /pk searches for pk directory inside /.\n", "Q: Can I use GTK+ stock icons in a free closed source business application? If so, have I to indicate anything in license (classical \"About\" window)?\n\nA: Stock icons are taken from the user's currently used icon theme, you don't have to include them in your program. So you only have to follow the GTK+ license terms to use them.\nIf you want to ship a special icon theme with your program have a look at that icon theme's license if you are allowed to do so and what kind of attribution you have to show.\n", "Q: Is there a way to limit the upload rate of a particular application? I am looking for a way to set the limit on the upload rate for an application without limiting the entire machine.\nThe use case is the following:\nThe user (myself) creates a large file with the intention of uploading it to a video hosting site. However, the files are large and the internet connection is slow. So it can take hours (often tens of hours) to upload these files.\nWhile the file uploads it is very difficult to use the internet. Due to the complete take ofver the upstream by the file upload.\nThe goal is to be able to limit the browser to 80% of the internet connection speed.\nThe perfect solution would be to be able to change the limit during the process of upload without having to restart anything or interrupt the upload itself. (Say the user wants to take the nap, bath, something to eat, etc, and is able to temporarily allow the upload to take the whole 100% of the ISP limit).\n\nA: Try to install trickle\nsudo apt-get install trickle\n\n\nTrickle is a voluntary, cooperative bandwidth shaper. it works\n  entirely in userland and is very easy to use.\nThe most simple application is to limit the bandwidth usage of\n  programs.\n\nhere's a reference: http://www.tuxradar.com/content/control-your-bandwidth-trickle\n\nA: Yes so can use iptables to mark a packed based on the process (--pid-owner) and then use tc to limit the bandwidth.\nTry reading this link for example and see the HTTP outbound traffic shaping: just imagine doing the same but make the iptables mark rule apply to a PID instead of port 80!\n", "Q: proper package installation in Ubuntu I have read an introduction about PPA at ubuntu PPA and would like to revise my habit of installation in Ubuntu: \nSo, when I come to a Web page, click download for Ubuntu/Linux version and install the package by double-click or run an install script. What type of installation is that? is that the cause of unmet dependencies sometimes?\n\nA: If you're installing Debian packages (*.deb), this won't result in unmet depencencies. APT does the same: It downloads the deb file from the Ubuntu archives (or other PPAs) and installs them. The difference is: APT resolves unmet dependencies automatically. If you got unmet dependencies after installing a deb file, run apt-get install -f. This will try to resolve all unmet dependencies for you.\nInstallation by script usually keeps its fingers from APT or deb files, mostly it just copies the downloaded files to the destination directory (and compiles them previously if needed)\nSo either way: Fix unmet dependencies with apt-get install -f\n", "Q: NDK_ROOT enviroment variable defined but script does not see it In my ~/.bashrc i have this:\nexport ANDROID_SDK=~/Devel/android_dev_x64/sdk\nexport ANDROID_NDK=~/Devel/android-ndk-r9d\nexport NDK_ROOT=$ANDROID_NDK\nexport COCOS2DX_ROOT=~/Devel/cocos2d-x-2.2.2/cocos2dx\nexport PATH=${PATH}:${ANDROID_SDK}/tools:${ANDROID_SDK}/platform-tools:${ANDROID_NDK}:${COCOS2DX_ROOT}\n\nWhen I type $NDK_ROOT in my terminal I can see taht it is defined however when I'm running the script below it gives me:\nNDK_ROOT not defined. Please define NDK_ROOT in your environment or in local.properties\n\nhere is the script:\n#NDK_ROOT=\"/opt/android/android-ndk\"\nAPPNAME=\"CrystalCraze\"\n\n# options\n\nbuildexternalsfromsource=\nPARALLEL_BUILD_FLAG=\n\nusage(){\ncat << EOF\nusage: $0 [options]\n\nBuild C/C++ code for $APPNAME using Android NDK\n\nOPTIONS:\n-s  Build externals from source\n-p  Run make with -j8 option to take advantage of multiple processors\n-h  this help\nEOF\n}\n\nwhile getopts \"sph\" OPTION; do\ncase \"$OPTION\" in\ns)\nbuildexternalsfromsource=1\n;;\np)\nPARALLEL_BUILD_FLAG=\\-j8\n;;\nh)\nusage\nexit 0\n;;\nesac\ndone\n\n# exit this script if any commmand fails\nset -e\n\n# read local.properties\n\n_LOCALPROPERTIES_FILE=$(dirname \"$0\")\"/local.properties\"\nif [ -f \"$_LOCALPROPERTIES_FILE\" ]\nthen\n    [ -r \"$_LOCALPROPERTIES_FILE\" ] || die \"Fatal Error: $_LOCALPROPERTIES_FILE exists but is unreadable\"\n\n    # strip out entries with a \".\" because Bash cannot process variables with a \".\"\n    _PROPERTIES=`sed '/\\./d' \"$_LOCALPROPERTIES_FILE\"`\n    for line in \"$_PROPERTIES\"; do\n        declare \"$line\";\n    done\nfi\n\n# paths\n\nif [ -z \"${NDK_ROOT+aaa}\" ];then\necho \"NDK_ROOT not defined. Please define NDK_ROOT in your environment or in local.properties\"\nexit 1\nfi\n\nDIR=\"$( cd \"$( dirname \"${BASH_SOURCE[0]}\" )\" && pwd )\"\n# ... use paths relative to current directory\nCOCOS2DX_ROOT=\"$DIR/../../../..\"\nAPP_ROOT=\"$DIR/..\"\nAPP_ANDROID_ROOT=\"$DIR\"\nRESROUCE_ROOT=\"$APP_ROOT/../Shared/games/CrystalCraze/Published-Android\"\nBINDINGS_JS_ROOT=\"$APP_ROOT/../../../scripting/javascript/bindings/js\"\n\necho\necho \"Paths\"\necho \"    NDK_ROOT = $NDK_ROOT\"\necho \"    COCOS2DX_ROOT = $COCOS2DX_ROOT\"\necho \"    APP_ROOT = $APP_ROOT\"\necho \"    APP_ANDROID_ROOT = $APP_ANDROID_ROOT\"\necho\n\n# Debug\nset -x\n\n# make sure assets is exist\nif [ -d \"$APP_ANDROID_ROOT\"/assets ]; then\n    rm -rf \"$APP_ANDROID_ROOT\"/assets\nfi\n\nmkdir \"$APP_ANDROID_ROOT\"/assets\n\n# copy \"Resources\" into \"assets\"\ncp -rf \"$RESROUCE_ROOT\"/* \"$APP_ANDROID_ROOT\"/assets\n\n# copy bindings/*.js into assets' root\ncp -f \"$BINDINGS_JS_ROOT\"/*.js \"$APP_ANDROID_ROOT\"/assets\n\n\necho \"Using prebuilt externals\"\necho\n\nset -x\n\n\"$NDK_ROOT\"/ndk-build $PARALLEL_BUILD_FLAG -C \"$APP_ANDROID_ROOT\" $* \\\n    \"NDK_MODULE_PATH=${COCOS2DX_ROOT}:${COCOS2DX_ROOT}/cocos2dx/platform/third_party/android/prebuilt\" \\\n    NDK_LOG=0 V=0\n\n\nA: Do you run the script from the Bash shell? If not, you may want to define the variables in ~/.profile instead of ~/.bashrc.\nhttps://help.ubuntu.com/community/EnvironmentVariables#Persistent_environment_variables\n", "Q: weird characters in Terminal When I try to run command in ubuntu I get the garbage characters appear on command line. \nPlease look at the image the line of characters are repetation [[-^ repeating it many times. How do I fix this problem?\n\n\nA: The kind of output you are showing is normally due to a stuck key on your keyboard, you can test by using another one. Specifically, the ^[[2~ sequence is sent by Insert. So, you almost certainly have that particular key stuck.\nYou can try cleaning the Insert key, you can take the key cap off and clean behind it. If cleaning makes no difference, you will probably need to change keyboards. \n\nA: Try using the command reset.   \nreset - terminal initialization\ncheck http://linux.die.net/man/1/reset or type man reset for more info.\n\nYou can also reset your terminal through the \"Terminal\"->\"Reset\" menu.\n", "Q: ubuntu external ip addres I'm new to ubuntu and I need your help with this,\nAs you know when you install apache you put the internal ip address in your browser and you get it works, I want as well to access it from somewhere else beside my local network how do I do that ?\n\nA: You have first of all to do a port forwarding in your router that connects to the internet.\nYou may find your router here and follow the guide or you can read your routers manual if included or google your router to find some info. \nBy port forwarding you say to your router \"if someone asks something in that port forward the message to this computer\" \nNote* the default port of apache is 80\nThen you just need to know your ip address that you can find it in your router's interface or by writing in google \"my ip address\".\nFinally go to your browser and type your ip address like this: http://77.22.33.44\n", "Q: What Is Gnome, Gnome Classic and Gnome Classic(No Effects)? I am using ubuntu 12.04 lts and I was using unity 2D and i wanted to switch to unity 3D so i logged out and clicked on the ubuntu sign and there were 3 new options:\n1 GNOME\n2 GNOME CLASSIC and\n3 Gnome CLASSIC (NO EFFECTS) \nI started with all of the three one by one and I liked them but I dont what they are and how did i get them\ncan anyone tell me what they are?\nHere is a screenshot of my desktop:\n\nA: Here's the explanation:\n\n\n*\n\n*Gnome is Gnome version 3\n\n*Gnome Classic is Gnome version 2\n\n*Gnome Classic (No Effects) is version 2 but suited for less graphical VGAs\nA usefull answer is here\n", "Q: Auto Mount in Virtual Box and Ubuntu 13.04 How is it possible to auto mount in Virtual Box using Linux 13:04? \nI tried to put in fstab and rc.local \nProject/mnt/Project vboxsf umask=002,gid=1000,uid=1000 \n\nbut did not work \nCan anyone help me? When I put these files get an error on startup saying \n\n\"Unable to mount / mnt / Project\"\n\nThanks.\n\nA: Starting with version 4.0, VirtualBox can mount shared folders automatically, at your option. If automatic mounting is enabled for a specific shared folder, the Guest Additions will automatically mount that folder as soon as a user logs into the guest OS.\nSo you first have to install the guest addition in your VM.\nNote:\n\nAccess to auto-mounted shared folders is only granted to the user\n  group vboxsf, which is created by the VirtualBox Guest Additions\n  installer. Hence guest users have to be member of that group to have\n  read/write access or to have read-only access in case the folder is\n  not mapped writable.\n\nEnsure that the targeted users have been made member of the group vboxsf.\nSource: https://www.virtualbox.org/manual/ch04.html#sf_mount_auto\n", "Q: How to get options of choosing between windows 8 and ubuntu at start up? I installed Ubuntu 13.10 alongside windows 8.1 in a separate partition.\nBut on start up , windows 8.1 automatically boots without giving me options to choose between windows and Ubuntu.\nPlz help! I want to choose OS on start up!\n\nA: If you still have your Ubuntu disk with you, try booting from that and run grub-install /dev/sdX where X is the device letter for the hard drive that contains both Windows 8 and Ubuntu partitions, in a Terminal session.\n", "Q: Ctrl+L in terminal I accidentally typed ctrl + L in terminal and my terminal window jumped one 'screenful' size. I looked at the keyboard shortcuts in \"Edit\"->\"Keyboard shortcuts\" and didn't find that shortcut.\nWhat does ctrl + L do and where is it defined?\n\nA: Control-L is intercepted and interpreted by bash (actually by the readline library, which handles interactive editing on the command line). It is bound to the clear-screen function, as @souravc wrote. \nNote on the meaning of Control-L: It is defined as Form Feed in the ASCII character table, but this means nothing unless some program interprets it accordingly. The terminal does not clear the screen when it sees a form feed, as you can verify by by saving a ^L in a file and printing the file with cat. When bash/readline sees the ^L, it executes the clear-screen function. This sends a sequence of characters that is understood by your terminal emulator (as described by termcap or terminfo), and has the effect of clearing the screen.\nIn very old printers, a ^L would advance the paper start printing on the next sheet, hence the name \"form feed\". But modern terminals and terminal emulators follow a newer ANSI standard, in which control commands are multi-character \"escape codes\" that begin with ^[ (escape). When bash sees your ^L, it is probably sending the two-command sequence ESC [ H ESC [ J, which moves to the top left of the screen and clears everything below it (hence the whole screen).\n\nA: ctrl + L just clear the terminal screen.\nIt is the keyboard shortcut equivalent of the command clear -x. ref\nIt is property of bash, so you did not found it under keyboard shortcuts in your gnome-terminal. From man bash:\nclear-screen (C-l)\n          Clear the screen leaving the current line  at  the  top  of  the\n          screen.   With  an  argument,  refresh  the current line without\n          clearing the screen.\n\nSee a detail list of Bash Keyboard Shortcuts.\n\nA: If the shell you're using is not intercepting it, you are typing a \"Form-feed\" character in your terminal. If the terminal application does not intercept or use the keystroke in some way, Ctrl+Letter is translated to the ASCII code of the letter minus 64(1). 65 is the ASCII code of 'A', 'L' is the 12th letter -> code 76. If the shell does not know what to do of the code, it prints it. \nPrinting a FF char resulted in a new page on a line printer and a clear screen on the terminal (yes, I used a VT-52 back then, at 300 baud).  \nSo Ctrl+L is 12 which is FF. In the same way, Ctrl+I is a TAB, and Ctrl+G rings the bell --- if the terminal or the shell does not intercept it, like Ctrl+C for example. \nNotice from the other answer: it seems that bash do intercept CTRL-L and do a clear. Nice touch that the bash authors associated the key with a command which will do more or less the same that the ASCII code did on old terminals!\nOn the other hand, in my zsh the combination CTRL-I works as TAB and CTRL-H as a Backspace(2). \nOld nice ASCII... (notice that letter L is at column 4, row 12, it has ASCII code 4*16+12=76). \n\nOriginal Image here, from wikipedia article on ASCII. \n \nFootnotes: \n\n(1) Ctrl really used to clear the bit 7.\n(2) this is the source of the \"fail to remove word\" joke you sometime find like for example \"this was a bad^H^H^Hnot so nice idea\"... (with normally a word stronger than bad!)\n", "Q: Where is log file from rc.local? I have some commands to in my rc.local. I know that they are failing. How can I get log file with messages produced by executing rc.local? Where is it located?\nI have checked the /var/log/boot.log. I know my messages are not there because I know already what is the reason of failure. But I still want to make sure from log file.\nNote, I don't want to run script again, I could but I don't want. I would rather analyse wht happened during startup.\nThanks for any help.\nUbuntu 12.04 Desktop (if it matters)\n\nA: Unless a command has output or logging already configured, rc.local commands will not log anywhere.\nIf you want to see logs for specific commands, try redirecting the stdout and stderr for rc.local to somewhere you can check. Try adding this to the top of your /etc/rc.local file:\nexec 1>/tmp/rc.local.log 2>&1  # send stdout and stderr from rc.local to a log file\nset -x                         # tell sh to display commands before execution\n\nThough this will require to rerun the rc.local file.\n\nA: Look in \n\n\n*\n\n*/var/log/messages \n\n*/var/log/daemon\nOr use dmesg command\nless /var/log/boot.log\nless /var/log/dmesg\ngrep error /var/log/dmesg\ngrep <your expected error string> /var/log/boot.log\n\nOr use script or some other tool to capture a log in rc.local\n\nA: Try to check for failures in the /var/log/syslog file instead.\n\nA: With systemd rc.local is considered a service fo which systemd collects logs. You can review them with:\nsystemctl status rc.local.service\n\nYou can see errors (if they exist) through service log.\n\nA: To add to Sylvain's answer:\ngrep rc.local /var/log/syslog\nWill show you all error output related to rc.local\n", "Q: Was installing gcc 4.8, ran out of diskspace now cant use gui, how to fix? I have tried removing programs, including the unfinished gcc 4.8 install, but i get the error unmet dependancies. All the files I have left are really important so i cant delete them. Is there any other way I can fix this?\n\nA: Start by running sudo apt-get install -f. This should cater for the unsolved dependencies.\nThen you could recover space with sudo apt-get autoremove and sudo apt-get autoclean.\n", "Q: Tomcat7 deployment error I have a web application that I can build and test within my Eclipse environment. It runs perfectly fine when I run the application within Eclipse environment. However when I deployed it to my Tomcat7 server on Ubuntu, it reported errors.\nI launched my Tomcat using the following command:\nsudo /etc/init.d/tomcat7 start\n\nAnd initially it prompted to be OK at server startup:\n * Starting Tomcat servlet engine tomcat7                                [ OK ]\n\nBut when I typed the address in the browser: http://localhost:8080/RestWS, it didn't respond but just blank screen. Then it timed out and crashed.\nI looked up the log file located at /var/log/tomcat7, it shows the following error message:\nINFO: Deploying web application archive /var/lib/tomcat7/webapps/RestWS.war\nMar 14, 2014 11:19:49 AM org.apache.catalina.startup.HostConfig deployWARs\nSEVERE: Error waiting for multi-thread deployment of WAR files to complete\njava.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space\n    at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n    at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n    at org.apache.catalina.startup.HostConfig.deployWARs(HostConfig.java:751)\n    at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:471)\n    at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1412)\n    at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:312)\n    at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)\n    at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90)\n    at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:401)\n    at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:346)\n    at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:1145)\n    at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:782)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1566)\n    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1556)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n    at org.apache.tomcat.util.bcel.classfile.Code.<init>(Code.java:76)\n    at org.apache.tomcat.util.bcel.classfile.Attribute.readAttribute(Attribute.java:140)\n    at org.apache.tomcat.util.bcel.classfile.FieldOrMethod.<init>(FieldOrMethod.java:58)\n    at org.apache.tomcat.util.bcel.classfile.Method.<init>(Method.java:72)\n    at org.apache.tomcat.util.bcel.classfile.ClassParser.readMethods(ClassParser.java:268)\n    at org.apache.tomcat.util.bcel.classfile.ClassParser.parse(ClassParser.java:128)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsStream(ContextConfig.java:2032)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsJar(ContextConfig.java:1923)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsUrl(ContextConfig.java:1891)\n    at org.apache.catalina.startup.ContextConfig.processAnnotations(ContextConfig.java:1877)\n    at org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1270)\n    at org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:855)\n    at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:345)\n    at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)\n    at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90)\n    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5161)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:895)\n    at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:871)\n    at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:615)\n    at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:958)\n    at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1599)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    ... 4 more\n\nMar 14, 2014 11:19:49 AM org.apache.catalina.startup.HostConfig deployDirectory\nINFO: Deploying web application directory /var/lib/tomcat7/webapps/ROOT\nMar 14, 2014 11:20:03 AM org.apache.catalina.startup.HostConfig deployDirectories\nSEVERE: Error waiting for multi-thread deployment of directories to completehostConfig.deployWar=Deploying web application archive {0}\njava.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space\n    at java.util.concurrent.FutureTask.report(FutureTask.java:122)\n    at java.util.concurrent.FutureTask.get(FutureTask.java:188)\n    at org.apache.catalina.startup.HostConfig.deployDirectories(HostConfig.java:1018)\n    at org.apache.catalina.startup.HostConfig.deployApps(HostConfig.java:473)\n    at org.apache.catalina.startup.HostConfig.start(HostConfig.java:1412)\n    at org.apache.catalina.startup.HostConfig.lifecycleEvent(HostConfig.java:312)\n    at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)\n    at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90)\n    at org.apache.catalina.util.LifecycleBase.setStateInternal(LifecycleBase.java:401)\n    at org.apache.catalina.util.LifecycleBase.setState(LifecycleBase.java:346)\n    at org.apache.catalina.core.ContainerBase.startInternal(ContainerBase.java:1145)\n    at org.apache.catalina.core.StandardHost.startInternal(StandardHost.java:782)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1566)\n    at org.apache.catalina.core.ContainerBase$StartChild.call(ContainerBase.java:1556)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n    at java.io.DataInputStream.readUTF(DataInputStream.java:661)\n    at java.io.DataInputStream.readUTF(DataInputStream.java:564)\n    at org.apache.tomcat.util.bcel.classfile.ConstantUtf8.<init>(ConstantUtf8.java:48)\n    at org.apache.tomcat.util.bcel.classfile.Constant.readConstant(Constant.java:129)\n    at org.apache.tomcat.util.bcel.classfile.ConstantPool.<init>(ConstantPool.java:60)\n    at org.apache.tomcat.util.bcel.classfile.ClassParser.readConstantPool(ClassParser.java:209)\n    at org.apache.tomcat.util.bcel.classfile.ClassParser.parse(ClassParser.java:119)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsStream(ContextConfig.java:2032)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsJar(ContextConfig.java:1923)\n    at org.apache.catalina.startup.ContextConfig.processAnnotationsUrl(ContextConfig.java:1891)\n    at org.apache.catalina.startup.ContextConfig.processAnnotations(ContextConfig.java:1877)\n    at org.apache.catalina.startup.ContextConfig.webConfig(ContextConfig.java:1270)\n    at org.apache.catalina.startup.ContextConfig.configureStart(ContextConfig.java:855)\n    at org.apache.catalina.startup.ContextConfig.lifecycleEvent(ContextConfig.java:345)\n    at org.apache.catalina.util.LifecycleSupport.fireLifecycleEvent(LifecycleSupport.java:119)\n    at org.apache.catalina.util.LifecycleBase.fireLifecycleEvent(LifecycleBase.java:90)\n    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5161)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:895)\n    at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:871)\n    at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:615)\n    at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1095)\n    at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1617)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    ... 4 more\n\nI'm using Tomcat 7 and JDK 7 on Ubuntu 12.04. So what caused the problem? Why didn't Tomcat respond? It worked fine when I launched it in Eclipse though.\n\nA: It looks like the JVM is running out of memory, hence the error:\njava.util.concurrent.ExecutionException: java.lang.OutOfMemoryError: Java heap space\n\nCheck your Tomcat configuration and make sure that Tomcat is only allocating as much memory as is appropriate for your system.\nYou can find more information on modifying the heap size and other variables here:\nhttps://stackoverflow.com/questions/6398053/cant-change-tomcat-7-heap-size/10950387#10950387\n", "Q: Batch converting swf to png I have a folder with a lot of swf files. They are named that way: fis1.swf; fis2.swf; fis3.swf; ... fis20.swf. I want to convert all of them into png files. I know it can be done with swfrender from swftools, but it only renders one file per time.\n\nA: I'd probably use find to do this:\nfind -iname 'fis*.swf' -exec swfrender \"{}\" -o \"{}.png\" \\;\n\nBut you could probably use other sorts of loops:\nfor f in fis{1..20}.swf; do\n    swfrender \"$f\" -o \"$f.png\"\ndone\n\n\nA: First make a new file and call it for example swfconvert\ngedit swfconvert\n\nPaste the code below into it:\nfor img in *.swf; \ndo \n swfrender \"$img\" -o \"$img.png\"\ndone\n\nSave and close. Then run the new batch from terminal:\nsh swfconvert\n\nThis script should work for all swf files in a given directory. It should be saved in the same directory where your .swf files reside\n\nA: Similar to Oli answer, you can also use convert tool from imagemagick set.\nfor f in fis{1..20}; do\nconvert $f.swf $f.png\ndone\n\nThis can be put into single line as \nfor f in fis{1..20}; do convert $f.swf $f.png; done\n\n", "Q: Problem with deb installation I converted minetest-classic-1402.00-src.tar.bz2 to minetest-classic_1402.00-1_all.deb using the software alien in the terminal, using the command,\nsudo alien -k minetest-classic-1402.00-src.tar.bz2\nAfter installing the .deb using GDebi installer, it says that it is installed.\nI then go to the unity bar, and go to applications, and it is 'supposed' to be there, since I thought it was a software.\n\nA: Try to get a look into the converted deb file using your preferred Archive Manager. Does it contain the files you want? (Have a look into the data.tar.gz inside the deb file)\nIf it does, they should be on your disk where they are located in the archive. Check these locations on your disk. If the files are there, what's your problem?\nIf you're just missing the launcher file (The one listed in Dash/Application Menu), create one yourself.\nEDIT: You tried to install the sources. That won't work of course. The minetest repo contains precompiled packages, why don't you use them. Or just get it via APT, like stated in Downloads/Debian.\n", "Q: Unity launcher won't update the shortcuts after update-desktop-database (only after log out) I have written my first unity launcher shortcuts and places them in ~/.local/share/applications/.\nThe problem is that the shortcuts won't update on any of the commands I trigger in the terminal. \n$ sudo updatedb\n$ update-desktop-database\n\nOnly when I log out and log back in then the shortcuts will update.\nI have tried putting the shortcuts in root directories /usr/share/applications/ and then the shortcuts are being updated instantaneously. \nWhat is the problem here ? What is triggered on log out that trigger the update ?\nEDIT\nI have tried this answer https://askubuntu.com/a/353216/23006 to launch \n$ unity --replace \n\nbut it won't help.\nWhat will help is to go to AltCtrlF1-6 and restart lightdm by \n$ sudo service lightdm restart\n\nBut let's be honest - that's not really a solution to restart the whole DE for one unity launcher...\n\nA: the \"standard\" situation is that the launcher reads it's information from the .desktop files, located in /usr/share/applications. That is, unless the same application is represented by a local version of the .desktop file in ~/.local/share/applications.\nHowever, when you copy a .desktop file to ~/.local/share/applications/ directory, the system still links to the global one, until next login. \nFrom then on, the launcher links to the local .desktop file, and the changes you make in that local .desktop file take effect instantly.\nA Standalone quicklist (a \"home made\" .desktop file, not calling an existing installed application in its native execute line) is best located in the local directory.\n\nA: Have you tried the following?\nupdate-desktop-database ~/.local/share/applications/\n\n", "Q: Installation of Ubuntu on MSI U120 netbook How and what are the best versions of Ubuntu to install on a MSI U120 netbook? It has a Intel Atom Atom 1.6 Ghz CPU and memory of DDRII 1GB.\n\nA: The U120 came out in 2009- on a machine with such limited resources, you probably won't want to try running full Ubuntu with Unity, which can be a real resource hog. \nThat being said, you don't have to settle for an outdated OS. Give Xubuntu a look: The GTK-based XFCE desktop environment is good on systems with limited resources, and yet pretty and configurable.\n\nA: If you are looking for an even faster and more minimalistic version Lubuntu is your best bet. \nhttps://help.ubuntu.com/community/Lubuntu/GetLubuntu\n", "Q: RAID Controller Hardware compatability? I might be out of my element here, I am new to Ubuntu Server, and I am a intermediate Linux/Unix user, but zero experience with admin of such.  I am trying to build a server to play with for media sharing/streaming (Intel hardware Z77, 3770K).  I would like to add a SAS RAID controller card, but I am not able to find anything that says it will/won't work with Ubuntu.  I see some of the manufacturers say they work with Linux, or major Linux releases.  Is there a way to know for sure?  I could contact the manufacturers one by one, but I am curious if it supports Linux will it work in Ubuntu?  Is there a brand that works better or more consistently with Ubuntu like LSI, Adaptec, HP, Intel?  I am trying to add a PCIe x8 card.\nThank you :)\nD\n\nA: [update, 12/29/20]. I know it's been a few years.  I also realize that I am not sure if I did, or how, to mark my question answered, hence why it may still be opened, so thought I would update in case it helps someone else.  I ended up using Avago (LSI Logic > Avago > Broadcomm) HBA adapters and in Ubuntu 16 through 20 (server and desktop) the cards work perfectly and I didn't need to install anything for them to work (no special drivers required).  I used 9211-8i, 9212-4i4e, (pair of) 9206-16e (which ran too hot for a non-server case, even though I had a boat load of fans, and added some to the card heat sink, but that's another story), and a (pair of) 9202-16e which I am using today on an old i7-4770K/Asus ROG mobo.  The list provided in the comments below by Sylvain were helpful and got me in the right direction to help make the selection.  I ended up using the HBA cards (IT mode) for static media to support about 50 TB of storage (backed up separately since the media doesn't change, no need for live mirroring, and no need for excessive performance, so no need to stripe it), and I also run 2 MDADM mirror arrays for 6TB and 10TB for desktop backups and critical storage needs.\nThe 9206-16e cards are x16 (physical) cards, PCIe 2.0, about 13 watts, and working in 2x x16 slots, that are running in x8 mode (max operation for the cards is x8 each).  I had tried the 9206-16e's because they were PCIe 3.0, and x8 cards (physical) running x8, but due to heat from about 28 watts per card, and insufficient air flow, they would shutdown when they overheated.  In any case, streaming multiple instances of 4K, 1080P (tested 1x 4K, 3x 1080P, and 2x 720p instances simultaneously) and the controller cards and the drivers had no issues keeping up.\n\nA: You can check RAID supported hardware here.\nLSI Logic controllers are known to work without any problem.\n", "Q: Google Earth-Unsupported graphics card I've just installed Google Earth on my PC,which runs Ubuntu 12.04 LTS.\nWhen I open Google Earth,a window pop-ups and says:\"Unsupported Graphics Card\nYour graphics card does nor meet the minimum spec required to run Google Earth,which is a 3D accelerated card with shader support.It is strongly recommended that you try running Google Earth on a different machine or in a different rendering mode or upgrade to a newer graphics card.You may continue,but the application is unlikely to work.\"\nMaybe you'll say:\"Buy a better graphics card!\",but I used Google Earth on this machine an year ago,when I had Windows 7 & everything worked well,so my graphics card is good enough.\nThe Linux version has bigger requirements than the Windows one or what???\n\nA: I found the solution. Google Earth is now running, but I'm getting this error when I try to search for a location: invalid url. To get Google Earth to work I went back to www.google.com/earth/ and picked my 32-bit .deb installation file, there's also a 64-bit .deb file. Then I noticed the \"Advanced\" tab above and clicked it. There is a choice for an older version 7.0 instead of 7.1, so I downloaded it. Instead of a .deb file it's a .bin file. \nI then tried over and over again to find the right application to open it. After several non-working choices and much frustration I tried again and chose to run with \"gedit\". It took forever, but it loaded it and it's working. I had to look and click on \"bin\" and then open. I hope this helps you!\n", "Q: Open JDK doesn't run my jar files I decided to start java programming on Linux instead of Windows, but I can only open my projects in the NetBeans IDE. When I make the distribution into a .jar file, I can't open them. I already gave it the permission to be an executable file, but when I select Open JDK jre (either 6 or 7), it just stays there. It doesn't do anything and I don't see why it happens. Any help on what to do to proceed?\nPS: The program I'm trying to open has a GUI and when I run it in NetBeans it directly loads into the GUI, instead of doing something at the console\n\nA: With the amount of information you have provided I can give you only two suggestions:\n\n\n*\n\n*Make sure that you have exported the JAR file correctly - it needs to be exported as a runnable JAR & have a main class specified in the Manifest\n\n*Try running it via \"java -jar test.jar\"\n\n", "Q: How to mount a backup drive read only? I have a backup external USB drive.\nI wonder how to tell the system to always mount it read only without explicitly telling him everytime\nsudo mount -o ro /dev/sde1 /media/backup\n\nNote: My drive is not always attached to the system. I only attach it when I need something important from the backup. So I don't want't to edit ftsab and when booting up it tells me that it has failed to mount drive because it doesn't exist\n\nA: One method for doing this would be to explicitly set the mount options through the disks GUI.\nStep #1\n                                       \nStep #2\nNavigate to the USB HDD.\n      \nStep #3\nSelect the partition on the USB HDD you'd like to have mounted read only.\n                          \nStep #4\n\n\n*\n\n*From the next window that you get, move the button to the left, under the option ‘Automatic Mount Options’, to get access to the settings.\n\n*Now, remove the check-mark under the option ‘Mount at startup’.\nYou can let it stay enabled too, but I prefer to let Nautilus (file manager) mount the partitions, after the desktop is loaded, to speed up the boot-up process.\n\n*Then, as shown in the below screenshot, you will see a field that says nosuid,nodev,nofail,x-gvfs-show.\n\n\nNow all you have to do is, simply copy and paste the below code, and add (paste) it to the end of that text line (without a space). This will make the HDD mounted read only:\n,ro\n\n         \nStep #5\nOnce done, click on the ‘OK’ button at the bottom, when asked enter your administrative password, and now you are done!.\nNow try opening the partition in Nautilus (or any utility) and you will notice that you no longer can ‘Cut’ or ‘Delete’ files inside it, as it is mounted with read-only permissions.\nTo disable it later, you wanted to re-enable the read-write support, then simply remove that manually added ,ro code (or, you can also move that top button to the right side, until you see the option ‘ON), and save your changes. That's it!.\nSource: How to Easily make ‘NTFS’ Partitions read-only in Ubuntu 12.10?\n\nA: You can still set this up using fstab, just don't set it to be mounted automatically. Get the UUID of your drive (you can use blkid for that) and add this line to your /etc/fstab:\nUUID=123-ABC   /media/backup  ntfs   ro,noauto,users   0   0\n\nChange the UUID for whatever your's is and the ntfs to your filesystem. Now, the drive won't be mounted automatically (noauto) but it can be mounted manually by a normal user with:\nmount /media/backup\n\n\nTo make this work automatically in nautilus, use this line in /etc/fstab instead (thanks @Braiam):\nUUID=123-ABC /media/backup auto noauto,nosuid,nodev,nofail,x-gvfs-show,ro 0 0\n\n", "Q: Dual boot problem Windows 8 & Ubuntu new to Linux and am using Ubuntu 12.04 LTS. I'm having problems with the boot manager, as the GRUB2 menu is not allowing me to launch Windows 8. The Windows 8 Launcher option gives me this message every time I use it:\nerror: unknown command 'drivemap'.\nerror: invalid EFI file path.\n\nPress any key to continue...\n\nI have run boot-repair and that got the Ubuntu launcher working, but the problem with the Windows launcher in GRUB stays persistent.\nhttp://paste.ubuntu.com/7091293\n\nA: Your install is UEFI.\nIt looks like you ran the 'buggy' UEFI in Boot-Repair. That is only required if you have a system that only boots Windows from UEFI menu.\nTo undo & to rename files to their original names, you just need to tick the \"Restore EFI backups\" option of Boot-Repair.\nAlso it looks like the only boot entry that will work currently is:\nWindows UEFI bkpbootmgfw.efi\n\nThat is the renamed file that Boot-Repair renamed. If you undo the rename it will be without the bkp at beginning.\nBoot-Repair also adds all the efi files that HP added as boot options. If you do not want those you have to edit 25_custom.\nsudo cp -a /etc/grub.d/25_custom /etc/grub.d/bkup25_custom\ngksudo gedit /etc/grub.d/25_custom\nsudo update-grub\n\nIt also looks like os-prober is writing BIOS type entries that will not work.\n\nA: Try\napt-get install os-prober && os-prober\n\n", "Q: Why doesn't the `time` command work with any option? I tried to use time command with -f option to format the output of time, but I get the following error:\n-f: command not found\n\nThen I tried to use other options -a, -o, etc and I get the same error. Not even time --version doesn't work (--version: command not found).\nDon't tell me to read the man because I already do it by many times... All these options are specified there. So, where could be the problem?\n\nA: Since, as the other answers explain, time is a shell keyword, the only option available to you is -p:\nterdon@oregano ~ $ help time\ntime: time [-p] pipeline\n    Report time consumed by pipeline's execution.\n\nExecute PIPELINE and print a summary of the real time, user CPU time,\nand system CPU time spent executing PIPELINE when it terminates.\n\nOptions:\n  -p    print the timing summary in the portable Posix format\n\nSo, you need to run the time that's in /usr/bin. Here are a few ways to do so:\n\n\n*\n\n*Use the time executable instead:\n/usr/bin/time -f %Uuser ls >/dev/null\n\n\n*Use \\ which causes your shell to ignore aliases and keywords and instead search your $PATH for a matching executable:\n\\time -f %Uuser ls >/dev/null \n\n\n*Use the command builtin which has a similar effect:\ncommand time -f %Uuser ls >/dev/null\n\n\n*Use a different shell, one that has no such keyword. For example sh (which is actually dash on Ubuntu):\nsh -c \"time -f %Uuser ls >/dev/null\"\n\n\n*Use which,  which will search through your $PATH (OK, this one is silly):\n$(which time) -f %Uuser ls >/dev/null\n\n\nA: The bash and zsh shells have their internal time command. You have to use \n/usr/bin/time -f ...\n\nBTW, I discovered that using (from zsh): \n~% which  time\ntime: shell reserved word\n\n\nA: Well, even if you don't like it, I will put you to read again with more attention man time. At the end of EXAMPLES section you will find:\n  Users of the bash shell need to use an explicit path in order to run\n  the external time command and not the shell builtin variant.  On system\n  where time is installed in /usr/bin, the first example would become\n       /usr/bin/time wc /etc/hosts\n\nSo, I'm assuming that you use bash shell which uses an internal version of time, provided as a shell keyword. You can check this using the following command:\ntype time\n\nand the output will probably be:\ntime is a shell keyword\n\nIf this is the case, then it is clear that to use the real time command you must use its explicit path: /usr/bin/time.\nFurther, if you don't want to use anymore the shell keyword time, you can create a permanent alias as follow:\nalias time='/usr/bin/time'\n\nThis will overwrite the shell keyword time because the command:\ntype time\n\nwill give the following output now:\ntime is aliased to `/usr/bin/time'\n\n", "Q: Get information about my PSU I want to know what kind of power supply I have and what wattage it has. I tried:  \nsudo dmidecode -t 39\n\nbut that didn't show any specs. What do I need to do? I am on Ubuntu 13.10\n\nA: You should open your case and read all the data you are interested in at the power supply only or at the laptop adapter because power supplies don't have signals(no data bus) to \"tell\" about themselves to the any device like mainboard. \n", "Q: Is there an unofficial Box.com client for Linux? I know Box.com does not have a non-server client for Linux. Is there, then, a way to download my files to my PC using an unofficial client?\n\nA: I found box-linux-sync on github, but it's a command-line interface.\n\nA: rclone is a command line client which also supports mounting a remote box.com location.\nrclone mount ... can mount any of Rclone’s cloud storage systems as a file system with FUSE, so it works without the expired WebDAV support.\nLimitations\nWithout the use of “--vfs-cache-mode” this can only write files sequentially, it can only seek when reading. This means that many applications won’t work with their files on an rclone mount without “--vfs-cache-mode writes” or “--vfs-cache-mode full”. See the File Caching section of the docs for more info.\nThe bucket based remotes (eg Swift, S3, Google Compute Storage, B2, Hubic) do not support the concept of empty directories, so empty directories will have a tendency to disappear once they fall out of the directory cache.\nIt's available for download here\n\nA: This explanation on how to mount box.com as a folder via webdav may also help.\n\nA: There also \"BOXFS - A FUSE-based filesystem for box.com\" but I don't know if it is usable.\n\nA: WebDav will become depricated as of January 31, 2019.\nhttps://community.box.com/t5/Box-Product-News/Deprecation-WebDAV-Support/ba-p/55684\nAs of this time there is no available client for Linux.\n", "Q: How can I activate a custom keyboard layout I have defined a custom keyboard layout following this description: Custom keyboard layout definitions\nThe layout definition is added to this file: /usr/share/X11/xkb/symbols/us and it starts like this:\npartial alphanumeric_keys modifier_keys\nxkb_symbols \"usintde\" {\n\n  name[Group1]= \"English (US, alternative international and German)\";\n  include \"us\"\n\nI can use it on the command line using setxkbmap 'us(usintde)'.\nHowever, in Ubuntu 13.10, I can not choose it from the Unity settings menus. I tried settings > text input and then clicked on the + sign, but none of the layouts is named like mine (also after new login and restart).\nHow can I activate this customly defined layout (and then use it in the layout switcher)?\n\nA: Reading a similar question (Adding custom keyboard layout to Xubuntu 13.10), this page showed me the answer: I have to edit the evdev.xml and base.xml files in /usr/share/X11/xkb/rules, adding a variant snippet, too.\nThis is nicely described there. Just one more caveat: Use setxkbmap '<file>(<yourvariant>)' (for the example in the question: setxkbmap 'us(usintde)') to test your layout and to make sure that you can log in again.\nSorry for this duplicate. I read many similarly named questions and answers which only treated the symbols/xy files and old versions of the unity settings. I found this one too late.\n", "Q: Having trouble permanently setting gateway I am on a ubuntu 12.04 vm\nI read https://help.ubuntu.com/12.04/serverguide/network-configuration.html\nwhich says I can set the gateway with a command like:\n\nsudo route add default gw 10.0.2.211 eth0\n\nwhich works, but clears after a reboot.\nI also tried to set the gateway by editing my /etc/network/interface file:\n\nauto eth0\niface eth0 inet dhcp\ngateway 10.0.2.211\npre-up sleep 2\n\nI just added the gateway line.\nThat doesn't seem to work at all though.\nI tried rebooting and running:\n\nsudo /etc/init.d/networking restart\n\n\nA: Solution 1 [dirty]\nsudo nano /etc/rc.local\n\nput\nifconfig eth0 10.0.2.211 netmask 255.255.255.0 &&\nroute add default gateway XXX.XXX.XXX.XXX\n\ncrtl+O [write] and crtl+x [close nano]. And the end of boot process ubuntu read and execute rc.local\nSolution 2 [clear]\nsudo nano /etc/network/interfaces\n\nauto eth0\niface eth0 inet static\naddress XXX.XXX.XXX.XXX\nnetmask XXX.XXX.XXX.XXX\ngateway XXX.XXX.XXX.XXX\n\ncrtl+O [write] and crtl+x [close nano].\nYour ip and gw can not be same ip address.\nIf you wish to set only gateway after dhcp, put only this in rc.local\nsudo nano /etc/rc.local\n\nroute add default gateway XXX.XXX.XXX.XXX\n\ncrtl+O [write] and crtl+x [close nano]\n", "Q: Permissions issue with netatalk I set up an Ubuntu 12.04 server recently for my business, and we installed netatalk so we could share company files to our Mac computers. Here is the line we used in our AppleVolumes.default file:\n/media/files/business  \"Business\"  allow:@business  perm:0770  umask:0007\n\nAlso, our primary group for all users is \"business\".\nSo here's the issue. When we move a bunch of files and folders over, the correct permissions are set (770), but for some reason, for certain filetypes, the will only open for the owner.\nA text document will work for anyone, where as an .mp4 file only works for it's owner, even though their permissions are identical:\n-rwxrwx--- 1 user1 business 205328400 Jan  6 15:00 Video.mp4\n-rwxrwx--- 1 user1 business 665       Feb 21 09:14 Business.rtf\n\nNOTES:\n\n\n*\n\n*Server is Ubuntu 12.04. Everything is up to date.\n\n*We are exclusively Mac. All of our Macs run OS X Mavericks.\n\n*We have a Drobo that hosts our files currently (also using AFP), and it works fine when we use it. So we know it's not our computers.\n\n*The AFP shares are on the Ubuntu server all being shared from a local partition being mounted by fstab on boot.\n\n\nUPDATE (3/14/14): \nI got some help from sarnold on the #ubuntu-server channel, we tried removing extended attributes from all these files by mounting the partition without the extended attributes. After testing, it didn't help any.\nUPDATE (3/17/14):\nI tested if maybe it was a file size issue, but big text files over 200MB were fine, and really small .zip files under 1MB didn't work for non-owners. I also gave full permissions (777) to a zip file, and that didn't seem to make a difference.\n\nA: So I finally figured out that I was running Netatalk 2. I updated to Netatalk 3.1 and all of my issues are now resolved.\n", "Q: Problem to install LibreOffice When I install LibreOffice Appear \nvitor@vitor:~/Downloads$ sudo dpkg -i LibreOffice_4.2.2.1_Linux_x86_deb\ndpkg-split: erro: erro lendo LibreOffice_4.2.2.1_Linux_x86_deb: É um diretório\ndpkg: erro ao processar LibreOffice_4.2.2.1_Linux_x86_deb (--install):\n sub-processo dpkg-split retornou estado de saída de erro 2\nErros foram encontrados durante o processamento de:\n LibreOffice_4.2.2.1_Linux_x86_deb\nvitor@vitor:~/Downloads$ \n\nWhy I can't install LibreOffice using dpkg? \n\nA: What I did if I remember correctly:\nsudo su\n#Enter your password\napt-get remove libreoffice*.*\napt-get autoremove\n\nDownload all dpkg files pack from libreoffice. I suggest to use beta/development version, but it is your choice.\n#unzip it\n#do 'cd' into a unziped folder\ncd DEBS\n\nyou should be now in the folder where are all deb files, continue...\ndpkg -i *\n\ncan you see libreoffice installed? :)\n\nA: *\n\n*Better perform sudo apt-get -f install Just in case any dependencies got broken.\n\n*Re-download the file ; I prefer using wget http://download.documentfoundation.org/libreoffice/stable/4.2.2/deb/x86/LibreOffice_4.2.2_Linux_x86_deb.tar.gz\n\n*If download got interrupted, repeat last command adding -c As in wget -c http://download.documentfoundation.org/libreoffice/stable/4.2.2/deb/x86/LibreOffice_4.2.2_Linux_x86_deb.tar.gz\n\n*Upon completion, unzip the .tar.gz file and install again by sudo dpkg -i LibreOffice_4.2.2_Linux_x86_deb\n\nA: Another way to install directly from libreOffice rebositories\n\n\n*\n\n*Add repo by sudo add-apt-repository ppa:libreoffice/ppa Then press Enter\n\n*Run sudo apt-get update && sudo apt-get -y dist-upgrade Wait for completion and you should be good to go.\n\n\nP.S, This is obviously assuming you have an earlier version already installed.\nIf not, skip second step and you should be able to find it already listed in Sofware Center\nAlternatively, run sudo apt-get install libreoffice\n", "Q: A lot of system settings are missing after installing Pantheon I installed pantheon on Ubuntu 13.10 and a ton of settings are missing. I only have these settings: defaults, desktop, tweaks (I installed tweaks), keyboard, power, and about. What do I do?\n\nA: This is likely caused by the setting of XDG_CURRENT_DESKTOP.\nWhat does echo $XDG_CURRENT_DESKTOP say in a terminal?\nThe .desktop files used for gnome-control-center components contain a line like OnlyShowIn=GNOME;Unity; and are therefore not displayed with another XDG_CURRENT_DESKTOP setting.\nTry XDG_CURRENT_DESKTOP=GNOME gnome-control-center from a terminal.\nI am not sure, where and if it makes sense to override this variable, but I have just done so in my custom startup script for AwesomeWM.\n\nA: The problem isn't Pantheon-specific. This happens with every desktop that isn't GNOME or Unity: i3, xfce, and awesome, to name a few for Googlebot's benefit. \nBlueeyed gave the correct answer, but is also right that it's not obvious where to override that variable. Here's my solution: create a wrapper for gnome-control-center so that it is the only program affected.\nSteps\n\n\n*\n\n*Create a new shell script in ~/bin/gnome-control-center by cutting and pasting the following commands in the terminal:\nmkdir -p ~/bin\ncd ~/bin\necho 'XDG_CURRENT_DESKTOP=GNOME exec /usr/bin/gnome-control-center \"$@\"' >gnome-control-center\nchmod 755 gnome-control-center\n\n\n*Test it by running the program:\n./gnome-control-center\n\n\n*If it worked, then logout and log back in to add ~/bin to your PATH.\nGnome-control-center should now work for you.\nOptional\nA logical follow-up question might be, \"How do I get GNOME control center to show up in my menus?\" One answer is to copy /usr/share/applications/gnome-control-center.desktop to ~/.local/share/applications/ and remove the line that says OnlyShowIn=GNOME;Unity;. I'd recommend also changing Name=Settings to Name=GNOME Settings, just so it's more obvious in your menu which program it is.\nHere's my ~/.local/share/applications/gnome-control-center.desktop file, which you can copy directly:\n[Desktop Entry]\nName=GNOME Settings\nIcon=preferences-system\nExec=gnome-control-center --overview\nTerminal=false\nType=Application\nStartupNotify=true\nCategories=GNOME;GTK;Settings;System;\nKeywords=Preferences;Settings;\n\n", "Q: I did instaled ubuntu on inspiron b120 but can not connect to internet I try to connect tru wi-fi and also tru dsl cable, but I have not been able to connect yet. it waas connecting just fine when running on windows, I am really new to ubuntu so any advise I can get will be apreciated.\nI installed: Ubuntu 12.04 lts\nlaptop has: 2 gb ram and intel celeron m procesor 1.40GHz\n\nA: Problem solved with using the following command\nsudo apt-get remove --purge bcmwl-kernel-source\n\nhope it can help somebody else.\n", "Q: Where to get the latest GCC (GNU C Compiler) Currently my version is 4.8.4 but Ive found that some sites offer a 4.9 version. like this http://gcc.igor.onlinedirect.bg/snapshots\nBut where do they get the source from? I want to know so I can be sure I really have the latest version\nbecause of rep limits I cant answer my question here so I edited my question:\nI finally found it! :D\nftp://gcc.gnu.org/pub/gcc/snapshots\n\nA: You can get the latest source code form the SVN repository. You can browse the SVN history online to see the latest commits.\nThe sites that provide snapshots simply build the binaries from SVN trunk at regular intervals, usually a few times a day. To always have the latest available version you would have to compile from SVN after every single commit, which is even more often.\nUnless you want to contribute to GCC however, it is not recommended to use the development version and you should use the latest stable release.\n", "Q: Acer R7 - keyboard features in Ubuntu I'm considering to buy an Acer R7 572- I guess with an i7. So from previous HW-experiences I know, that \"runs on Ubuntu\" usually means, that most basics are fulfilled.\nBut with such a decent device (assumed that there is a working WiFi driver out there), I would like to know, which special keys of the keyboard actually work?\nAs being a keyboard baby, I'd like to see, that the most important things work - if not I will help the developers to work on it - if they like.\nMy Question:\nFrom existing postings I can see, that there are some people out there having Ubuntu running on an R7.\nCould you please be so kind, to describe here, which special keys on the keyboard actually work and which not?\nFor me and I guess for others as well there are some vital things:\n- Keyboard light on and off\n- Display brightness?\n- Sound buttons (on/off/volume up and down)\n- WiFi on and off\n=> if the R7 doesn't have some of the above buttons: Sorry, I only put my hands on the keyboard light button, as I was too overwhelmed by the R7 in general.\nI hope this doesn't cause too much efforts to you - it would be nice!\nThanks in advance!\n\nA: Tested on Acer Aspire R7 (i7) with 13.04, 13.10, 14.04\nAll special keys work as expected: WiFi on/off, Sleep, Switch Display output, Screen on/off, Touchpad on/off, Mute, Keyboard backlight, Keyboard on/off, Play/Pause, Stop, Next&Previous track, Volume Up&Down, LCD backlight Up&Down.\nThere is only one key that is not handled by Ubuntu (but works) - Keyboard backlight. \nSome additional xorg configuration is needed to make LCD backlight to work (/etc/X11/xorg.conf.d/80-intel_backlight.conf):\nSection \"Device\"\n  Identifier  \"Intel Graphics\"\n  Driver      \"intel\"\n  Option      \"AccelMethod\"     \"sna\"\n  Option      \"Backlight\"       \"intel_backlight\"\n  Driver      \"intel\"\n  BusID       \"PCI:0:2:0\"\nEndSection\n\nTouchscreen with multitouch works as well as Synaptic Touchpad.\nAlso note, there are no drivers for ALS (ambient light sensor) and Gyroscope/Orientation sensor in current Linux kernel, so it will not work. You'll need to adjust LCD backlight and screen orientation manually.\nWiFi works great with proprietary driver.\nBluetooth works only after some additional magic (/etc/rc.local):\n#!/bin/sh -e\n#\n# rc.local\n#\n# This script is executed at the end of each multiuser runlevel.\n# Make sure that the script will \"exit 0\" on success or any other\n# value on error.\n#\n# In order to enable or disable this script just change the execution\n# bits.\n#\n# By default this script does nothing.\necho 04ca 2004 > /sys/bus/usb/drivers/btusb/new_id\nexit 0\n\nnVidia works great with bumblebee/optirun and proprietary driver (nouveau driver is installed by default and it does not work).\nAdditional devices, such as USB Ethernet Adapter, VGA Adapter and HDMI also work without any problems.\n", "Q: Extra noise in speakers when all media applications are closed I use Ubuntu 12.04 system on my laptop and have the following problem.\nI plugged sound speaker and now I have some extra noise... The most wondering thing is that this extra noise appear only if I don't launch any application.\nFor instance if I run amarok, vlc or what ever to play music or movie I have high quality clear sound. But when I close that application in a few seconds I get extra noise again.\nI didn't have this problem before.\nCan somebody help me what is going wrong?\n\nA: This seems to be a problem with your speakers.\nIf your speakers have a volume control, set the volume to max in Ubuntu and all applications and use only the control of your speakers to adjust volume. This increases the signal-to-noise ratio.\n", "Q: Why won't Ubuntu recognize my login and password? I can't do anything because Ubuntu always asks for a login and password. I have auto-login selected and it still asks for a password.\n\nA: Go to System settings -> Brightness and lock. Turn the lock off, and disable Require my password when waking from suspend.\n", "Q: How to change avatar in Skype? I've installed Skype on my Ubuntu by doing this:\nsudo add-apt-repository \"deb http://archive.canonical.com/ $(lsb_release -sc) partner\"\nsudo apt-get update \nsudo apt-get install skype\n\nI've registered my account. And I want to change my avatar. But i don't know how :(\n\nA: Steps:\n\n\n*\n\n*Open Skype\n\n*Click on your username\n\n*Click on the image.\n\n*Select a new one!\n\n*Done!\n\n", "Q: Emacs hangs when run through SSHing to my Ubuntu Box (13.10), Running Ubuntu 13.10, I cannot run emacs when sshing to my box\nssh -l username someipaddress\n\nWhen I run emacs, it simply hangs.  \nI have also have recently installed dbus-x11 . Before installing dbus-x11, I would get a crash when trying to run emacs.  \n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\n(emacs:3306): GConf-WARNING **: Client failed to connect to the D-BUS daemon:\n//bin/dbus-launch terminated abnormally without any error message\n\nI have another ubuntu box (12.10) (vm though) running from a different provider.  However I have no issues running emacs.  In both cases I used apt-get to install emacs.\n\nA: If you're running the command you show, you are not exporting your X display details. You have two options:\n\n\n*\n\n*Command line emacs:\nemacs -nw\n\nFrom man emacs:\n      -nw, --no-window-system\n              Tell Emacs not to create a graphical frame.  If you  use\n              this switch when invoking Emacs from an xterm(1) window,\n              display is done in that window.\n\n\n*Forward your X server, this will allow you to run programs on the server that are shown on your local display. You can use either -X, or assuming this is a local, trusted network, -Y:\nssh -Y username@someipaddress\n\nFrom man ssh:\n -X      Enables X11 forwarding.  This can also be specified on a per-host\n         basis in a configuration file.\n -Y      Enables trusted X11 forwarding.  Trusted X11 forwardings are not\n         subjected to the X11 SECURITY extension controls.\n\n", "Q: How Do I Access Windows Shares From BASH? Probably total noob question. I installed Ubuntu in a VMWare Player. Works fine. I usually work in terminal and didn't realise until today that I could use the Files icon to connect to my Windows host machine (and indeed my office network.) Fabulous!\nBut... then... how do I access these new shares from inside bash? From my default prompt, shouldn't I see some \\my-windows-share\nOR do I need to mount these drives somehow 'manually' inside terminal? If so, how?\nI see a number of answers regarding VirtualBox. Don't know if that applies to me. I guess I assumed that once I was connected via Files I would automatically be connected with Terminal.\n\nA: Looks like this is an old article, but still very relevant. I found since the WannaCry ransomware (May 2017) issue many Windows shares refuse to use the old SMB V1.\nThis is what I ended up having to do\nI had the following installed:\nsudo apt install samba-common samba-common-bin cifs-utils\n\nThen add lines under [global] - vi /etc/samba/smb.conf\nserver min protocol = SMB2_10\nclient min protocol = SMB2\nclient max protocol = SMB3\n\nthis then allowed the following command:\nmount -t cifs -o vers=2.1 -o username=<username>,sec=ntlmssp //server/path /mnt/smb\n\n\nA: First you need to have samba and cifs-utils installed:\nsudo apt-get install samba cifs-utils\n\nThen use a Bash script to mount windows share folder in linux using samba:\n$ mkdir /mnt/smb\n\n$ touch smb.sh\n\nchmod +x smb.sh\n\n$ vi smb.sh\n\nWrite the following into the smb.sh file using vi:\n#/bin/bash\n\n\n\nSERVER_IP=\"192.168.1.1\"\n\nSHARE_NAME=\"c$\"\n\nUSERNAME=\"samba user name\"\n\nPASSWD=\"samba password\"\n\nDOMAIN=\"domain\"\n\n\nmount.cifs //$SERVER_IP/$SHARE_NAME /mnt/smb/ -o username=$USERNAME,password=$PASSWD,dom=$DOMAIN\n\nFinally run the script to mount your Windows share and cd into the share:\n./smb.sh\n\n$ cd /mnt/smb/\n\n\nAnother method that seems to me to be more straight forward and easier: It involves creating the mount point, editing fstab, and then mounting all filesystems in fstab with one command.\nMake the folder:\n    sudo mkdir /mnt/myDirectory\nEdit the fstab:\n    sudo vi /etc/fstab\nAppend the following to the fstab file:\n//server/Share /mnt/myDirectory cifs domain=myDomain,username=myUserName,password=myPassword 0 0\n\nBe sure to fill in all the appropriate information in place of those placeholders. And save the fstab file with wq for \"write and quit.\"\nFinally mount all the file systems listed in fstab:\nsudo mount -a\n\nNow you can verify that the share is available with:\nls /mnt/myDirectory\n\nAnd you should see the files in the top level directory of the Windows Share.\n", "Q: How to return to command line in 12.04 server How do I return to the command line in Ubuntu 12.04 server when all there is, is a line with nothing but a flashing underscore on it. I typed a command wrong and it is stuck like this.\n\nA: Try to press CTRL+Z, you should get a prompt then type bg to resume it but running as a background process.\nYou can type ps -aef to look for the command PID to eventually kill it:\nsudo kill -9 PID_of_your_command\n\n", "Q: Brightness function keys problem I have an HP 650 notebook, and I just finished installing ubuntu 13.10 . The problem is that brightness function keys don't work ( f2 and f3 ). I tried changing GRUB_CMDLINE_LINUX_DEFAULT and updating grub but it doesn't work.\nDirectory /sys/class/backlight is empty.\nand \"lspci | grep -i vga\" command outputs the following:\n\n00:02.0 VGA compatible controller: Intel Corporation 2nd Generation\n  Core Processor Family Integrated Graphics Controller (rev 09)\n\nAny help, please ?\n\nA: much more later :D\nI installed ubuntu 14.04 : Perfect ! Not a single problem !\n", "Q: Operating System loader I installed Ubuntu 12.04 with the option to keep Windows 7.  The installer indicated I could choose the OS to load on startup.  However, only Windows 7 loads when the computer is restarted, with no option for Ubuntu.  What can I do to fix?\n\nA: What do you see when you start the computer? You should see the BIOS spash screen, then if you had selected grub as the bootloader you would see the grub screen.\nIf grub is set to silent countdown to starting the default os, you will only see a blank but kinda purplish screen after the BIOS splash. When you see that screen hit Esc and the list of OS should show up. Then you could select the OS you would like to boot into.\n", "Q: Ruby - no such file to load [gems] This is error:\n[ERROR] no such file to load -- readline\n[TIP] Try to run 'gem install readline' or 'gem install --user-install readline'. If you still get an error, Please see README file or https://github.com/wpscanteam/wpscan\nThen i run those command but again i got error:\nERROR:  Could not find a valid gem 'readline' (>= 0) in any repository\nthose errors i got when i use \"ruby wpscan.rb\" help me please.\n\nA: After command:\nsudo gem install rb-readline\n\nI was still getting an error.\nI added to the Gemfile\ngem \"rb-readline\" \n\nAnd it worked. \n\nA: The readline library for Ruby is called rb-readline. Try\nsudo gem install rb-readline\n\nfor a system-wide installation, or\ngem install --user-install rb-readline\n\nfor a local installation inside your user's home directory.\n", "Q: Can't get any sound from Ubuntu I can't get any kind of sound from my PC. I installed Ubuntu 12.04 on my somewhat old desktop as the soundcard wasn't recognised by my (unlicensed) Windows 7. Ubuntu seems to have detected my card, as it shows up in the sound settings menu, and also in alsamixer (which isn't muted). I've tried all of the outputs on back and front of the machine, to no avail.\nCould one of you kind people tell me what the next step is?\nThanks a lot!\n\nA: If you are using ALSA on your system the I suppose you've installed Xubuntu or Lubuntu and not Ubuntu LTS. Ubuntu LTS comes with pulse audio which should be present on your system. If you want to keep ALSA as default then you must install some extra packages. You need 'gnome alsa mixer', 'esound' and quite a few other packages that can boost ALSA. \nYou should try first 'pulse audio' and install all software needed for pulse-audio to work. It does not generate conflicts with ALSA, and you can remove pulse-audio if you are not satisfied. You should consider disabling all hardware-accelerated features for your sound card if it is some legacy card that do not support hardware-acceleration. Pulse Audio has a built-in module especially for this kind of problems that old sound card have.\nThis is a good link to help you fix sound problems in Ubuntu 12.04.3 LTS (Precise Pangolin) or later: https://help.ubuntu.com/community/SoundTroubleshootingProcedure\n", "Q: ath9k driver suddenly doesn't see channel 13 anymore Suddenly, after upgrade to Linux kernel 3.11.0-19, my wireless card with the ath9k driver is no longer seeing the 13th channel, even though it worked fine for the last year and half. It also still works fine on another Ubuntu laptop and an Android phone.\nHow can I re-enable the 13th channel? It is very necessary as most of the channels are taken here.\n\nA: I installed the wireless-crda and the iw packages which automatically seem to have fixed things, before I saw these replies. Thank you for the answers, however!\n\nA: I seem to be having the same problem with Ubuntu 20.04, switching from Kernel 5.4.x to 5.13.x. Installing wireless-crda did not help at all.\nOn an Arch Linux forum I found the remark that crda is actually deprecated over wireless-regdb.\nAnyway. What solved it for me, was to force the regdomain when loading the cfg80211 module:\nAdd a file /etc/modprobe.d/cfg80211.conf with the content\noptions cfg80211 ieee80211_regdom=DE # or your country's 2-char ISO code.\n\n\nA: You need to set your regulatory domain\nEdit your /etc/default/crda and set your country code.\nThere is more info by running dmesg.\nSee. regulatory domain\n", "Q: System BIOS doesn't show Ubuntu as boot option after installation? After trying and failing many times to create a bootable USB, I finally managed to create one using Universal USB Installer from PenDriveLinux.com. I created a bootable USB with Ubuntu 13.10 64-bit flavour and managed to successfully boot to the USB after disabling Secure Boot, enabling UEFI & Legacy boot and manually selecting my USB drive.\nAfter successfully installing Ubuntu on a new partition on my SSD, I removed my USB stick, restarted my computer and spammed the Enter key in order to get into my BIOS. I went to manually select where to boot from, but there was no new option for Ubuntu. \nBecause I'm a computer science student, I think of myself as being fairly clever and so I simply selected my SSD, but it ran through a different boot sequence (neither what my computer used to boot through nor my new shiny Ubuntu OS). What I think is happening is that my computer normally quick boots Windows 8.1 through my 16GB mSATA, but it booted Windows 8.1 through my SSD when I selected it, rather than Ubuntu.\nSo what I'm asking is, how do I get it to boot Ubuntu rather than Windows 8.1 from my SSD when both are located on the SSD and there is no option for anything else? Is there a way to modify the BIOS so that it gives me the option to boot from one partition on my SSD rather than another? I have as of yet been unable to boot into Ubuntu, I've only managed to boot to Windows 8.1 two different ways.\nI've included tech specs below, but if you need any more information I'll make sure to follow up.\n\nMachine: ThinkPad S1 Yoga\nTech Specs:\n\n\n*\n\n*Intel Core i7-4500U Processor (4MB Cache, up to 3.00GHz)\n\n*Windows 8.1 64\n\n*8GB PC3-12800 DDR3L on MB\n\n*Intel HD Graphics 4400\n\n*256GB Solid State Drive SATA 6G\n\n*16GB mSATA\n\n\nA: Just a question before I start, you have 2 drives? 256GB with Windows and 16GB mSATA? What do you use the mSATA for if not Ubuntu?\n\nTo my knowledge PenDriveLinux.com creates MBR-style bootable media, with uncertain support for UEFI. If you want your machine to use UEFI, which is really recommended, you should disable CSM and create only UEFI bootable media just to be sure that you don't accidentally boot and install in MBR mode while installing to a GPT partitioned drive and probably making things more messy.\nYou seem to have installed in MBR mode, otherwise the installer would have recognized a UEFI machine and be able to register an EFI boot loader in the firmware bootmenu that it placed on the EFI System Partition (ESP). If you can't find an Ubuntu related .efi binary on your ESP, then you probably installed in MBR mode (or GPT MBR mode) and you should be able to boot from the drive in leagcy/MBR mode, you just need to figure out how. (Typically Thinkpads offer priority booting, e.g. booting legacy first.)\nGummiboot as default hotpluggable UEFI bootloader\nGiven that you already have a GPT partitioned target disk (all with preinstalled Windows 8 should be), you could try troubleshooting your existing MBR installation by trying the following instructions.\n\nNote: Please be aware that these instructions are not a permanent fix or proper setup. They are just a static configuration to get you into your installation and proceed with troubleshooting from there (e.g. installing GRUB properly).\n\n\n\n*\n\n*Get gummiboot\nDownload gummiboot from the Arch Linux repositories. (Everything is fine, we are just doing Linus Torvalds style package management. You can find the download link on that page far on the right under Package Actions > Download From Mirror)\nExtract gummibootx64.efi from the package (it's under /usr/lib/gummiboot/) and copy it as \\EFI\\BOOT\\BOOTx64.EFI to your ESP. Backup existing files with the same name (e.g. use zip).\n\n*Copy kernel files\nCreate a new folder at the root of your ESP named Ubuntu and copy all the files with the highest version number from /boot/ to the folder you just created.\nIf you are on Windows, download the latest package matching linux-image-$VERSION-generic for your distribution from the repositories. (initrd.img-$VERSION-generic is missing as it is generated automatically by Debian scripts.)\n\n*Configure gummiboot to boot the Ubuntu Linux kernel\nCreate folders along the path loader/entries/ at the root of your ESP and create a file named ubuntu.conf in there. Create a configuration by editing the file following this template:\ntitle          Ubuntu\nlinux          /Ubuntu/vmlinuz-$VERSION-generic\ninitrd         /Ubuntu/initrd.img-$VERSION-generic\noptions        root=UUID=$UUID ro\n\n\n\n*\n\n*title: Choose what you like. Must be human readable.\n\n*linux: The filename of the kernel to load, replace $VERSION with the version number of the file you copied.\n\n*initrd: The filename of the initial ram disk. Basically the same as with the linux option, $VERSION with the version number of the file you copied. Leave this line out if you don't have such a file (I don't know if it will work then though).\n\n*options: Replace $UUID with the filesystem UUID of your Ubuntu root filesystem. Run ll /dev/disk/by-uuid/ | grep sdxY to get the GUID, replace sdxY with the actual device name. (Forget what I wrote here earlier about partition GUIDs, that doesn't seem to work for now.)\nYou can add the remaining options of the linux line from your /boot/grub/grub.cfg. The UUID is necessary part, the rest should be rather optional. My linux line in grub.cfg looks like this: root=UUID=00000000-0000-0000-0000-000000000000 ro   quiet splash $vt_handoff\nYou also need to add the file loader.conf in loader/ to make gummiboot work.\ndefault        Ubuntu\ntimeout        4\n\ndefault is the title of the default entry to boot. Edit appropriately if you have chosen another title.\n\n*Reboot\nYou should be able to boot from the HDD/SSD that contains the ESP with gummiboot and be presented with the gummiboot menu, allowing you to boot your Ubuntu installation.\n\n*Optional: Create a gummiboot menuentry for GRUB\nSimilar to the instructions above, create loader/entries/ubuntu.conf with the following content:\ntitle          Ubuntu GRUB\nefi            \\EFI\\ubuntu\\grubx64.efi\n\nAlternative:\ntitle          Ubuntu GRUB\nefi            \\EFI\\ubuntu\\shimx64.efi\n\nI'm still researching this topic and I wanted to test this throughly before writing it down here in a clean and non-quirky way, but may be these instructions give you helpful directions and are more fun to you than trying to install again and again.\nGood luck.\nFurther reading\n\n\n*\n\n*AdamW's UEFI boot: how does that actually work, then? is a good but lengthy read on treating the UEFI boot topic not like magic.\n\n*https://wiki.archlinux.org/index.php/Gummiboot\n\n*https://wiki.archlinux.org/index.php/EFISTUB\nFYE\nStuff I suffered from during testing:\n\n\n*\n\n*PARTUUID/GUID - doesn't seem to work.\n\n*initramfs compiled with dep option instead of most.\n\n*initramfs of cloned installation finds a hibernation image from the source installation and boots that instead. m(\n\n*Windows avoids mounting ESPs.\n\n\nA: I suspect the same thing that LiveWireBT does: That you installed Ubuntu in BIOS/CSM/legacy mode onto a computer that already boots Windows in EFI/UEFI mode. This makes dual-booting more complex, and in some cases impossible.\nIMHO, though, LiveWireBT's solution is overly complex and limited. Two solutions are likely to be much easier and more flexible:\n\n\n*\n\n*Download and prepare a boot medium for the CD-R or USB flash drive version of my rEFInd boot manager. Boot with it. (You may need to disable Secure Boot in your firmware.) This should enable you to boot both Windows and Ubuntu. If this works, install the Debian-package version of rEFInd in Ubuntu.\n\n*Boot an Ubuntu live CD in EFI mode. (Verify that you've booted in EFI mode by looking for the /sys/firmware/efi directory. If it's present, you've booted in EFI mode. If not, you've probably booted in BIOS/CSM/legacy mode and should try again. Look for a boot option that includes the string \"EFI\" or \"UEFI\" in its description.) Run the Boot Repair tool. Be sure to record the URL that it provides; if you try this option and it doesn't work, post that URL here. It will point us to more detailed diagnostic information on your computer. In theory, using Boot Repair should set up a new EFI-mode version of GRUB, which should enable you to switch between Linux and Windows, both booted in EFI mode.\n\n\nThe second option is a little riskier than the first because there's no way to test what it will do, and on occasion Boot Repair actually makes matters worse. By contrast, testing rEFInd from a CD-R or USB flash drive means that you can stop without touching your hard disk or NVRAM settings if it doesn't seem to be working.\n", "Q: Trying to install Ubuntu on Lenovo T61 laptop I downloaded the Ubuntu file (Latest stable release) to a blank CD-R but got the error message that there was not enough room on the CD. One file got on the CD i think but more was supposed to be on it. So how big are the files going onto the CD from Ubuntu?\nI tried downloading to DVD-R but that didn't work at all: it appears that the Sonic program I used was not capable of burning DVDs.\nWhy does the Ubuntu help topic on downloading sometimes say use a CD and other times a DVD?\nThe program I was using is the default on my laptop, Sonic. Should I use another program? Isn't there a default Windows program for burning CDs and DVDs?\nHow do I change the default program for the optical D: drive?\nI used the Universal USB Installer for linux to make a CD but that did not work.\nSee comments below for details.\nWindows XP SP3. Firefox.\n\nA: \nSo how big are the files going onto the CD from Ubuntu?\n\nThe full ubuntu-12.04.4-dvd-amd64.iso image of all the files is 1.6G in size.\n\nWhy does the Ubuntu help topic on downloading sometimes say use a CD and other times a DVD?\n\nBecause some Ubuntu distributions (AKA 'distro') will fit on a CD, whereas the full Ubuntu distro with Unity requires a DVD. There are many flavors of Ubuntu, briefly explained on the Ubuntu wiki. You've got a choice with Ubuntu of which Desktop Environment you want to use to manage your desktop, and once you choose the desktop, then you also choose the utility programs which work with it, and the 'libraries' of files which support it. \n\nIsn't there a default Windows program for burning CDs and DVDs? \n\nNot with XP. The Microsoft Forums recommend the free app ImgBurn, but the highest rated free app for Windows CD/DVD burning at Sourceforge is cdrtfe.   \nTo make what you burn bootable, you must burn it using the Mastered format, as the Live File System on a CD or DVD is not bootable. The Mastered format is explained at this Windows Explorer for Windows 7 link.\n\nShould I use another program? \n\nSince you're having problems with using a CD and DVD, perhaps you should use the free app for Windows which lets you create a LiveUSB on a flash drive to install from. \nThere's a big advantage to the LiveUSB; freedom of choice. LiveUSBs lets you try one version, wipe it clean, and then try another, to seee which you like then best. Then, once you settle on your preference and actually install it to your hard drive, then you can customize it with wallpaper, fonts, cursor and other visual elements. \nThe LiveUSB also leaves your XP install intact, and you can access the data on the hard drive, and save files to the hard drive. \nThe Xubuntu and Kubuntu versions are more similar to XP, IMHO, than Ubuntu with Unity, which uses a more different desktop.\n\nA: I ran into the same problem trying to burn the ISO onto a CD.  Had to use a DVD+R.  I burned my image using Windows 10 \"burn ISO\" function.  Worked perfectly.  Also I had to use the boot option - boot cd/dvd on my laptop to get the ISO to load.\n", "Q: Problems moving a web link on the desktop I am having this annoying problem that my web links that I have dragged from Firefox can not be moved afterwards. When I try, I just get a copy of the link as a file. \nI don't know if the problem is caused by bad settings on Firefox or on Ubuntu. But what I see is that the property of the web file states: filesize, access or modification is unknown. The permission could not be determined. \nI have Ubuntu version 14, but 13 had the same problem. The \"Desktop\" dir has all the read/write rights set and the web link has the same! chmod 777 on the web link did not do anything good. \nI hope you can help me with some of you magic. \nThanks. \nHenrik.\n\nA: That's a bug in Nautilus, see bug #1278437.\nAs far as I know there's no magic spell for that :-(\n", "Q: Software to Index and Document large-number of PDF documents based on certain criteria I am not tech savvy at all....at our law firm we have literally tens of thousands of pdf documents that the attorney wants indexed.  When I say indexed, I mean she wants to make a chart and input the bates numbering, the title of the document, and the date of the document.  Is there any such software anywhere that will help with this?  This literally takes us weeks to complete, and so I am searching for someone or something that would help out so we can get more accomplished.\n\nA: Regarding the huge number of documents I would strongly advise you to use a full fledged document management system in your company. These systems rely on a database management system to store documents and metadata, they may require some advanced knowledge to install and manage, but the end result is worthy the effort.\nIn the past I worked with Liferay, which is fully web based, relying on Tomcat and Postgres. It did not manage the database properly (missing foreign keys) and could go into an inconsistent state. This was some years ago, later versions could be more reliable.\nI also worked with Alfresco for a short time, which is a bit more complex, but also more reliable. It is probably the most complete open source solution out there.\nOther open source options are OpenKM, Nuxeo, OpenDocMan and Plone, none of which I have ever used.\nDepending on your experience managing software systems, you might profit from professional support.\n", "Q: Installing ubuntu on Android netbooks I'm thinking to buy one of these cheap chinese netbooks, they run android, ideal for university, so I won't have to carry my laptop.\nI want to remove android, and install Ubuntu derivatives, Xubuntu, Lubuntu, but most probably xubuntu, Lubuntu isn't much lighter as far as I know.\nWill the ARM version work? Or Linux can't be installed on such devices? what I'm looking at is more of a mobile tablet than a laptop. Knowing that Linux can't be installed on mobiles got me thinking about the possible issue.\nIf the problem was about the requirements, I'd install debian or build Gentoo and make the lightest weight distro ever, but I think it's not about how heavy the distro is, it's about whether linux runs on mobile like laptops or not, besides Xubuntu is pretty much as lightweight as it gets especially when using the mini CD\n\nA: Before buying a laptop, make sure that you do some due diligence by checking if its hardware components are known to be supported by Linux: At Present Which is the best choice for a Ubuntu graphics card, AMD or nVidia?. Numerous hardware compatibility lists exist on the web (I'm not sure which is the most useful), including Phoronix.\nIf the device that you're looking into has an ARM-based processor, then you might want to look at ARM Processor support on the wiki. \nAnother avenue would be Ubuntu Touch. They even talk about Ubuntu for Android. For a list of compatible devices check Ubuntu Touch devices support on the wiki (they also have a mailing list) and these related questions:\n\n\n*\n\n*What is Ubuntu Touch (Ubuntu for Phones)\n\n*What hardware does Ubuntu Touch support?\n\n*How do I go about porting Ubuntu Touch to different devices?\n\nA: yea you would have to check the chip set to see if Ubuntu software will run on it. Most likely it will, but I would double check with the seller to see if it can use another OS. \n", "Q: Double Boot: Why can I not start Ubuntu? I just installed Ubuntu 12.04. I have Windows XP SP3, 2 GB RAM, 1 TB HDD. I did everything that says that I should. I made swap partition and everything. Though, it didn't ask me if I want to import data from xp to Ubuntu while it was installing. In the end, it said that everything installed successfully.\nThen it rebooted it itself, it said in tutorial that if Windows start first, it is not big of a deal. I rebooted it again and againg Windows started. I read somewhere that I should hold SHIFT while booting so that GRUB menu start, but it didn't. I also went to BIOS and made a first boot device a HD that Ubuntu is on. NOTHING!\n\nA: Download the Boot Repair ISO, burn that to a CD, run the automated Boot Repair program. It will take care of everything else. If it doesnt work generete a Super Grub2 Disk CD and in a Ubuntu system try with GNU GRUB in this site: http://www.gnu.org/software/grub/, but dont forget BACKUP FIRST !!!\n", "Q: Media buttons type a zero character After updating to 13.10, pressing a multimedia button (volume, media playback, and wifi controls) types a zero character '0', as well as performing its desired function. I'm using an hp dv7 laptop. How can I stop this?\n\nA: A recent update in 14.04 fixed this issue for me.\nIf anyone figures out what caused it, or what update fixed it, post and I'll accept that answer.\n", "Q: My StarCraft on wine 1.5.24 is on all workspaces I use PlayOnLinux and configured it to work on wine version 1.5.24.\nThe thing is the app is working on all workscapes, just like that\n\nSo how that to work only on one?\nIt behaves just like any app that is on\n\"Always visible workspace\"\nI i change wine version, i must agian configure the wine, but it still behaves so.\nThe change whas about just after SC2 game whas updated.\nThank you!\n\nA: Found a problem. Stupid simple.\nThis solved my issue:\n\n\n*\n\n*Go to PlayOnLinux\n\n*pick an app and click on configure button\n\n*pick a \"Graphics\" tab\n\n*make sure that \"Allow the window manager to...* checkboxes are selected\n\n\nAnd than again click to play a game, now it is working on one workspace only. Yey!\n", "Q: fix block device name in /dev I have several block volumes in /dev like /dev/sds. These block volumes are located on a SAN device. Every time I restart my Ubuntu server, the device names change. \nI was wondering if there is any way to fix the device names (e.g. \"sds\") for these devices ? \n\nA: There is a built in solution. Use the /dev/disk/by-id link, for example -\n$ ls -l /dev/disk/by-id | grep sda\nlrwxrwxrwx 1 root root  9 Mar 11 21:56 ata-ST95005620AS_5YX07EY0 -> ../../sda\nlrwxrwxrwx 1 root root 10 Mar 11 21:56 ata-ST95005620AS_5YX07EY0-part1 -> ../../sda1\nlrwxrwxrwx 1 root root 10 Mar 11 21:56 ata-ST95005620AS_5YX07EY0-part2 -> ../../sda2\nlrwxrwxrwx 1 root root 10 Mar 11 21:56 ata-ST95005620AS_5YX07EY0-part5 -> ../../sda5\n\nThat output means /dev/disk/by-id/ata-ST95005620AS_5YX07EY0 will always be the drive that is currently \"/dev/sda\".\n", "Q: Can not install UBUNTU from USB or CD/drive I have been trying to install from flash drive, and CD with no luck . I am running a IBM ThinkCenter M50 (8189A1EU) PC Desktop with 3GB RAM.\nI have gone into BIOS and changed the boot order to be CD, or REMOVABLE DEVICE first, and tried putting both of them sequentially, and then even removing HD from the list completely with no success. The machine just hangs with a black screen and a blinking cursor and allows no input. \nI have also pressed F12 during normal startup and attempted to select one of these BOOT options from the menu with the same results. I even updated  the BIOS with no success. I have disabled the admin security features for all bootable devices in the BIOS.\nI was reading somewhere that maybe the machine is too old to install? I also read it might have something to do with ATI card, so I disabled that in BIOS and used the on-board one. Not much happened there either. That being said i do notice that while the screen hangs while I wait for the CD or USB to boot my monitor changes resolutions from 640 x480 to 720 x 400. \nAll i see is blinking white underscore on black screen.  \nADDENDUM -I successfully booted from the windows XP disk without problems,but no luck with the UBUNTU boot disk. As a test I even tried the UBUNTU disk on my other machine with no success. Something tells me the files extracted from the ISO and put onto the USB will not work on CD? \n\nA: Prior to your edits, I thought there was something wrong with your computer but now that you mention extracted and XP disc booting without a problem, I'm pretty sure the problem's with your disc and flash drive.\nYou should burn the ISO image using proper utility tools to do it, instead of simply extracting the content onto the disc and burning it that way. There's a difference between the two, as burning it as an image will keep the bootloader whereas simply extracting won't (for more information). As for the bootable USB drive, do what To Do mentioned instead.\nThe only other explanation I can give is the MD5 checksum of the ISO being wrong in the first place (possibly an incomplete download), but you should always check it after downloading it, and after burning it to a disc to be safe.\nI'm not exactly sure of which OS you're using currently (I'm guessing XP), but here are some links which I think may help:  \nCDBurnerXP, a freeware burner that should work on any Windows platform above 2000 SP4\nHow to verify integrity for Ubuntu ISO\n\nA: \"I was reading somewhere that maybe the machine is too old to install?\"  \nYou will want to start with, not Ubuntu, but Xubuntu or Lubuntu, as your machine does not have the horsepower for full-on Ubuntu with Unity, a very demanding UI with requires compositing and 3D capability in your video adapter. Both of those lighter versions can be booted from a LiveUSB, and once you make up your mind which you like, you can install your preference. Until you install, the files on the hard drive are intact, and even accessible.\n\nA: From within yourwindows installed,try a wubi i stallation then reboot your computer and see what you get (you can always start Windows again and remove Ubuntu installation from Add/Remove programs\nWUBI guide is here\nAnd if you have the .ISO file already, download WUBI installer from here, where you will find installation instructions as well.\nNote: WUBI installer is compatible with Ubuntu 12.04 LTS and its derivatives only.\n", "Q: How can I have my Ubuntu PC (13.10) connect to a Xbox 360 Kinect? How can I have my Xbox 360 Kinect be registered as a device to my computer? I don't just want to be able to use it as a webcam, although that is still helpful. Is there any software for Ubuntu that allows me to make use of Kinect while still keeping its 3D capabilities?\n\nA: Have you tried https://github.com/OpenKinect/libfreenect ?\nmake sure to read README.md and also check this one out : https://github.com/OpenKinect/libfreenect/issues/348\n", "Q: Installing Nvidia Additional Driver failed in Ubuntu 12.04 I have a GeForce 6150SE nForce 430 graphics card installed in an HP Compaq Presario CQ5000 Series desktop with an AMD Athlon II X3 435 processor, 2GB RAM and Ubuntu 12.04 64-bit installed. I tried to install the NVIDIA driver from the Additional Drivers window for the recommended driver Nvidia 304 (Nvidia web recommends version 325, but says it is better to use the recommended Ubuntu driver!), but it failed!, and I need a driver to use Unity (3D). Thanks in advance for your help.\nThis is the content in the jockey.log file:\n2014-03-14 18:52:35,784 DEBUG: Installing package: nvidia-304\n2014-03-14 18:52:36,540 ERROR: Binary package nvidia-304 has no trusted origin, rejecting\n2014-03-14 18:52:36,786 WARNING: modinfo for module nvidia_304 failed: ERROR: modinfo: could not find module nvidia_304\n\n2014-03-14 18:52:36,788 ERROR: XorgDriverHandler.enable(): package or module not installed, aborting\n2014-03-14 18:52:36,805 ERROR: xorg:nvidia_304: get_alternative_by_name(nvidia-304) returned nothing ....etc.\n\n\nA: I made this jobs step and it works! :\nsudo apt-get update\nsudo apt-get install linux-headers-generic  (was already installed)\nsudo apt-get dist-upgrade\nsudo reboot\nsudo apt-get install nvidia-current\nsudo nvidia-xconfig\nsudo reboot\nand thats all, install nvidia 304 driver and could use MyUnity perfectly !!!\n(based on How to install NVIDIA driver in Ubuntu  by Max Tither)\n", "Q: How can I read a crash file from /var/crash php-fpm crashed on us and dumped a file in \n/var/crash/_usr_sbin_php5-fpm.1002.crash\n\nThere is some info in that file but what I'm after is in the section called CoreDump in a base64 encoded format. How can I read what was running at the time of the crash?\n\nA: In case if you don't want to install a bunch of sub-dependencies for apport-retrace tool, you can unpack apport format into separate files and to use only CoreDump dump with gdb as usual.\n\n*\n\n*apport-unpack systemGeneratedCrashReportPath.crash yourNewUnpackDirectoryHere\n\n\n*cd yourNewUnpackDirectoryHere/\n\n\n*gdb `cat ExecutablePath` CoreDump (pay attention to backticks here!)\n\n\n*bt (output actual back-trace)\nNote: apport-unpack will sometimes crash itself on unpack operation (apport seems broken all around... xD), but your CoreDump and other files will be there, just ignore it and delete all .crash files in /var/crash after you move them elsewhere in order to allow system to output new crash reports from same apps there.\n\nA: There is a tool called apport-retrace that reads the .crash files and allows you to either fill it with a fully-symbolic stack trace or run a gdb session using the core dump. To start a gdb session, run apport-retrace -g CRASHFILE.crash. Note that you need to have the -dbg packages installed to get a good stack trace.\nThat being said (I'm not an expert on PHP), it might actually be something that you wrote in one of your files that is causing the crash.\n", "Q: start up disk creator doesnt have ubuntu file Step 5 of How to create bootable USB stick on ubuntu \"Select the file and click 'Open'.\" Doesnt show anything under Desktop after I click \"Other\".. Its just blank.\n\nA: When you click the Other button to browse for an Ubuntu installation iso file, Startup Disk Creator looks for a file with an .iso extension which has a name similar in form to this file: xubuntu-13.10-desktop-amd64.iso . If there is a file like that on your desktop, then Startup Disk Creator should recognize it.\n", "Q: Windows 8 doesn't start after installing ubuntu 13.10 I've just installed Ubuntu 13.10 on my Acer AspireOne D255E alongside an old installation of Windows 8. After the Ubuntu install, I started Windows and Ubuntu without problems but suddenly I tried to start Windows 8 and it showed me a blue screen with a :( emoticon telling me that there was some troubles and windows couldn't start. I tried with the windows auto-repair but, as expected, it didn't work. Ubuntu is working very well but I need my old Windows 8 operative system and I don't know what to do to recover it. I'm a beginner using Ubuntu, so if you need any extra information, just tell me. Thanks in advance!\n\nA: I'm not allowed to comment due to my reputation, so as an answer:\nDid you happen to change anything to your hardwareconfiguration? \nAdded a harddisk/drive? Or maybe altered the order? Or maybe altered any order in your BIOS?\nThose edits could change the order Grub (the bootloader, which handles your choice to boot to Win/Ubuntu) reads the drives and tells windows how to access them.\nFor instance: (HD0,0) could be labeled /dev/sda1 during instalation, while since altering something, (HD1,0) points to /dev/sda1 and (HD0,0) points to label /dev/sdb1)\n", "Q: How do I recursively create a folder inside another non-existent folder? I want to create this folder: $HOME/a/b/c/d while $HOME/a has not yet been created! Is it possible with one line in Terminal?\n\nA: You can use the command mkdir with -p option to create a folder inside another non-existent folder. Consider an example,\nmkdir -p \"$HOME/a/b/c/d\"\n\nWhere the folders a,b,c and d do not exist in home before running the command. After execution of the command all these folders will be created recursively inside one another. \nYou can see from man mkdir\n-p, --parents\n          no error if existing, make parent directories as needed\n\n\nA: Here is the answer to the question,below command will do the job you want in just the way you want :) This can be done with mkdir (make directory command) as shown below:\nroot@test:~# sudo mkdir -p /abcd/efgh/ijkl/mnop/qrst/uvwx/yz/  \nroot@test:~#   \n\nIf you want it to show you the directories it created while it is working then use verbose with it as shown below:  \nroot@test:~# sudo mkdir -pv /abcd/efgh/ijkl/mnop/qrst/uvwx/yz/  \nmkdir: created directory `/abcd'\nmkdir: created directory `/abcd/efgh'  \nmkdir: created directory `/abcd/efgh/ijkl'  \nmkdir: created directory `/abcd/efgh/ijkl/mnop'  \nmkdir: created directory `/abcd/efgh/ijkl/mnop/qrst'  \nmkdir: created directory `/abcd/efgh/ijkl/mnop/qrst/uvwx'  \nmkdir: created directory `/abcd/efgh/ijkl/mnop/qrst/uvwx/yz/'  \nroot@test:~#  \n\nEnjoy!! :)\n", "Q: How to make a pendrive snapshot I am building a NAS server with Ubuntu Server 12.04 on an old laptop and am very happy with it. The OS is installed on a 8Gb pendrive (the swap partition and grub are also installed on it).\nI did a 'backup' using:\ndd if=/dev/sdb of=/mnt/nas-disk/backups/ubuntu-nas-server/pendrive.iso bs=4M\n\nI worked perfectly, in fact I made a mistake and overwrited the pendrive with garbage and I was able to restore all with:\ndd if=/mnt/nas-disk/backups/ubuntu-nas-server/pendrive.iso of=/dev/sdb bs=4M\n\nHowever, I have another pendrive with no exactly the same capacity (it is a 8GB pendrive but has 7.9 more or less). When I executed the previous command and tried to boot using the new drive it did not work at all.\nThe dd command let me know that it was not able to copy all the file in the new device. \nI need a way to be able to 'clone' my pendrive in case it fails. Is the any way to do that?\n\nA: For restoring: you could try to:  \n\n\n*\n\n*make the (new) partitions on your pendrive (swap and ext3/ext4) using fdisk /dev/sda for example\n\n*mount the new created partition (mkdir /mnt/tmp1 && mount /dev/sda1 /mnt/tmp1/)\n\n*Mount the data-partition from your .iso/.img (mkdir /mnt/tmp2/ && kpartx -a imagefile.img && mount /dev/mapper/loop0p1 /mnt/ -o loop,ro )\n\n*copy the data from mounted image to the new data-partition (cp /mnt/tmp2 /mnt/tmp1 -r )\n\n*Unmount the image (kpartx -d imagefile.img)\n\n*Install grub to the MBR of the usbstick  (grub-install /dev/sda) (see: https://www.gnu.org/software/grub/manual/html_node/Installing-GRUB-using-grub_002dinstall.html)  \n\n\nThese are just example commands. Make them fit to your needs!\nFor backing up, you could try to just backup the data-partition (/dev/sda1 for example), it will make it easier to extract the data to anywhere, and not just a complete suitable USBstick\n", "Q: A Wine videogame console Would a PC-like game console with a single hardware configuration for every unit running wine on top of Ubuntu be easier for developers to \"port\" (more like configure in this case) games to than existing solutions used to port to Linux or valve's upcoming DX to openGL system?\nEDIT: just wanted to add a few details to avoid confusion\n\n\n*\n\n*I did say ubuntu but it could be any distro really, debian-based is still the most popular so it would be better to used that for compatibility reasons.\n\n*Consider this to be a stop-gap measure to try to lure developers to Linux, like some apps that were released by coming pre-configured to run on top of wine from the get-go, and now thanks to sales are being ported to run natively on Linux.\n\n*The steambox got delayed all the way to next year, and I wouldn't be surprised if many developers are putting any ports on stand-by. Getting a game to run on Wine is much simpler than porting it, and with a one-configuration software+hardware anyone can contribute to improve a game on Wine and it will run the same in any other user's system.\n\n\nA: Probably not.\nWine is not specific to Ubuntu; it will run on most Unix-like OSes and virtually all GNU/Linux systems. Wine can run on SteamOS. (SteamOS is actually not that dissimilar to Ubuntu--both are derived from Debian. But Wine came before Ubuntu and runs fine on systems that are quite unlike Ubuntu, too.)\nTherefore, if a game needed Wine, it could simply use Wine on SteamOS or any other GNU/Linux OS. Having access to an alternative implementation of DirectX wouldn't prevent Wine from being used; if a game worked better with Wine, it could simply use that instead. Each game could ship with Wine (whatever version worked best for it), or Wine could be included in the platform.\nYou might be thinking that using DirectX DLLs taken from a Windows system, using Wine would be more effective than using an alternative DirectX implementation (such as the OpenGL-based port that you mention Valve is developing). After all, Microsoft DirectX can be installed in Wine, and many gamers (including many Ubuntu users) do this on their regular PCs.\nHowever, distributing Microsoft's DirectX implementation(s) in this way--as part of the underlying platform or together with a game--would likely violate Microsoft's license. Note that I am not a lawyer, I could be wrong, and this is not legal advice even if I am not wrong. Furthermore, DirectX doesn't work perfectly on Wine currently and future versions (even minor updates) can't be relied on to continue working as well as existing versions do.\nA related but different possible solution comes to mind: Traditionally, gaming consoles don't have to keep track of much state between games, and are able to start up and shut down very quickly. For a console intended to run only Windows games, it seems likely that Windows Embedded would be a technically appropriate choice of platform (though it is not free open source software, the platform vendor would have to pay license fees to Microsoft, and I'm not sure whether or not current licensing schemes for Windows Embedded would facilitate this sort of deployment). For a console intended to run games that are available for GNU/Linux or can be ported to GNU/Linux with reasonable effort, a GNU/Linux system would likely be most appropriate. The natural synthesis of these needs would be a dual-boot console, which simply boots into whatever OS is needed by a game. If the platform were to support concurrently running non-game applications, they'd probably be more portable and could have a version for both OSes, and otherwise, they'd probably not be graphically or otherwise resource intensive, so virtualization could be used.\n", "Q: \"command not found\" when using arithmetic expansion in bash shell Using Ubuntu Desktop, I have terminal open and I am using the bash shell. One of the shell expansions of bash is the arithmetic expansion, with the following syntax:\n$(( EXPRESSION ))\nor \n$[ EXPRESSION ]\n\nWhen i do arithmetic, it does return the correct value but it is always followed by \"command not found\":\n$ $((1+2))\n3: command not found\n$ $[1+2]\n3: command not found\n$ $[2+2]\n4: command not found\n$ $((2*6))\n12: command not found\n\nMy question is why does it display \"command not found\" and how can I fix that?\n\nA: You have to add echo command before all of your commands,\n$ echo $[1+2]\n3\n\nYou don't have to put directly $[1+2] on terminal, because bash computes $[1+2] and again parses the same, so command not found error occurs.\nFor Example\n$ var=\"sudo apt-get update\"\n$ $var\n\nIgn http://archive.canonical.com saucy InRelease                               \nIgn http://ppa.launchpad.net saucy InRelease                                   \nIgn http://ubuntu.inode.at saucy InRelease                          \nIgn http://extras.ubuntu.com saucy InRelease                        \n29% [Waiting for headers] [Waiting for headers] [Waiting for headers]\n\nIn the above example, sudo apt-get update command was assigned to a variable var.On running $var, first bash expands it and again parses the expanded one.\n\nA: $ $((1+2))\n3: command not found\n\nWhat is happening here is that bash computes $((1+2)) which results in 3.  bash then looks for a command named 3 to execute.  It doesn't find it.  Hence the error.  As @Avinash suggests, use echo to avoid this.  \n$ echo  $((1+2))\n3\n\n\nA: Because bash is trying to execute the output of your expansion and it doesnt find any command with name 3 in the PATH. To just try out, use echo or assign it to a variable and use it later.\necho $((1+2))\n3\ntest=$((1+2))\necho $test\n3\n\n", "Q: what is vdb partition in this manual i'm trying to do this manual as it say here but in the DRBD Section it says VDB partition that don't understand what kind of partition is that ???\ncould any one help !!!\n\nA: The vdb is defined in the manual as follows:  \n\nPrepare Partitions\nThe first step in setting up DRBD is to prepare the partitions/disks\n  to be used as DRBD devices. We are assuming that we have a disk (vdb)\n  on which we will create a partition table, and a primary partition of\n  1Gb for the DRBD device.\n\nI suggest you re-read the manual from the top. I guess you will get what they are talking about, if you just take the time to understand it all\n\nA: vdb stands for vd second device b\nvd : Virtio Block Device\nb: second device with the above type\n\nIt is usually used in virtual machines like kvm and virt-manager from Virtio Disks\nThey will at at this form:\n /dev/vd[a-z][1-9]\n\nfrom redhat:\n\nDevice naming\nvirtio-blk devices are represented by the guests with\nfiles whose names start with /dev/vd. This  is unlike devices in a\nbare-metal system, whose names typically start with /dev/sd\n\n", "Q: Error while creating qcow2 file using qemu-img When I am creating an qcow2 file using qemu-img command I am getting error as librbd.so.1 file not found. When I check for the dependencies that .so file is present in the /usr/lib folder.\nCan any one solve this issue?\n\nA: First try to install this library if not exists:\nsudo apt-get install librbd1\n\nthen try you qemu-img command. If failed find the library location:\nsudo find / -name  librbd.so.1\n\nmake a symlink to it\nln -s /usr/lib/librbd.so.1 /path/to/your/librd.so.1\n\nthen execute qemu-img again\n", "Q: Nautilus doesn't mount in Xmonad: Not authorized to perform operation I'm using Xmonad as my window manager.\nIn the application nautilus, whenever I try to mount my usb sticks, it shows me the dialog \"Not authorized to perform operation.\"\nI have tried putting this in ~/.xsession file:\nnautilus --no-desktop -n &\nBut that doesn't work. \nThis is my current ~/.xsession file:\n#!/bin/bash\n\ngnome-settings-daemon &\nexec dbus-launch --exit-with-session xmonad\n\nAlso, when I start a pure gnome session, everything works fine. Any idea on how to make nautilus ask password or mount the usb stick on clicking it in the nautilus ?\n\nA: *\n\n*Open Disks from Dash\n\n\n\n*Choose the desired disk/partition\n\n\n\n*Edit Mount Options\n\n\n\n*Uncheck require additional authorization\n\n\nA: You need to start polkit in your xsession. \nYou most likely have a .desktop file in /etc/xdg/autostart in the path somewhere with the full path to your polkit daemon.\nFor me adding /usr/lib/policykit-1-gnome/polkit-gnome-authentication-agent-1 in ~/.Xsession fixed the issue. \n\nA: You will have this error if using XRDP. You need to login directly to Xwindow \nfrom KVM.\n\nA: This nice overview of polkit from archlinux wiki is very useful to understand the topic. \nIn my case, since I'm running a custom configured desktop composed of awesome, nodm, consolekit, and other hand picked software, I have to start a polkit authentication agent manually. This is provided by mate-polkit-bin package in debian. I believe xmonad will be a very similar case.\nBefore: thunar failing to mount, saying \"Failed to mount XXX. Not authorized to perform operation.\"\nAfter running mate-polkit: thunar upon attempt to mount asks me to authenticate according to the polkit rules for the given action. This is actually requested by the udisks tool that thunar uses to do the mounting. Once correctly authenticated, devices mount as expected.\nSolution is to add a polkit authentication agent (like mate-polkit) to your session startup commands (autostart).\n", "Q: Unable to access my local server from outside the domain I would really appreciate it if you could help me with this.\nIm setting up an internal mail server using Zimbra server 8.0.3 and i want people from outside the domain to be able to access this server which is located locally.\nI have a public ip provided by my ISP and i have assigned that IP to one port of the router(Where the link from the ISP comes in) and this server is located behind that Cisco Router with a public IP 192.168.xxx.xxx. \nIn that router i performed Nat Port Forwarding as seen below so that mail requests from outside will be forwarded to that server.\nip nat inside source list 10 interface GigabitEthernet0/1 overload\nip nat inside source static tcp 192.168.30.254 22 41.59.xx.xx 22 extendable\nip nat inside source static udp 192.168.30.254 22 41.59.xx.xx 22 extendable\nip nat inside source static tcp 192.168.30.254 25 41.59.xx.xx 25 extendable\nip nat inside source static tcp 192.168.30.254 80 41.59.xx.xx 80 extendable\nip nat inside source static tcp 192.168.30.254 110 41.59.xx.xx 110 extendable\nip nat inside source static tcp 192.168.30.254 143 41.59.xx.xx 143 extendable\nip nat inside source static tcp 192.168.30.254 389 41.59.xx.xx 389 extendable\nip nat inside source static udp 192.168.30.254 389 41.59.xx.xx 389 extendable\nip nat inside source static tcp 192.168.30.254 443 41.59.xx.xx 443 extendable\nip nat inside source static tcp 192.168.30.254 993 41.59.xx.xx 993 extendable\nip nat inside source static tcp 192.168.30.254 995 41.59.xx.xx 995 extendable\nip nat inside source static tcp 192.168.30.254 7025 41.59.xx.xx 7025 extendable\n\nAfter that i change MX and A records of my internet domain mail.example.co.tz to point to that public ip  41.59.xx.xx so that any one accessing that link will be redirected to the public ip and then port forwarded to the mail server.\nSo here comes the problem...after all that when i access mail.example.co.tz opn a web browser it says Unable To connect. \nAm i going wrong somewhere?? \n\nA: The Zimbra wiki lists ports 465 and 587, which you do not have forwarded. (It also marks 7025 as internal.)\nOtherwise, please check each step of the connection:\n\n\n*\n\n*Run nslookup mail.example.co.tz, and confirm that the domain is forwarded to the right public IP.\n\n*Run dig mail.example.co.tz, and confirm that your MX and A DNS records are sending mail to the right place. (You may need to configure records for example.co.tz, instead.)\n\n*If both of those are correct, use telnet to try and connect to a mail port. telnet mail.example.co.tz 22 should get some kind of response from the server. Try some of the other ports, too.\n", "Q: UI Problem in Ubuntu after give update and run VLC player I have Ubuntu 12.10 in my Lenovo G580 machin.I have given update to my system two days before VLC player and other applications are working fine till that date.After that update i can't run VLC player in my machine i can't see UI of VLC and my OS not performing regular actions,i mean it'll not show any applications close minimize buttons and it's not showing system menus.If i didn't run VLC then it's working fine.Can anyone help in this?\n\nis this compatibility issue in new version of VLC?\n\nA: re install vlc\n$ sudo apt-get purge vlc\n\nor \n$ sudo apt-get autoremove vlc\n\ninstalling the stable version\n$ sudo add-apt-repository ppa:djcj/vlc-stable\n$ sudo apt-get update\n$ sudo apt-get install vlc\n\nthen reset the unity \n$ setsid unity \n\nif that didnt workout try to re-install the unity & the desktop\n$ sudo apt-get autoremove ubuntu-desktop \n$ sudo apt-get autoremove unity \n$ sudo apt-get update \n$ sudo apt-get install unity\n$ sudo apt-get install unity-2d \n$ sudo apt-get install ubuntu-desktop \n$ sudo shutdown -r\n\n", "Q: Unable to create `file' (while processing ): Read-only file syste I am trying to update my softwares but I get the following error:\nThe package system is broken\nCheck if you are using third party repositories. If so disable them, since they are a common source of problems.\nFurthermore run the following command in a Terminal: apt-get install -f\nThe following packages have unmet dependencies:\nlinux-image-generic-lts-quantal: Depends: linux-image-3.5.0-45-generic but it is not installed***\n\nAfter this, I tried installing the package linux-image-3.5.0-45-generic from the software center but I have the same dialog box as above stating that I have unmet dependencies and I need to install the very same package to install itself.\n$ sudo apt-get install -f\n\n[sudo] password for shashank: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nCorrecting dependencies... Done\nThe following extra packages will be installed:\n  linux-image-3.5.0-47-generic linux-image-generic-lts-quantal\nSuggested packages:\n  linux-lts-quantal-doc-3.5.0 linux-lts-quantal-source-3.5.0\n  linux-lts-quantal-tools linux-headers-3.5.0-47-generic\nThe following NEW packages will be installed:\n  linux-image-3.5.0-47-generic\nThe following packages will be upgraded:\n  linux-image-generic-lts-quantal\n1 upgraded, 1 newly installed, 0 to remove and 103 not upgraded.\n4 not fully installed or removed.\nNeed to get 0 B/40.8 MB of archives.\nAfter this operation, 158 MB of additional disk space will be used.\nDo you want to continue [Y/n]? y\n(Reading database ... 224750 files and directories currently installed.)\nUnpacking linux-image-3.5.0-47-generic (from .../linux-image-3.5.0-47-generic_3.5.0-47.71~precise1_amd64.deb) ...\nDone.\ndpkg: error processing /var/cache/apt/archives/linux-image-3.5.0-47-generic_3.5.0-47.71~precise1_amd64.deb (--unpack):\n unable to create `/boot/abi-3.5.0-47-generic.dpkg-new' (while processing `./boot/abi-3.5.0-47-generic'): Read-only file system\ndpkg-deb: error: subprocess paste was killed by signal (Broken pipe)\nExamining /etc/kernel/postrm.d .\nrun-parts: executing /etc/kernel/postrm.d/initramfs-tools 3.5.0-47-generic /boot/vmlinuz-3.5.0-47-generic\nrun-parts: executing /etc/kernel/postrm.d/zz-runlilo 3.5.0-47-generic /boot/vmlinuz-3.5.0-47-generic\nrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 3.5.0-47-generic /boot/vmlinuz-3.5.0-47-generic\nErrors were encountered while processing:\n /var/cache/apt/archives/linux-image-3.5.0-47-generic_3.5.0-47.71~precise1_amd64.deb\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nAnd the output of uname -r shows,\n$ uname -r\n3.5.0-44-generic\n\nI typed the command sudo mount in terminal and following is the output\nshashank@shashank-HP-ProBook-445-G1:~$ sudo mount\n/dev/sda6 on / type ext4 (rw,errors=remount-ro)\nproc on /proc type proc (rw,noexec,nosuid,nodev)\nsysfs on /sys type sysfs (rw,noexec,nosuid,nodev)\nnone on /sys/fs/fuse/connections type fusectl (rw)\nnone on /sys/kernel/debug type debugfs (rw)\nnone on /sys/kernel/security type securityfs (rw)\nudev on /dev type devtmpfs (rw,mode=0755)\ndevpts on /dev/pts type devpts (rw,noexec,nosuid,gid=5,mode=0620)\ntmpfs on /run type tmpfs (rw,noexec,nosuid,size=10%,mode=0755)\nnone on /run/lock type tmpfs (rw,noexec,nosuid,nodev,size=5242880)\nnone on /run/shm type tmpfs (rw,nosuid,nodev)\n/dev/sda1 on /boot type vfat (rw,errors=remount-ro)\n/dev/sda5 on /home type ext4 (rw,errors=remount-ro)\nbinfmt_misc on /proc/sys/fs/binfmt_misc type binfmt_misc (rw,noexec,nosuid,nodev)\ngvfs-fuse-daemon on /home/shashank/.gvfs type fuse.gvfs-fuse-daemon (rw,nosuid,nodev,user=shashank)\n\n\nA: You need to remount the file system as read write, otherwise it will fail:\ndpkg: error processing /var/cache/apt/archives/linux-image-3.5.0-47-generic_3.5.0-47.71~precise1_amd64.deb (--unpack):\n unable to create `/boot/abi-3.5.0-47-generic.dpkg-new' (while processing `./boot/abi-3.5.0-47-generic'): Read-only file system\ndpkg-deb: error: subprocess paste was killed by signal (Broken pipe)\n\nUse sudo mount | grep -v rw to find out the device that is mounted as read only, then run:\nsudo mount -o remount,rw /dev/sda1\n\nReplace sda1 with whatever is the device that is mounted as readonly, but I'm pretty sure it will be /boot.\n\nA: I had exactly the same issue today. And solved it as follows:\nIn a terminal window...\ndeleted the downloaded kernel's .deb file, in my case:\nsudo rm /var/cache/apt/archives/linux-image-3.5.0-47-generic_3.5.0-47.71~precise1_i386.deb\n\nthen ran the update manager again, refreshing it. Not sure if this did anything but I did it.\nsudo apt-get -f install\n\nThis downloaded the deb file anew and installed it just fine.\nHope this helps. It seems, at least in my case, that the deb file had been corrupted during an initial download by the update manager. \n", "Q: Blackscreen after installing nvidia drivers I am running into black screen problems after installing nvidia drivers in my notebook. I have a nvidia mobile 540 but everytime I try installing the driver, I boot to a black screen. Only the cursor shows.\nMy notebook has an intel onboard graphic and the nvidia. Without the drivers, it burns by watching videos.\n\nA: Installing the latest nvidia drivers seem to help in some cases so please check this link for a step-by-step guide: Insall Latest Nvidia Drivers for Ubuntu\n...also...  Check out how to fix and use a dual-graphics setup as well: Using Dual-Gfx on Ubuntu Fix\n", "Q: Avoid initial full directory commit & rather add file to VCS just before modifying the file? Could I put a certain file in some VCS like git/subversion/etc only \"when\" I am modifying it. So first I put the unmodified version & then the modified version. The desire is to put the file in VCS only when I want, rather than doing initial full directory commits.. Is this possible ?\nI want to version some of the configuration files that I modify on my ubuntu server, but I wish not to do an initial full directory commit, rather i'm looking if it is possible to a add file to VCS just before I am modifying the file.. how could i achieve this ?\nI'm aware of      etckeeper\n but that is only for /etc & it does a initial full directory commit ? why do I do that.. i would rather only want to keep the files i modify & manually manage rather than autocommits at each install.\n\nA: If I understand you correctly, what you want to do is possible with bazaar (and probably other version control systems). Run:\nbzr init /path/to/dir\ncd /path/to/dir\nbzr ignore \"*\"\nbzr ci -m \"Initial commit.\"\n\nThis will put the directory into version control, but none of the actual files will be versionized. Later, when you want to add a specific file to the repo, run bzr add file\nThis is what I've done with my home directory.\n\nA: You would need a trigger right before a file was changed. So right before it is opened for writing. If this is possible at all, then inotify would be the way to go. But looking at its man page, I only see IN_OPEN, which seems too generic for the purpose, so I don't really see a way to make this work.\nWhy you are so strongly against the full directory commit? The content will be stored zipped, and your configurations shouldn't be too large. You can also exclude part of the configuration files by marking them ignored. Or you can exclude everything by default, and only include specific files.\n", "Q: Why is the evolution-calendar-factory process running? Why is the evolution-calendar-factory process running?\nHere are some of the running processes (created with ps aux --forest)\nlightdm\n \\_ /usr/bin/X -core :0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch\n \\_ lightdm --session-child 12 31\n     \\_ init --user\n         \\_ ssh-agent\n         \\_ dbus-daemon --fork --session --address=unix:abstract=/tmp/dbus-tGrbQ6SZd8\n         \\_ /usr/lib/evolution/evolution-source-registry\n         \\_ /usr/lib/x86_64-linux-gnu/gconf/gconfd-2\n         \\_ /usr/lib/evolution/evolution-calendar-factory\n\nAFAIK I don't need evolution-calendar-factory. I don't want it to run, since it takes up a lot of RAM \nWhy is it started?\nHow to stop it starting the next time?\n\nA: If you don't use Evolution, you could just completely remove it, there are some instructions how to here:\nHow do I completely remove Evolution?\nHere is the command: sudo apt-get --purge remove evolution evolution-exchange evolution-plugins evolution-common evolution-webcal\n", "Q: Update Manager crashes, says it needs 3.2.0.58.69 but linux-image-generic on system is 3.2.0.59.70 Recently Update Manager ceased working. Ubuntu Software Centre, when I enter it instead, offers to repair, then fails and offers to repair again, and so on.\nThis is the key sentence I keep getting and am sick of seeing:\nlinux-generic depends on linux-image-generic (= 3.2.0.58.69); however: Version of linux-image-generic on system is 3.2.0.59.70.\n\nIt makes no sense to me. Why would linux need an earlier version than the one installed to update itself?\nI am not certain, but it may be that this problem started after attempting to install Google Chrome.\nWhen I checked with Synaptic PM, having tried some of the suggested apt commands at the unmet dependencies thread to no avail, it identified linux-generic as broken, tried to update to 3.2.0.60.71, but then failed again, saying it needed the earlier version (which synaptic says is installed).But that 3.2.0.60.71 is installed instead!\nSo, it says it needs to upgrade, but then acts like it already has. I have not seen anyone else with precisely (no pun intended) this problem on these forums, though someone else unknown has saved virtually the same system response on pastebin here.\n\nA: The problem you have is that linux-generic and other packages depending on it, like linux-image-generic need to be of same version.But on your system, They both are of different version.There are many reasons for this, which I won't go in details of.\nAs linux-generic is not an essential package, you can reinstall it to fix the system.\nTo do this, run the following commands.\nsudo apt-get remove linux-generic\nsudo apt-get install linux-generic\n\n\nNOTE:- It is a good idea to run sudo apt-get clean and sudo apt-get autoclean occasionally.This considerably decreases the chances of future dependency problems.\n\n", "Q: How to upgrade Mate 1.6 to 1.8 in Ubuntu 12.04 I installed Mate using the official directions (http://wiki.mate-desktop.org/download) but it installed 1.6 instead of 1.8. How can I upgrade in Ubuntu 12.04?\n\nA: Did you follow the way provided here? If so, try to re-enter the following into terminal. Especially the sudo apt-get update thing.\nsudo apt-get update\nsudo apt-get --yes --quiet --allow-unauthenticated install mate-archive-keyring\nsudo apt-get update\n# this installs base packages\nsudo apt-get install mate-core\n# this installs more packages\nsudo apt-get install mate-desktop-environment\n\nThen if the package for 12.04LTS is available, it should be updated into 1.8.\nPlease specify more info on your question (about how did you install the MATE).\n", "Q: xprintidle doesn't work in cronjob. Why? I have lxle (Lubuntu) 12.04 installed and I spent lots of time looking for working solution to make PC shutdown after some period of idle state.\nAfter checking many programs  which haven't worked I decided to spend much time of shell script solution run by cronjob\nI am stuck on 2 problems here.\n\n\n*\n\n*xprintidle doesn't give any results (empty string) when it is run by cronjob - no matter in crontab file or shell file in those environments it just give empty string instead of number of milliseconds of idle.\n\n*Secondly it seems not simple for me to run my script from crontab for shutdown commend as a root. \nCould you give me a link explaining that topic? I know only sudo as a user, but script shouldn't ask for password but just shutdown system.\n\nA: You need to set the DISPLAY environment variable before calling it, you can try this in the virtual consoles (Ctrl-Alt-F1) since they don't have the DISPLAY variable set, they will act exactly like the cron script will act.\nDISPLAY=:0 xprintidle\n\nor\nexport DISPLAY=:0\nxprintidle\n\neither should work.\n", "Q: How can I list last updated packages from terminal? After upgrading packages my system is not booting anymore. How can I list last updated packages from terminal in order to revert the changes?\nOr is there a simpler way to take back latest upgrade?\n\nA: Command to list recently installed packages that were installed via any method (apt-get, Software Center...):  \ncat /var/log/dpkg.log | grep \"\\ install\\ \"\nExample output:\n2010-12-08 15:48:14 install python-testtools <none> 0.9.2-1\n2010-12-08 15:48:16 install quickly-widgets <none> 10.09\n2010-12-08 22:21:31 install libobasis3.3-sdk <none> 3.3.0-17\n2010-12-09 12:00:24 install mc <none> 3:4.7.0.6-1\n2010-12-09 23:32:06 install oggconvert <none> 0.3.3-1ubuntu1\n2010-12-09 23:34:50 install mpg123 <none> 1.12.1-3ubuntu1\n2010-12-09 23:34:52 install dir2ogg <none> 0.11.8-1\n2010-12-09 23:34:53 install faad <none> 2.7-4\n2010-12-09 23:34:54 install wavpack <none> 4.60.1-1\n2010-12-10 11:53:00 install playonlinux <none> 3.8.6\n\n\nCommand to list history of apt-get (NOTE: this doesn't list dependencies installed, it simply lists previous apt-get commands that were run):\n\ncat /var/log/apt/history.log | grep \"\\ install\\ \"\nExample output:\nCommandline: apt-get install libindicate-doc\nCommandline: apt-get install googlecl\nCommandline: apt-get --reinstall install ttf-mscorefonts-installer\nCommandline: apt-get install valac libvala-0.10-dev\nCommandline: apt-get install libgtksourceview-dev\nCommandline: apt-get install python-sphinx\nCommandline: apt-get install python-epydoc\nCommandline: apt-get install quickly-widgets\nCommandline: apt-get install libreoffice3* libobasis3.3*\nCommandline: apt-get install mc\n\n", "Q: Linux driver for tplink-wn725n nano wireless adapter I have recently installed UBUNTU 12.04 but can not connect to the net as my wireless adapter has no drivers yet. I found some documentation on it, but I am such a noob I don’t know what to do with all this. The adapter is the Linux driver for tplink-wn725n nano wireless adapter\nIs there anyone who could explain to me what I have to do with this information? ----https://github.com/liwei/rpi-rtl8188eu.\nsomeone else in another thread mentioned to try:sudo apt-get install linux-backports-modules-cw-3.6-precise-generic but I dont know how I can do that if my machine is offline. Can any of this stuff be downloaded on one machine and transfered with a USB disk?\n\nA: Install common wifi drivers and wicd network manager.\nsudo apt-get install linux-firmware-nonfree wicd wicd-gtk wicd-daemon\n\nThen try to connect with wicd network manager.\n", "Q: Can sudo be reinstalled after being removed? This seems to be a chicken-egg problem.\nThe most common task using sudo is installing and removing software.\nsudo apt-get purge <appname>\n\nBut sudo itself can be removed.\nsudo apt-get purge sudo # Do not run this command on production computers!\n\nThis is where the fun comes\nubuntu@ubuntu:~$ sudo\nbash: /usr/bin/sudo: No such file or directory\n\nAlthough it's obvious that no person in his right mind will purge sudo (other than me), someone can be fooled to run this command (not directly, in its hex mode, or whatever it's called) or a person could SSH in disguised as tech guru and do the mess.\nSo is there a way of reinstalling sudo?\n\nA: I can install applications using:\npkexec apt-get install <appname>\n\nFrom man pkexec:\n\n  pkexec allows an authorized user to execute PROGRAM as another user. If\n  username is not specified, then the program will be executed as the\n  administrative super user, root.\n\n\nSo, I suppose that pkexec apt-get install sudo should work as well.\n\nEdit: now I can confirm: yes, sudo can be installed using using pkexec  apt-get install sudo:\n\n(click to enlarge)\n\nA: Boot with the extra parameter init=/bin/sh on the kernel command line.  This will put you directly into a root shell, from where you can simply run apt-get install sudo and then reboot.  You may need to run /etc/init.d/networking start to get a working network connection first. Far simpler than messing around with recovery CDs or live disks, if you ask me.\n\nA: You can always boot into Recovery Mode, drop to root shell and install it without sudo.\n\nA: Yes, reinstalling sudo package would be possible via chroot method.\n\n\n*\n\n*First boot from Ubuntu live disk.\n\n*Mount the previously installed Ubuntu partition into whatever directory you want.In my case, i mounted it in /media/ubuntu.\nsudo mkdir /media/ubuntu\nsudo mount /dev/sdaX /media/ubuntu   # /dev/sdaX - previously installed Ubuntu partition.\n\n\n*By default you didn't able to get internet connection after chrooted into a partition.So run the below command to make it work.\nfor d in dev sys run proc; do sudo mount --bind /$d /media/ubuntu/$d ; done\n\nThanks to @Oli for this wonderful piece of code .\n\n\n*\n\n*Now chroot into that mounted directory,\n$ sudo chroot /media/ubuntu\n# apt-get update\n\n\n*Install sudo package by running,\n# apt-get install sudo\n\n\n*Now exit out of chrooted environment.\nexit\n\n\n*Finally boot up your Ubuntu OS.Now test your sudo command, it will surely works.\n\nA: If you already set or update  the root user account password by this command sudo passwd root then you don't worry about purging sudo.Just login into your root account and then install sudo,\nsu\napt-get install sudo\n\n\nClick here to enlarge\n\nA: This problem seems to be very ubuntu-specific. As non-ubuntu user I didn't even understand at first why sudo would be a special case in any way (a lot of distributions don't install it by default).\nYou don't need sudo at all. It's just a lazy shortcut that allows you to execute a root command without actually logging in as root. However, if you have to do anything more than a single command, it's just awful constantly prefixing everything with sudo. Not to mention that using sudo makes users ignorant about how permissions and root account work. It makes much more sense to just login as root, do the administration of the system and logout. That you do with su if you are already logged in as a regular user. Or you could log in directly as root.\nOf course you need to have root password set, that's the reasonable configuration, otherwise you have a windows-like system where there are actions that nobody can perform and you are really locked out if somehow sudo isn't available (it requires working /etc/, set $PATH and other things mounted - which you may not have if something goes wrong early in boot).\n\nA: sudo (and any other root privilege) only applies to the running OS. If you have been silly and removed sudo (or /usr/ for that matter) and don't have alternates like pkexec you can simply boot from something else, copy the missing software, and restart again.\nPhysical access nullifies any and all software security your system may have.\n", "Q: Gaining internet access during installation over XP I am trying to install over XP.\nWhen booted in XP connect wirelessly and it is working.\nWhen I enter Ubuntu set up there is no connection showing.\nI've tried to edit the connection but it is not detecting my wireless.\nI suspect this may be because the wireless driver (for Ubuntu?) is not installed or booted.\n(I'm not an expert).\nHow would you advise I proceed?\n\nA: I suggest, if possible, to gain internet access with a wired ethernet connection, if possible. If this is not possible, you will have the best luck installing with working wireless if you install the latest Ubuntu version 13.10. There are drivers included in the October 2013 version that were not yet available in Ubuntu 12.04. The exception is that Ubuntu 12.04.4 LTS includes the same kernel and therefor the same drivers as 13.10.\nIf you still find no wireless driver and therefor connectivity, I'd go ahead and install without internet and research and install a driver after installation. Search your pci.id from the terminal command:\nlspci -nn | grep 0280\n\nHere is an example from my machine:\nIntel Corporation Centrino Advanced-N 6200 [8086:4239]\n\nIf you can't find a method to install your wireless drivers after a search, post a new question here.\n", "Q: Help about sed command A Linux textbook covering sed command gives me an example as follow:\nsed -e 's/\\(<[^ ]*>\\)\\([ ]*\\)\\(<[^ ]*>\\)/\\3\\2\\1/g'\nGNU Linux is cool\nLinux GNU cool is \n\nbut while I typing exactly the same command as the about one, it shows me:\nsed -e 's/\\(<[^ ]*>\\)\\([ ]*\\)\\(<[^ ]*>\\)/\\3\\2\\1/g'\nGNU Linux is cool\nGNU Linux is cool\n\nAnyone can help me solve this? I'm using Ubuntu 12.04LTS. Many thanks.\n\nA: It may just be a problem with the forum formatting, but the < and > are presumably intended to be word anchors and as such need backslash escapes \\< and \\>\nsed -e 's/\\(\\<[^ ]*\\>\\)\\([ ]*\\)\\(\\<[^ ]*\\>\\)/\\3\\2\\1/g'\n\ni.e.    \necho 'GNU Linux is cool'| sed -e 's/\\(\\<[^ ]*\\>\\)\\([ ]*\\)\\(\\<[^ ]*\\>\\)/\\3\\2\\1/g'\nLinux GNU cool is\n\nHowever like the previous posters I'd also suggest using the GNU -r extended form to cut down the number of escapes\nsed -re 's/(\\<[^ ]*\\>)([ ]*)(\\<[^ ]*\\>)/\\3\\2\\1/g'\n\nThe word anchors would not seem to be necessary at all if you change the * (zero or more) to + (one or more)\necho 'GNU Linux is cool'| sed -re 's/([^ ]+)([ ]+)([^ ]+)/\\3\\2\\1/g'\nLinux GNU cool is\n\n\nA: Well I don't know. There were a few problems here:\n\n\n*\n\n*You need extended mode on for these matches (-r)\n\n*You don't need script mode on (-e) but that wasn't an error\n\n*There was a lot of bracket escaping which was syntatically incorrect ( you needed those to match)\n\n*I couldn't work out what the angle brackets were for at all. So I nuked them.\n\n*/g global mode breaks it because it swaps the last three words and breaks the space. Try it if you like.\n\n\nAnd here it is working:\n$ echo \"GNU Linux is cool\" | sed -r \"s/([^ ]*)([ ]*)([^ ]*)/\\3\\2\\1/\"\nLinux GNU is cool\n\nA better/shorter/easier-to-read way to do this would be to nuke the second group and just use a literal space. Like so:\n$ echo \"GNU Linux is cool\" | sed -r \"s/([^ ]*) ([^ ]*)/\\2 \\1/\"\nLinux GNU is cool\n\n", "Q: Cannot boot my computer. Hard Drive is not recognized by BIOS I have an ASUS Laptop running Windows 8.1 (K55A-DH51 Intel Core i5-3210M 2.50GHz - 750GB)\nI am completely new to Linux and Ubuntu. I tried to install Ubuntu 13.10 from an USB drive (I modified my BIOS so that it would boot from my USB and start the installer).\nEverything was going great until the installer did not recognize Windows 8, so I clicked the \"Something else\" option in the installer and was presented with a list of partitions (I believe that's what they were) and that is when I decided to quit the installation as I did not know what to do.\nI then tried to boot to Windows, but my computer kept going to my BIOS. I checked my Boot menu and tried to change my Boot priority to my Hard Drive but I did not see that option. I am not sure what to do as I can't tell my BIOS to boot from my hard drive, even when I reset it to it's defaults settings.\nI have tried multiple things (including Boot-repair, which gave me this: http://paste.ubuntu.com/7094345/ ) but I don't understand most of the terms and procedures. I am currently running Ubuntu from my USB drive but I want to go back to Windows. I don't want to lose my files.\nI think I just need to to find a way for my BIOS to recognize my hard drive and tell it to boot from it.\n\nA: If you have a CD/DVD of your Windows (The clean solution) :\n\n\n*\n\n*Boot from Windows CD/DVD and choose “Repair” when it shows up.\n\n*Choose Command Prompt on the resulting screen and run the following\ntwo commands:\nbootrec /fixmbr\nbootrec /fixboot\n\n*Remove the CD/DVD and you should boot straight into Windows\n\nA: I do not know what you have done while installing, but it looks like you have accidentally overwritten your windows partition with a blank ext2 partition. The boot-repair paste shows that you don't have any operating system currently installed. So it would appear that windows has somehow been deleted. Sorry to be the bearer of bad news, but the files are probably already gone... I hope you kept backups.\n\nA: Try this: burn super GRUB2 DISK http://www.supergrubdisk.org/ this will tell you if you have your windows yet or lost it !!\n", "Q: I want to download ubuntu 14.04 I can't wait to download ubuntu 14.04. When wil it be able to download? And will I be able to turn on wifi and bluetooth? please answer\n\nA: you can already download it here, but it is still in development, en I would not suggest to install it on your daily machine. The final release will be on April 17th (see comment Jacob).\nIf you have problems with your bluethooth and wifi, look on this site if someone else asked the question, or ask a new question to try to solve it. Make sure to include as much technical information as possible about your machine and the wireless chip.\n", "Q: Identify duplicate lines in a file without deleting them? I have my references as a text file with a long list of entries and each has two (or more) fields. \nThe first column is the reference's url; the second column is the title which may vary a bit depending on how the entry was made. Same for third field which may or may not be present.\nI want to identify but not remove entries that have the first field (reference url) identical. I know about sort -k1,1 -u but that will automatically (non-interactively) remove all but the first hit. Is there a way to just let me know so I can choose which to retain?\nIn the extract below of three lines that have the same first field (http://unix.stackexchange.com/questions/49569/), I would like to keep line 2 because it has additional tags (sort, CLI) and delete lines #1 and #3:\nhttp://unix.stackexchange.com/questions/49569/  unique-lines-based-on-the-first-field\nhttp://unix.stackexchange.com/questions/49569/  Unique lines based on the first field   sort, CLI\nhttp://unix.stackexchange.com/questions/49569/  Unique lines based on the first field\n\nIs there a program to help identify such \"duplicates\"? Then, I can manually clean up by personally deleting lines #1 and #3?\n\nA: If I understand your question, I think that you need something like:\nfor dup in $(sort -k1,1 -u file.txt | cut -d' ' -f1); do grep -n -- \"$dup\" file.txt; done\n\nor:\nfor dup in $(cut -d \" \" -f1 file.txt | uniq -d); do grep -n -- \"$dup\" file.txt; done\n\nwhere file.txt is your file containing data about you are interested.\nIn the output you will see the number of the lines and lines where first field is found two or more times.\n\nA: If I read this correctly, all you need is something like\nawk '{print $1}' file | sort | uniq -c | \n    while read num dupe; do [[ $num > 1 ]] && grep -n -- \"$dupe\" file; done\n\nThat will print out the number of the line that contains the dupe and the line itself. For example, using this file:\nfoo bar baz\nhttp://unix.stackexchange.com/questions/49569/  unique-lines-based-on-the-first-field\nbar foo baz\nhttp://unix.stackexchange.com/questions/49569/  Unique lines based on the first field   sort, CLI\nbaz foo bar\nhttp://unix.stackexchange.com/questions/49569/  Unique lines based on the first field\n\nIt will produce this output:\n2:http://unix.stackexchange.com/questions/49569/  unique-lines-based-on-the-first-field\n4:http://unix.stackexchange.com/questions/49569/  Unique lines based on the first field   sort, CLI\n6:http://unix.stackexchange.com/questions/49569/  Unique lines based on the first field\n\nTo print only the number of the line, you could do\nawk '{print $1}' file | sort | uniq -c | \n while read num dupe; do [[ $num > 1 ]] && grep -n -- \"$dupe\" file; done | cut -d: -f 1\n\nAnd to print only the line:\nawk '{print $1}' file | sort | uniq -c | \nwhile read num dupe; do [[ $num > 1 ]] && grep -n -- \"$dupe\" file; done | cut -d: -f 2-\n\n\nExplanation:\nThe awk script just prints the 1st space separated field of the file. Use $N to print the Nth field. sort sorts it and uniq -c counts the occurrences of each line. \nThis is then passed to the while loop which saves the number of occurrences as $num and the line as $dupe and if $num is greater than one (so it's duplicated  at least once) it will search the file for that line, using -n to print the line number. The -- tells grep that what follows is not a command line option, useful for when $dupe can start with -.\n\nA: This is a classical problem that can be solved with the uniq command. uniq can detect duplicate consecutive lines and remove duplicates (-u, --unique) or keep duplicates only (-d, --repeated).\nSince ordering of duplicate lines is not important for you, you should sort it first. Then use uniq to print unique lines only:\nsort yourfile.txt | uniq -u\n\nThere is also a -c (--count) option that prints the number of duplicates for the -d option. See the manual page of uniq for details.\n\nIf you really do not care about the parts after the first field, you can use the following command to find duplicate keys and print each line number for it (append another | sort -n to have the output sorted by line):\n cut -d ' ' -f1 .bash_history | nl | sort -k2 | uniq -s8 -D\n\n\nSince you want to see duplicate lines (using the first field as key), you cannot directly use uniq. The issue that make automation difficult is that the title parts vary, but a program cannot automatically determine which title should be considered the final one.\nHere is an AWK script (save it to script.awk) that takes your text file as input and prints all duplicate lines so you can decide which to delete. (awk -f script.awk yourfile.txt)\n#!/usr/bin/awk -f\n{\n    # Store the line ($0) grouped per URL ($1) with line number (NR) as key\n    lines[$1][NR] = $0;\n}\nEND {\n    for (url in lines) {\n        # find lines that have the URL occur multiple times\n        if (length(lines[url]) > 1) {\n            for (lineno in lines[url]) {\n                # Print duplicate line for decision purposes\n                print lines[url][lineno];\n                # Alternative: print line number and line\n                #print lineno, lines[url][lineno];\n            }\n        }\n    }\n}\n\n\nA: No doubt the most verbose one in the list, could probably be shorter:\n#!/usr/bin/python3\nimport collections\nfile = \"file.txt\"\n\ndef find_duplicates(file):\n    with open(file, \"r\") as sourcefile:\n        data = sourcefile.readlines()\n    splitlines = [\n        (index, data[index].split(\"  \")) for index in range(0, len(data))\n        ]\n    lineheaders = [item[1][0] for item in splitlines]\n    dups = [x for x, y in collections.Counter(lineheaders).items() if y > 1]\n    dupsdata = []\n    for item in dups:\n        occurrences = [\n            splitlines_item[0] for splitlines_item in splitlines\\\n                       if splitlines_item[1][0] == item\n            ]\n        corresponding_lines = [\n            \"[\"+str(index)+\"] \"+data[index] for index in occurrences\n            ]\n        dupsdata.append((occurrences, corresponding_lines))\n\n    # printing output   \n    print(\"found duplicates:\\n\"+\"-\"*17)\n    for index in range(0, len(dups)):\n        print(dups[index], dupsdata[index][0])\n        lines = [item for item in dupsdata[index][1]]\n        for line in lines:\n            print(line, end = \"\")\n\n\nfind_duplicates(file)\n\ngives on a textfile like:\nmonkey  banana\ndog  bone\nmonkey  banana peanut\ncat  mice\ndog  cowmeat\n\nan output like:\nfound duplicates:\n-----------------\ndog [1, 4]\n[1] dog  bone\n[4] dog  cowmeat\nmonkey [0, 2]\n[0] monkey  banana\n[2] monkey  banana peanut\n\nOnce you picked the lines to remove:\nremovelist = [2,1]\n\ndef remove_duplicates(file, removelist):\n    removelist = sorted(removelist, reverse=True)\n    with open(file, \"r\") as sourcefile:\n        data = sourcefile.readlines()\n    for index in removelist:\n        data.pop(index)\n    with open(file, \"wt\") as sourcefile:\n        for line in data:\n            sourcefile.write(line)\n\nremove_duplicates(file, removelist)\n\n\nA: See the following sorted file.txt:\naddons.mozilla.org/en-US/firefox/addon/click-to-play-per-element/ ::: C2P per-element\naddons.mozilla.org/en-us/firefox/addon/prospector-oneLiner/ ::: OneLiner\naskubuntu.com/q/21033 ::: What is the difference between gksudo and gksu?\naskubuntu.com/q/21148 ::: openoffice calc sheet tabs (also askubuntu.com/q/138623)\naskubuntu.com/q/50540 ::: What is Ubuntu's Definition of a \"Registered Application\"?\naskubuntu.com/q/53762 ::: How to use lm-sensors?\naskubuntu.com/q/53762 ::: how-to-use-to-use-lm-sensors\nstackoverflow.com/q/4594319 ::: bash - shell replace cr\\lf by comma\nstackoverflow.com/q/4594319 ::: shell replace cr\\lf by comma\nwiki.ubuntu.com/ClipboardPersistence ::: ClipboardPersistence\nwiki.ubuntu.com/ClipboardPersistence ::: ClipboardPersistence - Ubuntu Wiki\nwww.youtube.com/watch?v=1olY5Qzmbk8 ::: Create new mime types in Ubuntu\nwww.youtube.com/watch?v=2hu9JrdSXB8 ::: Change mouse cursor\nwww.youtube.com/watch?v=Yxfa2fXJ1Wc ::: Mouse cursor size\n\nBecause the list is short, I can see (after sorting) that there are three sets of duplicates.\nThen, for example, I can choose to keep:\naskubuntu.com/q/53762 ::: How to use lm-sensors?\n\nrather than \naskubuntu.com/q/53762 ::: how-to-use-to-use-lm-sensors\n\nBut for a longer list this will be difficult. Based on the two answers one suggesting uniq and the other suggesting cut, I find that this command gives me the output I would like:\n$ cut -d \" \" -f1 file.txt | uniq -d\naskubuntu.com/q/53762\nstackoverflow.com/q/4594319\nwiki.ubuntu.com/ClipboardPersistence\n$\n\n\nA: Her is how I solved it:\nfile_with_duplicates:\n1,a,c\n2,a,d\n3,a,e <--duplicate\n4,a,t\n5,b,k <--duplicate\n6,b,l\n7,b,s\n8,b,j\n1,b,l\n3,a,d <--duplicate\n5,b,l <--duplicate\n\nFile sorted and deduped by columns 1 and 2:\nsort -t',' -k1,1 -k2,2 -u file_with_duplicates\n\nFile sorted only by columns 1 and 2:\nsort -t',' -k1,1 -k2,2 file_with_duplicates\n\nShow  the difference only:\ndiff <(sort -t',' -k1,1 -k2,2 -u file_with_duplicates) <(sort -t',' -k1,1 -k2,2 file_with_duplicates)\n\n 3a4\n   3,a,d\n 6a8\n   5,b,l\n\n", "Q: Wireless Hard Block I have a Lenovo Yoga 2 11\" with Ubuntu 13.10 (x64). I have just a litle problem with my wifi. (bluetooth is working)\nI tried:\nsudo rfkill list\n\nStatus:\n0: ideapad_wlan: Wireless LAN\n    Soft blocked: no\n    Hard blocked: yes\n1: ideapad_bluetooth: Bluetooth\n    Soft blocked: no\n    Hard blocked: yes\n2: phy0: wireless LAN\n    Soft blocked: no\n    Hard blocked: no\n3: hci0: bluetooth\n    Soft blocked: no\n    Hard blocked: no\n\nnext:\nsudo rfkill unblock all\nsudo rfkill unblock number\n\nThey work only soft block ... my hard block is still on \"yes\".\nMy yoga has not hardware button. I tried settings in bios, but not working.\nIf anyone has any other solution I will be very grateful.\n\nA: So, it sounds like your IdeaPad Yoga 2 semi-bricked the rfkill the same way mine did.  I just figured out how to fix it with the following:\nThe rfkill is controlled by the embedded EC, which is driven by the ideapad-laptop module.  This module tweaks some wrong bits on the Yoga 2, but thankfully not in a way that permanently breaks stuff.\nThe EC presents itself as an ACPI platform device, with enumerated commands and a property read and write method.  The structure is fairly obvious if you look at the ideapad-laptop.c in your local linux source tree.\nThere are 3 bits of interest:\nVPCCMD_W_RF: turns on/off RF devices in general? This one is interesting, as it's not used in ideapad_laptop.c, but its inverse, VPCCMD_R_RF -is-.\nVPCCMD_W_BT: turns on/off Bluetooth devices.\nVPCCMD_W_WIFI: turns on/of wi-fi.\nFor each of these commands, sending a 1 to them turns their function on, and 0 turns them off.  I suspect that the W_RF is actually non-functional on the yogas.  The ideapad-laptop driver will see its setting though, and turn on the persistent rfkill flags for the BT and WIFI devices.\nI fixed this by compiling a local version of the ideapad-laptop.c driver that executes the following commands as soon as it can, then has the module abort:\nwrite_ec_cmd(ideapad_handle, VPCCMD_W_RF, 1);\nwrite_ec_cmd(ideapad_handle, VPCCMD_W_BT, 1);\nwrite_ec_cmd(ideapad_handle, VPCCMD_W_WIFI, 1);\n\nAfter that, I made sure to keep the ideapad-laptop module with the blacklist ideapad-laptop option in a file in /etc/modprobe.d/whatever.conf.\nI've been working fine since.\nUnfortunately, the ideapad-laptop module has changed from one kernel version to another, so I can't just dump a built module for full source file, but if you search that file for write_ec_cmd strings, and build your own copy of that file with instructions like those at https://www.kernel.org/doc/Documentation/kbuild/modules.txt for building external modules, you could be fine.\nYou'll probably want to put it in one of the debugfs files so you can run it by catting  a debugfs file, then unload the module before you accidentally hit a rfkill button.\nYou should then be able to rfkill list and see yourself unblocked!\n\nA: Several things to try\n\n*\n\n*echo \"blacklist ideapad_laptop\" | sudo tee /etc/modprobe.d/ideapad.conf disables the Lenovo driver module, or\n\n\n*reset the bios:\n\nHit F2 to enter bios, then F9 to reset, then F10 to save and exit. Your wireless\nshould be working at that point.\n\n\nA: BIOS update available solved it for me.\n", "Q: Upgrading 13.04 to 13.10 compatibility I have an AMD CPU with radeon graphics card tower. When I tried to install 12.04 and 13.10 using burned disc I had problems with the graphics from the installation phase. 13.04 installed without problems and after the installation I downloaded the catalyst software which improved performance. I was wondering if upgrading to 13.10 using the notification popup that appears at startup is going to mess up the drivers again, or it should be safe? \n\nA: I had an AMD/Intel Hybrid Graphics Card with proprietary driver working well under Ubuntu 13.04 and I experienced a number of problems while upgrading to 13.10, and finally managed to get it done a couple of weeks ago.\nI don't know much about the cause(s) of upgrading problems (which I never had before in years with Ubuntu) I experienced and how they disappeared as I took the precaution of disabling the proprietary AMD driver and switching to much more trouble-free Intel driver before upgrade on both occasions.   \nBut my experience shows that it's very handy to use Clonezilla to backup your Ubuntu partition so that you can always go back in time in case of a disaster ;-)\n\nA: A simple way is to check!\n\n\n*\n\n*Get the Ubuntu 13.10 ISO.\n\n*Get your hands on a USB drive or a Cd/DVD.\n\n*Create an bootable USB/CD/DVD using unetbootin or multibootusb or any of your favorite software.\n\n*Boot the device and check if everything goes well.\n\n*If everything is fine, upgrade.\n\n\n\nIf you want to save some data, you can use the iso to do an in-place-upgrade. Just select install-->update existing OS.\n\nThe easier way is to upgrade!(blind dive in)\nYou can even ask someone with same/similar configuration using Ubuntu 13.10\n", "Q: how to trim dpkg upgraded packages list Latest upgrade borked my system and I`m trying to revert the last upgrade. I opened my comp with live USB and chrooted to partition that is OS installed. I get the upgraded packages with \ncat /var/log/dpkg.log | grep upgrade >>upgradeddpkg\n\nIt lists pakages like \n2014-03-14 15:31:45 upgrade libprocps0:i386 1:3.3.3-2ubuntu5.3 1:3.3.3-3\n2014-03-14 15:31:52 upgrade libreadline-dev:i386 6.2-9ubuntu1 6.2+dfsg-0.1\n2014-03-14 15:31:53 upgrade libreadline6-dev:i386 6.2-9ubuntu1 6.2+dfsg-0.1\n2014-03-14 15:31:55 upgrade readline-common:all 6.2-9ubuntu1 6.2+dfsg-0.1\n2014-03-14 15:32:25 upgrade libreadline6:i386 6.2-9ubuntu1 6.2+dfsg-0.1\n2014-03-14 15:32:33 upgrade libudev0:i386 175-0ubuntu19 175-7.2\n2014-03-14 15:32:40 upgrade libdevmapper-dev:i386 2:1.02.74-6ubuntu4 2:1.02.74-8\n2014-03-14 15:32:42 upgrade libdevmapper-event1.02.1:i386 2:1.02.74-6ubuntu4 2:1.02.74-8\n2014-03-14 15:32:43 upgrade libdevmapper1.02.1:i386 2:1.02.74-6ubuntu4 2:1.02.74-8\n2014-03-14 15:32:44 upgrade dmsetup:i386 2:1.02.74-6ubuntu4 2:1.02.74-8\n\nHow can I get only the name of the packages by means of grep, awk or whatever tool?\n\nA: Try the below command,\nawk ' { print $4 } ' upgradeddpkg > upgrade.txt\n\nIf you don't want the colon : then run,\nawk -F ':' ' { print $1 } ' upgrade.txt > upgrade1.txt\n\nExplanation:\nawk ' { print $4 } ' upgradeddpkg > upgrade.txt\n\nIn this, awk takes the input from  upgradeddpkg and prints only the $4(column number 4).That output was redirected to upgrade.txt file.So upgrade.txt file contains only the package names with colon.To remove the colon and its upcoming part(following), you have to run the second command.By default awk considers space as a delimiter.\nawk -F ':' ' { print $1 } ' upgrade.txt > upgrade1.txt\n\nDelimiter colon was manually set and awk considers colon as a delimiter instead of space.Now awk takes the input(stdin) from the upgrade.txt and prints(stdout) the coloumn1(part before the colon).Finally the standard output was redirected to upgrade1.txt.Now it contains only the package names.\n\nA: There's a problem using grep for the initial search in that it's including things like ubuntu-release-upgrader-core:all. I would use a single awk to match and pick the right field.\nawk '$3==\"upgrade\" { print $4 }' /var/log/dpkg.log\n\nBy default awk splits each line based on spaces. The third field is the action (so we check that it equals \"upgrade\") and the fourth is the package name.\nSome packages get upgraded a lot so you can cut out the noise of duplicates with:\nawk '$3==\"upgrade\" { print $4 }' /var/log/dpkg.log | sort -u\n\n\nI've seen Avinash's answer now... I'd be slightly cautious of snipping off the architectures... Depending on what you're doing, they could be as relevant as the package name... But if you did want to snip them out, I'd probably do that in the same awk statement:\nawk '$3==\"upgrade\" { split($4, a, \":\"); print a[1] }' /var/log/dpkg.log | sort -u\n\nAlternatively, you could set multiple fields separators for awk, so that it splits either on spaces or on colons:\nawk -F'[ :]' '$5==\"upgrade\" { print $6 }' /var/log/dpkg.log\n\n", "Q: Recover overwritten contents of text file I deleted my file content in the file how can i recover back using timestamps is it possible \nfor ex: I am having the file1.txt\ncat file1.txt \ni am linux user \ni am new to linux \ni love linux \n\nAfter sometime i later i delete the file content \ncat file1.txt \nempty: \n\nhow to get back the content again in the file\n\nA: Depends how you edited / deleted and how many times the content. Some editors like gedit creates a backup copy of file before saving with the '~' (tilde) suffix. These files  with the '~' suffix are hidden files for most of file managers (like Nautilus). So, with a little bit of luck you can recovery your lost content from these files.\n\nA: Backup file for  some text document files will be automatically created if it was opened using gedit text editor.Which was hidden and it ends with ~.By default this text document backup option was enabled.If you dont want gedit to create any backups.Then you can disable this option from,\nGedit-->Edit-->Preferences-->Editor\n\nTo ensure it's presence try ls command after cding into the current directory.If it was located, then copy its contents to the main file by running the below command,\ncat file1.txt~ > file1.txt\n\n", "Q: Problem with ~/.cache/upstart I'm not experienced at all with Ubuntu yet and I know there are lots of things I have to learn, but I'm kinda puzzled about this one.\nI just got (suddenly after a reboot) a free disk space warning about only having 17MB of free disk space left. I know I don't have many things on my home folder - it's a fresh installation (installed Ubuntu 13.10 only about 2 months ago on my new SSD).\nAccording to Disk Usage Analyzer there's a ~/.cache/upstart directory of size 46GB (out of 50.7GB dedicated to my /home folder). After searching there I realised it's the gnome-session.log file being 46GB big.\nI have no idea what is this - except from a few things I just read around googling it. I don't try things that I don't know how to handle on the specific machine because I don't want to risk harming it these days, so I don't really know what should I do now.\nIs it possible that I did something wrong causing it ? Is it safe to just delete that /upstart folder to free some disk space, or that could cause me more problems. Should I do something else ?\nSorry if it's something common but I couldnt find anything clear and reliable to help me.\nThank you in advance.\n\nA: You're experiencing this bug #1240848.\nI have never on that condition. But, I'm sure It is safe to delete this dir (or just delete file(s) that's very big). You can also backup them if not so sure.\nTry sudo apt-get purge logrotate then sudo apt-get install logrotate. If this not fixing the problem, then it is possible one of your application (or package) affecting it.\nMany people say that it is periodically occured.\n\nA: The log file gets bigger and bigger as it keeps appending to itself some recurring problem. First, identify the log file in the directory .cache that is growing in size using baobab (Disk Usage Analyzer), then open the log file using gedit and try to identify what is causing the problem. In my case it was one of the Startup Applications that was looking for a keyboard input, and was continuously writing to the log file since it wasn't getting that input. So in my case I editted the startup applications list and solved my problem.\nDeleting the log file is an option, but it may not solve the root of the problem.\n\nA: In my case the problem was caused by an outdated python ssl library, I updated it by using this command from home directory: \nwget https://launchpad.net/ubuntu/+archive/primary/+files/python-cryptography_1.7.1-2_amd64.deb && wget https://launchpad.net/ubuntu/+archive/primary/+files/python-openssl_16.2.0-1_all.deb && sudo dpkg -i --auto-deconfigure python-cryptography_1.7.1-2_amd64.deb && sudo dpkg -i  python-openssl_16.2.0-1_all.deb\n\nThe original thread and discussion of the issue is here\n", "Q: Can't do anything on startup until terminating Kate in Kubuntu When my Kubuntu starts i can't do anything until starting System Activity and killing Kate. I can not start any program or for example run Dolphin file manager. After terminating Kate a message is shown:\n\nAfterwards everything is OK. How may i solve this problem?\n\nA: The problem was that i had a shell script in my /home/user/.kde/Autostart folder which was supposed to run on start. But i had not changed its mode to executable. Changing the mode by \"sudo chmod +x \" solved the problem.\n", "Q: youtube-dl problem my ubuntu is showing me this error:\nabhishek@abhishek-ThinkPad-R61:~$ youtube-dl -f worst http://www.youtube.com/watch?v=QGhx-u-c5Cg\n[youtube] Setting language\nWARNING: unable to set language: nonnumeric port: 'port_no'\n[youtube] QGhx-u-c5Cg: Downloading video webpage\nERROR: unable to download video webpage: nonnumeric port: 'port_no'\nabhishek@abhishek-ThinkPad-R61:~$ \n\n\nA: Try adding as a service in Konqueror browser the youtube-dl addon. You can find it in Konqueror - Settings - Configure Konqueror - Services, and once you get here press the Download New Services button, and look for youtube-dl or video-dl package and install it.\n", "Q: Can I run 64 bit apps in 32 bit Linux? There are some proprietary apps that are being provided only in 64-bit version.\n\nA: No, I think there is no way to do this, because 64bit programs are not compatible with 32bit OS, but most 32bit programs are compatible with 64bit OS. It's simply another architecture. Which program do you want to use?\n", "Q: Which application does the vi command open? When you type vi in the terminal, the following output is shown\n~                             VIM - Vi IMproved                                \n~                                                                             \n~                               version 7.3.547                                 \n~                           by Bram Moolenaar et al.                            \n~           Modified by pkg-vim-maintainers@lists.alioth.debian.org             \n~                 Vim is open source and freely distributable                   \n~                                                                               \n~                        Help poor children in Uganda!                                                                             \n\nSo according to this, vi must be launching VIm.\nBut when you type  vim it gives\naditya@aditya-desktop:~$ vim\nThe program 'vim' can be found in the following packages:\n * vim\n * vim-gnome\n * vim-tiny\n * vim-athena\n * vim-gtk\n * vim-nox\nTry: sudo apt-get install <selected package>\n\nThis shows that vim is not installed.\nNotably man vi and man vim launch the same man pages.\nSo what does the vi command actually launch?\n\nA: If you do type vi:\n➜  ~  type vi\nvi is /usr/bin/vi\n\nYou will know where's the binary, now if you do:\n➜  ~  ls -l /usr/bin/vi \nlrwxrwxrwx. 1 root root 20 jun 22  2013 /usr/bin/vi -> /etc/alternatives/vi\n\nIt's provided by the alternative vi, which can be known by:\n➜  ~  update-alternatives --display vi\nvi - auto mode\n  link currently points to /usr/bin/vim.basic\n/usr/bin/vim.basic - priority 30\n  slave vi.1.gz: /usr/share/man/man1/vim.1.gz\n  slave vi.fr.1.gz: /usr/share/man/fr/man1/vim.1.gz\n  slave vi.it.1.gz: /usr/share/man/it/man1/vim.1.gz\n  slave vi.ja.1.gz: /usr/share/man/ja/man1/vim.1.gz\n  slave vi.pl.1.gz: /usr/share/man/pl/man1/vim.1.gz\n  slave vi.ru.1.gz: /usr/share/man/ru/man1/vim.1.gz\nCurrent 'best' version is '/usr/bin/vim.basic'.\n\nSo, in my case, vi is a symbolic link to the alternative vi which is provided by vim.basic.\nYou can change which package provided vi if you do sudo update-alternatives --config vi\n\nA: It's similar to @ignis answer, but i reduced the steps.It only works, if the file is a symbolic link to another.You can get the original file path easily, if it has thousands of symlinks in it's path.\nsymlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->symlnk-->.................-->original file\n$ which vi\n/usr/bin/vi\n$ ls -l $(which vi)\nlrwxrwxrwx 1 root root 20 Feb 22 20:14 /usr/bin/vi -> /etc/alternatives/vi  # So /usr/bin/vi is an symlink to /etc/alternatives/vi\n$ dpkg -S $(readlink -f $(which vi))    \nvim-tiny: /usr/bin/vim.tiny\n\nSo vi belongs to the package vim-tiny.\nreadlink -f gives you the canonical path of the file(Original file path).\n\nA: It is vim-tiny: \"Vi IMproved - enhanced vi editor - compact version\".\nI did this on 13.10:\nuser@ubuntu:~$ which vi\n/usr/bin/vi\nuser@ubuntu:~$ which vim\nuser@ubuntu:~$ ls -l /usr/bin/vi\nlrwxrwxrwx 1 root root 20 ago 13  2013 /usr/bin/vi -> /etc/alternatives/vi\nuser@ubuntu:~$ ls -l /etc/alternatives/vi\nlrwxrwxrwx 1 root root 17 dic 20 04:39 /etc/alternatives/vi -> /usr/bin/vim.tiny\nuser@ubuntu:~$ apt-cache search vim.tiny\nvim-common - Vi IMproved - Common files\nvim-tiny - Vi IMproved - enhanced vi editor - compact version\nuser@ubuntu:~$ dpkg --get-selections | grep vim\nvim-common                  install\nvim-tiny                    install\n\nAs you can see, vim is not installed (empty output), vi is a symlink to /etc/alternatives/vi (see alternatives mechanism), which is a symlink to /usr/bin/vim.tiny, which belongs to package vim-tiny.\n", "Q: Reinstalling Ubuntu via Terminal I've currently encountered some issues with ubuntu causing me to be stuck in tty mode.\nI already tried fixing the issue but since I'm not sure of what really happened for this issue to occur I now just want to reinstall ubuntu.\nI was wondering if there is a way to reinstall ubuntu via terminal?\nI'm currently running 12.04.4 lts and I already tried the command line:\nsudo dpkg-reconfigure -phigh -a\nBut that didn't do anything (after ~10 min of nothing happening a new command line appeard, I tried to restart but nothing changed)\nAny help is highly appreciated\nThanks \n\nA: Trying to recover from a failed update between Ubuntu 14.04 and 16.04. The update was locked, the only to get out of it was to reboot the computer, and after reboot, I was presented with the terminal prompt and it would not launch Ubuntu desktop.\nI followed your suggestion : \nsudo apt-get install --reinstall ubuntu-desktop\n\nIt did not work, system told me to do : \nsudo dpkg --configure -a\" first. \n\nWhich I did.\nA new : \nsudo apt-get install --reinstall ubuntu-desktop\n\nfailed and suggested to do : \nsudo apt-get -f install\n\nBack to a \nsudo apt-get install --reinstall ubuntu-desktop\n\nThis one terminated. I shutdown the computer. During Shutdown I noticed it was displaying Ubuntu countdown. Good sign. I restarted again the computer, and it start to load as usual and launch Ubuntu desktop Unity. Success. Thanks for the tips !\n\nA: Reinstall Ubuntu Operating System\nYou can install programs/applications via Terminal, but in neither case an operating system. The Terminal is good and you can do a lot of things with it, but this time you will need more than only the Terminal to reinstall Ubuntu.\nPlease read the following community wiki to find out what you need:\n\n*\n\n*How To Reinstall Ubuntu\nReinstall Ubuntu desktop system\nIf you are referring only to the Ubuntu desktop system package, then you can use the following command to reinstall it:\nsudo apt-get install --reinstall ubuntu-desktop\n\n", "Q: 12.04 can't connect to 64 bit WEP I'm an absolute beginner to Linux, and I already have a problem. Go me!\nI have installed Ubuntu 12.04 32 bit on my desktop PC, dual booted with my previously installed Windows XP.\nI have a 64 bit WEP encrypted Wireless connection that I can't change because I want to connect my DSi and Wii to the internet and they only accept 64 bit WEP encryption.\nOn Windows XP I can connect with no problem at all, but on Ubuntu it tries to connect, but after a few minutes asks again for my password. I checked it many times, and it's entered 100% correctly.\nI have searched all over the internet for possible solutions, since it seems to be a VERY common problem, but nothing I tried worked.\nSo, any suggestions from someone more experienced than me would be extremely appreciated.\nThank you in advance. :-)\n\nA: I don't think that there are 64bit WEP networks at all. And I think Wii does understand WPA after an update.\nIn ubuntu is the kernel used to deliver drivers for Hardware. If your computer is newer, you should use the newest version of ubuntu with the newer kernel.\nAs an user of XP I would use the lxde Version of ubuntu, lubuntu: https://help.ubuntu.com/community/Lubuntu/GetLubuntu.\n", "Q: Can you add a startup and a shutdown sound ? I recently installed Ubuntu 12.04 LTS and was wondering if there was any way to insert a startup and shutdown sound (ideally using a piece of software). If anybody has any ideas, they would be much appreciated.\n\nA: You could make that (and other customizations) by replacing the default sound files in /usr/share/sounds/ubuntu/stereo (broadly in /usr/share/sounds/*).\nTry to replace (keep a backup if you want to) these files and check:\n/usr/share/sounds/ubuntu/stereo/desktop-login.ogg\n/usr/share/sounds/ubuntu/stereo/desktop-logout.ogg\n\n(remember to use the correct extensions and permissions. You have to use elevated privileges to do the operations. Use sudo when doing it from terminal or launch Nautilus with gksu nautilus & and then make the customizations. Please comment if you need more help with this.)\n", "Q: How do I add a new user with specific configuration files? I am new to Ubuntu and *nix OSes.\nI have just installed the latest stable version of Ubuntu on my computer. During the installation process, I created a user account. Let us call it N1.\nJust to try it out, I added a new user account. Let us call it N2. However I noticed that N2 inherited all the applications and the file system of N1.\nI would like N2 to have a separate file system with a separate iptables, sources list, etc...(different from N1). And when I make changes to, for example, the iptables of N1, they will not be reflected in N2 (and vice versa).\nHow do I go about doing it?\n\nA: \nHow do I go about doing it?\n\nYou don't.  Firewalling (iptables) takes place inside the kernel, as do the port assignments it pertains to.  For example, if you want to run a web server on the system using the standard HTTP port (80), then that's what you have.  Other computers can connect to yours using that port.  There is only one port 80.  If another user wants to run a separate web server, he/she will have to use a different port.  In this manner, you could apply different restrictions to the different ports using iptables.\nBy analogy:\n\nI have two people in my car.  I notice they are driving on the same street in the same direction together.  I would like to have two steering wheels in the car so they can drive on separate streets.\n\nSince we all understand what a car is, we all understand this is a non-sensical desire.\nThe same logic applies to the root filesystem.  There is only one.  Different users can have different restrictions placed on them with regard to accessing it.  WRT to applications, you can use the per user $PATH variable to control which ones are used by default.\nAs steeldriver points out, it is possible to run a completely separate operating system inside a virtual machine, on which you could have users unrelated to the ones on your \"real\" (aka host) OS.  This option is a little like setting up a video game console in the back seat of your car so driver #2 can have somewhere different to go.\nThere are other mechanisms, such as chroot, which can box a user's perspective on the system.  However, the normal way to customize a user's environment is to do so by using application specific, per user configurations.  For example, you can specify a different desktop environment by adding an .xinitrc in your home directory, so that one user uses GNOME and another KDE.  If that file is not present, the user uses the system default.\n\nA: What you are describing would probably require having a separate virtual machine for each user. Popular virtualization platforms include VirtualBox and VMware Player.\n", "Q: Acer Aspire One 751h multimedia support I have installed Ubuntu 12.04 on my Acer Aspire One 751h netbook. Recently I updated my Linux kernel to 3.11.08-18. Thankfully my video works awesome, but there is no sound. \nI have Realtek Audio hardware and Dolby speakers. Earlier in Kubuntu 12.10 with kernel 3.5 series it worked out of the box. \n\nA: Try sudo depmod -a command, sometimes it helps after updating kernel in ubuntu.\n", "Q: How to dual boot ubuntu with windows 7 Hi i have total 3 partition in windows7\n\n\n*\n\n*(C) Windows OS\n\n*(D) erase all content for ubuntu\n\n*(E) For files \n\n\nI want to install Ubuntu on D drive. How to install Ubuntu here? \nAnd after installing Ubuntu here is the left partition become 2 only in Windows. \nPlease help me.\n\nA: You shouldn't be worried about partitions (if you are installing Ubuntu for the first time). Just get Ubuntu from here (I recommend using BitTorrent client).\nBurn the image you downloaded to any CD/DVD or USB Flash. Insert the disc in the tray and restart your computer. The Ubuntu installer will pop up. Try Ubuntu without installing if you want or install it right away (you can also cancel the installation,obviously). If you still want to partition it yourselves, refer to this article or this one.\nI recommend you do not partition the drive yourselves as you can damage your system (as I did). If you do not do the partitioning correctly, Ubuntu will fail to mount the partitions. That's all! Hope it was not boring and it helps! Cheers! :)\n\nA: Download the ubuntu iso , prepare a live usb,its fairly easy. find how to do it,yourselves.\nGo to windows 7 , press winkey + R type diskmgmt.msc,press enter. \n1)delte the D drive , so that it shows up as unallocated space.\nmake sure you apply the changes.\n2)Now restart the computer go into bios, usually it is done by pressing f2 or f10.. find the boot sequence and set the usb on top.(in short boot from the damn usb)\nNOTE:An yeah don't forget to change it again to the hard drive when installation is complete.\n3) A \"window\"or screen will open,press enter on the optiopn that says try without installing.\nAfter booting in ubuntu , press the window key and type gparted, open it up.\nDont worry about the confusion of sda1 and all. \nIf you aren't sure then refrain from doing anything,without seeking help.\nNow Press on the unallocated space,and change...set the ENTIRE SPACE AS EXTENDED PARTITION.\nafter doing it you will still have unallocated space from that space do the following \nall of them are LOGICAL PARTITION.\n1)set the size as around 30Gb(approx 30,000), choose type as ext4 , mount point as / .\nthis is where ubuntu will be installed.\n2)again press on the remainig unallocated space, set the size around 2gb(approx 2000) , choose type as swap.\n3)press on the unallocated space, change size to the maximum, this is where you will be storing your FILES/DATA. choose type as ext4 and mount point as /home.\nApply the changes and close gparted.\nIf you aren't sure what you haev done then , post a screenshot of gparted after doing all this.\nIf you have come this far , then go to the desktop press on install ubuntu icon ,when the option comes choose SOMETHING ELSE and choose the drive which has the partions you just made above and bingo! proceed to install.\nGood Luck.\n", "Q: Ubuntu 13.10 touchpad problem Hey guys i have problem with my laptop in Ubuntu, I don't know how exactly to describe it.\nEvery time I the cursor with Touch Pad and stops its will automatically do a right mouse click, also when i click the right mouse button it will take a second to start dragging ?!!? Sorry for the bad description if there any outputs please tell me what to do because i don't know how to deal with such things.\n\nA: I had similar issues with my Logitech touchpad in 13.10, but after updating the to latest 14.04 build it has been fixed.  I used to not be able to right click and select an option - the first one would always be selected as soon as I started to move to the option I wanted.  Now in 14.04 I can right click and touch scroll to the option I want.  There must have been something fixed in 14.04 to support touchpad use?\n", "Q: How can I disable my internet connection from terminal? The connect automatically option is allowed for my wired Wired connection 1. Disconnecting the connection works when I do it from the panel's Network > Disconnect menu. But when I do that with command:\nnmcli con down id \"Wired connection 1\"\n\nno sooner than it disconnects, the connection is back on.\nHow does Network > Disconnect work? Could we do the same with nmcli without disabling the automatic connection?\nNote:\n\n\n*\n\n*nmcli con down id \"Wired connection 1\" works as with automatic connection disabled (but again that's not an option),\n\n*I don't want to use sudo (wouldn't be good to implement in a script!).\n\n\nA: The following command works for me like a charm if I want to disable any internet connection from terminal:\nnmcli networking off\n\nTo enable it again:\nnmcli networking on\n\nNote: As commented by CPBL, this works in Ubuntu 15.04 and later. For older versions try nmcli nm enable false and nmcli nm enable true.\n\nAnother way very close to your quest is to use:\nnmcli dev disconnect iface eth0\n\nTo enable eth0 again you need to type:\nnmcli -p con up id \"<connection name>\" iface eth0\n\nExample for connection named \"Wired connection 1\":\nnmcli -p con up id \"Wired connection 1\" iface eth0\n\nChange eth0 to your wired interface name. This will prevent any further connections without user/manual intervention as man nmci says:\ndisconnect iface <iface> [--nowait] [--timeout <timeout>]\n           Disconnect a device and prevent the device from automatically\n           activating further connections without user/manual intervention.\n\n           Available options are:\n                --nowait     – exit immediately without waiting for\n                command completion\n\n                --timeout    – how long to wait for command completion\n                (default is 10 s)\n\nPlease read man nmcli for more info.\n", "Q: System don't recognize ubuntu partition \"\"All boot options are tried. Press F4 key to recover.\" I just formatted my Samsung Ultrabook and installed Ubuntu 12.04 via USB using rufus to create the bootable USB (my ultrabook don't have a cd/dvd reader). The problem is, when the instalation finish and ask for a reboot, it skips the hdd boot and start via USB right away, and when I remove the USB it says \"All boot options are tried. Press F4 key to recover...\" Wich I suppose says that I don't have a valid OS installed in my HDD. I reinstalled in the same partition overwriting the former ubuntu installation (the live cd recognized the previous installation). Same problem. After that I followed the instructions from here: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows And the same happened. I don't know what to do, and I can't use my ultra anymore. Help pls!\nEDIT: I tried installing Windows 7 in half my hdd. Everything ok. But when I installed Ubuntu in the other half, I can't access to any of them. At startup says: \n\"error: file not found.\ngrub rescue>\"\nHowever, I can access both OS with the bootable Super Grub Disk in my pendrive. Using the Super Grub I managed to install Lilo in my Ubuntu partition. After installing Lilo, the computer booted normally only windows 7. With further google hunting I read that this can be a grub problem, and messed up with grub settings via terminal. After that I can't access any OS, neither I can get to boot with lilo (can't find config files).\nNow I know it's a problem with the boot files, not the ubuntu partition. What can I do? Is there any other boot type that may work for me?\n\nA: I did it! It appears that the windows 7 boot don't recognize Ubuntu without help. I followed the steps from this page and everything went fine:\nhttp://www.linuxbsdos.com/2012/05/17/how-to-dual-boot-ubuntu-12-04-and-windows-7/2/\n\nA: Refer to this article. I think this might help you. Cheers! Hope this helps! :)\n", "Q: Can't boot to Windows 8 after installing Ubuntu First of all, I know a lot of people has asked this question, but after revising a lot of questions, I didn't find my answer so I ask here because I'm desesperated and I need a solution... Here's my problem:  \nI have Windows 8.1 preinstalled in my PC, and I've also installed Ubuntu 12.04. Firstly, when I installed it, it worked perfectly and I didn't have any problem running the two OS.\nBut, lately, this last week, it gave me some errors because I couldn't start Ubuntu, so I reinstalled it. The problem now is that when I try to access my Windows 8.1, it gives me this error:\n\nError: no boot disk has been detected or the disk has failed.\n\nWhen I enter my BIOS settings, it successfully shows the Windows Boot Manager under the boot menu options, but when I try to access it, it gives me that error. Also, I've tried to solve the problem with the Windows 8 recovery mode but it doesn't detect my OS...\nI know my hard drive is working, because I can access to my Ubuntu and I can also access my Windows 8 files through Ubuntu.\nI've found this guide but I'm not sure if it's what I have to do, is it?\nIf this could solve my problem, I'm stucked in the first step where I have to assign my EFI partition a drive letter, because I don't know which volume is my EFI partition. \nSo, I would appreciate it a lot if you could help me because I really need to access my Windows 8.1 without losing any data...\nThanks!\n\nA: Follow this`Ubuntu community page for your problem. It can surely helps you in a long way.And if any problems occurs after these steps please comment below .\n\nA: Maybe you can look via Gparted how big your EFI-partition is and then identify it simply by the size.\n\nA: When your system boots up hit f12 repeatedly a few times to get an os selection menu. Select windows 8 boot manager there and hit return key. Your windows 8 os should start normally. Worked for me.\n", "Q: Cannot acquire DHCP address I am unable to acquire a wired DHCP ip address.\nI have Ubuntu 13.10 installed on a thin mini-itx ECS Q77H2-TI motherboard. I'm connecting to my cable modem which does provide ip addresses to other (windows, mac osx) machines I've connected to it.\nWhen I run ifconfig I see:\neth1      Link encap:Ethernet  HWaddr 74:27:ea:c2:62:58          \n          inet6 addr: fe80::7627:eaff:fec2:6258/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:267 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:516 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:50017 (50.0 KB)  TX bytes:111906 (111.9 KB)\n          Interrupt:20 Memory:f7c00000-f7c20000 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:1624 errors:0 dropped:0 overruns:0 frame:0          \n          TX packets:1624 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0    \n          RX bytes:132240 (132.2 KB)  TX bytes:132240 (132.2 KB)\n\ncat /etc/network/interfaces gives:\nauto lo\niface lo inet loopback\n\nWhen I try tcpdump -i eth0 -n, I see nothing, but tcpdump -i eth1 -n, I see plenty of activity when wired.\nI would love some pointers on how to get this machine connected to the internet.\nCheers,\nOwen.\n\nA: Your pc view only eth1 interface. Ifconfig don't see eth0.\nYou can try with nm-tool command to see nic card, state ...\nSimple output will be like this\n$ nm-tool\nNetworkManager Tool\nState: connected\n- Device: eth0  [Auto eth1] ----------------------------------------------------\n Type:              Wired\n Driver:            xxxxx\n State:             connected\n Default:           yes\n HW Address:        74:27:ea:c2:62:58\n Capabilities:\n Carrier Detect:  yes\n Speed:           100 Mb/s\n Wired Properties\n Carrier:         on\n IPv4 Settings:\n Address:         xxx.xxx.xxx.xxx\n Prefix:          24 (255.255.255.0)\n Gateway:         xxx.xxx.xxx.xxx\n DNS:             xxx.xxx.xxx.xxx\n DNS:             xxx.xxx.xxx.xxx\n\nAlso you can try to renew ip settings from dhcp server\nfirst\nifconfig eth1 down\n\nnext\nifconfig eth1 up\n\nor\ndhclient eth1\n\nYou will probably get ip from dhcp ...\nIf is your cable in eth0 interface try to up interface \nifconfig eth0 up\n\n\nA: To answer my own question,\n\n\n*\n\n*I added a dhcp entry to /etc/network/interfaces\nauto eth1\niface eth1 inet dhcp\n\n\n*I then restarted my cable modem. The modem appears to only provide one DHCP ip address per power cycle. \nFixed.\n", "Q: Java 7 installation error I'm getting this output when i try to install oracle-java7 from webupd8 ppa\nDownload done.\nRemoving outdated cached downloads...\nsha256sum mismatch jdk-7u51-linux-x64.tar.gz\nOracle JDK 7 is NOT installed.\ndpkg: error processing oracle-java7-installer (--configure):\n subprocess installed post-installation script returned error exit status 1\nSetting up gsfonts-x11 (0.22) ...\nErrors were encountered while processing:\n oracle-java7-installer\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: This is the key:\nsha256sum mismatch jdk-7u51-linux-x64.tar.gz\n\nThe file jdk-7u51-linux-x64.tar.gz has been corrupted and fails to validate against the expected hash. Try downloading it again, that might fix your issue.\n\nA: I face same problem and get in a solution:\n\n\n*\n\n*Download the JDK here.\n\n*Then go to /var/cache/oracle-jdk7-installer/ \n\n*In that dir remove jdk-7u51-linux-x64.tar.gz and paste the version downloaded from Oracle website.\n\n*Try sudo apt-get install oracle-java7-installer again.. this time should work fine!\n\n\nA: I download source file from Oracle's website and installed manually from scratch... It is working well now ... The solution I used is here \nThe instructions given are as follows and should be updated for the current version:\n\n\nDownload Java SE 7 JDK for Linux x86 archive. At the time of writing,\n    the file I'm using is jdk-7u21-linux-i586.tar.gz, but the filename\n    will change as updates are released. Apparently there is no longer a\n    jvm folder, so create one.\n\nsudo mkdir /usr/lib/jvm\n\nMove the archive to the jvm folder\n\nsudo mv jdk-7u21-linux-i586.tar.gz /usr/lib/jvm/\n\nChange to the jvm folder and extract the JDK from the archive\n\ncd /usr/lib/jvm\nsudo tar zxvf jdk-7u21-linux-i586.tar.gz\n\nEverything will be extracted to a new jdk1.7.0_21 folder and you can\n    delete the archive file now. Make symbolic links to the new java\n    binary.\n\nsudo ln -s -b /usr/lib/jvm/jdk1.7.0_21/jre/bin/java /etc/alternatives/java\nsudo ln -s -b /usr/lib/jvm/jdk1.7.0_21/jre/bin/java /usr/bin/java\n\nDouble-check the version\n\njava -version\n\n", "Q: How to recursively upload a directory to a ftp server but skip hidden dot-directorys I have found that ncftp has this ability to recursive upload directorys. My problem now is that my directory contains a .svn and a .git folder that I do not want uploaded.\nncftpput -R -v -u \"user\" -p \"pass\" ftp.own.com /ftp/folder/to/to/place/local/folder/in /local/folder/to/upload\n\n\nA: Actually I got the idea how to do this while writing up this question. Might seem a but hacky but if I not missed something ncftp does not provide some exclude option.\nSo since I use a script anyway. I just deny ncftp access to that folders temporary. Resulting in creation but empty .git and .svn folders on the ftp server.\nchmod 000 .svn\nchmod 000 .git\nncftpput -R -v -u \"user\" -p \"pass\" ftp.own.com /ftp/folder/to/to/place/local/folder/in /local/folder/to/upload\nchmod 700 .svn\nchmod 700 .git\n\n", "Q: \"dpkg-source: unrepresentable changes to source\" when trying to debuild a modified package I downloaded the source to a package using:\n$ apt-get source gkrellweather\n\nI also made sure I had the compile dependencies:\n$ sudo apt-get build-dep gkrellweather\n\nAnd I tested that it could build fine:\n$ cd gkrellweather-2.0.8\n$ debuild\n\nIt built a .deb package in the folder above, which I could install using:\n$ sudo dpkg -i ../gkrellweather*.deb\n\nOK so everything is in place.  Let's get started!\nI opened up the source code in Vim and made some changes I wanted.  Then I tried to rebuild:\n$ debuild\n\nBut I got the following error:\n...\ndh_clean: Compatibility levels before 5 are deprecated (level 4 in use)\n dpkg-source -b gkrellweather-2.0.8\ndpkg-source: warning: no source format specified in debian/source/format, see dpkg-source(1)\ndpkg-source: info: using source format `1.0'\ndpkg-source: info: building gkrellweather using existing gkrellweather_2.0.8.orig.tar.gz\ndpkg-source: info: building gkrellweather in gkrellweather_2.0.8-2.diff.gz\ndpkg-source: error: cannot represent change to gkrellweather-2.0.8/.gkrellweather.c.swp: binary file contents changed\ndpkg-source: warning: the diff modifies the following upstream files: \n GrabWeather\n Makefile\n gkrellweather.c\ndpkg-source: info: use the '3.0 (quilt)' format to have separate and documented changes to upstream files, see dpkg-source(1)\ndpkg-source: unrepresentable changes to source\ndpkg-buildpackage: error: dpkg-source -b gkrellweather-2.0.8 gave error exit status 1\ndebuild: fatal error at line 1357:\ndpkg-buildpackage -rfakeroot -D -us -uc failed\n\nWhy?\n\nA: Thanks to joeytwiddle's answer as it gave me a great place to start in my solution to this issue. \nIn my Python project that I attempted to create a debian package for, I am using:  \n\n\n*\n\n*pybuild to prepare the debian package before running debuild\n\n*git for version control\n\n*PyCharm IDE for the Python development\n\n\ngit creates a .git directory, pybuild creates a .pybuild directory and PyCharm creates a .idea directory all in the root of my project. \nBecause joeytwiddle mentioned that debuild didn't like a certain file (in his case a swp file) then I felt it probably had a fit about the hidden directories. I found out that for git, you can do: debuild -i and it ignores version control directories for as for the pybuild and idea directories, I have not found another option yet. So for my solution, I copied over my project to a blank directory, deleted .git, .idea, and .pybuild directories and success!\n\nA: This has tripped me up more than once before.  Sometimes I thought the reason for debuild errors after changing the source was that after the source has been changed, the package maintainers signature (signoff) is no longer valid for that source.\nBut actually in this case the answer was simple:\ndpkg-source: error: cannot represent change to gkrellweather-2.0.8/.gkrellweather.c.swp: binary file contents changed\n\nThe problem is that Vim had created a swafile, and debuild didn't like that!\nThe solution was simple: remove the swapfile, and then building can work:\n$ rm ./.gkrellweather.c.swp\n$ debuild\n\n", "Q: Steam launch error when I try to download steam with Ubuntu on my Samsung ARM it tells me:\nE: unable to locate package libgl1-mesa-dri:i386\nE: unable to locate package libgl1-mesa-glx:i386\nE: unable to locate package libc6:i386\n\nI don't know how to fix this but if anyone does please reply.\n\nA: You're running a Samsung ARM Chromebook? Yeah that's not going to work.\nSteam is x86/x86_64 only. As are the vast majority of its games. Sorry.\n", "Q: Lamp package lamp-server^, auto enter mysql pw? Is there a way to pass the desired MYSQL password to the prompts in the apt-get install lamp-server^ package in a single command line?\nNote:\nI tried finding the package repository to read up on it, but I can't find it.\n\nA: You can preset the password:\nsudo debconf-set-selections <<< 'mysql-server mysql-server/root_password password your_password'\nsudo debconf-set-selections <<< 'mysql-server mysql-server/root_password_again password your_password'\nsudo apt-get -y install lamp-server^\n\nThis is adapted from a SO Question which has a few variants on this idea.\n", "Q: Additional drivers to ubuntu 13.10 Hi im new at this ubuntu way of life,\ni got and install ubuntu 13.10 saucy salamander, i dont know where but get kind of lost in the installing process.\ni got a lot of problems getting the music been able to play, movies in the other hand i cant get it right, already done the \"Things to do after installing ubuntu\" list and didnt work for movies, additionals drivers or codecs needed? where can i find it?\nCan someone please help :( im thinking to reinstall everything al over again :|. thank you all in advance for your suggestions :D\n\nA: Starting from a standard Ubuntu 13.10 install, add the following:\nUpdate the system (manually)\nsudo apt-get update && sudo apt-get upgrade\nsudo apt-get dist-upgrade\n\n(Optional) If you need to remote access (to this platform)\nsudo apt-get install openssh-server\n\nAdd some tools, used below\nsudo apt-get -y install vim curl build-essential\nSet to auto-update, for security updates\nsudo vim /etc/apt/apt.conf.d/10periodic\n.. by replacing existing file contents with:\nAPT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Download-Upgradeable-Packages \"1\";\nAPT::Periodic::AutocleanInterval \"5\";\nAPT::Periodic::Unattended-Upgrade \"1\";\n\nDisable 'Guest' login account\nsudo /usr/lib/lightdm/lightdm-set-defaults -l false\n\n(Optional) Add 'Ubuntu Tweak' tools/app\nsudo add-apt-repository ppa:tualatrix/ppa && sudo apt-get --quiet update\nsudo apt-get -y install ubuntu-tweak\n\nLoad ALL video, audio codecs, etc.\ncurl ftp://ftp.videolan.org/pub/debian/videolan-apt.asc | sudo apt-key add -\necho \"deb ftp://ftp.videolan.org/pub/debian/stable ./\" | sudo tee /etc/apt/sources.list.d/libdvdcss.list\nsudo apt-get update\nInstall VLC, Mplayer, and Ubuntu restricted extras\nsudo apt-get -y install vlc vlc-data vlc-plugin-pulse browser-plugin-vlc\nsudo apt-get -y install mplayer\nsudo apt-get -y install ubuntu-restricted-extras\nInstall full DVD capabilities\nsudo apt-get -y install libdvdcss2 libdvdnav4 libdvdread4\nsudo /usr/share/doc/libdvdread4/install-css.sh\nThe should cover most things you needed ..\n\nA: Install all XINE packages and dependencies. Open a terminal and type in this code:\nsudo apt-get xine*\nInput your user password when prompted, and after you get the list with packages to be installed press 'y' which is YES to finish installing xine. This will add a few extra codecs, and if you want to start xine from the start menu to play your favorite video files you can also install gxine (xine user interface). Code:\nsudo apt-get install gxine \nNext, you should open Synaptic, type 'vlc' without the quotes in the Search field, and look for some extra packages that can boost VLC player, and also add some extra codecs. If VLC player is not present on your system, you can easily install all the packages, and dependencies in a terminal. Code:\nsudo apt-get install vlc*\nDon't forget to provide your password and press 'y' again to finish installation.\nAnd finally you can install mplayer and mencoder packages. Type in a terminal:\nsudo apt-get install mplayer mencoder\nAnd you're done. I hope you have enough free space on your Linux/Ubuntu partition because all these packages to be installed can use sometimes up to 500-600 MB of your free space or even more depending on your Ubuntu distro.\nI forgot to mention that you can also install Audacious player if you want to play your music files at their best. Code:\nsudo apt-get install audacious*\nYou can customize audacious interface to look very similar to how Winamp looks if you go to Audacious preferences menu - View - Interface and choose 'Winamp Classic Interface. Next you can choose a skin for audacious from Interface Preferences. If you want latest version of Audacious, you can find it here: https://launchpad.net/~nilarimogard/+archive/webupd8\nI am editing this post because I am not allowed to give long replies in a simple comment. Before you get tired of all these errors, and decide to reinstall Ubuntu ( maybe you want to try Ubuntu 14.04 LTS for a change, and not Ubuntu 13.10) I have some more suggestions for you:\nYou should look for Software Sources ( Open Update Manager from the main menu, and press Settings button ), and see in there if all is checked under UBUNTU tab, and also if you have the required official keys from Ubuntu developers under the AUTHENTICATION tab. There is a button saying RESTORE DEFAULTS under AUTHENTICATION tab, and you can press it to get back your authentication keys assuming that you did something wrong and changed something in there which prevents you from updating and installing software. But before anything check your Internet connection, and if it is working try to run this code in a terminal and see if it works:  \nsudo apt-get update\nGood luck, and if you can't do anything about it, then you should reinstall Ubuntu, whichever version you prefer, 13.10 or 14.04.\n", "Q: Cannot get Asus laptop to correctly wake up from Suspend mode I have Asus X53S laptop running Ubuntu 12.04.\nOn my previous 12.04 installation, suspend was working.\nNow, after waking up from suspend mode, all I got, was a blank screen.  \nWhat I've tried so far: \n\n\n*\n\n*The script mentioned here\n\n*Adding acpi_osi=Linux at GRUB_CMDLINE_LINUX=\"\"\n\n*Adding quiet splash nolapic at GRUB_CMDLINE_LINUX_DEFAULT=\"\"\n\n*After these, I ran sudo update-grub\n\n*Also, disabled, requesting password after wake up\n\n\nResults: \n\n\n*Now, the screen after wake up isn't blank, but it's the last screen that was displayed before the suspend (probably).  \n\n*Moving the mouse, shows nothing - which is, the display is dead.  \nSome progress: \n\n\n*Switching to tty1 (Ctrl + Alt + F1) got me at a terminal with a working screen. From which I could use sudo lightdm restart, which did nothing.  \n\n*After that, I typed who and saw that my user was connected to tty7, so I changed to it, and voila, I have now access to my session, as it was before the suspend.  \nBut with problems: \n\n\n*Probably the graphics are messed up. The border of the right click dialog is a thick white one (about 4mm).\n\n*My wallpaper doesn't show up, and instead I get this: \nLook the wallpaper, and also, the border of the terminal window. \n\nOn a sidenote, my laptop has a Nvidia GTX520M GPU (with the \"great\" optimus technology).\nSome related info: \n\n\n*\n\n*Running Additional Drivers program, I see that the version 331 of Nvidia Driver is activated and currently in use\n\n*I remember that at my previous installation I had installed BumbleBee.  \n\n\nShould I try deactivating the proprietary driver, removing it, and then installing BumbleBee?\n\nA: I finally solved this by doing the following:  \n\n\n*\n\n*Opened Additional Drivers app, and Deactivated the driver in use\n\n*Rebooted (something was wrong with the cursor, as it was going way past the screen on the right\n\n*Ran all the commands from well my previous question regarding a problem with the same laptop.  \n\n\nNow, it wakes up from suspend successfully! :) \n", "Q: How to get Ubuntu installer to sense Windows 8.1 as an OS When I go to install Ubuntu so I can dual boot Ubuntu with windows 8.1 on my Toshiba Satellite C55 the Ubuntu installer does not sense My pre-installed windows 8. \nI referred to these guides: UEFI and installing Ubuntu on pre-installed-windows8 64bit system, but the first link suggests, to use the install Ubuntu along sideoption or make an EFI partition however it also says to only have one EFI partition on the hard drive and windows is in an EFI Partition.\n\n\n*\n\n*So I need to know how to Get Ubuntu to sense windows 8.1 or how to manually partition the hard drive so I can dual boot. Just so you know I have a Kubuntu 13.10 on a disk, Ubuntu 13.10 on a disk, and Ubuntu 12.04 on a disk. \n\n\nIf you need any more tech specifications I can give them to you.   \n\nA: First, try disabling Fast Startup in Windows. This feature is incompatible with dual-boot configurations, and it's conceivable that it's causing the problem you're seeing, although I'm far from positive of that. If this works, I'd appreciate seeing a comment to that effect so that I know it's a possible solution.\nSecond, if that doesn't work, you'll just have to use the \"Something Else\" installation option. (That referenced question/answer refers to Windows 7 and may have some Windows 7-specific elements, but the basic principles still apply.) Unfortunately, a lot of people have been seeing this problem with Windows 8 and 8.1 installations, and doing the partitioning manually is what works for most people.\n", "Q: How to fix invisible Unity panel, launcher and dash in a VM? I've got Ubuntu 13.10 installed on my laptop's physical drive. System can be booted as a standalone OS through NeoGrub. It's also attached to a VirtualBox machine in Windows host using a raw VMDK file. It worked perfectly until recently.\nI haven't started the VM for a while, but I've been using Ubuntu on bare metal. Today I have started the VM and it booted correctly, but Unity panel and launcher were invisible. Panel's shadow is visible, though, and both panel and launcher are clickable. Here's a screenshot with the menu opened by clicking where the appropriate icon should be:\n\n\n\n*\n\n*I haven't changed any Unity settings recently.\n\n*The OS was installed on a clean partition, not upgraded from previous versions.\n\n*Everything is up to date.\n\n*VirtualBox Additions are installed.\n\n*I've got dedicated NVIDIA GPU, but Nouveau is blacklisted and Ubuntu is using Intel's integrated GPU when running on bare metal. No NVIDIA drivers are installed. This setup worked before.\n\n*All required partitions (/, /home and swap) are attached to the VM. Raw VMDKs present real partition layout to guests, so it's probably not a culprit. /home is accessible and free -m shows that swap is available.\n\n*All other windows show up correctly.\n\n*OpenGL and Unity are enabled in CCSM. Re-enabling Unity doesn't fix the problem. (suggested here)\n\n*Removing ~/.compiz and ~/.config/compiz-0 followed by sudo service lightdm restart didn't work too.\n\n*The file ~/.drirc mentioned here doesn't exist.\n\n*The problem appears only in the VM. Everything is fine when running on bare metal.\n\n*Disabling accelerated 3D in VM settings helps, but performance is terrible. I consider it a workaround, not a solution. \n\n\nI recall this happened before when I was trying to run Ubuntu in a pure VM (with a virtualized hard disk image) after installing VBox Addons. It started to work later, thanks to some update I guess.\nCan this problem be fixed without waiting for patches to appear?\n\nA: OK, this time I have an answer, at least for my Virtualbox installation:-\nThe problem was with the version of \"VirtualBox Guest Additions\".\nI was running version 4.2.12.\nAfter updating my VB installation I then fired up my guest and pressed HOST+D\n(HOST in my case is the right CTRL key)\nThis popped up a message asking if it was ok to install the Guest Additions.\nAfter OK'ing this the old version was replaced.\nOn restarting the guest now displays the Panel and Launcher correctly \n", "Q: Unable to set the HUD launcher key I was finding that the left Alt key for opening the HUD was not working, so I went to Keyboard Shortcuts to re-set it. Selecting the shortcut to set it and pressing the Alt key just sets it to 'Disabled', however.\nHow can this be fixed?\n\nA: Try using the dconf command, open your terminal to type:\ndconf write /org/compiz/integrated/show-hud '[\"&lt;Alt&gt;\"]'\n\nThis should restore the HUD default key to \"Alt Left\"\n", "Q: How to install a Star Tsp-600 printer driver? I am trying to get my printer (Star Tsp-600) to work on Ubuntu 12.04. I found this page that suggested the following:\n# get the cups development headers needed to compile the drivers\nsudo apt-get install libcups2-dev libcupsimage2-dev\n\n# download and extract the drivers from Star\nwget http://www.starmicronics.com/Download/Drivers/starcupsdrv-3.0.0_Linux.zip\nunzip starcupsdrv-3.0.0_Linux.zip\ncd starcupsdrv-3.0.0_linux/SourceCode\ntar -xzf starcupsdrv-src-3.0.0.tar.gz\ncd starcupsdrv\n\n# build and install the drivers\nmake\nsudo make install\n\nFor Ubuntu 11.x and up, you need to modify the makefile, at lines 15 and 16.\n\nIn both cases, you need to correct the path for cups files...\nCorrect location is /usr/lib/x86_64-linux-gnu\n\nHowever, when I run make, I get the following error:\nmake: * [rastertostar] Error 1\n\nWhat should I do?\n\nA: Ok, I downloaded the driver and checked it. I do not guarantee that it will work, but at least it will compile. \nThe problem is that the code in the makefile (a makefile is a file that specify how to compile programs)  that check for dependencies is obsolete. So the correct solution would be to ask to the manufacturer that they update their driver. \nMeanwhile, you can use a \"hammer\" solution: delete the dependencies check and try to compile the driver anyway. \nTo do that you have to change the makefile. After the cd starcupsdrv step on your question, open the file makefile with your preferred editor (for example with gedit makefile); go to this point: \n\nand REMOVE the lines 14, 15 and 16, so that it's like this one:\n\nNow make will succeed, with some nasty warning. Then continue as instructed, I hope it works for you.  \nThe binaries do run on my machine, so there is a quite high probability that they'll work --- if the makefile will install them in the correct place. Remember that the install phase must be done as root, so with\nsudo make install\n\nGood luck!\n\nA: The instructions you have found are telling you exactly what to do:\n\nFor Ubuntu 11.x and up, you need to modify the makefile, at lines 15\n  and 16.\nIn both cases, you need to correct the path for cups files... Correct\n  location is /usr/lib/x86_64-linux-gnu\n\nSo:\n\n\n*\n\n*Open a terminal an move into the directory where you extracted the data:\ncd starcupsdrv-3.0.0_linux/SourceCode/starcupsdrv/\n\n\n*Open the makefile in a text editor\ngedit makefile\n\n\n*Scroll down to lines 15 and 16, they look like this:\n@if ! (ls /usr/lib | grep libcups.* > /dev/null); then echo \"libcups not available - exiting\"; exit 1; fi\n@if ! (ls /usr/lib | grep libcupsimage.* > /dev/null); then echo \"libcupsimage not available - exiting\"; exit 1; fi\n\n\n*Make them look like this:\n@if ! (ls /usr/lib/x86_64-linux-gnu | grep libcups.* > /dev/null); then echo \"libcups not available - exiting\"; exit 1; fi\n@if ! (ls /usr/lib/x86_64-linux-gnu | grep libcupsimage.* > /dev/null); then echo \"libcupsimage not available - exiting\"; exit 1; fi\n\n\n*Save the file and go back to the terminal\n\n*Run make and make install \nmake && make install\n\n\nA: Digging in the manufacturer's site, I found this FAQ. There is a link to a pdf file with instructions, but it refers to Ubuntu 8.04. Having said that, the procedure described in the pdf is fairly straight forward and it should be easily adapted.\nIn effect you have to do the following:\nFirst, download the drivers (you have already done that) and then extract the contents of the downloaded file. To do that, open a terminal window with Ctrl+Alt+T, cd to the directory where your file is located, and type \ntar xzvf starcupsdrv-3.0.0_linux_20090130.tar.gz\nThis will extract the contents of the archive to a folder. cd to that folder and\ntype \nmake\nThis will compile and build the driver. After the successful  completion of make, type \nsudo make install\nto install the driver on your system. You will be prompted to enter your password.\nNow that the driver is installed, open a browser window and type localhost:631 in the address bar (I'm assuming here you have a working CUPS installation). The interface is pretty much straightforward. Select Add printer and fill in the fields in the forms that are presented to you.\n\nA: I have ubuntu xenial 16.04 i386 and star TSP-700.\nstarcupsdrv-3.6.0 driver is for i386, so I've installed i386 version of ubuntu. For successful build of drivers I've installed packages\napt-get install libcups2-dev libcupsimage2-dev \n\nThen in source folder, make and make install.\nAdditional problem was something with usb: \"Printer does not have vid, pid, and serial\". Solution was to add printer in cups entering device USI directly \nparallel:/dev/usb/lp0\n\nHopefully it will save a lot of time to somebody.\n", "Q: Reinstall Ubuntu I am using Ubuntu alongside Windows 7. And my system does not allow me to part my disk more than 4 partition. And I want to delete Ubuntu and reinstall it again. But this case I want to give it more space and swap space. How can I do this correctly and without risk.\n\nA: You should use an extended partition in place of your current partitions for Ubuntu and swap. Inside that extended partition, you will be able to have multiple logical partitions.\nTo avoid risks: Do a backup of all your data, that means backup all partitions, including those you intend to leave unchanged! Manipulating the partition scheme is always subject to possible data loss. A good program for editing partitions is gparted. There is also a live CD version of it.\nIf possible, try to avoid MBR partition tables. Instead, use a GPT, which doesn't have the limitations of MBR partitioned volumes. This is possible on all computers with EFI and on some computers with BIOS (check manual of your mainboard first). Be aware: Windows 7 might refuse to install on a GPT partition if you have a BIOS computer, even if your computer actually can boot off it!\nIf you want to reinstall Ubuntu and you want to use the same version of it, first write the installed packages to a file using this command:\ndpkg --get-selections | grep -v ^lib > file\nSave this file on a safe place like a USB flash memory. Libraries are excluded, because apt will resolve required dependencies on its own.\nOnce you reinstalled Ubuntu, issue these commands:\n\napt-get install dselect && dselect access && dselect update\ncat file | dpkg --set-selections\napt-get dselect-upgrade\nThen you should have a system with the same software installed as you had before. After that it might be clever to restore some files in /etc of your Ubuntu backup.\n", "Q: How to save text buffer to file using Python and gtk? I am trying to create a text editor for Ubuntu (going to give it a try!) using gtk2 and python.\nSo far I have been able to implement the open function.  However I just don't know how I can get the contents of the TextView and write them into a file (the user would have named and decided which directory to save it in).\nHere is the code for the gtk.FileChooserDialog save function:\ndef on_saveButton_clicked(widget):\n        print 'saveButton clicked'\n        savechooser = gtk.FileChooserDialog(title='Save File', action=gtk.FILE_CHOOSER_ACTION_SAVE, \n                                                        buttons=(gtk.STOCK_CANCEL, gtk.RESPONSE_CANCEL,\n                                                        gtk.STOCK_SAVE, gtk.RESPONSE_OK))\n        filter = gtk.FileFilter()\n        filter.set_name('All files')\n        filter.add_pattern('*')\n        savechooser.add_filter(filter)\n\n        pyFilter = gtk.FileFilter()\n        pyFilter.set_name('Python source file')\n        pyFilter.add_pattern('*.py')\n        savechooser.add_filter(pyFilter)\n\n        rbFilter = gtk.FileFilter()\n        rbFilter.set_name('Ruby source file')\n        rbFilter.add_pattern('*.rb')\n        savechooser.add_filter(rbFilter)\n\n        cppFilter = gtk.FileFilter()\n        cppFilter.set_name('C++ source file')\n        cppFilter.add_pattern('*.cpp')\n        savechooser.add_filter(cppFilter)\n\n        response = savechooser.run()\n        if response == gtk.RESPONSE_OK:\n            filename = savechooser.get_filename()\n            print filename, 'selected.'\n        elif response == gtk.RESPONSE_CANCEL:\n            print 'Closed, file not saved.'\n        savechooser.destroy()\n\nDoes anyone have any ideas?\n\nA: In the first place, consider updating your code to Python 3 and Gtk+3 (PyGObject) as @SylvainPineau suggests. Then, you need to make the GtkTextView an instance property/member so you can access it from within on_saveButton_clicked. Lastly, to actually save the contents of the GtkTextBuffer you can use Python builtin functions or GIO.\nWith Python builtin functions (and assuming you save the GtkTextView in self.view):\nif response == gtk.RESPONSE_OK:\n    filename = savechooser.get_filename()\n    print(filename, 'selected.')\n\n    buf = self.view.get_buffer()\n    text = buf.get_text(buf.get_start_iter(),\n                        buf.get_end_iter(),\n                        True)\n    try:\n        open(filename, 'w').write(text)\n    except SomeError as err:\n        print('Could not save %s: %s' % (filename, err))\n\nPS: I notice you are not using classes, since your on_saveButton_clicked function doesn't have the self argument. If so, for the sake of testing your current code you can make self.view into a TEXT_VIEW global variable.\n", "Q: unable to run Tor browser Downloaded, extracted, and executed, then I got \"tor unexpected exited\".\nHere are some terminal stuffs:\ntor-browser_en-US$ ./start-tor-browser    \nLaunching Tor Browser Bundle for Linux in /home/jackbutton/Downloads/tor-browser_en-US    \n(process:6331): GLib-CRITICAL **: g_slice_set_config: assertion 'sys_page_size == 0' failed    \n(process:6331): GLib-CRITICAL **: g_slice_set_config: assertion 'sys_page_size == 0' failed    \nTor Browser exited cleanly.\n\n\nA: This is unfortunately a bug in Firefox, for which no sure workaround is known. For some users, it seems to be a permission problem, while some users had success removing custom themes and using default widget styles.\n\nA: I had similar problem and it was a permission problem, because firstly I copied whole folder with Tor browser to NTFS partition and then back to ext4 partition. Apparently, executable bits on some files were lost. I solved it with not very nicely, but it works for me:\nchmod -R +x ./\n\ninside directory with Tor browser.\n", "Q: What app should i get to help open Starmade/Minecraft I have downloaded Starmade (minecraft in space basically) and I want to open it but I don't know what to use or download to play it. The default is squeeze but that doesn't do anything.\n\nA: You need a Java runtime to run the game.\nTo install it, run sudo apt-get install openjdk-7-jre in a terminal. You can then run the game by double-clicking the .jar file (if it opens in Archive Manager instead, right-click it and select Open With > OpenJDK) or from a terminal by running java -jar ./StarMade-Starter.jar from the folder where the file is stored.\n", "Q: cannot install python3 after dist-upgrade How can I install python3?\nI try to install python3 like this:\nsudo apt-get install python3\n\nBut I get the error below:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\npython3 is already the newest version.\nThe following packages were automatically installed and are no longer required:\n  apport-symptoms caribou digikam-data enblend enfuse finger gcc-4.7-base:i386 gir1.2-accounts-1.0 gir1.2-gdata-0.0 gir1.2-goa-1.0 gir1.2-muffin-3.0\n  gir1.2-signon-1.0 gnome-applets-data gnome-media gstreamer0.10-gconf icoutils kde-runtime-data kipi-plugins-common lib32z1 libc6-i386\n  libgnome-media-profiles-3.0-0 libkactivities-bin libkactivities6 libkcalcore4 libkdcraw-data libkdcraw21 libkdeclarative5 libkdesu5 libkdnssd4\n  libkexiv2-11 libkexiv2-data libkface-data libkface1 libkgeomap-data libkgeomap1 libkipi-data libkipi9 libkmediaplayer4 libknotifyconfig4 libksane-data\n  libksane0 libkvkontakte1 libkxmlrpcclient4 liblensfun-data liblensfun0 libmail-sendmail-perl libmarblewidget14 libmediawiki1 libmuffin0\n  libnemo-extension1 libnepomuksync4 libntrack-qt4-1 libntrack0 libopencv-calib3d2.3 libopencv-core2.3 libopencv-features2d2.3 libopencv-flann2.3\n  libopencv-highgui2.3 libopencv-imgproc2.3 libopencv-legacy2.3 libopencv-objdetect2.3 libopencv-video2.3 libplasma3 libplot2c2 libqapt-runtime libqapt1\n  librpmbuild3 librpmsign1 libsys-hostname-long-perl libthreadweaver4 muffin-common ncurses-term nepomuk-core ntrack-module-libnl-0 oxygen-icon-theme pax\n  plasma-scriptengine-javascript po-debconf python-gpgme python-lxml rpm shared-desktop-ontologies\nUse 'apt-get autoremove' to remove them.\n0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n21 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue [Y/n]? y\nSetting up python3.3-minimal (3.3.2-7ubuntu3.1) ...\nTraceback (most recent call last):\n  File \"/usr/lib/python3.3/py_compile.py\", line 8, in <module>\n    import imp\n  File \"/usr/lib/python3.3/imp.py\", line 28, in <module>\n    import tokenize\n  File \"/usr/lib/python3.3/tokenize.py\", line 28, in <module>\n    import re\n  File \"/usr/lib/python3.3/re.py\", line 122, in <module>\n    import sre_compile\n  File \"/usr/lib/python3.3/sre_compile.py\", line 14, in <module>\n    import sre_parse\n  File \"/usr/lib/python3.3/sre_parse.py\", line 17, in <module>\n    from sre_constants import *\n  File \"/usr/lib/python3.3/sre_constants.py\", line 18, in <module>\n    from _sre import MAXREPEAT\nImportError: cannot import name MAXREPEAT\ndpkg: error processing python3.3-minimal (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of python3-minimal:\n python3-minimal depends on python3.3-minimal (>= 3.3.1-1~); however:\n  Package python3.3-minimal is not configured yet.\n\ndpkg: error processing python3-minimal (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3.3:\n python3.3 depends on python3.3-minimal (= 3.3.2-7ubuntu3.1); however:\n  Package python3.3-minimal is not configured yet.\n\ndpkg: error processing python3.3 (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3:\n python3 depends on python3.3 (>= 3.3.1-1~); however:\n  Package python3.3 is not configured yet.\n python3 depends on python3-minimal (= 3.3.2-14ubuntu1); however:\n  Package python3-minimal is not configured yet.\n\ndpkg: error processing python3 (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-gi:\n python3-gi depends on python3 (<< 3.4); however:\n  Package python3 is not configured yet.\n python3-gi depends on python3:any (>= 3.3.2-2~); however:\n  Package python3 is not configured yet.\n python3-gi depends on python3 (>= 3.3); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing python3-gi (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-dbus:\n python3-dbus depends on python3 (>= 3.3); however:\n  Package python3 is not configured yet.\n python3-dbus depends on python3 (<< 3.4); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing python3-dbus (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of bluez:\n bluez depends on python3-dbus; however:\n  Package python3-dbus is not configured yet.\n\ndpkg: error processing bluez (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of lsb-release:\n lsb-release depends on python3 (>= 3.2.3-3~); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing lsb-release (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-apt:\n python3-apt depends on python3 (>= 3.3); however:\n  Package python3 is not configured yet.\n python3-apt depends on python3 (<< 3.4); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing python3-apt (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of gnome-menus:\n gnome-menus depends on python3; however:\n  Package python3 is not configured yet.\n gnome-menus depends on python3:any (>= 3.1); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing gnome-menus (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of gnome-control-center:\n gnome-control-center depends on gnome-menus (>= 2.12.0); however:\n  Package gnome-menus is not configured yet.\n\ndpkg: error processing gnome-control-center (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of gnome-bluetooth:\n gnome-bluetooth depends on bluez (>= 4.36); however:\n  Package bluez is not configured yet.\n\ndpkg: error processing gnome-bluetooth (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of indicator-bluetooth:\n indicator-bluetooth depends on bluez (>= 4.36); however:\n  Package bluez is not configured yet.\n indicator-bluetooth depends on gnome-control-center | ubuntu-system-settings; however:\n  Package gnome-control-center is not configured yet.\n  Package ubuntu-system-settings is not installed.\n indicator-bluetooth depends on gnome-bluetooth | ubuntu-system-settings; however:\n  Package gnome-bluetooth is not configured yet.\n  Package ubuntu-system-settings is not installed.\n\ndpkg: error processing indicator-bluetooth (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of gnome-user-share:\n gnome-user-share depends on gnome-bluetooth; however:\n  Package gnome-bluetooth is not configured yet.\n\ndpkg: error processing gnome-user-share (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-pkg-resources:\n python3-pkg-resources depends on python3 (>= 3.2); however:\n  Package python3 is not configured yet.\n python3-pkg-resources depends on python3 (<< 3.4); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing python3-pkg-resources (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-defer:\n python3-defer depends on python3 (>= 3.2); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing python3-defer (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-aptdaemon:\n python3-aptdaemon depends on python3:any (>= 3.3.2-2~); however:\n  Package python3 is not configured yet.\n python3-aptdaemon depends on python3-apt (>= 0.8.5~ubuntu1); however:\n  Package python3-apt is not configured yet.\n python3-aptdaemon depends on python3-defer (>= 1.0.6); however:\n  Package python3-defer is not configured yet.\n python3-aptdaemon depends on python3-dbus; however:\n  Package python3-dbus is not configured yet.\n python3-aptdaemon depends on python3-gi; however:\n  Package python3-gi is not configured yet.\n python3-aptdaemon depends on python3-pkg-resources; however:\n  Package python3-pkg-resources is not configured yet.\n\ndpkg: error processing python3-aptdaemon (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of python3-aptdaemon.pkcompat:\n python3-aptdaemon.pkcompat depends on python3:any (>= 3.3.2-2~); however:\n  Package python3 is not configured yet.\n python3-aptdaemon.pkcompat depends on python3-aptdaemon (= 1.1.1-0ubuntu4); however:\n  Package python3-aptdaemon is not configured yet.\n\ndpkg: error processing python3-aptdaemon.pkcompat (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of system-config-printer-gnome:\n system-config-printer-gnome depends on packagekit-system-interface; however:\n  Package packagekit-system-interface is not installed.\n  Package python3-aptdaemon.pkcompat which provides packagekit-system-interface is not configured yet.\n\ndpkg: error processing system-config-printer-gnome (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of aptdaemon:\n aptdaemon depends on python3:any (>= 3.2); however:\n  Package python3 is not configured yet.\n aptdaemon depends on python3.3; however:\n  Package python3.3 is not configured yet.\n aptdaemon depends on python3-aptdaemon (= 1.1.1-0ubuntu4); however:\n  Package python3-aptdaemon is not configured yet.\n aptdaemon depends on python3-gi; however:\n  Package python3-gi is not configured yet.\n\ndpkg: error processing aptdaemon (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of dh-python:\n dh-python depends on python3:any (>= 3.3.2-2~); however:\n  Package python3 is not configured yet.\n\ndpkg: error processing dh-python (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n python3.3-minimal\n python3-minimal\n python3.3\n python3\n python3-gi\n python3-dbus\n bluez\n lsb-release\n python3-apt\n gnome-menus\n gnome-control-center\n gnome-bluetooth\n indicator-bluetooth\n gnome-user-share\n python3-pkg-resources\n python3-defer\n python3-aptdaemon\n python3-aptdaemon.pkcompat\n system-config-printer-gnome\n aptdaemon\n dh-python\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nWhen I do:\nsudo dpkg --configure python3\n\nI get:\ndpkg: dependency problems prevent configuration of python3:\n python3 depends on python3.3 (>= 3.3.1-1~); however:\n  Package python3.3 is not configured yet.\n python3 depends on python3-minimal (= 3.3.2-14ubuntu1); however:\n  Package python3-minimal is not configured yet.\n python3 depends on dh-python; however:\n  Package dh-python is not configured yet.\n\ndpkg: error processing python3 (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n python3\n\nAnd when I do:\nsudo dpkg --configure python3.3-minimal\n\nI get:\nSetting up python3.3-minimal (3.3.2-7ubuntu3.1) ...\nTraceback (most recent call last):\n  File \"/usr/lib/python3.3/py_compile.py\", line 8, in <module>\n    import imp\n  File \"/usr/lib/python3.3/imp.py\", line 28, in <module>\n    import tokenize\n  File \"/usr/lib/python3.3/tokenize.py\", line 28, in <module>\n    import re\n  File \"/usr/lib/python3.3/re.py\", line 122, in <module>\n    import sre_compile\n  File \"/usr/lib/python3.3/sre_compile.py\", line 14, in <module>\n    import sre_parse\n  File \"/usr/lib/python3.3/sre_parse.py\", line 17, in <module>\n    from sre_constants import *\n  File \"/usr/lib/python3.3/sre_constants.py\", line 18, in <module>\n    from _sre import MAXREPEAT\nImportError: cannot import name MAXREPEAT\ndpkg: error processing python3.3-minimal (--configure):\n subprocess installed post-installation script returned error exit status 1\nErrors were encountered while processing:\n python3.3-minimal\n\nEDIT after comment by user193537:\nWhen I try to remove python3:\nsudo apt-get remove python3\n\nThen I get this dependency problem:\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nPackage 'python3' is not installed, so not removed\n0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n2 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nSetting up python3.3-minimal (3.3.2-7ubuntu3.1) ...\nTraceback (most recent call last):\n  File \"/usr/lib/python3.3/py_compile.py\", line 8, in <module>\n    import imp\n  File \"/usr/lib/python3.3/imp.py\", line 28, in <module>\n    import tokenize\n  File \"/usr/lib/python3.3/tokenize.py\", line 28, in <module>\n    import re\n  File \"/usr/lib/python3.3/re.py\", line 122, in <module>\n    import sre_compile\n  File \"/usr/lib/python3.3/sre_compile.py\", line 14, in <module>\n    import sre_parse\n  File \"/usr/lib/python3.3/sre_parse.py\", line 17, in <module>\n    from sre_constants import *\n  File \"/usr/lib/python3.3/sre_constants.py\", line 18, in <module>\n    from _sre import MAXREPEAT\nImportError: cannot import name MAXREPEAT\ndpkg: error processing python3.3-minimal (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of python3.3:\n python3.3 depends on python3.3-minimal (= 3.3.2-7ubuntu3.1); however:\n  Package python3.3-minimal is not configured yet.\n\ndpkg: error processing python3.3 (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n python3.3-minimal\n python3.3\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: My question was answered by @Gx1sptDTDa here:\nBroken dependencies after upgrade\nGx1sptDTDa links to:\nhttps://bugs.launchpad.net/ubuntu/+source/ubuntu-release-upgrader/+bug/1165281\n\nThe solution is to edit these files:\n/usr/lib/python3.3/sre_constants.py\n/usr/lib/python3.3/sre_parse.py\n/usr/lib/python3.3/sre_compile.py\n\nIn sre_constants.py I replace:\nfrom _sre import MAXREPEAT\n\nwith:\nMAXREPEAT = 65535\n#from _sre import MAXREPEAT\n\nIn sre_parse.py and sre_compile.py I comment out:\nfrom _sre import MAXREPEAT\n\n", "Q: Managing multiple servers with shared accounts and filesystem At work we have about 7 servers, quite heterogeneous but all running AMD64 architectures, which we would like to join and manage from a single machine, preserving the fact that all of them can also be used as desktop computers.\nThe basic idea is to have all servers share configuration (i.e. installed software), accounts and one partition devoted to a shared filesystem.\nIs this posible with Ubuntu? So far we have had to install Ubuntu and manage it on each individual computer, but it is a mess to keep up with upgrades and allow people access to different computers. Does Ubuntu and any of the tools it provides (MAAS, Juju, etc) help in any way here?\nP.S.: We would like to stick to free software here. We cannot afford pay for maintenance and also this is a private network sitting behind a firewall.\n\nA: You primary requirement need to set up an environment with a shared authentication database\nBut If you only need a nice management tool, install and try Webmin and give it a try.\nwget http://prdownloads.sourceforge.net/webadmin/webmin_1.680_all.deb\ndpkg -i webmin_1.680_all.deb\napt-get -f install\n\nOpen interface by https://yourserverIP:10000 and login\n", "Q: Ubuntu 13.10 32 bit - Install screen prevents install I created a DVD install and a USB boot.  Bothe only get as far as the what Language screen and I am unable to choose or move beyond the strange screen.\nApprently being new prevents use of images. I hope the links provided work.\nI am using an HP dv6707 laptop with 2GB memory. \n\n\n\nA: Darent, thanks for making my links visible.\nI got up this morning and seeing no answers, created a dvd for Ubuntu 12.04 LTS - 32bit.  The install went perfectly and I am now exploring the Ubuntu Desktop.\nThanks again.  \n", "Q: Any way to get an AMD HD4250 Graphics to work in 13.10 with good performance? Mine gets slower until unusable I have an ASUS M5A88-V EVO motherboard with an integrated AMD/ATI RS880[Radeon HD4250].\nI am running Ubuntu 13.10 64bit and it seems to get slower until it is unusable.    Especially the graphics animations, ie switching windows.\nI checked and it is using the Gallium 0.4 on AMD RS880 driver.\nIs that the right one and is there something that needs to be done to get it to work correctly? \nThe only thing I have seen suggested in other places is to go back to a version before 12.10. That seems impractical at this point.  Is there any reason to expect it will work in 14.04 LTS?\n\nA: Upgrade to 14.04 - the latest kernel enables dynamic power management by default, which means the GPU clock frequency is automatically increased in order to get better performance. Without DPM the clock rate is left at whatever the BIOS originally set it to.\n", "Q: youtube works with my xp but ubuntu I have a self made computer amd pros gforce video card 6600gt running xp \nand my windows plays youtube fine but when I boot ubuntu it don't can anybody tell why\n\nA: You likely need flash player.\nOpen a terminal (control-alt-t), and type the following:\nsudo apt-get install flashplugin-installer \n\nOnce it's done installing, exit the terminal and then restart your browser.\nYou may possibly need to enable multiverse for this to work, see this link for how: How do I enable the \"multiverse\" repository?\n", "Q: Script to install Ubuntu and same set of programs on several computers I have several computers at different locations, and I want all of them to be set up in exactly the same way.\nIs it possible to write a script which I can run once I have installed a new Ubuntu OS to automatically download and install all the programs which I need?\nI would like to install programs such as\n\n\n*\n\n*Google Chrome\n\n*R\n\n*Eclipse\n\n*etc\n\n\nA: Check out Diskless Remote Boot Linux and Clonezilla. The idea here being that you would install the Desired OS on a dedicated server with all the apps, clone it and then use DRBL to install the image via Clonezilla.\nDRBL: http://drbl.org/\nArticle describing all this: www.linuxjournal.com/article/10884\n\nA: The script is as following\n#! /bin/bash\nmkdir  install9327\ncd install9327\nwget -c <link to google chrome.deb>\nwget -c <link to etc.deb>\nsudo dpkg -i *\nsudo apt-get -y install r-base-core eclipse\ncd ..\nrm -r ./install9327\nspd-say \"mission completed, no guarantee of success.\"\n\nMake the script executable with\nsudo chmod +x /path_to_script/filename.sh    # filename.sh is your script name.\n\nThis script will create a folder, download chrome and etc, install them, install R and eclipse and then clear all the stuff.At last it gives a spoken message.\nIn case of failure(due to disconnection,broken dependencies etc), this script will just leave a folder behind, which you may want to delete.\n\nNOTE:- You have to manually ensure the links to google chrome and etc, do not install wrong packages on wrong distro.\n\n", "Q: Install ubuntu as a dual boot system in mac air http://www.maketecheasier.com/install-dual-boot-ubuntu-in-macbook-air\nThis is what I followed to install ubuntu as a dual system for my mac air.\nI have finished installing ubuntu in my mac and I can see the icon in the interface of rEFIt. \nBut when I selected it and typed enter, I just got a black screen.\nAs this article said, I need to install GPT fdisk and build a hybrid boot menu.\nSo I install the GPT fdisk in the OS X.\nbut for the hybrid boot menu, I really don't understand how to build it even if there is another post: http://ubuntuforums.org/showthread.php?t=1810275&page=19&p=11215214#post11215214\nCan any one help me to build a hybird boot menu?\n\nA: Some comments:\n\n\n*\n\n*rEFIt has been abandoned for four years. Two years ago, I forked it as rEFInd, which has significant improvements, particularly with respect to booting Linux. You're better off using rEFInd than rEFIt.\n\n*The instructions you followed had you do an installation in BIOS/CSM/legacy mode. IMO, this should be done only as a last resort; instead, you should attempt to boot Linux in EFI mode. This is more easily done with rEFInd than with rEFIt. I've written a page on how to do this, but it's outdated and uses a very old 32-bit Mac as a model. Nonetheless, if you follow the instructions under \"Fixing the Installation,\" they should be mostly applicable.\n\n*With an EFI-mode boot of Linux, a hybrid MBR becomes unnecessary and even undesirable, so don't bother trying to muck with one.\n\n*Unfortunately, Macs vary an awful lot among themselves. Some of them boot and work fine in EFI mode. Others are incredibly uncooperative and must be booted in BIOS/CSM/legacy mode to work correctly. Thus, I can't make any promises about what will work for you.\n\n", "Q: Ubuntu 12.04 wired connection doesn't work I just installed Ubuntu again after a few months of using Windows.\nAt first, I tried to install it by using an .ISO file; but, I got stuck at 43% on the partitioner, so I figured out I should use the Wubi installer.\nSo, I installed Ubuntu 12.04, rebooted my PC, and went on to Ubuntu.\nEverything was working fine, except the internet connection.\nIt was stuck trying to connect to Wired Ethernet, but it didn't work. When I changed from DHCP to manual and entered an IP- address. It connected; but, I still couldn't use internet and it wouldn't enter any sites.\nI've searched all over internet and tried different solutions, but none of them is working for me. I've had Ubuntu installed on the same computer before, and then it worked just fine, but not this time.\nifconfig output:\neth0      Link encap:Ethernet  HWaddr c8:60:00:c4:4c:b4  \n      inet6 addr: fe80::ca60:ff:fec4:4cb4/64 Scope:Link\n      UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n      RX packets:3399 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:3090 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:1000 \n      RX bytes:2340549 (2.3 MB)  TX bytes:334975 (334.9 KB)\n      Interrupt:20 Memory:f7300000-f7320000 \n\nlo        Link encap:Local Loopback  \n      inet addr:127.0.0.1  Mask:255.0.0.0\n      inet6 addr: ::1/128 Scope:Host\n      UP LOOPBACK RUNNING  MTU:65536  Metric:1\n      RX packets:796 errors:0 dropped:0 overruns:0 frame:0\n      TX packets:796 errors:0 dropped:0 overruns:0 carrier:0\n      collisions:0 txqueuelen:0 \n      RX bytes:58956 (58.9 KB)  TX bytes:58956 (58.9 KB)\n\nNetwork Manager Tool output:\nNetworkManager Tool\n\nState: connecting\n\n- Device: eth0  [Wired connection 1] -------------------------------------------\n  Type:              Wired\n\n  Driver:            e1000e\n\n  State:             connecting (getting IP configuration)\n\n  Default:           no\n\n  HW Address:        C8:60:00:C4:4C:B4\n\n\n  Capabilities:\n  Carrier Detect:  yes\n\nSpeed:           100 Mb/s\n\nWired Properties\n\nCarrier:         on\n\nroute -n output:\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n\nping output:\nping \nconnect: Network is unreachable\n\nWhen I try to configure the /etc/network interface file to set DHCP, my network tab says:\nDevice not managed. I have also tried to reinstall Ubuntu, but it still wont work.\nHow can I fix this?\n\nA: To get networkmanager to manage this interface, try this in a terminal\nsudo nano /etc/NetworkManager/NetworkManager.conf\n\nChange the line 'managed=false' to 'managed=true'\nSave, then in the same terminal we need to restart the network manager.\nsudo service network-manager restart\n\nThat should clear it up for you.\n", "Q: What is the difference between sudo -i and su? It seems as if there is no difference whatsoever. When the whoami or id commands are run, they all yield root credentials. Is this an illusion? If the root account is disabled by default in Ubuntu, and therefore su gives and authentication error, then why allow sudo -I\nEdit: Excuse me, the ONLY difference I have learned of is that sudo -I asks for the password of the user who invoked the command, and su asks for root, or some other target user's password.\nIs there any OTHER difference?\n\nA: EDITED. Note: This answer has been heavily edited since its last iteration based on Eliah Kagan's comments.\nsudo -i runs a login shell with root privileges, simulating an initial login with root, acting similar to su -. The primary difference between sudo -i and su - is that sudo -i can be executed using a sudoer's password, while su - must be executed with the root account's password. Hence, if you are on a default *buntu install, where root login is disabled, sudo -i can be used while su and its variants cannot.\nIf you run the following commands:\n$ sudo -i\n[sudo] password for <username>: <enter user's password>\n# cd ~\n# pwd\n\nyou will get the output:\n/root\n\nHence, you can see that sudo -i simulates an initial root login, including changing the home folder ($HOME) to root's, rather than your own. This also means sudo -i reads login files like .profile.\nMeanwhile, sudo -s starts a new shell but without simulating initial login - login files are not read and $HOME is still set to your user's home folder.\nIf you run the following commands:\n$ sudo -s\n[sudo] password for <username>: <enter user's password>\n# cd ~\n# pwd\n\nyou will get the output:\n/home/<username>\n\nFrom this, you can see that sudo -s does not simulate an initial login, and does not change $HOME.\n\nA: sudo -i tries to become the user whose password you use, it runs that user's login specific resources (.profile etc) and tries to run from the user's home directory.\nsu on the other hand logs you in as other users, in the other user's home directory. And that account's login specific resources will be run.  By default su logs you in as root.\nI recommend using sudo -i over su, unless you know what you're doing.\n", "Q: How do I install Popcorn Time from the new Yify Github? How can I install Popcorn Time in Ubuntu?\nThe old Popcorn Time is no more, the new Popcorn Time is being maintained by yify. \n\nA: To build and install Popcorn Time in Ubuntu using THIS script. Download and run the script (which will build and install Popcorn Time in Ubuntu) using the following commands:\n  wget https://raw.github.com/hotice/webupd8/master/popcorn-build\n  chmod +x popcorn-build\n ./popcorn-build\n\nWebupd8\n", "Q: Why does exclamation mark within double quotes cause a Bash error? Please look at these commands:\n$ notify-send SYNC TIME!\n$ notify-send 'SYNC TIME!'\n$ notify-send \"SYNC TIME!\"\nbash: !\": event not found\n$\n\nThe first two commands produce a notification bubble as expected. The third gives the error shown.\nand\n$ echo SYNC TIME!\nSYNC TIME!\n$ echo 'SYNC TIME!'\nSYNC TIME!\n$ echo \"SYNC TIME!\"\nbash: !\": event not found\n$\n\nHere as well, the echo works for first two commands but not in the third.\nMore problems here (although I was not planning on using this): both notify-send \"SYNC!TIME\" and echo \"SYNC!TIME\" give bash: !TIME\": event not found.\nBut both notify-send and echo work with \"SYNC! TIME\"\nCan someone please explain why the bash: !\": event not found error appears?\n\nA: ! is the default history expansion character in Bash, see the section \"HISTORY EXPANSION\" in the Bash manpage\n\n\n*\n\n*History expansion doesn't take place if the ! is enclosed by single quotes, as in \nnotify-send 'SYNC TIME!'\n\n\n*History expansion doesn't take place if the ! is followed by a space, tab, newline, carriage return,  or =, as in \nnotify-send SYNC TIME!\n\n\n*History expansion does take place in\necho \"SYNC TIME!\"\n\nSo you'll get an error if there isn't a command starting with \" in your history\n\nA: Because in bash, ! is a reserved word (OK, character), it has special meaning in different contexts. In this particular case, you are falling afoul of its significance in history searching. From man bash:\n   History expansions introduce words from the history list into the input\n   stream, making it easy to repeat commands, insert the  arguments  to  a\n   previous command into the current input line, or fix errors in previous\n   commands quickly.\n\n  [...]\n\n   History expansions are introduced by\n   the appearance of the  history  expansion  character,  which  is  !  by\n   default.   Only  backslash  (\\) and single quotes can quote the history\n   expansion character.\n\nBasically, what this means is that bash will take the characters after the ! and search your history for the first command it finds that starts with those characters. It is easier to demonstrate than explain:\n$ echo foo\nfoo\n$ !e\necho foo\nfoo\n\nThe ! activated history expansion, which matched the first command starting with e which was the previously run echo foo which was then run again. So, when you wrote \"SYNC TIME!\", bash saw the !\", searched history for a command starting with \", failed and complained about it. You can get the same error by running, for example !nocommandstartswiththis. \nTo print an exclamation mark, you need to escape it in one of these two ways:\necho 'Hello world!'\necho Hello world\\!\n\n", "Q: Change keyboard layout (English UK) on command line to English US I am using Ubuntu 12.04. The keyboard layout is English US everywhere except for the Command Line where it works in English UK. Terminal also has English US. How do I change the default keyboard layout in Command Line to English US?\nAlso, I think it might be worth noting here, that when I had installed Ubuntu (dual boot with Windows 8. 1), I had initially set the language as English UK, but later changed it to English US from the system settings.\n\nA: I'm running 14.04 LTS with a standard US keyboard.  My problem was that I had relied on the installer to choose US-Intl for me and it caused \"dead keys\" and improper formation of the \" and ' keys (as well as others I don't know about, I'm sure).  \nAfter a lot of frustration and trial and error, I ran the \"sudo apt-get install console-common\" suggestion and it fixed my problem, but only while I was logged in.  \nWhen I logged out, restarted the server and back in, it failed.  \nIt only took hold permanently when I executed the \"sudo dpkg-reconfigure keyboard-configuration\" command and specified the generic US keyboard.\n\"setxkbmap\" did not work for me.  \nIt seems that (I don't KNOW) setxkbmap is obsolete in 14.04 LTS.\n\nA: Update 2017-04-13: This seems to have changed in recent Ubuntu versions and running sudo apt-get install console-common will try to remove other packages. So, for recent Ubuntu versions, use this instead (Tested in 17.04):\nsudo dpkg-reconfigure keyboard-configuration\n\n\nThe simplest way would indeed be as @steeldriver suggested to open a terminal and run this command:\nsudo apt-get install console-common\n\nThat will install the console-common package and in the process allow you to chose your console layout. If that is already installed, use this to bring up the same wizard and set the layout:\nsudo dpkg-reconfigure console-data\n\nTested on 13.10, and taken from here.\n\nA: The above didn't work for me, but this did. From terminal enter the following command:\nsetxkbmap us\n\n\nA: Run this command:\nsudo dpkg-reconfigure keyboard-configuration\n\nThis worked for me.\n\nA: I have a console only (without X) Linux running inside a VirtualBox. Needed to change layout from US keyboard to a German one. I used loadkeys (load keyboard translation tables by kbd package):\nloadkeys de\n\nTo make it permanent use systemd's localectl:\nlocalectl set-keymap de\n\nFrom manual:\n\nset-keymap MAP [TOGGLEMAP]\nSet the system keyboard mapping for the console and X11. This takes a mapping name\n(such as \"de\" or \"us\"), and possibly a second one to define a toggle keyboard mapping.\nUnless --no-convert is passed, the selected setting is also applied as the default\nsystem keyboard mapping of X11, after converting it to the closest matching X11\nkeyboard mapping. Use list-keymaps for a list of available keyboard mappings (see\nbelow).\n\nSee also\n\n*\n\n*Arch wiki: Linux console/Keyboard configuration\n\nA: On Ubuntu/Debian you have /etc/default/keyboard config file which actually manages the keyboard layout on your distro. When you boot your system the /etc/default/keyboard file is read by setup scripts along with other config files. If you look  at the output of  /etc/default/keyboard  file you can see my keybord layout is set to german de :\n# KEYBOARD CONFIGURATION FILE\n\n# Consult the keyboard(5) manual page.\n\nXKBMODEL=\"pc105\"\nXKBLAYOUT=\"de\"\nXKBVARIANT=\"\"\nXKBOPTIONS=\"\"\n\nIt is not good idea (like other config files) to directly change the attributes of /etc/default/keyboard file. \nTo change the layout or model of your keyboard always use following command:\nsudo dpkg-reconfigure keyboard-configuration\n\n\nA: Additional Information.\nYou should probably also change your locale!\nUse locale -a to show all possible languages:\n$ locale -a\nC\nC.UTF-8\nde_AT.utf8\nde_BE.utf8\nde_CH.utf8\nde_DE.utf8\nde_LI.utf8\nde_LU.utf8\nen_AG\nen_AG.utf8\n...\nPOSIX\n\nIf your locale is not in the above list, then you have to generate it:\n$ sudo locale-gen fr_FR.UTF-8\nGenerating locales...\n  fr_FR.UTF-8... done\nGeneration complete.\n\nThe default settings are stored in /etc/default/locale:\nYou can either manually configure it, or use the tool:\nupdate-locale LANG=de_DE.UTF-8\n\nMore details (german source).\n", "Q: Maximum simultaneous connections on desktop vs server Ubuntu Do desktop and server versions of Ubuntu have different capabilities for simultaneous connections?  In the Windows world, windows desktop versions can only support 10 or 15 max TCP/IP connections at the same time vs 1000's of connections that server versions can maintain.  This is important if you want to run a web server like IIS or Apache.\nI am going to start using Ubuntu for an OS for Apache to run on.  So the question is which Ubuntu version (desktop or server) would allow more connection or do both versions support the same number of concurrent connections?\n\nA: This is copied form Ubuntu's own wiki page:\nWhat's the difference between desktop and server?\nThe first difference is in the CD contents. The \"Server\" CD avoids including what Ubuntu considers desktop packages (packages like X, Gnome or KDE), but does include server related packages (Apache2, Bind9 and so on). Using a Desktop CD with a minimal installation and installing, for example, apache2 from the network, one can obtain the exact same result that can be obtained by inserting the Server CD and installing apache2 from the CD-ROM.\nThe Ubuntu Server Edition installation process is slightly different from the Desktop Edition. Since by default Ubuntu Server doesn't have a GUI, the process is menu driven, very similar to the Alternate CD installation process.\nBefore 12.04, Ubuntu server installs a server-optimized kernel by default. Since 12.04, there is no difference in kernel between Ubuntu Desktop and Ubuntu Server since linux-image-server is merged into linux-image-generic.\nFor Ubuntu LTS releases before 12.04, the Ubuntu Desktop Edition only receives 3 years of support. This was increased to 5 years in Ubuntu LTS 12.04 In contrast, all Ubuntu LTS Server Edition releases are supported for 5 years.\n", "Q: Prevent www-data from running scripts and programs I discovered this little PHP script that allows you to enter GET requests manually from the browser address bar and execute commands. I played around with it and discovered that I could do all kinds of things as www-data, including view the entire directory structure, copy files user accounts, painstakingly write scripts and PHP files, upload scripts, PHP files and executable programs, and upload and compile C source code.\nI played with it on a spare machine that is not reachable from the Internet but it got me thinking about what could happen if this code was injected into a webpage (similar has been done with open source software I've used in the past) and wondering about steps that can be taken to lock down a server to prevent it.\nSo, is there any way to prevent www-data from executing commands that would allow these actions on a server, in case it is ever accessed in this manner?\n\nA: If you do not need something, better turn it off, indeed.\nThere are two things that you can generally do:\n1) If you do not need PHP, then turn it OFF. Under Ubuntu you can see the list of modules that are turned on under /etc/apache2/mods-enabled/\nTry:\nls /etc/apache2/mods-enabled/\n\nIf you see entries such as php5.conf and php5.load, delete them. Similarly, you can find cgi*.* modules, and if installed others like ruby and perl (not installed by default). As mentioned by someone else, the suexec is also a potential problem because with \"su\" capability you can see the whole world.\n2) If you do use PHP, then you can try to run mod-security. That will prevent a lot of things, assuming you turn on most of the checks they have there. However, it will also prevent a lot of legal things (i.e. if you have bash code on a page, that page may not get served at all!)\n\nOf course, the main idea is to be able to install systems such as Drupal or Wordpress. Such use PHP and thus you are forced to use it. Now note that a system such as Drupal has a full security team working on issues that present potential danger to the server or the client using Drupal. So it is generally secure.\n", "Q: Help with Canon CanoScan LiDE scanned PDF Documents I have just started working with Ubuntu for the last 10 days, with the intention to stop using Windows permanently. So far it has been awesome. I have replaced almost all my Microsoft applications with available Ubuntu apps and some help from Google Docs.\nI am experiencing a problem with my Canon CanoScan LiDE 110 Scanner. When I use the scanner in Windows 7, and saved scanned pages of a book as PDF, I can open the PDF scanned page and copy text from it directly to paste at Google Docs or any LibreOffice document. I tried doing the same in Ubuntu using the Simple Scan app. I scanned the page as text in Simple Scan and saved it as a PDF. However in Ubuntu when I open the scanned PDF page, it opens OK, but I cannot copy the texts.\nThis is quite important for my workflow, as I am a medical physician and I need to study a lot of books.\nI would really appreciate it if you can help me with this.\n\nA: Tesseract OCR\n\nTesseract was one of top 3 OCR's in 1995.The development is now handled by google since 2006.It can scan images, convert to text and recognize 40 languages.\n\nTo install Tesseract\nsudo apt-get install tesseract-ocr\n\n\nCuneiform\n\nCuneiform is another OCR system.It recognises 23 languages which include English, German, Russian, French etc.\n\nTo install Cuneiform\nsudo apt-get install cuneiform\n\n\nOther apps that maybe useful\n\n\n*\n\n*Ocradjvu\n\n*Ocrad\n\n*gocr\n\n*ocrfeeder\n\n*pdf studio 8 series\n\n", "Q: Android IDE for Ubuntu Are there any other IDEs other then eclipse for Ubuntu which can be used for Android Development\n\nA: Android application development IDE's for Ubuntu:\n\n\n*\n\n*Android studio \n\n*Phonegap\n\n*Netbeans\n", "Q: What happens if a file listed for backup with rsync is in use? I have a cron job to rsync certain files from my home folder every hour.\nWould anything bad happen if a file scheduled to be backed up is being edited at the time of backup?\nRight now, I am avoiding that chance by using another cron job to run two minutes before the backup one to remind me to save open stuff.\n(I looked through \"Questions that may already have your answer\" and \"Similar Questions\" before posting but I'm not seeing a duplicate hence the question.)\n\nA: In Ubuntu files that are opened by any program aren't handled any special but are accessible like any other file. You even can delete them (but that will only delete the file name entry, the file's data will still be there until the file is closed).\nBut depending on the program that is using the file the file's content may be invalid or out of sync with other file's content. So for a backup it is usually a good idea to make sure that all files are closed unless to know that this isn't a problem. Otherwise restoring your backup may get you an unusable or faulty system.\n", "Q: Dell laptop screen brightness is not working after upgrade from 12.04 to 13.10 I tried with \nGRUB_CMLINE_LINUX_DEFAULT=\"quiet splash acpi_backlight=vendor\" \n\nand \nsudo update-grub \n\nbut did not worked.Please help me out\n\nA: take a look at: https://bugs.launchpad.net/ubuntu/+source/xserver-xorg-video-intel/+bug/1273234\nThe answer from Antonio worked for me. I have a dell vostro laptop as well. \nRafa\n", "Q: Install Windows 7 with Ubuntu in GPT UEFI mode My computer is running Ubuntu on a disk in the markup GPT. Ubuntu runs mode UEFI (created FAT32 partition and boot loader was set there). Now I need to install Windows 7 as an alternative system for games.\nInstall it need in the UEFI. I know that if I install Windows 7 over Ubuntu, the installer will overwrite the boot Ubuntu.\nAgain I repeat that you need to get everything working in UEFI. No BIOS. How to implement it? Sorry for Google Translate.\n\nA: The default UEFI bootloader is \\EFI\\BOOT\\BOOTx64.EFI on your EFI System Partition (ESP). \nI have reinstalled Ubuntu last week and it looks like Ubuntu is not creating this file. So Windows cannot overwrite what isn't there. Windows should also not delete entries (registered bootloaders) from the UEFI bootmenu and to my experience it does not.\nI would say that UEFI is a major improvement, because bootloaders can coexist on the ESP (if the UEFI firmware, that the manufacturer implemented, isn't functionally broken or crippled).\nWhat you can do to be safe:\n\n\n*\n\n*Backup the current contents of your ESP. (Zipping should be fine.)\n\n*To get Ubuntu's GRUB as the default hotpluggable bootloader on your ESP after the Windows 7 installation has finished: copy and create \\EFI\\ubuntu\\ from your backup as \\EFI\\BOOT\\ and rename grubx64.efi to BOOTx64.EFI.\n\n*Have Ubuntu live media ready so you can use efibootmgr to recreate accidentally deleted bootmenu entries.\n\n\nI never did a UEFI install of Windows 7. With Windows 8 however it's very easy to create the Windows boot data on the ESP, even after installation. It's basically bcdboot c:\\Windows /l en-gb /s b: /f ALL, but the Windows 7 version doesn't have the /f option.\n\nA: The main EFI-specific issues  are:\n\n\n*\n\n*The ESP. I agree with LiveWireBT that you should back it up before you do anything else.\n\n*The boot loader list in NVRAM. When you install Windows in EFI mode, it will modify this list, and you'll want to modify it back to its starting point with efibootmgr or some equivalent utility.\n\n*Getting the Windows 7 installer to start in EFI mode. Most Windows 7 installation media boot fine in BIOS/CSM/legacy mode but are reluctant to boot in EFI/UEFI mode. Getting them to do so is covered here, among other places. (Try Googling if you want more references.)\n\n*Until recently, Ubuntu created GPT partitions for itself that used the same type code that Microsoft uses. This meant that Ubuntu's partitions would show up as \"unformatted disks\" in Windows, making it too easy to trash Ubuntu from Windows. The solution is to use gdisk to set the type code of the Ubuntu partitions from 0700 to 8300, as described here. Some recent versions of Ubuntu don't have this problem, since they use the correct type code from the start, but I don't recall when the transition occurred, and you haven't said what version of Ubuntu you're using, so I thought I'd mention this.\n\n\nThere are also the usual dual-boot issues. For instance, you should boot with a live CD and resize your partitions to make room for Windows. You may want to have a separate data-transfer partition to reduce the risk of Ubuntu trashing the Windows installation. These issues are the same for UEFI as for BIOS.\n", "Q: Prevent other sudoers to use apt-get command How can I prevent other sudoers to run apt-get install command? Other commands such as mount and others are OK with them.\n\nA: You can't! If you wish to give root access to an user, nothing can stop him from do anything he want with the system. Root privileges means no restrictions. So, better, give to an user only the permissions he needs.\n", "Q: My Ubuntu VM keeps wanting to reinstall Ubuntu! I've already installed ubuntu 12.04 in Virtual Machine but whenever I shut down the machine and open the Virtual Machine again it keeps asking to install it again?\nAny idea how to solve this problem?\n\nA: It sounds like your virtual machine is booting from the installation media. \nIn virtual box go to your virtual machines configuration and  ensure that you remove the live usb / disk image from the available devices section.  \n\nA: You have to disable the CD/DVD option in virtual box settings or changing the boot-order to hard-disk as the first option will make you to boot into your installed Ubuntu OS.\n\n\n*\n\n*On your virtualbox right-click on the Ubuntu virtual machine and select the Settings option.\n\n*Go to system tab and change the boot-order like in the below screenshot.And finally select OK option.\n\n\n\n*\n\n*Now start your virtual machine.It will surely boot your installed Ubuntu OS.\n\n", "Q: Why doesn't /etc/fstab use XML or JSON? This is more like a general Linux / programming question, but I've been programming for a while, and I'm used to using a format such as XML or JSON on any file which is used for configuration purposes. \nBeing new to Linux, I realized that the first configuration file I bumped into (/etc/fstab) uses some sort of table format. So why not XML or JSON? \n\nA: /etc/fstab is much older than XML and JSON, and as quite a lot of programs use it changing its format would be a nightmare.\nBesides this  /etc/fstab needs to be parsed before there is a functional system as it is used to mount all essential file systems. Hence the format of /etc/fstab should be as simple as possible as the parser should not depend on any external libs.\nParsing XML is quite difficult and you really want to avoid it if you can't relay on external libs. JSON is a bit easier but still quite difficult. \nThe semantics of /etc/fstab are quite simple, they don't include any tree-like data structures or any other fancy stuff. All you need is records consisting of six values. \nWhitepace-separated values are good enough for that, and they are easy to parse even if all you have is the C standard libs.\nSo there's just no reason to use JSON, XML or something similar.\n\nA: You should really read Eric Raymond's The Art of Unix Programming sometime.  You seem to be making the assumption that the Unix designers would have used XML for /etc/fstab if they had known about it.  On the contrary, although XML specifically had not been invented, they were quite aware of its similar predecessors, and deliberately rejected them for configuration files like /etc/fstab.\nQuoting from his subsection on XML:\n\nXML is well suited for complex data formats (the sort of things for which the old-school Unix tradition would use an RFC-822-like stanza format) though overkill for simpler ones. It is especially appropriate for formats that have a complex nested or recursive structure of the sort that the RFC 822 metaformat does not handle well.\n\nand farther down:\n\nThe most serious problem with XML is that it doesn't play well with traditional Unix tools. Software that wants to read an XML format needs an XML parser; this means bulky, complicated programs. Also, XML is itself rather bulky; it can be difficult to see the data amidst all the markup.\n\nThe Unix philosophy is to make configuration easily scriptable and human readable wherever possible.  You should be able to process config files with tools like awk, grep, sed, tr, and cut, and easily parse them in scripting languages without bulky libraries. This is a huge reason behind Unix's success and should not be underestimated.\nAlthough Eric Raymond praises XML for its ability to handle \"formats that have a complex nested or recursive structure,\"  /etc/fstab certainly has no need for those, and therefore the simplest file format possible was chosen for it.\nSo although XML certainly has its uses, you might want to consider that some of the smartest programmers on the planet who pioneered the field might have known what they were doing.  Perhaps XML isn't always the best fit for your own configuration files.\n\nA: The main reason at which I can think now is:\n\n\n*\n\n*The fstab file is most commonly used by the mount command\n\n*The history of mount command started probably before 1985\n\n*XML became a W3C Recommendation on February 10, 1998\n", "Q: Problem on Cinnamon keyboard shortcuts I installed Cinnamon on Ubunutu 12.04 by terminal. Now all keyboard shortcuts work on Unity but do not work on Cinnamon. For example sound volume up is not active for Cinnamon. \nDespite to check Cinnamon settings these shortcuts haven't effect. \n\nA: Search cinnamon in synaptic and unintsall all installed packages. Then installing cinnamon with requested packages would solve problems. \n", "Q: Pointing the default localhost folder to joomla in apache2 Please help me to solve this issue as I am new to apache2. \nMy question is how to point \"localhost\" default /var/www to /var/www/joomla. Because whenever I type \"localhost\" in the browser it shows like it works! But instead of that I want to point that \"localhost\" default to my joomla site folder.\nEven I tried running gksu gedit /etc/apache2/sites-available/site1 through the terminal and point it to my sites but nothing has changed.\nThanks in advance.\n\nA: These worked for me:\n\n\n*\n\n*Using the terminal, start to edit with root priviledges /etc/apache2/sites-available/000-default.conf file using nano for example:\nsudo nano /etc/apache2/sites-available/000-default.conf\n\n\n*Find the following line:\nDocumentRoot /var/www\n\n\n*Replace the above line with:\nDocumentRoot /var/www/joomla\n\n\n*Save the file and close it.\n\n*Restart apache2 server:\nsudo service apache2 restart\n\n", "Q: Resize GIMP 2.8 window on Ubuntu 13.10 I had to use GIMP for the first time on Ubuntu 13.10 a few days ago and its window looks pretty weird. It occupies a full workspace and a third of the workspace below:\n\n\nBut it can not be maximised (note the missing button) neither can it be resized. How can I adjust the GIMP window so that it occupies only one workspace? Thanks.\nUpdate: the output of sudo aptitude show gimp:\nPackage: gimp                            \nState: installed\nAutomatically installed: no\nVersion: 2.8.6-1ubuntu1.1\nPriority: optional\nSection: graphics\nMaintainer: Ubuntu Developers <ubuntu-devel-discuss@lists.ubuntu.com>\nArchitecture: amd64\nUncompressed Size: 15.7 M\nDepends: libgimp2.0 (>= 2.8.6), libgimp2.0 (<= 2.8.6-z), gimp-data (>= 2.8.6), gimp-data (<= 2.8.6-z), python-gtk2 (>=\n         2.8.0), libgdk-pixbuf2.0-0 (>= 2.24.1), libaa1 (>= 1.4p5), libbabl-0.1-0 (>= 0.1.10), libbz2-1.0, libc6 (>= 2.15),\n         libcairo2 (>= 1.10.2), libdbus-1-3 (>= 1.0.2), libdbus-glib-1-2 (>= 0.88), libexif12, libfontconfig1 (>= 2.9.0),\n         libfreetype6 (>= 2.2.1), libgegl-0.2-0 (>= 0.2.0), libglib2.0-0 (>= 2.37.3), libgs9 (>= 8.61.dfsg.1), libgtk2.0-0\n         (>= 2.24.10), libgudev-1.0-0 (>= 146), libjasper1, libjpeg8 (>= 8c), liblcms1 (>= 1.15-1), libmng1 (>= 1.0.10),\n         libpango-1.0-0 (>= 1.29.4), libpangocairo-1.0-0 (>= 1.29.4), libpangoft2-1.0-0 (>= 1.29.4), libpng12-0 (>=\n         1.2.13-4), libpoppler-glib8 (>= 0.18.0), librsvg2-2 (>= 2.14.4), libtiff5 (> 4.0.0-1~), libwebkitgtk-1.0-0 (>=\n         1.3.10), libwmf0.2-7 (>= 0.2.8.4), libx11-6, libxcursor1 (> 1.1.2), libxext6, libxfixes3, libxmu6, libxpm4, zlib1g\n         (>= 1:1.1.4), python:any (>= 2.7.1-0ubuntu2), python2.7\nRecommends: ghostscript\nSuggests: gimp-help-en | gimp-help, gimp-data-extras, gvfs-backends, libasound2\nConflicts: gimp\nBreaks: gimp-plugin-registry (< 4.20120506), gimp-plugin-registry (< 4.20120506)\nReplaces: gimp-plugin-registry (< 4.20120506), gimp-plugin-registry (< 4.20120506)\nProvides: gimp-helpbrowser, gimp-python\nDescription: The GNU Image Manipulation Program\n GIMP is an advanced picture editor. You can use it to edit, enhance, and retouch photos and scans, create drawings, and\n make your own images. It has a large collection of professional-level editing tools and filters, similar to the ones you\n might find in Photoshop. Numerous fine-control settings and features like layers, paths, masks, and scripting give you\n total control over your images. \n\n Many image file formats are supported, including JPEG, Photoshop (.psd), and Paint Shop Pro (.psp) files. It can also be\n used to scan and print photos. \n\n To open files remotely (like over HTTP), install the gvfs-backends package. \n\n To use a MIDI device (like a musical keyboard) as an input controller in GIMP, install libasound2 and read the how-to at\n /usr/share/doc/gimp/README.MIDI\nHomepage: http://www.gimp.org/\n\n\nA: I suggest you to try to reinstall GIMP using the following commands in terminal:\n\n\n*\n\n*Uninstall GIMP:\nsudo apt-get purge gimp*\n\n\n*Delete ~/.gimp-2.8 directory (you can make a backup first) which may contain others GIMP configuration files .\n\n*Install GIMP again:\nsudo apt-get install gimp\n\nThose images from your question don't look as GIMP should, after a clean installation.\n\nA: This is Linux, not Windows, so reinstalling a program doesn't blindly reset the user data and rarely fixes problems.\nTo reset Gimp windows, just use Edit>Preference>>Window management and click Reset saved windows positions to default values.\nIf that doesn't work (but it should) or if the windows positions make it hard to use (windows positioned off-screen), you can also just erase the sessionrc file in your Gimp profile.\n", "Q: Problem reinstalling Ubuntu 12.04 (Dual with Windows 8) - Black Screen It have been a week since I use Ubuntu alongside with Windows 8. Yesterday I tried to reinstall Ubuntu 12.04 from the CD, I chose the option Erase Ubuntu 12.04.4 LTS and reintall, I followed the installation process as I followed when I installed it for the first time. \nWhen the pc restarts, after reinstallation, I had a Grub problem so I followed the steps from this webpage howtoubuntu.org/how-to-repair-restore-reinstall-grub-2-with-a-ubuntu-live-cd#.UyVs4JDLTIU , I restored the Grub.\nThe problem came when I try to enter in Ubuntu from the grub, I got a black screen and the message is :\nKernel panic - not syncing : VFS : Unable to mount the root fs on unknown-bloking(0,0)\nCPU: 2 PID : 1 Comm: swapper/0Not tainted 3.11.0-15 generic #25 pe1-Ubuntu\nHardware name: Dell Inc. Inspiron 5423/0H4MCJ. BIOS A0206/21/201\n0000000000008001 ffff8802238addc8 ffffffff8173bc5e 0000000000001\nffffffff81ae6718 ffff8802238ade48 ffffffff8172e8d8 ffff8802236ea\nffffffff00000010 ffff8802238ade58 ffff8802238addf8 0000000000017\nCall Trace:\n[<ffffffff8173bc5e>] dump_stack+0x46/0x58\n[<ffffffff8172e8d8>] panic+0c1/0x1d7\n[<ffffffff81d263ec>] mount_block_root+0x17/0x231\n[<ffffffff81d26624>] mount_root+0x53/0x57\n[<ffffffff81d26795>] prepare_namespace+0x16d/0x1a6\n[<ffffffff81d2610d>] kernel_int_freeable+0x124/0x131\n[<ffffffff81723be0>] ? rest_int+0x80/0x80\n[<ffffffff81723bee>] kernel_int+0xe/0xf0\n[<ffffffff817508ec>] ret_from_fork+0x7c/0xb0\n[<ffffffff81723be0>] ? rest_int+0x80/0x80\n\nIn this moment I can use Windows 8 normally, I access from the grub.  \nThanks in advance for any help you are able to provide.   \n\nA: Download Boot Repair iso image, burn it on a regular CD, reboot computer with your new Boot Repair CD in tray, and choose the 'Recommended Repair' option after Boot Repair finished loading. You should be able to boot into Ubuntu after that. \nIf you can boot into Ubuntu, first thing to do, after you login is to run a required update-grub command. Code:\nsudo update-grub\n\nAnd I think that you're done. Very important is to choose the right Boot Repair iso image \nIf you're running Win8 and Ubuntu 64bit, then you choose the 64bit iso image for Boot Repair,\nIf you're not then you choose the 32bit iso image, and download it and burn it. Boot Repair iso image can also be written on any decent USB pendrive (with a minimum 1GB space) using Unetbootin tool. \n", "Q: What are virtualization and KVM? Can anyone explain this: \n\n\n*\n\n*What is virtualization?\n\n*What KVM Kernel Virtual Machine?\n\nA: Visualization is running an operating system on top of another operating system. It is a good way to try out new OS's, and several programs exist to let you do this, such as virtual box. KVM is a kernel module (similar to a driver), that allows linux to use build in parts of computer hardware that are designed specially for the purpose of visualization.\n\nA: Virtualization is a very broad term on which everyone could interpret in a different way.\nSo let me quote the following from the official Ubuntu Server Guide and if you need more details; I could guide you to more resources.\n*Virtualization is being adopted in many different environments and situations. \nIf you are a developer, virtualization can provide you with a contained environment where you can safely do almost any sort of development safe from messing up your main working environment. \nIf you are a systems administrator, you can use virtualization to more easily separate your services and move them around based on demand.\nThe default virtualization technology supported in Ubuntu is KVM. \nKVM requires virtualization extensions built into Intel and AMD hardware. \nXen is also supported on Ubuntu. Xen can take advantage of virtualization extensions, when available, but can also be used on hardware without virtualization extensions. \nQemu is another popular solution for hardware without virtualization extensions.*\n", "Q: Wireless driver on cd not working for ubuntu distribution, but in windows it works fine I have a USB wireless dongle, which is not detected by ubuntu. The drivers that come with the dongle are useless in linux and have major issues with installation. I have tried to install NDISWRAPPER, but the NDISGTK install fails with the error ndisgtk. I cannot install through the store as the ethernet port is dead. When i type in lsusb in terminal i get:\n0bda:0179 realtek semiconductor corp\n\n\n\n*\n\n*Is there any way to get the dongle working without the need of internet prior to the dongle working. The system I am running is ubuntu 12.04 32bit.\n\n\nA: Your device uses the driver 8188eu. It is certainly possible, although quite difficult, to download the driver, the build tools required to compile the driver and all their dependencies on another computer, transfer them on a USB or CD and install them on the Ubuntu 12.04 computer. You will need this file: https://github.com/lwfinger/rtl8188eu/archive/master.zip \nIn order to compile the driver, you will need linux-headers matching your running kernel; find out with:\nuname -r\n\nFor instance, if you find that you have 3.11.0-18-generic, then you need linux-headers-3.11.0-18-generic. Find and download the headers and all their dependencies here: http://packages.ubuntu.com/ Search for linux-headers matching your kernel version. Be sure to note and download all the package dependencies.\nYou also need to search for and download build-essential and all its dependencies. In some cases, the dependencies may already be installed; check:\nsudo dpkg -s <some_package>\n\nIn some cases, the dependencies have their own dependencies that also need to be downloaded.\nOnce everything is on the USB or CD, copy them to the desktop of the Ubuntu machine. Open a terminal and install them with:\ncd ~/Desktop\nsudo dpkg -i *.deb\n\nIf any package fails because a dependency is missing, download it and copy it over and try again. Once everything is installed, right-click the file master.zip and select 'Extract Here.' It will decompress into a folder named rtl8188eu-master. Compile the driver:\ncd ~/Desktop/rtl8188eu-master\nmake\nsudo make install\nsudo modprobe 8188eu\n\nYou will have compiled the driver for your currently running kernel only. We need just one more step in order to be able to recompile when a later kernel version is installed. Once you are connected:\nsudo apt-get install linux-headers-generic\n\nWhen Update Manager installs a later kernel, after reboot, recompile:\ncd ~/Desktop/rtl8188eu-master\nmake clean\nmake\nsudo make install\nsudo modprobe 8188eu\n\nOr, you could trade this device for a fully supported plug and play USB.\n", "Q: List closed-source installed applications Is it possible to list all installed applications/packages that are not open source?\n\nA: The program vrms will do this. Run sudo apt-get install vrms, and then run vrms. This identifies which programs are free/open source by seeing which repository they were installed from. However it will ignore programs you installed by just downloading a .deb file from the web, as they are not from any repository.\n", "Q: Can rtl8723ae card work with airmon-ng? I have rtl8723ae wireless card. When I run:\nairmon-ng start wlan0\n\nit tells me that the chipset is unknown:\nFound 5 processes that could cause trouble.\nIf airodump-ng, aireplay-ng or airtun-ng stops working after\na short period of time, you may want to kill (some of) them!\n\nPID     Name\n3001        avahi-daemon\n3003        avahi-daemon\n3083        NetworkManager\n3179        wpa_supplicant\n3810        dhclient\nProcess with PID 5523 (dumpcap) is running on interface mon0\nProcess with PID 3810 (dhclient) is running on interface wlan0\n\n\nInterface   Chipset     Driver\n\nmon0        Unknown     rtl8723ae - [phy0]\nmon1        Unknown     rtl8723ae - [phy0]\nmon2        Unknown     rtl8723ae - [phy0]\nwlan0           Unknown     rtl8723ae - [phy0]\n            (monitor mode enabled on mon3)\n\n\nA: The chipset is unknown for airmon-ng, but as you can see this is not a problem, the monitor mode is enabled. So, airmon-ng works well with your network device.\n", "Q: \"Open Containing Folder\" In Firefox & Chrome Doesn't Highlight The File In Nautilus I won't say I am new to Ubuntu, but I have been on and off for several years -- although I find myself on Ubuntu more than on Windows nowadays I still consider myself a newbie. I am currently using 13.10 and I also remember having this issue in 12.04 LS, as well.\nAfter I download anything in Chrome or Firefox. There is this option in the downloads page of the browser (Ctrl+J) to open the file location. It is \"Open containing folder\" in Firefox and \"Show in folder\" in Google Chrome. When I click it these links in the downloads page of the browser, the \"Downloads\" folder opens as expected, but it still doesn't highlight the file in the directory. This becomes extremely painful to find the file especially if you have a ton of files in your Downloads folder. Of course I can switch to list view and sort the items by date and find the file. However, don't you guys think it should actually highlight the file when Nautilus opens?\nIt was already posted by some other user a month ago and I think the issue was not addressed properly. Ubuntu Community Forums\nIs it a bug or is this normal and something I have to deal with? I'm assuming it's a bug since the feature sounds pretty basic and its there on Windows and OS X.\n\nA: It's a longstanding issue which was reported here for Chromium. At that time, there was no way to select an individual item in a folder, only open the folder, and so was marked as fixed, with half of it being implemented. However, according to this bug report, Nautilus has implemented the ability to select individual items, and it seems so has Dolphin (KDE equivalent of Nautilus). Perhaps it's time to open a new bug on this.\n", "Q: Install archlinux package pk2cmd-plus on Ubuntu 12.04 64bit I'm quite new to Linux and Ubuntu so please be patient :)\nI would like to install the package Archlinux package pk2cmd-plus on Ubuntu 12.04 64bit to be able to program the Microship PIC18F24K50 with PicKit2. I believe it is a 32bit program. Can I install the package directly somehow? Or do I need to compile it manually, and in that case how?\n\nA: Ok, so I finally solved it. I had to have the package libusb-dev installed.\nThis is what I did:\n1) I downloaded the source and the new device file from Archlinux, unzipped it, and compiled it.\nmake linux\n\n2) Copied the executable and the device file to another folder (according to the readme-file).\nsudo cp pk2cmd /usr/local/bin/\nsudo cp PK2DeviceFile.dat /usr/share/pk2\n\n3) Changed user privileges to the binary (before doing this I had to run pk2cmd as root).\nsudo chmod u+s /usr/local/bin/pk2cmd\n\n4) Updated .bashrc with the line.\nexport PATH=$PATH:/usr/share/pk2\n\nAnd now it works :)\nmikael@computer:~$ pk2cmd -?v\n\nExecutable Version:    1.21.00\nDevice File Version:   1.63.148\nOS Firmware Version:   2.32.00\n\n", "Q: Disable logon prompt show hostname Per default the login prompt shows %hostname% login:.\nI don't want anybody with console access to see the hostname of the server that easily.\nHow to get rid of the hostname there? \n\nA: Add the option --nohostname to getty. Edit the files /etc/init/tty[1-9].conf to change the exec line from something like\nexec /sbin/getty -8 38400 tty1\n\nto\nexec /sbin/getty --nohostname -8 38400 tty1\n\nIt may also be necessary to edit /etc/issue to remove the \\n escape code, which displays the hostname before the login prompt. Change it so it looks like:\nUbuntu XX.YY \\l\n\nDefault text mode login screen:\n\nText mode login screen after adding --nohostname too /etc/init/tty*.conf and playing with /etc/issue:\n\nMore information:\n\n\n*\n\n*getty manpage\n\n*issue manpage\n", "Q: Open Containing Folder become Choose Appication in Firefox in Kubuntu The title says it all. Every time I download something, clicking Open Containing Folder when the download is finished, it says Choose Application and I don't know what to do. I use Firefox in Kubuntu.\n\nA: In Kubuntu if you want to open the downloaded file's directory, you would choose Dolphin, as it is the File Manager for KDE, and therefore for Kubuntu (think Windows Explorer on Windows). If you would like to open the downloaded program directly, then it would depend entirely on what type of file was downloaded. \nOnce Dolphin is chosen as the desired action, you can choose to have Firefox remember the association with Dolphin so that you do not encounter the Choose Application dialogue again.\nAlternatively, you can always open Dolphin from the Kickoff menu and browse to the Downloads folder in your Home directory, which will get you to the same place. \n", "Q: Setting \"Always on Visible Workspace\" does not work As I stated in the title, Always on Visible Workspace does not work.\nIt used to, but I think that plugging another monitor (via HDMI) changed some options and now, after unplugging - this option does not work.\nI've found http://gregcor.com/2011/05/07/fix-du...es-are-broken/ but I don't have desktop/gnome/shell config, so there was no help.\nDo you have some ideas what might have happened?\nDescription: Ubuntu 13.10\nMove to other workspace makes current window dissapear - so I suppose it exists in some other (virtual?) workspace, that actually doesn't exist. So I think something in wrong with workspaces (!). \nBut Ctrl+Shift+Right/Left/Up/Down works all right. It moves window to other workspace. So I suppose the application that moves by \"Ctrl+Shift+Right/Left/Up/Down\" has a proper settings while window manager does not. \n\nA: I had the exact same issue.  The following worked for me.\nOpen up CompizConfig Settings Manager (ccsm).  Go to the 'Workarounds' section -> Window stickyness (bottom of General Tab).  Select/enable the checkbox next to 'Make \"on all desktops\" windows \"sticky\"'.\n", "Q: Software RAID 5 Disk Failure I'm going to need some expert help - free beer/coffee to anyone who get's me on my way!  \nMy System\nI'm running Ubuntu 11.10 with a 3 disk software RAID 5 configuration, with 3TB hard drives, in ext4 format.  \nWhat I Did\nI recently reviewed the health of the disks in the Disk Utility, and saw that two of my drives had bad sectors.  Everything was working fine, but I got a little worried.  When I looked at the mdadm --detail, I could see that one of the drives was in failure, and the raid was running degraded.  However, one of the drives with a few failed sectors was in fact not reporting a failure by mdadm.  \nI bought a new hard drive, and followed the steps to replace a failed drive in a RAID 5 software configuration.  (I marked the drive as failed, removed it, turned off computer, replaced it, partitioned the new drive, and added it back to the RAID).  The process nearly completed (I think), but when I reviewed mdstat detail again, things looked far worse than they were before.\nWhat I Have Now\nHere is the output of mdstat --detail /dev/mda127\nroot@mediapc:/home/jason# mdadm --detail /dev/md127 \n/dev/md127:\n        Version : 1.2\n  Creation Time : Sun Mar 10 08:57:16 2013\n     Raid Level : raid5\n     Array Size : 5860530176 (5589.04 GiB 6001.18 GB)\n  Used Dev Size : 2930265088 (2794.52 GiB 3000.59 GB)\n   Raid Devices : 3\n  Total Devices : 3\n    Persistence : Superblock is persistent\n\nUpdate Time : Sun Mar 16 06:48:06 2014\n      State : clean, FAILED\nActive Devices : 1\nWorking Devices : 2\nFailed Devices : 1\nSpare Devices : 1\n\n     Layout : left-symmetric\n Chunk Size : 512K\n\n       Name : mediapc:127  (local to host mediapc)\n       UUID : ffbed825:f397afb1:86535cd8:64f8c314\n     Events : 373600\n\nNumber   Major   Minor   RaidDevice State\n   0       8        1        0      active sync   /dev/sda1\n   1       0        0        1      removed\n   2       0        0        2      removed\n\n   3       8       32        -      faulty spare   /dev/sdc\n   4       8       17        -      spare   /dev/sdb1\n\nMy newly added drive (dev/sdb1) was added as a spare. The partition that was reporting some sector issues (in Disk Utility) but was working ok in RAID is now reporting as a faulty spare.  \nI'm pretty sure all/most of the data is still present, I just have no way to get to it.  I'll buy more drives (external) if anyone has an idea on how to get my data back, or how to get my raid running again, if at all possible.  \nI wanted to try and fix the sectors on the now-faulty spare drive (/dev/sdc) but fsck fails a couple of different ways:\nroot@mediapc:/home/jason# fsck /dev/sdc\nfsck from util-linux 2.19.1\nfsck: fsck.linux_raid_member: not found\nfsck: Error 2 while executing fsck.linux_raid_member for /dev/sdc\n\nOR:\nroot@mediapc:/home/jason# fsck /dev/sdc1\nfsck from util-linux 2.19.1\ne2fsck 1.41.14 (22-Dec-2010)\nfsck.ext4: Device or resource busy while trying to open /dev/sdc1\nFilesystem mounted or opened exclusively by another program?\n\nI tried added both drives back to the array as they are, but both fail to add:\nroot@mediapc:/home/jason# mdadm --add /dev/md127 /dev/sdb1\nmdadm: Cannot open /dev/sdb1: Device or resource busy\n\nI tried search on way to get fsck to run, but I didn't want to reboot the system until I was sure that was the next correct move.\nReally looking for some expert help.  I want my data, and I want to get this RAID 5 working - but first and foremost I'd like the data.  Thank you in advance.  Let me know if there is anything else I can provide.  \nRegards, Jason\n\nA: You'll need to umount the RAID-array before you can run fsck on any of the devices that are part of it.\nI really hope you have a backup, cause it looks like you're heading for a crash.\nTrying to recover from a single disk failure increases the chance of other disks in the array to fail as well due to the fact that the load on them increases during the repair. (ref: http://www.zdnet.com/blog/storage/why-raid-5-stops-working-in-2009/162)\n", "Q: Live CD: Script doens't work correctly after login I have a PXE/NFS Server (192.168.1.10), a client PC and a diskless PC. I installed base ubuntu to client PC.\nI wrote this script (update.sh) to work after login to client PC.\nSERVER=192.168.1.10\necho \"Copying files\"\nmount $SERVER:/srv/nfs/updatefiles  ~/nfs\ncp ~/nfs/file.txt ~/texts/\numount ~/nfs\necho \"Reconfigure SSH\"\ndpkg-reconfigure openssh-server\necho \"Completed\"\n\nI changed chown and chmod and added permission at the end of the sudoers.\nsudo chown root:root ~/updatefiles/update.sh\nsudo chmod 700 ~/updatefiles/update.sh\nsudo nano /etc/sudoers\n- hduser ALL=(ALL) NOPASSWD:/home/hduser/updatefiles/update.sh\n\nI created .bash_profile to invoke this script after login.\nsudo nano ~/.bash_profile\n- sudo $HOME/updatefiles/update.sh\n\nIt works correctly after reboot client PC. \nThen I created a linux live cd (ubuntu.iso) from client PC with using Relinux (an implement of remastersys).\nI copied ubuntu.iso to NFS server and booted diskless PC via PXE/NFS.\nI'm getting this error message after login to diskless PC. \nCopying files\nmount.nfs: /home/hduser/nfs is busy or already mounted\numount.nfs: /home/hduser/nfs: device is busy\ndebconf: DbDriver \"config\": /var/cache/debconf/config.dat is locked by another process: Resource temporarilt unavailable.\nCompleted\n\nSometimes NFS mount works and sometimes reconfigure SSH works but mostly I'm getting this error.\nI added sleep 5 to top of the script to make it work but I got same error message again. \nIt works correctly when I invoke update.sh by hand after login completed. What is causing this error?\nThanks for any help.\n\nA: Because some processes are keeping files open for writing, try to use:\nwhile :; do mount $SERVER:/srv/nfs/updatefiles ~/nfs && break || sleep 3; done\n\nThis will run mount command every 3 seconds (change this as you wish) until success.\nAnd try also a lazy unmount:\numount -l ~/nfs\n\nRead also man mount and man umount for more info and more options.\n", "Q: Open Office Default Font I have imported a document from another Ubuntu computer (made in open office).\nThe other computer had the font Merriweather installed, which the present system does not. As a result my present system has defaulted to a different font. Strangely enough I prefer the default font to my previous choice of Merriweather and would like to keep it set to this even if I export this file back to the original computer (which will have Merriweather installed!).\nTrouble is I have no idea which font Libre Office is currently using, in the bar at the top it says Merriweather, but this is obviously not true as it is neither installed nor looked like the font.\nHow do I find out what Libre Office defaults to on Ubuntu and what is the quickest way to divine which font is being used.\nFailing that I attach an image below for anyone with a sharp typographic eye (but I would prefer to know how to solve this one without simply recognising the font!)\n\n\nA: The font looks like DejaVu Sans. \n\nA: \nIn LibreOffices' Menu Bar go to 'Tools -> Options', which will open a pop up window, like shown in the screenshot above.\nFrom there choose from options:\n\n\n*\n\n*LibreOfficeWriter -> Fonts\n\n*LibreOfficeWriter -> Basic Fonts \n\n\nYou can set new fonts or simple find out, what fonts are set in your current setup.\n", "Q: is there anyway to write Arabic root in Libreoffice? I have searched in the internet about writing Arabic root in Libreoffice without any results ?!\nIs there a way to write an Arabic root in Libreoffice or not ?\nThought: the complex text layout has to do nothing with the Arabic root or the Arabic math symbols.\n\nA: Click on tools --> options\n\nOnce the options window open, click on language settings --> languages, and make sure that you have a check mark in Complex Text Layout, and choose Arabic.  See image below.\n\n", "Q: Memory check without rebooting? I picked up a laptop at the flea market.  Seems to be Chinese product for internal market. It had Windows Starter that didn't even boot at all. I installed Linux and found out that its motherboard can't boot in non-UEFI mode at all. So no LiveCDs.  In UEFI, there in no memstest86+. \nHow can I ran some memory check of this machine, short of disassembling it and plugging memory somewhere else??? Windows can run memory tests after booting, can we?\n\nA: Try memtester. It's in the repositories (at least, for 14.04, which I happen to have running at the moment).\nAlternatively, you could try memtest86 for EFI.\n", "Q: Internal Microphone not working with Ubuntu 13.10 on Compaq CQ-45 I am unable to get the internal microphone working with Ubuntu.\nIt works perfectly with Windows.\nHere is the output of lspci:\n00:14.2 Audio device: Advanced Micro Devices, Inc. [AMD/ATI] SBx00 Azalia (Intel HDA)\n01:05.1 Audio device: Advanced Micro Devices, Inc. [AMD/ATI] RS780 HDMI Audio [Radeon (HD) 3000 Series]\n\nI am using a laptop Compaq CQ-45 with an AMD Turion X2 64 bit processor with Ubuntu 13.10 32-bit version.\n\nA: I searched some solutions on the Internet. Following worked for me.\n\n\n*\n\n*I have added to /etc/modprobe.d/alsa-base.conf the following lines and worked for me:\noptions snd-pcsp index=-2    \nalias snd-card-0 snd-hda-intel    \nalias sound-slot-0 snd-hda-intel    \noptions snd-hda-intel model=dell-m4-1    \noptions snd-hda-intel enable_msi=1    \noptions snd-hda-intel position_fix=1 enable=yes\n\n\n*And then in Pulse Audio volume control, I set the Built-in Audio to \"Analog Stereo Input\".\n", "Q: Why I cannot download software on Ubuntu? I have found out that suddenly i am unable to install ANYTHING on my ubuntu distro.\nEvery time I try \nsudo apt-get install anything\n\ni actually get the same error message:\nubuntu@ubuntu:~$ sudo apt-get install adobe-flashplugin\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package adobe-flashplugin\n\nHow can I solve this problem?\nThanks)))\n\nA: You should probably update your repository first.\nsudo apt-get update\n\nand then try installing with the following code.\nsudo apt-get install flashplugin-installer\n\nAlso if you have GUI, you can get flash from Software Center. It's much easier if you don't find the terminal comfortable.\nAdobe Flash for Ubuntu\n", "Q: Installing Ubuntu on extra HDD I've  got three HDDs in my setup, with Win7-64bit running on my main one. Now I'd like to install Ubuntu on a secondary HDD and be able to choose between it and Windows at the boot screen (while maintaining Windows as the automatically booted OS).\nI don't believe what I mean to do is \"partitioning\", but then again I'm not totally sure what it should be called.\nCould anyone instruct me as to how to begin (and proceed, for that matter)?\nI plan on dedicating all 320GB of this secondary drive to Ubuntu, but don't want to partition either of my other HDDs or potentially lose data.\nNote: this 320GB HDD has been used before, so I will need to format it, but in Windows it only gives me the option to format it in NTFS.\nThanks in advance.\n\nA: Format the partition using the \"ubuntu installer\" or G-part editor from the ubuntu live CD\n\nA: Be careful with the following instructions. Working with partitions and stuff like that can result in losing your data. To be sure, save your personal data before fiddling around with the Live System.\nI would recommend the following solution: boot your PC from the Ubuntu Live CD and start the installation routine. There you can choose the destination for your system, in your case the 320GB HDD and install it. Installing Ubuntu will automatically format the HDD. \nAfter the installation procedure you enter the BIOS and set the HDD with Windows at the first position of the boot order. That causes that Windows will boot automatically. If you want to boot Ubuntu instead, press the key for entering multi boot selection (mostly F12) while starting the PC and then choose the HDD with Ubuntu. \n\nA: Install each OS on separate HDD, say Windows on HDD1 and Ubuntu on HDD2. It would be best to remove all HDDs except the one you're installing OS on so that boot-loader doesn't get messed up.\nWhen PC is powered on enter the BIOS (usually by pressing one of F1 through F12, Esc and Del keys). On the BIOS window look for Boot options or Boot priority (usually under Settings or System Configuration tab)  and select HDD1 as the first boot device. Save and exit BIOS by pressing F10. Windows will be the default OS.\nFor booting Ubuntu enter Boot menu or boot device. This will not change boot priority.\n", "Q: Which language is most completly translated, Russian or Polish? My mom is switching to Ubuntu because XP support is ending, her English isn't great but she speaks both Russian and Polish natively.\nWhich language is most completely translated, Russian or Polish?\n\nA: If you go to https://translations.launchpad.net/ubuntu/trusty/+translations and click \"View all languages\", you'll find that Russian and Polish are currently quite similar with respect to completeness in 14.04.\nI'd like to also mention the language priority list feature included in Ubuntu. It's possible to choose e.g. Russian as the first language and Polish as the fallback language. If you open Language Support and click the \"Help\" button, you can read more about it.\n", "Q: Cannot find -lxi I am trying to compile and run an OpenGL/GLUT program i created on another pc on my virtual machine ubuntu at home. I've installed freeglut3 and the other OpenGL libraries, but when I try to compile I get:\n  cannot find -lXi\nThis is the line in my Makefile:\nLDLIBS=-lGL -lGLEW -lglut -lGLU -lX11 -lXi -lm\n\nI cannot seem to find which library it is I still need to install?\nThanks for the help\n\nA: You need libXi-devel (or equivalent): \nsudo apt-get install libxi-dev\n\nlibXi provides an X Window System client interface to the XINPUT extension to the X protocol.\n", "Q: noob: uninstall eclipse from 12.04 precise I'm very new to ubuntu. Today I've installed eclipse kepler, I got it not from the terminal, not from the software center but from their website. It simply downloaded .tar.gz file which I extracted and run a file.\nNow I have to change it to indigo version so I'd like to uninstall kepler, what do I need to do?\n\nA: Try: which eclipse in the Terminal\nIf the result is not found \"Empty result\"\n   then: just delete the eclipse folder you had created\nelse:\ndelete the file in the output path, Ex sudo rm -rf /bin/eclipse\n\"Make sure from the correct PATH\" and then delete the eclipse folder that you had extracted the tar file in\n\nA: I may be wrong(fairly new to this, not sure of nuances between builds) but you could try:\nsudo apt-get remove [package_to_be_removed] #removes associated folders and files\nsudo apt-get purge [package_to_be_removed] #removes associated folders, files, and config files.\n", "Q: 3 TB hard drive suddenly no longer recognized My 3TB Western Digital WD30EXRX hard drive that used to work perfectly fine, is suddenly no longer being recognized properly. It isn't mounted automatically anymore, the file manager does not recognize it at all and in gnome-disks it is shown as an empty hard drive with 802GB of free space.\nWhat could possibly be a reason for this and what can I do to repair the disk/recover the data?\n\nA: Your drive is most probably suffering from corrupt firmware and the drive will need to be set back to its native/default capacity.\nHDD Capacity Restore Tool will be able to help you with that.\n", "Q: Getting Errors when I try to install Lubuntu I have a notebook with these specs:\n\n\n*\n\n*HP Pavilion dm1 Notebook \n\n*AMD E-450 APU with Radeon(tm) Graphics 1.65 GHz\n\n*4.00 GB RAM\n\n*32 bit Operating System\n\n\nI cannot get Lubuntu to install. I have installed the ISO to the USB drive and changed the BIOS to lauch from USB but I am still getting the following message:\n(initramfs) Unable to find a medium containing a live file system.\n\nHow can I install Lubuntu?\n\nA: I'm assuming that you are using windows?\nJust follow these three simple steps in order to install the iso to your stick and make it bootable: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows\nIf you are on any Ubuntu derivative open a terminal and type usb-creator-gtk and follow this guide from 'Step 4' onward: \nhttp://www.ubuntu.com/download/desktop/create-a-usb-stick-on-ubuntu\nOr if you're on apples OS X follow this guide:\nhttp://www.ubuntu.com/download/desktop/create-a-usb-stick-on-mac-osx\nHope this helps\n\nA: Perhaps ur notebook have \"fast boot\" option like my samsung laptop. try to disable it.\n", "Q: How to add a scrollable time bar to the sound indicator The Ubuntu sound indicator is nice because you can pause the playing song, go next or previous. Is there a way to add a scrollable time bar to that interface for the playing song?\nI got the idea from a mockup in DeviantArt\n\n\nEDIT 1\nI think it's possible. I found this screen shot here even though it's from 2010 :-)\n\n\nEDIT 2 \nI would like a global solution not just for rhythmbox like shown in the screenshot above. A global solution means that it can be used  for controlling the current playing song irrespective of the media player used, be it VLC, Banshee, Rhythmbox, Audacious etc.\n\nEDIT 3\nSince a global solution is kinda impractical (see comments below), how about for VLC only? It's practically the only media player I use.\n\nA: You'll have to change the source code for indicator-sound.  \nHowever, I came up with a hack based on this question.  \n(For VLC) \nFirst of all, to add VLC to the sound indicator, you have to enable the MPRIS Dbus interface. (Follow this link for more detailed explanation.) Once you have enabled it, VLC (along with other Music Players) can be controlled via D-bus interface.  \nFor example, for VLC you can run the following command from terminal to seek 10s forward.\nqdbus org.mpris.MediaPlayer2.vlc /org/mpris/MediaPlayer2 org.mpris.MediaPlayer2.Player.Seek 10000000\n\nYou can read all the available functions from the MPRIS interface here.\nNow based on this question, you can create your own custom script to seek 10s forward, backward etc.\n\nA: For Gnome-Shell users (not Unity)\nYou can use gnome-shell-extensions-mediaplayer.\nsudo add-apt-repository ppa:webupd8team/gnome3\nsudo apt-get update\nsudo apt-get install gnome-shell-extensions-mediaplayer\n\nPlease go through below link, you can customize many things:\nhttps://github.com/eonpatapon/gnome-shell-extensions-mediaplayer/blob/master/README.md\n\nA: I have created a custom Application indicator with 3 menu items viz. Rewind, Forward & Quit. I have tested it in unity it works fine. It can give you some idea. I am trying to make it look like picture provided by you. Meanwhile I am posting the code that I am using you can work on that too.\nRequirement: mdbus2\nInstall it using: sudo apt-get install mdbus2\nBelow is the python code:\n#!/usr/bin/env python\n'''\nTo rewind and forward the currently playing song\ndepend on mbus2 and can be installed using sudo apt-get install mbus2\nversion 0.1 (public domain)\n\nAuthor: Vivek Mishra\n'''\n\nimport dbus\nbus = dbus.SessionBus()\nproxy = bus.get_object('org.mpris.MediaPlayer2.rhythmbox','/org/mpris/MediaPlayer2')\nplayer = dbus.Interface(proxy, 'org.mpris.MediaPlayer2.Player')\n\nAPPNAME = \"Player Navigation\"\nICON = \"/usr/share/icons/hicolor/48x48/apps/totem.png\"\n\nfrom gi.repository import AppIndicator3 as AI\nfrom gi.repository import Gtk\n\n# Forwards a song for 100 sec\ndef forward(item):\n    player.Seek(100000000)\n\n# Rewinds a song for 100 sec    \ndef rewind(item):\n    player.Seek(-100000000)\n\ndef scroll(aai, ind, steps):\n    print \"hello\" # doesn't print anything\n\ndef makemenu():\n    ' Set up the menu '\n    menu = Gtk.Menu()\n\n    forward_item = Gtk.MenuItem('Forward')\n    forward_item.connect('activate', forward)\n    forward_item.show()\n\n    rewind_item = Gtk.MenuItem('Rewind')\n    rewind_item.connect('activate', rewind)\n    rewind_item.show()\n\n    exit_item = Gtk.MenuItem('Quit')\n    exit_item.connect('activate', Gtk.main_quit)\n    exit_item.show()\n\n    menu.append(forward_item)\n    menu.append(rewind_item)\n    menu.append(exit_item)\n    menu.show()\n    return menu\n\ndef startapp():\n    ai = AI.Indicator.new(APPNAME, ICON, AI.IndicatorCategory.HARDWARE)\n    ai.set_status(AI.IndicatorStatus.ACTIVE)\n    ai.set_menu(makemenu())\n    ai.connect(\"scroll-event\", scroll)\n    Gtk.main()\n\nstartapp()\n\nHope this helps. :)\n", "Q: How can I switch between windows with an active corner like in gnome 3? The title basically says it.\nI want to switch fastly between windows without using the keyboard. How do I do that in Unity?\n\"How does Gnome 3 do it?\":\nGnome 3 has an active corner in the upper left (That was used by Unity to show the launcher earlier). It shows all windows on one screen, so you can select which you want to focus on.\n\nA: I found the solution with the help of Acatar Partos comment:\n\n\n*\n\n*Install ubuntu-tweak, open it.\n\n*Go to optimizations.\n\n*Click workspace\n\n*In the upper left dropdown menu, select show windows.\n\n", "Q: Full Apps Directory not available in Software Center Can anyone tell me what depository I'm missing? If I search for say \"Apache\" at apps.ubuntu.com it comes up with what I'm looking for, if I search for it in the Software center all it comes up with are books and maybe some games.  Right now it looks like it's using the following sources:\nhttp://extras.ubuntu.com/ubuntu\nThank you,\nDavid\n\nA: Try this: \nAfter searching for apache you are likely shown a page like this:\n\nAt the bottom you see a button Show .. technical items. Click that and you should be presented with what you want.\n\n", "Q: How long should it take to create a bootable USB drive? I followed all the instructions to create a bootable USB drive so I can try Ubuntu without actually installing it on my Windows 7 machine.  Everything seemed to be going ok but now it appears to be \"stuck\" and I can't tell if it's doing anything or not. The extract window has been at 99% for 20 mins now and says it has 1 error - \"cannot open outfile autorun.inf.\"   \nThe universal USB installer window just says to be patient and the progress bar will not move until the installation is complete.  My USB stick looks like it is just \"Idling\" and not trying to do anything.  I see a bunch of Ubuntu files have been installed on it but I have no idea of its actually done or not since the progress bar is not moving.  How much longer should I wait before I try to start over?  Is there anything I can do to find out if the installation is actually still working or has it frozen up and I need to just start over? Should this be a 5-10 min job or is this something that takes hours to do?  \n\nA: UNetbootin is an application in the Ubuntu Software Center that does the same thing as Universal USB Installer if you want to try it using a different app. There is also a version of UNetbootin for Windows. I have also seen UNetbootin stall at 99% more than once for about 2-3 minutes, but it didn't give any error message and it always finished after that.\n\nShould this be a 5-10 minute job or is this something that takes hours to do?\n\nYes, it should be a 5-10 minute job from start to finish, including the wait at the end.\nUNetbootin has been dropped from the Ubuntu 18.04 repositories. When I tested the built-in Startup Disk Creator application in Ubuntu 18.04 as a UNetbootin replacement app with 5 different non-*buntu live .iso images it worked every time.\n\nA: If you're under Windows try Lili-USB Creator. It's the best tool I found under Windows to make bootable USB Disks from Ubuntu .iso files.\nYou can also try burning .img files directly to usb with a tool like Win32 DisK Image.\nUnder Ubuntu for .iso files there is the Startup Disk Creator and for .img file simply burn by:\ndd if=/path/to/downloaded.img of=/dev/sdX bs=1M\n\n(LEARN ABOUT dd PRIOR TO USING IT: THINGS MAY TURN REALLY BAD!)\nYou can find all the .iso and .img files to download in http://cdimage.ubuntu.com/releases\n\nA: Thank you for your responses...it turns out that once I clicked on the \"close\" button on the 99% complete extract dialog box it finished up without an issue.  So the trick is to know that closing the extraction dialog box, once the extract timer shows \"0\" time left, even if it does not show 100% complete is how you have to end the program. So 99% complete for extraction seems to mean \"I'm done with the extract so click on the close button and then I will be 100% complete\"  \nThank again! \nSteve  \n", "Q: rsync creating target directory with old date I have a script that automates backups - hourly snapshots of my xubuntu 12.04LTS workstation.  It creates a directory named according to the date and time, ie: 20140316-1033, representing 10:33 this morning, March 16th.  The backup works flawlessly, hard links functioning as they should.\nThat changed two days ago.  I had been running it manually - sporadically, and finally I decided to have cron automate the task, running it once an hour.  I changed the verbosity within the script, a couple tweaks as to what was being copied with each backup.  So, I apparently changed something, and I cannot figure out what I did.\nWhen I check the creation date of the target directory, it is always March 14th, 2014 at 11:23.  Up until I started fiddling, it worked properly.  Since then, the creation dates are static.\nBecause of this, I have had to change the script so that it uses directory names rather than creation dates of the directories to determine the most recent snapshot for the snapshot.\nAnything you can point me to would be greatly appreciated.  Thanks in advance.\nSOURCE=\"/\"\nNOW=$(date +\"%Y%m%d-%H%M\")\nBASE=\"/media/backup-internal/furgesson\"\nPREVIOUS=$(ls -r $BASE | head -1)\n\nif [[ \"$NOW\" != \"$PREVIOUS\" ]];\nthen\n    TARGET=\"$BASE/$NOW\"\n    LINK=\"$BASE/$PREVIOUS\"\n    OPTIONS=\"-avH --delete --link-dest=$LINK\"\n    rsync $OPTIONS --include-from '/home/carolyn/BackupScripts/include-list.txt' --exclude-from '/home/carolyn/BackupScripts/exclude-list.txt' $SOURCE $TARGET\nfi\n\nAnd here is what the directory listing looks like...\ntotal 124\ndrwxr-xr-x 25 root root 4096 Mar  7 04:04 20140314-0445\ndrwxr-xr-x 25 root root 4096 Mar 14 04:48 20140314-0512\ndrwxr-xr-x 25 root root 4096 Mar 14 04:48 20140314-0515\ndrwxr-xr-x 25 root root 4096 Mar 14 04:48 20140314-0821\ndrwxr-xr-x 25 root root 4096 Mar 14 04:48 20140314-0822\ndrwxr-xr-x 23 root root 4096 Mar 14 09:38 20140314-1013\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-1140\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-1314\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-2059\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-2128\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-2141\ndrwxr-xr-x 23 root root 4096 Mar 14 11:23 20140314-2144\ndrwxr-xr-x  3 root root 4096 Mar 14 11:23 20140315-0846\ndrwxr-xr-x  3 root root 4096 Mar 14 11:23 20140315-0848\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-0849\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-0856\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1125\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1135\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1138\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1405\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1409\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1433\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1533\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1633\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1733\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1833\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140315-1933\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140316-0733\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140316-0833\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140316-0933\ndrwxr-xr-x  4 root root 4096 Mar 14 11:23 20140316-1033\n\n\nA: A few small issues:\n\n\n*\n\n*You should never parse ls. That said, in this case, you seem to have full control of the file names in your target directory so ls can be an option. However, I recommend you use ls -tr so sort by time, instead of alphabetically:\nPREVIOUS=$(ls -tr $BASE | head -n 1)\n\n\n*Let's have a look at your rsync options. -a equals -rlptgoD:\n-r, --recursive             recurse into directories\n-l, --links                 copy symlinks as symlinks\n-o, --owner                 preserve owner (super-user only)\n-g, --group                 preserve group\n-t, --times                 preserve modification times\n\nThe problem is the -t, this preserves the real modification time of the source files so it does not actually set the modification date of the backup to the time the backup was created bu to the last modification time of the original files. Replace -a with -rlog (removing -t) to set the time to what you are expecting.\n", "Q: Ubuntu Slow in Virtualbox even with 256mb vram So I'm trying this virtualbox software which I heard was relatively good. \nThough I'm not pleased with the performance that I'm getting. I'm running the 13.xx version of Ubuntu. I have the FX-8320. I have switched my vram to 256mb which is maximum and performance has improved. I'm still thinking that its' not as fast as I would like. I'm thinking it might be the CPU which has not been giving enough power but I'm not sure.\nI have installed the virtualbox drivers and it didn't really help.\nany ideas would be greatly appreciated.\n\nA: Are you saying that you have assigned the virtual machine 256MB of \"virtual\" RAM, or 256MB of video RAM?\n\n\n*\n\n*What do you consider to be poor performance?  \n\n*What are you trying to do, specifically?  \n\n*What kind of workload are you trying?  I mean, if you're trying to do smooth 3D architectural walk-throughs or play high frame-rate games, maybe you're just barking up the wrong tree completely here, and you should just be doing that on an operating system installed on bare metal using your video card manufacturer's optimized video drivers, and so on.\n\n\nHaving said that; make sure: \n\n\n*\n\n*that virtualization support is enabled in your BIOS configuration.  \n\n*make sure that the virtual machine configuration in VirtualBox has hardware virtualization assist enabled. \n\n*In your storage settings, disable use of the host's disk cache, because if you have that enabled, you have both your VM and your host machine caching disk writes, which is redundant at best and 'can' affect performance and also potentially lead to data loss and/or tears. \n\n*Try switching your virtual hard drive controller to SCSI or SAS, if you're using SATA.\n\n\nI have to assume, that your Ubuntu VM is running a graphical user interface, right? How much virtual RAM does the machine have to work with? \nTry enabling 2D video acceleration.  What kind of video hardware do you have?  Is there even any point in assigning the virtual machine 256MB of video RAM (if that's what you're doing), based on the actual underlying hardware that you have?  Virtual machines can perform pretty handily, but they can't magically make your underlying hardware more capable than it is.\n", "Q: Sand boxed Virtual Games PC? I have an Ubuntu box with 16gb of RAM and a Dual Core CPU and a GT220 GPU (1Gig). I was thinking that maybe for gaming (I've a lot of steam titles) that maybe some sort of virtual windows environment might be the way to go. While the theory is good in my head I actually have very little idea how to go about doing this. I do know that the only Windows I could run legitimately would be an XP for which I have several old boxes that don't really work that have license stickers on them that I could legally transfer the usage rights from.\nAre there any drawbacks to gaming with this approach and can I profile the GPU and memory usage so as to stop my GPU cooking or the game hogging memory (my GPU does not like to work very hard as it hots up quite rapidly - new fan is on order)?\nBasically would you mind assuming that having never done this before I'm a total newbie in need of some solid advice and directions?\n\nA: You could try VirtualBox and let Windows run in the Virtual Machine. But especially when it comes to using the GPU like with games VMs often aren't a good (and performance wise efficient) way to go. The problem is mainly that compared to running it directly on the hardware the GPU isn't used as efficient in a VM which results in worse performance inside the VM. How bad this is depends on a lot of factors, so it is hard to give any general advice.\nYou can limit how much of the GPU,CPU,... is given to the VM if this is your concern.\nWhat about a Dual-Boot System Ubuntu/Windows?\nAnother solution without actually installing a \"real\" Windows is using PlayOnLinux.\n", "Q: Upgrading from 12.04 to 13.10 ( Unanswered questions ) I want to upgrade to 13.10 mainly because I want my computer to recognize my Samsung GS4. I am pretty happy with Ubuntu as it's faster then windows and way more everything, tough it's hard sometimes with compatibility.\nI want to know what will happen:\n-The new stuff ( ok please not everything )\n-Will this erase stuff I have right now ? ( like folder with music, background, etc...)\n-How long will it take ?\n-How should I do it ?\n\nA: Unfortunately you can not upgrade directly from 12.04 to 13.10.\nYou have to do all the steps in between as this answer explains: Can I skip over releases when upgrading?\nSo in your case from 12.04 to 12.10 to 13.04 to 13.10.\nAs this is neither practical nor desirable I would suggest that you either make a backup of your /home/YOUR_USERNAME folder to keep all your music and other personal files save and then download the Ubuntu 13.10 image to make a fresh install.\nOr the other thing you could do is wait till Ubuntu 14.04 LTS comes out in april and then do an update.\nThe good thing about the second possibility is that you don't have to reinstall your system because you can do direct system upgrades between LTS (Long-Term Support) releases.\n", "Q: No sound over HDMI on Desktop 13.10 I have the option for HDMI and have the output set to 100% but no sound. I get sound from the speaker port on the front of my case and the back but not over HDMI to my TV. I have tried a ton of thing in CLI I found on fourms but still nothing is working.\nI am running an A4 5300 with an ASUS mobo A55BM-A/USB3.  \n\nA: in 'sound' settings you can change the audio output to HDMI. \nYou will need to change it back afterwards. \n", "Q: Xubuntu menu bar disappeared after unplugging external monitor I've searched for something similar to this problem and I didn't find it. I apologise if it's a duplicate.\nI'm trying Xubuntu installed ontop of my Ubuntu 13.10. I've been trying to connect an external monitor and extend the desktop. It worked, no complains there. This is the result (left: latop - right: 24\" VGA external monitor):\n \nHowever, when I go back to the laptop screen only the menu bar disappears, as shown on the next screenshot:\n\nIf I plug in/activate the external monitor again it goes back to work normally as shown earlier. \nUpdate:\noutput of xrandr as requested (no external monitor)\nScreen 0: minimum 320 x 200, current 3286 x 1080, maximum 32767 x 32767\nLVDS1 connected 1366x768+0+0 (normal left inverted right x axis y axis) 277mm x 156mm\n   1366x768       60.0*+\n   1360x768       59.8     60.0  \n   1024x768       60.0  \n   800x600        60.3     56.2  \n   640x480        59.9  \nVGA1 disconnected 1920x1080+1366+0 (normal left inverted right x axis y axis) 0mm x 0mm\nHDMI1 disconnected (normal left inverted right x axis y axis)\nDP1 disconnected (normal left inverted right x axis y axis)\nHDMI2 disconnected (normal left inverted right x axis y axis)\nHDMI3 disconnected (normal left inverted right x axis y axis)\nDP2 disconnected (normal left inverted right x axis y axis)\nDP3 disconnected (normal left inverted right x axis y axis)\nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\n  1920x1080 (0x4d)  148.5MHz\n        h: width  1920 start 2008 end 2052 total 2200 skew    0 clock   67.5KHz\n        v: height 1080 start 1084 end 1089 total 1125           clock   60.0Hz\n\nExternal monitor plugged in:\nScreen 0: minimum 320 x 200, current 3286 x 1080, maximum 32767 x 32767\nLVDS1 connected 1366x768+0+0 (normal left inverted right x axis y axis) 277mm x 156mm\n   1366x768       60.0*+\n   1360x768       59.8     60.0  \n   1024x768       60.0  \n   800x600        60.3     56.2  \n   640x480        59.9  \nVGA1 connected 1920x1080+1366+0 (normal left inverted right x axis y axis) 531mm x 299mm\n   1920x1080      60.0*+\n   1600x1200      60.0  \n   1680x1050      60.0  \n   1280x1024      75.0     60.0  \n   1440x900       59.9  \n   1280x960       60.0  \n   1152x864       75.0  \n   1024x768       75.1     70.1     60.0  \n   832x624        74.6  \n   800x600        72.2     75.0     60.3     56.2  \n   640x480        75.0     72.8     66.7     60.0  \n   720x400        70.1  \nHDMI1 disconnected (normal left inverted right x axis y axis)\nDP1 disconnected (normal left inverted right x axis y axis)\nHDMI2 disconnected (normal left inverted right x axis y axis)\nHDMI3 disconnected (normal left inverted right x axis y axis)\nDP2 disconnected (normal left inverted right x axis y axis)\nDP3 disconnected (normal left inverted right x axis y axis)\nVIRTUAL1 disconnected (normal left inverted right x axis y axis)\n\n\nA: OK, the issue is that when you unplug the monitor, your desktop settings are not refreshed and the system still thinks it has a second monitor attached. This can probably be fixed using udev rule but they can get complicated for this kind of thing. I have written a little script that refreshes my desktop and I have mapped it to a shortcut key so I can easily run it and fix this type of issue. I have modified it to match your setup based on the output of your xrandr\n#!/usr/bin/env bash\n\n\n## If the VGA1 screen is currenlty connected  \nif ( xrandr | grep VGA1 | grep -qw connected )\nthen\n    ## print a pretty message\n    notify-send \"Extending desktop to screen VGA1\"\n\n    ## extend the desktop to the external screen. If you want your panel\n    ## to appear on the right hand screen move the '--primary' flag to\n    ## the VGA1: --output VGA1 --primary ...\n    xrandr --output LVDS1 --auto  --primary --output VGA1 --auto --right-of LVDS1\nelse\n\n    ## If the external screen is not connected, refresh the desktop and\n    ## make everything appear on the laptop's\n    xrandr --output LVDS1 --auto --primary --output VGA1 --off\n\nfi\n\nSave this script as ~/screen_switch.sh, make it executable (chmod +x ~/screen_switch.sh) and then use the System Settings to set a keyboard shortcut that runs it. You can now use the shortcut to fix your problem.\n", "Q: How to skip boot-time fsck check preferably by editing grub menu-entry? I want to make an menuentry in grub, which boots up as normal but skips fsck. If that is possible, I could create two menu-entries one of which would skip filesystem check and the other would not.\nMy /etc/fstab file looks like below, \n# /etc/fstab: static file system information.\n#\n# Use 'blkid' to print the universally unique identifier for a\n# device; this may be used with UUID= as a more robust way to name devices\n# that works even if disks are added and removed. See fstab(5).\n#\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>\n# / was on /dev/sda7 during installation\nUUID=0a0fda6a-a0af-461f-936e-fe6feff3adba /               ext2    errors=remount-ro 0       1\n# /home was on /dev/sda5 during installation\nUUID=b9ed5358-a68a-48ef-8c51-7241f0462913 /home           ext4    defaults        0       2\n# swap was on /dev/sda6 during installation\nUUID=301dcfce-1bb3-415d-a71a-df64add29443 none            swap    sw              0       0\n/dev/sr0        /media/cdrom0   udf,iso9660 user,noauto     0       0\n\n\nA: Editing /etc/fstab file to bypass fsck check at boot:\nYou can change the value of <pass>, the 6th field of file system description line in /etc/fstab to 0 (zero) to avoid filesystem check at the boot. (For your swap it's already 0, so you'll have to change your / and /home partitions' values from 1 and 2 respectively to 0 each.)\n# <file system>                  <mount point>  <type> <options>      <dump>   <pass>\n\nUUID=0a0fda6a-a0af-461f-936e-fe6feff3adba /      ext2  errors=remount-ro 0       1\n\nUUID=b9ed5358-a68a-48ef-8c51-7241f0462913 /home  ext4  defaults          0       2\n\nUUID=301dcfce-1bb3-415d-a71a-df64add29443 none   swap    sw              0       0\n\n..so that the entries look like:\n# <file system>                  <mount point>  <type> <options>      <dump>   <pass>\n\nUUID=0a0fda6a-a0af-461f-936e-fe6feff3adba /      ext2  errors=remount-ro 0       0\n\nUUID=b9ed5358-a68a-48ef-8c51-7241f0462913 /home  ext4  defaults          0       0\n\nUUID=301dcfce-1bb3-415d-a71a-df64add29443 none   swap    sw              0       0\n\n\nThe documented description of the fs_passno i.e. <pass> field in /etc/fstab file:\n\nThe sixth field (`fs_passno`):\n\nThis  field  is used by the fsck program to determine the order in which filesystem checks are done at reboot time. The root filesystem should be specified with a fs_passno of 1, and other filesystems should have a fs_passno of 2.  Filesystems within  a drive  will be checked sequentially, but filesystems on different drives will be checked at the same time to utilize parallelism available in the hardware.  If the sixth field is not present or zero, a value of zero is returned and fsck will assume that the filesystem does not need to be checked.\n\n\nA: As a complement to @rusty's answer, by default a pass value of 1 or greater in fstab will cause the disk to be checked once every 30 mounts. That really shouldn't be an issue and you should let it do so. \nIf for some reason your drive is being checked more often or if you want to change the frequency, you can do so with this command:\ntune2fs -c 50 /dev/sda1\n\nThat will set /dev/sda1 to be checked every 50 times it has been mounted. \n", "Q: How can I know when my screen was locked last time? Exist a log where I can look for that information? I want to know last days when my PC automatically locked the screen because was idle.\n\nA: FWIW: what works for me on Ubuntu 16.04.4 LTS with Unity, is monitoring DBUS with the following command:\ndbus-monitor --session \"type='signal',interface='com.canonical.Unity.Session'\"\n\n...and then monitoring for \"Locked\" and \"Unlocked\" events. Example output:\n\nsignal time=1525269138.855107 sender=:1.51 -> destination=(null destination) serial=86735 path=/com/canonical/Unity/Session; interface=com.canonical.Unity.Session; member=LockRequested\nsignal time=1525269139.409261 sender=:1.51 -> destination=(null destination) serial=86892 path=/com/canonical/Unity/Session; interface=com.canonical.Unity.Session; member=Locked\nsignal time=1525269151.238899 sender=:1.51 -> destination=(null destination) serial=86937 path=/com/canonical/Unity/Session; interface=com.canonical.Unity.Session; member=UnlockRequested\nsignal time=1525269151.791874 sender=:1.51 -> destination=(null destination) serial=86938 path=/com/canonical/Unity/Session; interface=com.canonical.Unity.Session; member=Unlocked\n\n\nA: You can find the unlock screen events using the following command:\ngrep screen /var/log/auth.log*\n\nBut there is not so simple to find the lock screen events because by default doesn't exist any log for these events (as far as I know).\nAnyway, you can run the following command for logging the lock screen events:\ndbus-monitor --session \"type='signal',interface='org.gnome.ScreenSaver'\" | ( while true; do read X; if echo \"$X\" | grep \"boolean true\" &> /dev/null; then  echo \"Screen locked on $(date)\" > $HOME/lock_screen.log; fi; done )\n\nin ~/lock_screen.log file.\nIf you like the above command, then use it in a script and make the script to run automatically at startup.\nReferences:\n\n\n*\n\n*Logging lock-screen events\n\n*Run script on screen lock/unlock\n\nA: This is what I use in Ubuntu 16.04. It logs to the system syslog.\nAdd to your home folder, mark as executable, and then use gnome-session-properties to configure it to run on session startup.\n#!/bin/bash\n\nexit_report(){\nlogger \"$(date) Lockscreen Monitoring Terminated.\"\n}\ntrap \"exit_report; exit;\" 0\n\nlockmon() {\nadddate() {\n    while IFS= read -r line; do\n      echo $line | grep string | grep '\"start\"' -q\n      if [ $? -eq 0 ] ; then\n        logger \"$(date) Screen locked\"\n      fi\n      echo $line | grep string | grep '\"stop\"' -q\n      if [ $? -eq 0 ] ; then\n        logger \"$(date) Screen unlocked\"\n      fi\n    done\n}\nlogger \"$(date) Lockscreen Monitoring Started.\"\ndbus-monitor --session \"type='signal',interface='com.ubuntu.Upstart0_6.Instance'\" | adddate\n}\n\nlockmon\n\nBased on a similar answer for Fedora systems.\n", "Q: Why Doesn't The Full Amount of RAM appear? I just upgraded by Gateway DX300x PC running Ubuntu 13.10 with a full 4GB of RAM. The specs say it should be able to handle this but when I check the System Settings it only shows 3.2GB of RAM.\nIs this normal? I never upgraded a PC running Linux so I'm not sure if it should display the full amount of RAM. The PC previously had 2GB and it always displayed 2GB in the System Settings.\nThe upgrade involved 4 separate sticks of RAM that were brand new.\nThanks for any replies.....\n\nA: If your system is 32-bit then this is no surprise. There are not enough bits to address 4 GBs of RAM on 32-bit operating systems.\nRead this to get a clearer picture on why that is.\nYou can check if you are running 32 or 64 bit version of Ubuntu by running uname -a command. Look at the output and search for one of these:\n\n\n*\n\n*\"x86_64\" - means you have 64-bit OS\n\n*\"i386\" or \"i686\" - means you have 32-bit OS\n\n", "Q: Mac iBook G4 crashed, how to make bootable Ubuntu for Mac I have a Mac iBook G4, which is not booting at all and it requires 'OS X Recovery CD', which i do not have. So I wanted to install Ubuntu on, which I already use on another system.\n\n\n*\n\n*A step by step guide, for burning the .iso image, or a bootable USB version guide for Ubuntu 13.10 for my iBook is highly appreciated.\n\n\nA: *\n\n*ubuntu 12.04.4 LTS\n\nFor extended support, choose Ubuntu 12.04 LTS \nUbuntu 12.04.4 LTS is a long-term support release. It has continuous hardware support improvements as well as guaranteed security and support updates until April 2017.\nFull installation instructions\n\n\n\n*\n\n*ubuntu 13.10\n\nUbuntu 13.10 will be supported for 9 months and includes cutting-edge new features that make your music, videos, documents and apps much easier to access.\nFull installation instructions\n\n.\n\nAlso refer to the detailed guide on How to burn a DVD on OS X\n  Also refer to the detailed guide on How to create a bootable USB stick on OS X\n\n\n\nTry Ubuntu before you install it\nIf you’re not yet sure about installing Ubuntu, you can try it out without affecting your current system. \nYou can try Ubuntu without actually installing it on your computer’s hard drive. You can do this by starting up your computer with either an Ubuntu DVD in the drive or a USB stick with Ubuntu on it in a USB port.\n\n", "Q: Ubuntu 12.04 boot-repair gets in infinite loop I am attempting to dual-boot Ubuntu 12.04 with Windows 8.1, but I am unable to run a LiveUSB without turning on legacy mode first. In legacy mode I was able to install. I planned to fix the legacy mode problem by running boot-repair from the 'Try Ubuntu' option on the LiveUSB. However, boot-repair gives me the following error in an infinite loop:\n\"The boot of your PC is in Legacy mode. You may want to retry after changing it to EFI mode.\nDo you want to continue?\"\nI press yes, it says it is applying changes, then it gives me this prompt again, over and over. But it doesn't fix my boot. I have the 'Separate/boot/efi partition' option ticked.\nSo, if I can't run Ubuntu in EFI mode, and I can't run boot-repair in legacy mode, what am I supposed to do? \nThe strange part is, I had Ubuntu-Windows8 dual boot set up on this machine before and it worked fine, but I broke my Ubuntu side and had to do a fresh install. I remember that I had to run boot-repair to fix the legacy mode problem before, and it worked. Is there something I'm missing?\n\nA: First, disable Secure Boot in your firmware. That might enable you to boot the live CD (or installer, for that matter) in EFI mode.\nIf that doesn't help, then I recommend you try my rEFInd boot manager. This lowest-risk way to do this is to download the USB flash drive or CD-R image and try booting from it. It should give you options to boot both Windows and Ubuntu. If both work, boot into Ubuntu and then install the Debian-package version of rEFInd. It should then launch from the hard disk when you restart the computer in EFI mode.\n", "Q: Add \"open in terminal\" shortcut I would like to create a Keyboard shortcut in order to open the terminal when browsing a given folder. I am using nautilus and Ubuntu 12.04.3\nIf we right click in a folder there is the option \"Open in terminal\".\nI tried by adding in the  \"System Settings > Keyboard > Shortcut\" a new shortcut. As name I put \"Open in Terminal\" and as command for example I did \"Ctrl+Super+t\" but it does not work.\n\nA: The best way I have found to do this without removing my hands from the keyboard:\nMost keyboards nowadays have a \"right click\" key (don't know if it has an official name), located between the right alt and right ctrl, looks like an icon of a menu. Clicking on that opens up the right click menu of the current window (your mouse doesn't have to be in the window itself).\nTherefore, the shortcut is Keyboard Right Click Key + E.\nBTW, If you don't have a right click button on keyboard, you can right click using:\nSHIFT+F10, and then press E. Less intuitive, but also works...\n\nA: I assume you are asking for opening a folder that you are browsing in nautilus, in a terminal.\nJust install nautilus open in terminal plugin by doing, \nsudo apt-get install nautilus-open-terminal\n\nfollowed by restarting nautilus.\nNote that Ctrl+Alt+T will open the terminal always in your home folder path.\n", "Q: How to create /etc/.java/deployment directory How to create /etc/.java/deployment directory and to move DeploymentRuleSet.jar file in that directory which sits on my desktop. I need this so I can use my netbanking but since I'm a new Linux user (very new) I dont know to use it. I tried but nothing.\nCan anyone write commands for terminal step by step?\n\nA: Open a terminal, by hitting Ctrl+Alt+T. Use the following command in the terminal,\nsudo mkdir -p /etc/.java/deployment\nsudo cp ~/Desktop/DeploymentRuleSet.jar /etc/.java/deployment\n\nThis will do the job.\n", "Q: Installing Ubuntu 13.10 alongside, 13.04. Potential boot loader issues Below is an image of my hard drive partitions as they exist currently.\n \n/dev/sda4 is Windows 8\n/dev/sda9 is Ubuntu 13.04\n/dev/sda5 is where I plan to install 13.10 as I am currently not using it for anything.\nMy goal is to have both versions of Ubuntu bootable for a time while I test the 13.10 installation. Once I feel confidant in it I will install something else to sda9.\nAlso on the 13.10 installation I plan to install /home to its own partition.\nI have two questions:\n\n\n*\n\n*Does anyone for see any issues I will likely run into with the bootloader?\n\n*What is a good standard ratio of disk space to allocate to the home partition and the root partition?\nEDIT: All the standard stuff of disabling fast boot, secure boot etc. is already taken care of. \n\nA: *\n\n*You need to decide which version (13.04 or 13.10) controls the boot loader.  You will need to use expert mode when you install.\n\n*\n\n*You could point 13.10 to install the boot loader at /dev/sda5 (it's partition) and then you will see grub twice when you boot 13.10.  You can then set it to point to /dev/sda when you are ready to remove 13.04.  This is probably the easiest.  \n\n*Alternatively, You can tell 13.10 to skip installing a boot loader and then configure 13.04 to include 13.10.  Then install the boot loader under 13.10 when you remove 13.04.\n\n\n*Your mileage will very. \n\n*\n\n*I'm at 59% with a 24GB \"/\" partition.  \n\n*Since you are dual booting windows and linux, I would probably keep /home to a modest 4G and dump the rest of your data under an NTFS partition so it is visible by both.  If you are especially daring, you could make /home an NTFS partition and give everything available to it.\n\n\n", "Q: Compiling cowpatty on Ubuntu 13.10 64bit fails So, I downloaded cowpatty from their site[1] and I am trying to compile it. However, there is an error that prevents the make-process.\nroot@phil-laptop:/home/phil/wifite-2.0r85/cowpatty-4.6# make\ncc -pipe -Wall -DOPENSSL  -O2 -g3 -ggdb   -c -o md5.o md5.c\nmd5.c:20:25: fatal error: openssl/md5.h: No such file or directory\n #include <openssl/md5.h>\n                      ^\ncompilation terminated.\nmake: *** [md5.o] Error 1\n\nOpenSSL is installed on this system. Any advice?\nThanks!\n[1] http://wirelessdefence.org/Contents/coWPAttyMain.htm#Installing_coWPAtty:\n\nA: After looking at the cowpatty Makefile:\nLDLIBS   = -lpcap\nCFLAGS   = -pipe -Wall -DOPENSSL \nLDLIBS  += -lcrypto\n\nI'd suggest you to install the following development packages:\nsudo apt-get install libpcap-dev libssl-dev\n\n", "Q: Overload capslock with esc and ctrl using xcape I want to:\n\n\n*\n\n*Turn off capslock when hitting the capslock key\n\n*Escape when hitting the capslock key\n\n*Behave like ctrl when pressing down the capslock key\nWhat I have in my ~/.Xmodmap:\n!Set Capslock to LCtrl\nremove Lock = Caps_Lock\nremove Control = Control_L\nkeycode 66 = Control_L\nadd Control = Control_L\n\n!Set Escape to Capslock\nkeycode 9 = Caps_Lock\nadd Lock = Caps_Lock\n\n!Dummy Escape Key for XCape\nkeycode 254 = Escape\n\nWhat I have at the end of my ~/.profile:\n$HOME/xcape/xcape -e 'Control_L=Escape' # Run xcape after login\n\nThings work mostly as expected with just Xmodmap, and mostly as expected with Xmodmap + $HOME/xcape/xcape -e 'Control_L=Escape' when not run from .profile.\nI get some strange behaviors when it runs from .profile; capslock key still toggles capslock in addition to behaving as esc and ctrl. My left ctrl exhibits this exact behavior as well. \nMaybe I should be running this from somewhere other than .profile?\nEdit: tried running $HOME/xcape/xcape -e 'Control_L=Escape' from xubuntu's menu -> settings manager -> Session and Startup -> Application Autostart with no effect at all.\n\nA: .Xmodmap:\nclear lock\nclear control\nkeycode 66 = Control_L\nadd control = Control_L Control_R\n\nUnder Settings > Session and Startup > Application Autostart > Add:\n/path/to/xcape -e 'Control_L=Escape'\n\nThis works with the side effect of LCtrl also escaping when tapped. Not perfect but hasn't bothered me enough to fix it in the years I've used it.\n", "Q: Duplicate sources.list entry cdrom: I am getting the following error msg when entering sudo apt-get update in terminal:\nW: Duplicate sources.list entry cdrom://Ubuntu 13.10 _Saucy Salamander_ - Release i386 (20131016.1)/ saucy/main i386 Packages (/var/lib/apt/lists/Ubuntu%2013.10%20%5fSaucy%20Salamander%5f%20-%20Release%20i386%20(20131016.1)_dists_saucy_main_binary-i386_Packages)\n\nW: Duplicate sources.list entry cdrom://Ubuntu 13.10 _Saucy Salamander_ - Release i386 (20131016.1)/ saucy/restricted i386 Packages (/var/lib/apt/lists/Ubuntu%2013.10%20%5fSaucy%20Salamander%5f%20-%20Release%20i386%20(20131016.1)_dists_saucy_restricted_binary-i386_Packages)\nW: You may want to run apt-get update to correct these problems\n\nI'm running Ubuntu from a flash-drive. I've run apt get update several times, to no avail. How do I correct these? \n\nA: Try removing everything in the /var/lib/apt/lists directory first (sudo rm /var/lib/apt/lists/*) and then updating again.\n", "Q: How to find all dependencies not installed I have .deb file which is not updated for Ubuntu 13.10, it needs a lot of dependencies to be installed. How can I get a list of all its dependencies not installed in my Ubuntu 13.10?\n\nA: Try either apt-cache showpkg <package-name> or dpkg -I <package.deb> \n\nA: The most easiest approach is using gdebi:\nsudo apt-get install gdebi-core\nsudo gdebi package.deb\n\nIt would install all dependencies you need.\n", "Q: How do I bypass The TTY login on ubuntu 12.04 lts and what is it? I have Ubuntu 12.04 LTS and I want to know what is a tty login. I was opening my laptop and the screen went black and was written \"Ubuntu 12.04 LTS harshira-HP-ProBook-445-G1 tty1\". Now it does not go through this. What is a tty? And how do I bypass the tty login so that I can use my PC in graphical mode?\n\nA: Simplest solution first, have you tried Ctrl+Alt+F7 (Not F8)? If this doesn't work, try this:\n\n\n*\n\n*Login from the command line using your username and password.\n\n*Try starting the lightdm service.\nsudo service lightdm restart\n\nOtherwise, if your computer displays a message there's something wrong with the swap, you could try doing sudo swapoff -a and repeat the above steps. If they work now, something probably is wring with your swap.\nThat's all I have now. If these don't work, try posting some more info.\n\nA: tty is the communication module with the kernel. On a tty port, you can telnet data to kernel. It is one of the ttys which hosts your display. \nIt's Ctrl+Alt+F7 for the tty containing display. If you press Ctrl+Alt+F1 or F2 up to F6, you can open new connections to your kernel.\nIf you don't have unsaved information you can try killall -u <user_name> and it kills everything except kernel.\n\nA: As others have explained, tty (teletype) is the base communication module for the kernel.  It is the first layer of communication a user has with the kernel itself, prior to loading a GUI and etc.  \nIt looks like when you closed your laptop, the computer attempted to hibernate, which caused the swap to turn off.  I have had this issue a few times on my laptops.  The best thing I can tell you is to go into the Power Settings and make sure to change the action that happens when you close the lid so that it does not hibernate.\nIf you had your GUI working prior to this, then I suggest a hard reboot (hold down the power button until the computer turns off, then turn it back on) as long as you are not afraid of losing anything.  If everything works, then it proves the above stated. \n", "Q: No wifi on Ubuntu 13.10 I just installed Ubuntu 13.10 on my Toshiba Satellite L645D-S4030 laptop and I am unable to detect any wifi networks, my wifi light is not on, but I can still use an Ethernet connection. I know that our wifi is working since we are using it on other devices. I already tried fn f8 and it does not turn on the wifi. I am new to Ubuntu and Linux and I am sorry if I am missing something obvious. How do I get my computer to connect to my wifi network?\nEdit: http://pastebin.com/MgD4pzsZ Wireless-info.txt\n\nEDITS FROM DISCUSSION BELOW \n\n\n*\n\n*sudo rfkill unblock all didn't work.\n\n*lspci -v | grep -i wireless Doesn't return any results.\n\n\nFrom @WildMan. It's a custom script written by him and friends that helps to diagnose wireless issues.\nwget -N -t 5 -T 10 http://dl.dropbox.com/u/57264241/wireless_script && chmod +x wireless_script && ./wireless_script\n\nThe results of the script can be found at http://pastebin.com/MgD4pzsZ as above.\n@WildMan's response:\n\nYour wifi is not showing up, it is an internal wifi correct? You may want to go into your bios and see if there is a setting to enable wifi if your bios is not UEFI then reset it and see if your wifi shows up. You can make sure it is plugged in good if none of those things help then your wifi card may be bad. Even if it was turned off or a driver was not installed you should be able to see if in the information you posted for me. \n\n\nA: Try running sudo rfkill unblock all in terminal and trying again to reconnect.\n\nA: short answer:\nsudo apt-get install linux-firmware-nonfree\n\nexplanation:\nIn lsmod you see the module \"b43\" gets loaded.\nAs you can see in modinfo this is a Broadcom chip and it requires firmware files. These are only available as BLOBs. That's why they are in a package with -nonfree in the name (in the \"Multiverse\" repository) and are not installed by default.\nTo find the package I simply picked one of the file names for the firmware and searched for package contents at Ubuntu Packages Search.\n", "Q: Ubuntu 12.04 LTS with Ralink RT3290, are monitor mode and packet injection supported with rt2800pci that came with the distro? I have a fresh installation of Ubuntu 12.04 LTS and have a Ralink RT3290 wireless adapter. The distribution comes with rt2800pci driver and I've installed no other drivers or patches.\nMy network interface is - wlan0, and I can put it into monitor mode using:\nsudo iwconfig wlan0 mode Monitor\n\nIf I check with iwconfig, it shows Monitor mode enabled.\nIf I try to inject packet with Aireplay, it says:\nARP linktype is set to 1(Ethernet) expected ARPHRD_IEEE80211 or ARPHRD_IEEE80211_PRISM instead.\nMake sure RFMON is enabled; run sudo ifconfig wlan0 up, sudo iwconfig wlan0 mode Monitor channel #\n\nI can get a list of networks with sudo iwlist scan.\nMy question is, Does this card/driver truly supports Monitor mode and packet injection ? and if yes, how can I enable both Monitor mode and packet injection the right way?\nInfo - Kernel - 3.11.0-15-generic, \nDistro - Ubuntu 12.04.4 LTS, no patches, no upgrades, rfkill - Hard blocked : no\nUpd1 - After I disable networking, then I can go to Monitor mode using code above but the moment I enable networking and wireless networking, checking iwconfig says mode is Managed. Driver or Card problem ? \nIf I stop using distro rt2800pci and install backports driver, will it work perfectly ?\n\nA: I don't really understand in this kind of things but I tried exactly the same thing with the same UBUNTU version and the same nic.\ntry the following:\nsudo ifconfig wlan0 down\nsudo iwconfig wlan0 mode monitor\n\n/**(the internet connection in this stage would probably be gone)\nsudo ifconfig wlan0 up\n\nto exit the monitor mode:\nsudo ifconfig wlan0 down\nsudo iwconfig wlan0 mode managed\nsudo ifconfig wlan0 up\n\nhope I could help.\n\nA: I read that Ralink rt3070 (with rt2800usb as driver) supports monitor mode, I'll have my AWUSO36NH 2000mw antenna soon, but as you can see, Atheros chipset are the best for packet injection. both driver and chipset support monitor mode, so, follow the instructions under my comment or:\nifconfig [interface] down\niwconfig [interface] mode monitor\nifconfig [interface] up\n\nTo check if it's on monitor mode:\niwconfig [interface]\n\nFor testing Packet Injection:\naireplay-ng -9\n\n\nA: I know its too old, but it may help other.\nrt28000pci supported chips are     RT2760, RT2790, RT2860, RT2890, RT3060, RT3062, RT3090, RT3091, RT3092, RT3290, RT3592, RT5360\nAnd for more information you can check\nhttps://wikidevi.com/wiki/Rt2800pci\nFor packet injection:\naireplay-ng -1 1 -a [The BSSID of the router] mon0\nPacket injection can fail due to several reason.You will have to check those one by one as your fully supports packet injection.\n:)\n", "Q: Will I lose my data when I install Ubuntu alongside windows? Currently I am using windows 8.1(Trial version), but I wanted to check out Ubuntu as my trial ends within 2 months. I have 500GB HDD and half of it is filled with important Data. Now, I want to install Ubuntu 12.04 LTS alongside windows 8.1. Before that I wanted to make sure if I'd lose my data when I install it. The question is how do I install Ubuntu on my computer without losing data?\n\nA: If you install Ubuntu alongside Windows 8.1 you will not lose any data, I have done this in the past. P.S. If I was you I would wait an extra month for Ubuntu 14.04 LTS (Trusty Tahr) to come out and then install it (that's what I would do) If you have a USB backup the data aswell, just to be extra safe.\n", "Q: Modify sound indicator menu to hide controls from inactive player or remove it after closeing I like Spotify's indicator menu which expands whenever the application is open. I don't like Rhythmbox's which shows all the buttons all the time. \nI'd like to hide the Rew/Play/FF buttons from Rhythmbox when the application is inactive.  \nThank you for your help. \n\nA: Sound indicator, with no active player (launchers only, no control buttons)\n\nSound indicator, with active player (full control buttons)\n\n\n15.10\nHave same build steps as 14.04.\n\n\n*\n\n*Remove player from menu after close\nModify src/service.vala for desktop menu to HIDE_INACTIVE_PLAYERS.\nthis.menus.insert (\"desktop\", new SoundMenu (\"indicator.desktop-settings\", SoundMenu.DisplayFlags.SHOW_MUTE|SoundMenu.DisplayFlags.HIDE_INACTIVE_PLAYERS));\n\nAnd modify src/sound-menu.vala for add_player function to remove_player_section if it is not running & hide inactive is set.\npublic void add_player (MediaPlayer player) {\n    if (this.notify_handlers.contains (player))\n        return;\n\n    if (player.is_running || !this.hide_inactive)\n            this.insert_player_section (player);\n        else         \n            this.remove_player_section (player);\n    this.update_playlists (player);\n\n\n*Hide player controls (Prev/Play/Next) from menu after close, keep only its launcher\nSame as 14.04, no change.\n\n14.04\n\n\n*\n\n*Download build dependencies and source\nsudo apt-get build-dep indicator-sound\napt-get source indicator-sound\n\n\n*Choose the behavior you want: \n\n\n*\n\n*Remove player from menu after close\nModify src/service.vala for desktop menu.\nthis.menus.insert (\"desktop\", new SoundMenu (\"indicator.desktop-settings\", SoundMenu.DisplayFlags.SHOW_MUTE | SoundMenu.DisplayFlags.HIDE_INACTIVE_PLAYERS));\n\nI added | SoundMenu.DisplayFlags.HIDE_INACTIVE_PLAYERS, You can remove SoundMenu.DisplayFlags.SHOW_MUTE | if you want hide volume control with muted players.\n\n*Hide player controls (Prev/Play/Next) from menu after close, keep only its launcher\nModify src/sound-menu.vala\n\n\n*\n\n*Add new flag HIDE_INACTIVE_PLAYERS_CONTROLS = 128 with , in end of previous line.\npublic enum DisplayFlags {\n    NONE = 0,\n    SHOW_MUTE = 1,\n    HIDE_INACTIVE_PLAYERS = 2,\n    HIDE_PLAYERS = 4,\n    HIDE_INACTIVE_PLAYERS_CONTROLS = 128\n}\n\n\n*Add bool hide_inactive_controls; variable to hold flag status\nbool hide_inactive;\nbool hide_inactive_controls;\nbool hide_players = false;\n\n\n*Add this.hide_inactive_controls =... line. to pass SoundMenu constructor flag parameter to its variable.\nthis.hide_inactive = (flags & DisplayFlags.HIDE_INACTIVE_PLAYERS) != 0;\nthis.hide_inactive_controls = (flags & DisplayFlags.HIDE_INACTIVE_PLAYERS_CONTROLS) != 0;\nthis.notify_handlers = new HashTable<MediaPlayer, ulong> (direct_hash, direct_equal);\n\n\n*Add if (player.is_running || !this.hide_inactive_controls) { and }. to wrap instructions which create (prev/play/next) in menu item. So they are not created only if player is running or hide flag is inactive. \nif (player.is_running || !this.hide_inactive_controls) {\n    var playback_item = new MenuItem (null, null);\n    playback_item.set_attribute (\"x-canonical-type\", \"s\", \"com.canonical.unity.playback-item\");\n    playback_item.set_attribute (\"x-canonical-play-action\", \"s\", \"indicator.play.\" + player.id);\n    playback_item.set_attribute (\"x-canonical-next-action\", \"s\", \"indicator.next.\" + player.id);\n    playback_item.set_attribute (\"x-canonical-previous-action\", \"s\", \"indicator.previous.\" + player.id);\n    section.append_item (playback_item);\n}\n\n\n*Add if (this.hide_inactive_controls) { to next }. To force player menu section recreation when player is-running state changes.\nvar handler_id = player.notify[\"is-running\"].connect ( () => {\n    if (this.hide_inactive) {\n        if (player.is_running) {\n            this.insert_player_section (player);\n        }\n        else {\n            this.remove_player_section (player);\n        }\n    }\n    if (this.hide_inactive_controls) {\n        this.remove_player_section (player);\n        this.insert_player_section (player);\n    }\n    this.update_playlists (player);\n});\n\n\n*Finally, modify src/service.vala. Add our new created flag | SoundMenu.DisplayFlags.HIDE_INACTIVE_PLAYERS_CONTROLS to desktop menu.\nthis.menus.insert (\"desktop\", new SoundMenu (\"indicator.desktop-settings\", SoundMenu.DisplayFlags.SHOW_MUTE | SoundMenu.DisplayFlags.HIDE_INACTIVE_PLAYERS_CONTROLS));\n\n\n\n\n*Build and install\ncd indicator-sound-12.10.2+14.04.20140313/\nmkdir build\ncd build/\ncmake ..\nmake\nsudo make install\n\nNow, the players will disappear after closing them.\n\n12.04\n\n\n*\n\n*Download build dependencies and source\nsudo apt-get build-dep indicator-sound\napt-get source indicator-sound\n\n\n*Modify src/player-controller.vala, Replace \"rhythmbox.desktop\" with \"xrhythmbox.desktop\" in the two occurrences. (just different name)\n\n*Build and install\ncd indicator-sound-0.8.5.0/\n./configure\nmake\nmake install\n\nNote: That was a quick trick, the correct way may be:\n\n\n*\n\n*Replace\n  this.custom_items[widget_order.TRANSPORT].property_set_bool (MENUITEM_PROP_VISIBLE,\n                                                          this.app_info.get_id() == \"rhythmbox.desktop\"); \n\nwith\n  this.custom_items[widget_order.TRANSPORT].property_set_bool (MENUITEM_PROP_VISIBLE,\n                                                          false); \n\n\n*and\nif (this.app_info.get_id() == \"rhythmbox.desktop\"){\n  TransportMenuitem transport = this.custom_items[widget_order.TRANSPORT] as TransportMenuitem;\n  transport.handle_cached_action();\n}\nelse{\n  this.custom_items[widget_order.TRANSPORT].property_set_bool (MENUITEM_PROP_VISIBLE,\n                                                           true);         \n}\n\nwith\nthis.custom_items[widget_order.TRANSPORT].property_set_bool (MENUITEM_PROP_VISIBLE,\n                                                           true);\n\n", "Q: Create \"virtual\" LAN on laptop (not VLAN) I'm running a number of virtual machines on a Ubuntu 12.04 host. For various reasons all these VMs need fixed IP addresses. The laptop in question is used for demonstrations -- and this is where the problems arise...\nDepending on the circumstances I will either use WiFi or a mobile tether to get an internet connection, which in both cases leads to the laptop being assigned an address via DHCP. Frequently this dynamic address is on a different subnet to the one used by the fixed ones (192.168.0/20). This makes the static addresses unreachable from the host OS.\nAfter some thought, it seems the most elegant solution is to create a separate LAN on the host (for the subnet used by the VMs) and then bridge it to whatever subnet is assigned to the host.\nBear in mind the VM's only need to communicate with each other and the host. They do not need access beyond that.\nQuestions:\n\n\n*\n\n*is this the best approach?\n\n*if, it is how could I go about implementing it?\n\n\nMany thanks. \n\nA: If you're using VMware all you need to do is assign these virtual machines to a virtual LAN that has not connection with VMware itself nor the host machine. This is called \"LAN segments\" and it's easy to find under the Network Interface settings of each  machine.\nAll you have to do is create a new LAN segment for the first machine,  then add the other ones to the same network:\n\nThis is similar to the host-only network but with the difference that machines can't contact the hosts nor other external networks (Internet) so it's like having a LAN with those machines only. Since there's not a DHCP server in this network, you'll have to add the IP's manually in each system.\nIf you want them to communicate with the host, you need the host-only setting. In this case, the host will have the lower IP, since it will act as a gateway (but without forwarding packets to other networks).\n\nA: Any type 2 hypervisor will be already having virtual networks of multiple types (bridged, host only, internal network).\nBridged: VM will be attached to your physical NIC as your host do, and will acquire IP from DHCP -if enabled.\nHost only: VM can only communicate with HOST and not beyond that (Option should have been enabled when you were installing VMWare Workstation)\nmore details Here\n-NAT : VMs will be natted to your host IP and will communicate beyond host through its IP.\n\nA: When you install the metapackage apt-get install ubuntu-virt, you'll have a NATed bridge called virbr0 right on your Desktop, which all your KVM Virtual Machines will be attached to, so, I think that this will be enough for you...\nYou'll probably need the virt-manager too.\n", "Q: How to make Ubuntu honor \"ignore-hosts\" proxy settings for IPv6? I just typed under \"dconf-editor\", System → Proxy → ignore-hosts, the following content:\n['localhost', '127.0.0.0/8', '::1', '192.168.0.1', '2000::/3', 'fc00::/8']\n\nBut, Google Chrome (and apt-get update / upgrade) is just ignoring this settings.\nEDITED: Also, Firefox doesn't honor the ingore-hosts settings, even configuring it to \"Use system proxy settings\".\nFor example, my Proxy Server (Ubuntu with Squid3) is in dual-stacked mode BUT, I do NOT want to access IPv6 web sites through the Proxy, that's why I'm trying to ignore the entire IPv6 Internet with the entry 2000::/3, but, it does not work as expected.\nEDITED: Also, I don't need the proxy to access Hyperboria sites, which resides under fc00::/8 but, it doesn't work either...\nWhy I'm doing this?\nBecause my environment is already a IPv6-Only Network and, to access the old internet infrastructure (IPv4-Only), I need to go through the dual-stacked proxy. But I need the proxy only when a web site doesn't have IPv6...\nHow can I know that it doesn't work?!\nIt is simple, just access a web site that shows a IPv6 address on it, for example, http://www.sixxs.net or http://ipv6.whatismyv6.com, then, I'm still seeing the IPv6 address of the Proxy Server, so, \"ignore-hosts entry '2000::/3'\" doesn't seem to be working.\nEDITED: Plus, when I'm trying to access a Hyperboria website, Squid returns an error that it can not reach fc00::/8 network\n\n(Squid ERROR: (101) Network is unreachable)\n\n(of course it can't, the cjdns router is running right on my Ubuntu Desktop, so, no need to go through proxy when browsing Hyperboria fc00::/8 but, Ubuntu isn't honoring ignore-hosts under proxy settings.\n\nA: It looks like this won't work with Gnome proxy settings. The ignore-hosts setting works for hostnames, addresses and address ranges, but apparently does not resolve hostnames before checking against addresses.\nFrom the ignore-hosts documentation (emphasis by me):\n\nAlso note that hostname exclusions apply only to connections made to\n  hosts identified by name, and IP address exclusions apply only to\n  connections made to hosts identified by address. That is, if\n  example.com has an address of 192.168.1.1, and the :ignore-hosts list\n  contains only \"192.168.1.1\", then a connection to \"example.com\" (eg,\n  via a GNetworkAddress) will use the proxy, and a connection to\n  \"192.168.1.1\" (eg, via a GInetSocketAddress) will not.\n\n\nA: I don't know how to make Ubuntu obey that setting, but there might be workarounds:\n\n\n*\n\n*APT follows  settings in /etc/apt/apt.conf or the environment variables (such as http_proxy). The man pages for apt.conf don't mention dconf settings, so I think apt doesn't check them. To specify sites for which apt should ignore proxy, add to /etc/apt/apt.conf:\nAcquire::http::Proxy::<hostname/ip> DEFAULT;\n\nI think this can't be done for ranges or subnets, and you'll need an entry for each host to exclude.\n\n*Chrome honours the no_proxy environment variable, so one might try using that:\nno_proxy=localhost,127.0.0.0/8,::1,192.168.0.1,2000::/3,fc00::/8 google-chrome\n\nDefine no_proxy in /etc/environment to ensure its availability everywhere. Other programs are known to honour this variable too.\n\n*Lastly, you might consider running two squid servers. The new one will use your current one as a parent, but only for certain hosts, using the allow_direct/never_direct settings. Then set the new one as the proxy server everywhere (/etc/apt/apt.conf, /etc/environment, the dconf entries). I don't know much about dual stack networking, so I don't know if this would work, but it's worth a mention.\n\n\nI don't use dual stack networking, but since I am behind a campus proxy, I have to juggle proxy settings, and I find that the last option is best. Let squid do the juggling.\n\nA: For Google Chrome and Chromium you can create a machine wide policy file.  \nLinux Chrome Administrator Quick Start Guide\nHere are various proxy settings and descriptions from the Policy Template:\n// Proxy bypass rules\n  //-------------------------------------------------------------------------\n  // Google Chrome will bypass any proxy for the list of hosts given here.  This\n  // policy only takes effect if you have selected manual proxy settings at\n  // 'Choose how to specify proxy server settings'.  You should leave this\n  // policy not set if you have selected any other mode for setting proxy\n  // policies.  For more detailed examples, visit:\n  // http://www.chromium.org/developers/design-documents/network-settings#TOC-\n  // Command-line-options-for-proxy-sett\n\n  //\"ProxyBypassList\": \"http://www.example1.com,http://www.example2.com,http://internalsite/\",\n\n  // Choose how to specify proxy server settings\n  //-------------------------------------------------------------------------\n  // Allows you to specify the proxy server used by Google Chrome and prevents\n  // users from changing proxy settings.  If you choose to never use a proxy\n  // server and always connect directly, all other options are ignored.  If you\n  // choose to use system proxy settings or auto detect the proxy server, all\n  // other options are ignored.  If you choose fixed server proxy mode, you can\n  // specify further options in 'Address or URL of proxy server' and 'Comma-\n  // separated list of proxy bypass rules'.  If you choose to use a .pac proxy\n  // script, you must specify the URL to the script in 'URL to a proxy .pac\n  // file'.  For detailed examples, visit: http://www.chromium.org/developers\n  // /design-documents/network-settings#TOC-Command-line-options-for-proxy-sett\n  // If you enable this setting, Google Chrome ignores all proxy-related options\n  // specified from the command line.  Leaving this policy not set will allow\n  // the users to choose the proxy settings on their own.\n\n  //\"ProxyMode\": \"direct\",\n\n  // URL to a proxy .pac file\n  //-------------------------------------------------------------------------\n  // You can specify a URL to a proxy .pac file here.  This policy only takes\n  // effect if you have selected manual proxy settings at 'Choose how to specify\n  // proxy server settings'.  You should leave this policy not set if you have\n  // selected any other mode for setting proxy policies.  For detailed examples,\n  // visit: http://www.chromium.org/developers/design-documents/network-settings\n  // #TOC-Command-line-options-for-proxy-sett\n\n  //\"ProxyPacUrl\": \"http://internal.site/example.pac\",\n\n  // Address or URL of proxy server\n  //-------------------------------------------------------------------------\n  // You can specify the URL of the proxy server here.  This policy only takes\n  // effect if you have selected manual proxy settings at 'Choose how to specify\n  // proxy server settings'.  You should leave this policy not set if you have\n  // selected any other mode for setting proxy policies.  For more options and\n  // detailed examples, visit: http://www.chromium.org/developers/design-\n  // documents/network-settings#TOC-Command-line-options-for-proxy-sett\n\n  //\"ProxyServer\": \"123.123.123.123:8080\",\n\n  // Enable or disable PIN-less authentication\n  //-------------------------------------------------------------------------\n  // If this setting is enabled or not configured, then users can opt to pair\n  // clients and hosts at connection time, eliminating the need to enter a PIN\n  // every time.  If this setting is disabled, then this feature will not be\n  // available.\n\n\nA: On GNOME Shell 42.3.1, for IPv4 and IPv6 I notice Firefox v107 ignore Ignored hosts (gsettings get org.gnome.system.proxy  ignore-hosts; maybe due this bug). I have to added again on Firefox on No proxy for:\n\n", "Q: How can I know what programs some apt-get package contains? I would like to know what some specific package installs, for example, when installing ncurses, I have found that TAB key expands:\nsudo apt-get install ncurses-\n\nto show:\nncurses-base      ncurses-doc       ncurses-hexedit\nncurses-bin       ncurses-examples  ncurses-term\n\nHow could I know what, say, ncurses-term installs? I am interested mainly in programs, but libraries and any other filetypes could be useful too.\nCommand-line method, if possible, would be preferred (any others accepted too).\n\nA: You could use apt-file:\nsudo apt-file update        \napt-file list package_name\n\n\nA: There's a possibility using your browser (therefore not requiring access to a APT-system). For example, to list the file contents of package \"ncurses-term\", just type\nhttps://packages.debian.org/wheezy/all/ncurses-term/filelist\ninto your browser's address bar (replace \"wheezy\" as needed) for Debian or\nhttp://packages.ubuntu.com/saucy/all/ncurses-term/filelist\nfor Ubuntu (replace \"saucy\" as needed).\n\nA: Here are a few options, these will list all the files installed by a package:\nA. Listing all files included in a package\n\n\n*\n\n*For installed packages\ndpkg -L ncurses-term\n\n\n*For all packages, installed or not\napt-file -F list ncurses-term\n\nThe -F turns of pattern matching so that only packages whose exact name matches are returned. You may need to install apt-file with sudo apt-get install apt-file and then update its database with sudo apt-file update.\nB. Listing only executable files included in a package\n\n\n*\n\n*For installed packages\nJust install dlocate (sudo apt-get dlocate) and run:\ndlocate -lsbin ncurses-term \n\nAs explained in man dlocate:\n\n-lsbin List  full  path/filenames of executable files (if any) in package\n\nIf you don't want to install additional packages, you can do this manually. Just collect the list of files and find any among them that have the executable bit set:\napt-file -F list ncurses-term | cut -d ' ' -f 2 | \n    while read file; do [[ -x $file && -f $file ]] && echo \"$file\"; done\n\nThe little scriptlet above will print the path only (cut -d ' ' -f 2) and then pass it through a while loop that checks if the file is executable (-x $file) and if it is a regular file, no directories or symlinks (-f $file) and prints its name only if passes both tests. \n\n*For all packages, installed or not\nThere is no way I know of to list only executables included in an uninstalled package. However, since most executables are installed to bin directories, you can get most of them by parsing the output:\n apt-file -F list ncurses-term | grep -Ew \"bin|sbin\"\n\nThe -w option matches entire words, so you don't get things installed in, for example, trashbin or whatever.\n\nNOTE: None of the above commands will produce any output for ncurses-term but that is because this package installs no executable files. The commands work nevertheless, try with a different package.\n", "Q: bootstrap fails with Windows Azure: XML Schema validation error in network configuration I am trying to test Juju with Windows Azure. I always get this error: \nPUT request failed: BadRequest - XML Schema validation error in network configuration\n\nI have tried several times, with and without --update-tools parameter, always the same issue.\nThe admin certificate is uploaded correctly. The juju-azure-private is create inside the windows azure storage and it has new files uploaded.\nAny idea?\n\nA: We have seen this error in the past, but not for a while now. The Azure provider has seen various fixes recently, and I'm pretty sure this particular one is no longer an issue. See: https://bugs.launchpad.net/juju-core/+bug/1304778\n", "Q: Making more off forever in Octave Octave by default uses the \"more\" command to page results. It is possible to type \"more off\" to stop that in the current session. How can I stop it permanently without passing that command to Octave? (I want something like option, editing file, environment variable,...)\n\nA: The answer is given in the documentation about startup files and the more command. You just need to run more off on startup. To do this you can create the file .octaverc (the dot is important) in your home directory (~/.octaverc) and add the more off command to it. Now Octave should always start with more switched off.\n(There's also the file /usr/share/octave/site/m/startup/octaverc if you have more than one user on the computer who want this configuration.)\n", "Q: Minimalistic Ubuntu install without desktop for USB I'm looking for a Ubuntu installation that runs from a USB flash drive. I do not want a desktop, all I need is a shell. It should be as small and fast as possible.\nI currently work with Debian on a CubieBoard (cubian) and I really like it. I now bought a new system which has an intel CPU & a nVidia GPU. I was advised to switch to Ubuntu for better driver support.\nIs there such an ISO image for USB? or maybe a way to create it myself (with limited Linux knowledge)?\nThanks in advance for your time!\n\nA: Have you tried installing one of the minimal Ubuntu iso's? \nYou can find them here:\n\n\n*\n\n*MinimalCD\nThat way you can pick and choose exactly what features you want when installing.  I've successfully installed one of these on a USB that runs on a thin client with just 128Mb RAM (with a blackbox wm)\n", "Q: Ubuntu 64bit or 32bit We have a Advent PC that has 2GB of RAM and a 2.20GHz (I can list full specs if needed) 64bit CPU, on Ubuntu's website it says if you have 2GB of RAM or less install the 32bit version; but couldn't we benefit if we installed Ubuntu 64bit? That way the OS could take advantage of the CPUs 64it instruction set. Any answer would be appreciated.\n\nA: If you have a 64 bit CPU you can install a 64 bit version.\nThe 32 bit version of Ubuntu needs only 512MB RAM, the 64 bit version will need a minimum of 1024MB RAM. Since you have 2024MB RAM (2GB) you can install the 64 bit version on the 64 bit processor.\n\nA: If you Installed Latest ubuntu 13.10 64 bit and get into any trouble just get the previous version (e.g 12.04 or earlier) those version deal with less RAM and your computer will be fine  \n", "Q: Wireless does not work (ubuntu 13.04) I'm new to linux and installed Ubuntu 13.04 32bit on an older Dell Inspiron E1705 laptop. Both the wireless and wired ethernet connections are not recognized. I would appreciate any help getting either working but wireless would be the most useful. The WLAN card is a Broadcom BCM4311 b/g internal card. Please help Ubuntu power users, you are my only hope!\n\nA: Please hook up the ethernet and open a terminal and do:\nsudo modprobe b44\n\nYour ethernet should now be working. Now do:\nsudo apt-get purge bcmwl-kernel-source\nsudo apt-get install firmware-b43-installer\n\nDetach the ethernet, reboot and both should now be working. If it is not yet working, please do:\nsudo apt-get purge bcmwl-kernel-source\n\nReboot. If it is still not working, look for clues here:\nrfkill list all\ndmesg | grep -e b44 -e eth0\n\nThe driver b44 is correct for your ethernet device. Your system shouldn't hang loading the correct driver. Please run:\ndmesg > wifi.txt\nlsmod >> wifi.txt\n\nFind the file wifi.txt in your user directory and transfer it on a USB drive or similar and paste it here: http://paste.ubuntu.com Give us the link in your reply.\n\nA: Other useful steps for the accepted answer.\nLinks to .deb packages for Ubuntu 13.04 / Raring:\nhttp://packages.ubuntu.com/raring/i386/linux-firmware-nonfree/download\nhttp://packages.ubuntu.com/raring/i386/b43-fwcutter/download\nhttp://packages.ubuntu.com/raring/kernel/firmware-b43-installer \nThen:\nsudo dpkg -i each_downloaded_package\n", "Q: recover from rescue mode I have installed windows 8 then linux in dual boot in my laptop.  Windows installed on C drive and linux on D drive.\nOne day extremly I have format the linux drive D dtive from windows it was the succesful operation but after reboot the windows i have got the grub> window and I can't do anything  and I don't have any cd of llinux or windows to boot from it , so any body please tell me how to remove it .?\nI don't have knowledge about grub so I didn't try any thing..\nThere is no menu fo 'c' and when i type \nroot (hd0,0)\nit says \"file system type unknown, partition type 0x7.\nI formated the D drive in NTFS which contains linux data that is the reson of it.\n\nA: At the grub prompt (if it gives you a menu, hit 'c' first), I believe you can type:\nroot (hd0,0)\nmakeactive\nchainloader --force +1\nboot\n\nThat should get you back into windows. You may need to use the 'ls' command at the prompt to figure out which hd you need.\nOnce in windows, open an elevated command prompt, and issue the following commands:\nbootrec /fixmbr\nbootrec /fixboot\n\nAfter this, you should be able to boot back into windows normally.\n", "Q: How to track software usage Is it possible (preferably via some package) to know how many times have I used software? All software. And maybe for how long? Also when was it last opened. The more provided info the better.\nIt's also preferable to get the output in a GUI.\n\nA: Zeitgeist is exactly what this is for. It is available from the Ubuntu Software Center and has been covered many times by OMGUbuntu.\n", "Q: CryptoSLAX with Qualcomm Atheros Killer E2200 As many people, I am a newbie on Linux but found CryptoSLAX an amazing tool for cryptomining.\nI am currently trying to make my ethernet cards from my mobo MSI Z87G45 Gaming to work on CryptoSLAX, but because I am very, very stupid on Linux, I would like to perhaps have a little help from one of the enlightening Linux guys to get me to make this card to work.\nThe card is a Qualcomm Atheros Bigfoot Killer E2200.\nSo, what to do?\nmany thanks\nSODERI\n\nA: There are currently no linux drivers for the Bigfoot Networks onboard Ethernet (Killer Series).\nI take it you have a Gigabyte G1 board, probably LGA1366?\nI have a G1.Guerrilla that I tried to use before.\nIt will not work.\nHead on over to your local computer shop and pick up a cheap PCI ethernet card.\nThat's the only option you have.\n", "Q: How come the contents of Text elements aren't being properly justified? Consider the following page in a QML application:\nPage {\n    Text {\n        anchors.fill: parent\n        anchors.margins: units.gu(2)\n        horizontalAlignment: Text.AlignJustify\n        text: \"aaaaaa aaaaaa aaaaaa aaaaaa aaaaaa aaaaaa aaa aaa aaa aaa aaa aaa aaa aaa.\"\n        wrapMode: Text.WordWrap\n    }\n}\n\nI expect that the contents of the Text element would be justified but this is clearly not the case:\n\nAs you can see, the first line is not justified as it should be. What am I doing wrong?\n\nA: I ran your qml snippet in this qml file on Ubuntu 13.10:\nimport QtQuick 2.0\nimport Ubuntu.Components 0.1\n\n\nMainView {\n    id: main\n    width: units.gu(30)\n    height: units.gu(35)\n\n    Page {\n        Text {\n            anchors.fill: parent\n            anchors.margins: units.gu(2)\n            horizontalAlignment: Text.AlignJustify\n            text: \"aaaaaa aaaaaa aaaaaa aaaaaa aaaaaa aaaaaa aaa aaa aaa aaa aaa aaa aaa aaa.\"\n            wrapMode: Text.WordWrap\n        }\n    }\n}\n\nAnd I can say that it works perfectly, the text is properly justified:\n\n", "Q: Install older version of software and dependencies I need to install R 3.0.2 because a needed library isn't compatible with 3.0.3 yet (the latest). \nI can install the older version of R like so:\nsudo apt-get install r-base=3.0.2-1precise0\n\nHowever all the dependencies of r-base try and install with 3.0.3\nroot@foo:~# apt-get install r-base=3.0.2-1precise0\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n r-base : Depends: r-recommended (= 3.0.2-1precise0) but 3.0.3-1precise0 is to be installed\nE: Unable to correct problems, you have held broken packages.\n\nHow can I install r-base 3.0.2 and all the dependencies as 3.0.2 ? \n\nA: *\n\n*First remove the packages\nsudo apt-get remove r-base\n\n\n*A bit of cleaning\nsudo apt-get clean; sudo apt-get autoclean\n\n\n*Reinstall R forcing an older version\nsudo apt-get install r-base=3.0.2-1precise0\n\n\nA: You can downgrade packages by simply installing over the top. apt is smart enough to handle this properly. \nTo install R 3.0.2 I ran dpkg -S /usr/bin/R and found that the binary was provided by r-base-core. Downgrading that fixed the issue\napt-get install r-base-core=3.0.2-1precise0  \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages were automatically installed and are no longer required:\n  r-cran-foreign ...\nUse 'apt-get autoremove' to remove them.\nSuggested packages:\n  ess r-doc-info r-doc-pdf r-mathlib\nThe following packages will be REMOVED:\n  r-base r-cran-class r-cran-cluster r-cran-kernsmooth r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme r-recommended\nThe following packages will be DOWNGRADED:\n  r-base-core\n0 upgraded, 0 newly installed, 1 downgraded, 9 to remove and 123 not upgraded.\nNeed to get 21.5 MB of archives.\n\n\napt-get install r-base=3.0.2-1precise0\n...\napt-get install r-recommended=3.0.2-1precise0\n...\n\n\nA: Disable \"Universe\" repository from software and updates and then run the below commands on terminal,\nsudo add-apt-repository ppa:marutter/rdev\nsudo apt-get update \nsudo apt-get install r-base\n\n", "Q: Lenovo Battery threshold on Z570 still not working; even with tlp I tried following the tlp stuff in this manual, but still when I watch the battery status, it still gets charged even after the Stop Threshold is set at 60% and the battery is at 99%\nDoes it even work for IdeaPads?\n\nA: after some attempts to set up the charging thresholds on ubuntu for my ideapad u330 I can tell you that it won't work for ideapads. tlp needs additional kernel modules to do this, either \"tp-smapi-dkms\" or \"acpi-call-tools\" (http://thinkwiki.de/TLP_-_Linux_Stromsparen#Ubuntu_12.04_bis_13.10 [link is in german]), both of which only work for certain thinkpads, not ideapads.\nwhat eventually did the trick for me though was using the preinstalled win8 on my laptop (which I still have as a dual-boot backup) and set the thresholds there using the \"Lenovo Energy Manager\" software. Those changes affect the battery on a sub-OS level, so they also work on Ubuntu. It is a shame that we have to rely on Windows here, but that's what it is when Hardware companies have crappy Linux support.\n", "Q: Oracle Java Virtual Machine install? I cant get it install and I need it running for a job application i need to put in online. \njre-7u51-linux-i586.tar.gz\n\nthat's the file and every time I try to install it wont complete, says cannot find file. \n\nA: If you want to have Java 7, follow this:\nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java7-installer oracle-java7-set-default\n\nOracle java is better than the openjdk in terms of performance IMO\n\nA: You can use \nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-jdk7-installer\n\nThis will install Oracle JVM and will update it when needed.\nBut if you want to install JVM manually, you should use these commands:\ntar -xzf jre-7u51-linux-i586.tar.gz\nsudo mv jre1.7.0_51/ /usr/lib/jvm/jre1.7.0_51\n\nThen run\nsudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jre1.7.0_51/jre/bin/java\n\nand\n$ sudo update-alternatives --config java\nThere are 3 choices for the alternative java (providing /usr/bin/java).\n\n  Selection    Path                                       Priority   Status\n--------------------------------------------------------------------------------\n* 0            /usr/lib/jvm/java-6-openjdk/jre/bin/java    1061      auto mode\n  1            /usr/lib/jvm/ia32-java-6-sun/jre/bin/java   63        manual mode\n  2            /usr/lib/jvm/java-6-openjdk/jre/bin/java    1061      manual mode\n  3            /usr/lib/jvm/java-6-sun/jre/bin/java        63        manual mode\n  4            /usr/lib/jvm/jre1.7.0_51/jre/bin/java       4         manual mode  \n\nPress enter to keep the current choice[*], or type selection number:\n\nFollow the instructions on screen. Your numbers would be quite different from mine.\n\nA: Now the commands should be:\nsudo add-apt-repository ppa:webupd8team/java\nsudo apt-get update #(skip this line for Ubuntu 18.04)\nsudo apt-get install oracle-java8-installer\n\noracle-java8-set-default will be installed automatically on Ubuntu. For other OSes, the last line should be\nsudo apt-get install oracle-java8-installer oracle-java8-set-default\n\n\nA: The sudo apt-get procedures don't currently work due to changes at Oracle. @Danatela had the best answer that worked for me. There is only one change to using his sudo update-alternatives --install command. \nThe command should include a priority value at the end so is looks like --install <link> <name> <path> <priority>\nI updated the current JDK (complete file is jdk-12.0.2_linux-x64_bin.tar.gz) in the following command:\nsudo update-alternatives --install /usr/bin/java java /usr/lib/java/jdk-12.0.2_51/bin/java 1\nwhere link = /user/bin/java, name = java, path = /usr/lib/java/jdk-12.0.2_51/bin/java, and priority = 1 (auto)\n", "Q: How to get Windows data back I reinstalled Ubuntu few months ago. By accident I chose to install Ubuntu without Windows (I had dual boot operating systems before that). \nThis is a disaster! I lost all my data in Windows and lost the operating system as well. \nDo you know if I can recover my operating system? Bring Windows back to the laptop, or at least recover those data files in Windows? \n\nA: You won't be able to get Windows back as a functional system. Or at least, it's too unlikely to even attempt. However, you have good chances of finding your files. You might want to have a look at the testdisk package for a utility called photorec. It's very good and not too difficult to use, although you should read up before using it. \n", "Q: Doesn't Ubuntu 13.10 support the hostapd nl80211 driver? I could use hostapd-2.1 to set wireless AP in Ubuntu 12.04.\nBut in Ubuntu 13.10 it failed. The same source code for hostapd-2.1 was failing\nin 13.10.\nThe error message:\nnl80211 : Failed to set wlan0 as Ap\nnl80211 : driver initialization failed\n\nWhat should I do to modify hostapd-2.1 to work on Ubuntu 13.10?\n\nA: It appears that in the new hostapd (2.0+) that is on the ubuntu 13+ versions is now stopping on an error that it used to ignore.\n(from https://stackoverflow.com/a/22845597/3495026 )\nIf one turns off the programs that are accessing the resource, hostapd has a chance to grab it and work.\nIn Ubuntu desktop 14.04 beta, a solution is to turn off the programs that are using the wlan in question.\nThis worked for me:\nsudo nmcli nm wifi off\nsudo rfkill unblock wlan\n\nthen hostapd can start normally from command line. Of course, if you want hostapd to start on boot you must insure that the network manager is not grabbing the resource ahead of time.\n", "Q: Is any antivirus required in Ubuntu to use credit cards online -- suggestion needed Hope you are doing well.\nI know this topic has been answered in details in one thread - Do I need to have 'antivirus software' installed? \nBut I am still little confused, the only thing that I use Windows 7 for now is for paying bills with credit cards. \nMy credit card was once hacked, so I guess I am a little paranoid.\nI would really appreciate, if someone tell me if I need to install anti viruse in Ubuntu, and if yes, what I should go for?\nAny help will be earnestly appreciated.\nRegards\n\nA: Reasons FOR antivirus on Ubuntu:\n\n\n*\n\n*You are running a file or mail server with Windows clients.\n\n*You wish to scan files before transferring them, by email, flash drive, etc., to a Windows machine\".\n\n\nHere is the great information about security.\n", "Q: What are the possible threats if internal IP address is publicly revealed? In many cases, people do not take enough care to remove their IP addresses from some output before posting it to help forums and Q&A sites like askubuntu.\nConsidering one's IP address is revealed publicly, what are the possible threats he/she/bot may face and what can one do to avoid them?\nAlso, is there any threat in revealing other data like Broadcast address, Subnet mask, Default route, Primary DNS and Secondary DNS ?\nOf course we will consider that the person/bot is using a supported version of Ubuntu or it's official derivatives. \n\nA: Some qualifications to terdon's answer about public IPs.\nA public IP for most people these days is actually the IP of their router, not a computer. That may go on to give people access to other stuff on your computer and network but it's a layer of resistance. Most routers won't let people through by default so you're relying on the straight security  of that.\nAdditionally, many people's public IPs rotate around between customers at their ISP. This is exactly to prevent this sort of targeted attack. A customer might rotate around hundreds of thousands of IPs, or more.\nIn short, direct attacks for an IP address you posted probably aren't going to be any more a problem than the waves of automated scans hackers already do.\n\nBut an IP address isn't just a number. You can whois an IP to learn who owns it. Depending on the sort of network this provides:\n\n\n*\n\n*Country (usually correct)\n\n*ISP or network owner\n\n*Location of the network owner. Only a problem if you're in the same building (eg it's your corporate network, or a hotel or something)\n\n\nYou can also get a very approximate location via advertising networks.\nYou might be able to use this sort of information with the context it was posted, past posts, links to other profiles, random Wayback-logged content saying where you went to school. Deep digging information like this can be dangerous, but how much of that is really relevant to the IP address you posted when you posted it?\nI guess that really depends who's after you.\n\nA: Giving out your public IP address simply makes you a target. It is like posting your email address. Malicious people will then be able to use your IP and target your computer. Whether they will be successful or not depends on the way you've set up your machine but in any case, the first step will be getting your public IP.\nNow, posting your internal IP, is not dangerous at all. For example, my current internal IP is 192.168.0.37. There are certainly thousands of computers all over the world that are connected to their local LAN using the exact same IP. Internal IPs are just that, internal, they have absolutely no meaning outside your own network and sharing them is not dangerous.\nThe same goes for the rest. All of the information you mention is specific to your local network (assuming you mean the broadcast address of your internal IP, not the public one) and there is no danger in sharing them whatsoever. In fact, please make sure to use real addresses when you ask questions since they can help us understand where the error lies.\nIn summary, you don't really want to share your public IP or the MAC address of your network card but internal IPs, broadcast address, subnet mask, default route (that's just the internal IP of your router) and DNS servers can be shared with no risk. DNS servers are public anyway and all the rest are internal to your local network and have no meaning outside it.\n", "Q: Server unexpectedly closed So I know that similar veins to this topic have been posted, but mine specifically deals with the fact that my SSH login through Putty worked from my desktop and my laptop. \nHowever, after carrying out some steps to secure it, my laptop can still gain access through SSH but my desktop kicks me out and says:\n\nServer unexpectedly closed network connection \n\nThe fact that I can still connect from one and not the other means that the port is fine, but what firewall feature is causing this issue? I am using 12.04. I have uninstalled Fail2Ban and DenyHosts as a test, and this didn't fix the problem. The port is open, I have checked.\n\nA: You can try to remove known_host from desktop\nPutty stores known hosts under a registry key: HKEY_CURRENT_USER\\SoftWare\\SimonTatham\\PuTTY\\SshHostKeys\nAfter removing try to connect\n", "Q: Installing Ubuntu while dealing with partitions (Windows XP) I want to switch over to Ubuntu from XP. I looked at my C: drive and noticed that it is divided into 3 sections: my antiquated floppy drive (at least, I think that is correct), the C drive, and an unknown partition of 3GB.\nMy question is, do I need to remove the partition to free up the 3GB (which is FAT32)? I am not a techie, though I wish I was. Are there any simple instructions to deal with this?\nWill Ubuntu just write over the unknown partition, or is that wishful thinking? I was considering installing Ubuntu beside XP, but that might be problematic.\n\nA: Please Notice this action will delete all your files and partitions and you will loose windows XP so please make a  backup of your important files before doing this\nYou can boot using the ubuntu live installer (either by DVD or USB).\nthen wait until Ubuntu Live loads up.\nRun Gparted, then right click on the partitions and click delete.\nrepeat this steps for all partitions that is not needed. (in your case I think there will be two partitions: 1- your main C drive and another is the unknown 3GB)\nonce you have completed this click on apply changes.\nwait for a while.\nand then install Ubuntu by clicking on the installer on the top left of the screen. (Assuming you want to use 13.10)\nif you want to have a dual boot system then the story is different (Slightly different):\nyou can follow this tutorial for dual booting:\nhttps://sites.google.com/site/easylinuxtipsproject/installation\n", "Q: How to change plymouth in ubuntu 13.10 I installed ubuntu 13.10 and I want to change the plymouth.\nI tried using these commands but it did not work  \nsudo add-apt-repository ppa:mefrio-g/plymouthmanager\nsudo apt-get update\nsudo apt-get install plymouth-manager\n\nPlease help me to solve this problem I want to add my own custom boot screen. \n\nA: The PPA you are using is outdated. If you want to use this outdated Oneiric version, use\nsudo sed -i s/saucy/oneiric/ /etc/apt/sources.list.d/mefrio-g-plymouthmanager-saucy.list \nsudo rename s/saucy/oneiric/ /etc/apt/sources.list.d/mefrio-g-plymouthmanager-saucy.list \nsudo apt-get update\nsudo apt-get install plymouth-manager\n\nNote that it may be unstable on Saucy.\n", "Q: Evaluating a string in shell script I am following this bash shell scripting guide:\n\n\n*\n\n*http://www.tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html\nIn the section Numeric Comparisons, it cites an example:\nanny > num=`wc -l work.txt`\n\nanny > echo $num\n201\n\nanny > if [ \"$num\" -gt \"150\" ]\nMore input> then echo ; echo \"you've worked hard enough for today.\"\nMore input> echo ; fi\n\nWhat seems to happen above is we store a string of commands in a bash variable and then we invoke echo on the variable. What seems to happen is the string is evaluated and the wc command is executed and returns the line count to the controlling terminal. \nOk, so I launch my terminal in Ubuntu 12.04 and try something similar:\n$ touch sample.txt && echo \"Hello World\" > sample.txt\n$ cat sample.txt\nHello World\n$ num='wc -l sample.txt'\necho $num\nwc -l sample.txt\n\nWait a second, that didn't evaluate the string and return the line count. That just echoed the string back to the terminal. Why did I get different results?\n\nA: Please note that symbol:\n\n'\n\nSingle quote\n   Enclosing characters in single quotes preserves the  literal  value  of\n   each character within the quotes.  A single quote may not occur between\n   single quotes, even when preceded by a backslash.\n\nand\n\n`\n\nBackquote\n   Command substitution allows the output of a command to replace the com‐\n   mand name.  There are two forms:\n\n          $(command)\n   or\n          `command`\n\n   Bash performs the expansion by executing command and replacing the com‐\n   mand  substitution  with  the  standard output of the command, with any\n   trailing newlines deleted.\n\nSo the Backquote is returning result of the command to Standard Output. That is why \n`wc -l sample.txt`\n\nreturns results of the command, while\n\n'wc -l sample.txt'\n\njust return \"wc -l sample.txt\" as usual string\nConsider doing this as example:\n$ A='wc -l /proc/mounts'\n$ B=`wc -l /proc/mounts`\n$ C=$(wc -l /proc/mounts)\n\nAnd now echo all three variables:\n$ echo $A\nwc -l /proc/mounts\n$ echo $B\n35 /proc/mounts\n$ echo $C\n35 /proc/mounts\n\n\nA: If you want to capture the output of a command in a variable, you need to either use backticks `` or enclose the command in $():\n$ d=$(date)\n$ echo \"$d\"\nMon Mar 17 10:22:25 CET 2014\n$ d=`date`\n$ echo \"$d\"\nMon Mar 17 10:22:25 CET 2014\n\nNote that the string is actually evaluated at the moment of the variable declaration, not when you echo it. The command is actually run within the $() or backticks and the output of that command is saved as the variable's value.\nIn general, you should always use $() instead of backticks which are deprecated and only around for compatibility reasons and much more limited. You cannot, for example, nest commands within backticks but you can with $():\n$ echo $(date -d $(echo yesterday))\nSun Mar 16 10:26:07 CET 2014\n\nSee this thread on U&L for some more details of why `` should be avoided.\n\nA: You need to use backticks to evaluate the expression.\n$ num=`wc -l sample.txt`\n$ echo $num\n1 sample.txt\n\nIf you want to see only \"1\" in the output, use the command\n$ num=`cat sample.txt | wc -l`\n$ echo $num\n1\n\nAnd also works:\n$ num=`wc -l < sample.txt`\n$ echo $num\n1\n\nFor additional information, see Differences between doublequotes \" \", singlequotes ' ' and backticks ´ ´ on commandline?\n", "Q: Tomcat and Eclipse Integration Error: \"Unknown version of Tomcat was specified.\" I am using Ubuntu 13.10 and gnome 3.10.\nI have followed this tutorial to set up tomcat and eclipse.:\nSet up Eclipse and Tomcat 7 on Ubuntu 12.10 to create Java RESTful Web Services with Jersey \nBut when I reach step 9, I get the following error on eclipse:\n \nI tried many solutions I saw here on Ask Ubuntu but none worked for me.\nI have checked the usr/local folder but tomcat7 is not there.\nI checked the /usr/share folder and tomcat7 is there.\n\nI used the following command to install eclipse and tomcat:\nsudo apt-get install eclipse tomcat7 -y\n\n\nA: I suggest installing standalone Tomcat into /usr/local instead of using the one in /usr/share directory.\ncd ~/Downloads\nwget http://apache-mirror.rbc.ru/pub/apache/tomcat/tomcat-7/v7.0.52/bin/apache-tomcat-7.0.52.tar.gz\ntar -xzf apache-tomcat-7.0.52.tar.gz\nsudo mv apache-tomcat7.0.52 /usr/local/apache-tomcat7.0.52\n\nThen use /usr/local/apache-tomcat7.0.52.\n\nA: Make sure that the Tomcat folder you're pointing to contains the following files:\nconf/catalina.policy\nconf/server.xml\nconf/web.xml\nconf/context.xml\nconf/tomcat-users.xml\nconf/catalina.policy\nconf/catalina.properties\nlib/catalina.jar\n\nas Eclipse is scanning for them.\n\nHere is a Linux command which can help you to find that folder:\nfind /opt /usr '(' -name catalina.policy -o -name tomcat-users.xml -o -name catalina.properties ')' -exec sh -c 'dirname $(dirname {})' ';' | uniq\n\n\nA: In Ubuntu the application doesn't have default permission to read/edit all the folders.\nI realized that the permissions for the TOMCAT installation directory were not set correctly.\nI changed it to 755 and it worked.\nsudo chmod -R 755 /opt/tomcat/apache-tomcat-9.0.24/\n\n\nA: You can use your server in any directory, just that the Apache Tomcat directory has read access by its user.\nExample: sudo chmod -R 755 /usr/local/apache-tomcat7.0.52\n", "Q: Permission denied - running script I am new somewhat to scripting in Ubuntu and I have the following script which I am executing but getting back Permission Denied messages. Any help is greatly appreciated! \nHere's the sequence:\nThe Script:\n!/tm/local/bin/bash\nblockdev --setra 16384 /dev/sd[bcdefghijkl]\necho 1024 > /sys/block/sdb/queue/read_ahead_kb\necho 1024 > /sys/block/sdc/queue/read_ahead_kb\necho 1024 > /sys/block/sdd/queue/read_ahead_kb\necho 1024 > /sys/block/sde/queue/read_ahead_kb\necho 1024 > /sys/block/sdf/queue/read_ahead_kb\necho 1024 > /sys/block/sdg/queue/read_ahead_kb\necho 1024 > /sys/block/sdh/queue/read_ahead_kb\necho 1024 > /sys/block/sdi/queue/read_ahead_kb\necho 1024 > /sys/block/sdj/queue/read_ahead_kb\necho 1024 > /sys/block/sdk/queue/read_ahead_kb\necho 256 > /sys/block/sdb/queue/nr_requests\necho 256 > /sys/block/sdc/queue/nr_requests\necho 256 > /sys/block/sdd/queue/nr_requests\necho 256 > /sys/block/sde/queue/nr_requests\necho 256 > /sys/block/sdf/queue/nr_requests\necho 256 > /sys/block/sdg/queue/nr_requests\necho 256 > /sys/block/sdh/queue/nr_requests\necho 256 > /sys/block/sdi/queue/nr_requests\necho 256 > /sys/block/sdj/queue/nr_requests\necho 256 > /sys/block/sdk/queue/nr_requests\n# Set read-ahead.\necho \"Setting read-ahead to 64 MiB for /dev/md0\"\nblockdev --setra 65536 /dev/md0\n# Set stripe-cache_size for RAID6.\necho \"Setting stripe_cache_size to 16 MiB for /dev/md0\"\necho 16384 > /sys/block/md0/md/stripe_cache_size\necho 8192 > /sys/block/md0/md/stripe_cache_active\n# Disable NCQ on all disks.\necho \"Disabling NCQ on all disks...\"\necho 1 > /sys/block/sdb/device/queue_depth\necho 1 > /sys/block/sdc/device/queue_depth\necho 1 > /sys/block/sdd/device/queue_depth\necho 1 > /sys/block/sde/device/queue_depth\necho 1 > /sys/block/sdf/device/queue_depth\necho 1 > /sys/block/sdg/device/queue_depth\necho 1 > /sys/block/sdh/device/queue_depth\necho 1 > /sys/block/sdi/device/queue_depth\necho 1 > /sys/block/sdj/device/queue_depth\necho 1 > /sys/block/sdk/device/queue_depth\n\nI gave everyone execution access like this:\nchmod a+x /home/tm/raid-sync.sh\n\nI execute it like this:\nroot@LSERVER:~# sh /home/tm/raid-sync.sh\n\nIt returns this:\n/home/tm/raid-sync.sh: 1: /home/tm/raid-sync.sh: !/tm/local/bin/bash: not found\nSetting read-ahead to 64 MiB for /dev/md0\nSetting stripe_cache_size to 16 MiB for /dev/md0\n/home/tm/raid-sync.sh: 29: /home/tm/raid-sync.sh: cannot create /sys/block/md0/md/stripe_cache_active: Permission denied\nDisabling NCQ on all disks...\n\n\nA: First, to escape by first error (!/tm/local/bin/bash: not found), change !/tm/local/bin/bash with #!/bin/bash. See here more about shebang (what it is, how to use it, examples).\nSecond, if you set executing permissions to the script, then run it only using /home/tm/raid-sync.sh at the prompt (without sh in front).\nThird, the /sys directory in Linux is deceptive. Unlike most other directories, it does not provide persistent storage for arbitrary files and because of this you don't have permission to write even if you are root. See this answer for more info.\n\nA: your first line seems to have an error in it. (as seen from your error), I would start by fixing it,  maybe change it to \n#!/bin/bash\n\nthen try again, and we can look at next error\n", "Q: How to extend logical volume swap space to atleast 64 GB on SSD My current configuration of physical volumes is as follows.\n  --- Physical volume ---\n  PV Name               /dev/sda5\n  VG Name               vgssd\n  PV Size               190.89 GiB / not usable 1.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              48867\n  Free PE               0\n  Allocated PE          48867\n  PV UUID               SaJLLb-KpaE-ZeyS-k5HR-eNQ6-A1tp-zpZjUe\n\n  --- Physical volume ---\n  PV Name               /dev/sdb\n  VG Name               vgssd\n  PV Size               465.76 GiB / not usable 4.02 MiB\n  Allocatable           yes \n  PE Size               4.00 MiB\n  Total PE              119234\n  Free PE               194\n  Allocated PE          119040\n  PV UUID               yekbZZ-guPE-6Gjh-qJux-MjMi-RHYx-YevZop\n\nAnd below is the configuration of my logical volumes: \n  --- Logical volume ---\n  LV Name                /dev/vgssd/home\n  VG Name                vgssd\n  LV UUID                XozHK8-4dJ2-XfQE-7f2J-xGLB-2nVg-rO9yA3\n  LV Write Access        read/write\n  LV Status              available\n  # open                 1\n  LV Size                4.66 GiB\n  Current LE             1192\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           252:0\n\n  --- Logical volume ---\n  LV Name                /dev/vgssd/swp\n  VG Name                vgssd\n  LV UUID                CyYT1b-BQhM-vwQa-W8oU-0E8Y-OVYD-894T86\n  LV Write Access        read/write\n  LV Status              available\n  # open                 2\n  LV Size                1.86 GiB\n  Current LE             476\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           252:1\n\n  --- Logical volume ---\n  LV Name                /dev/vgssd/srv\n  VG Name                vgssd\n  LV UUID                aIwCXs-ibKG-5IUl-rxI1-UZJT-fypS-xpHyKC\n  LV Write Access        read/write\n  LV Status              available\n  # open                 1\n  LV Size                649.37 GiB\n  Current LE             166239\n  Segments               2\n  Allocation             inherit\n  Read ahead sectors     auto\n  - currently set to     256\n  Block device           252:2\n\nCurrently, I want to extend the swap space ( /dev/vgssd/swp ) from ~2 GB to 64 GB. I think I can shrink /dev/vgssd/srv and save 64 GB for swap space. However, I am not sure which physical volumes ( /dev/sda5 or /dev/sdb ) the new swap space is allocated to when I actually extend ( /dev/vgssd/swp ).\nI want to make sure the swap space is on ( SSD with PV name /dev/sda5 ) so data can be written and read in high speed.\nDo you have any ideas how I can do that?\n\nA: The lvextend command accepts physical devices as argument :  \nlvextend -L 64000 /dev/vgssd/swp /dev/sda5  \n\nWill allocate all the new extends on /dev/sda5\n", "Q: Add words to a text file using a single terminal command (no editors) I'm new to Linux. I need to edit a .conf file from the open terminal only and not using any text editors. That is, can I add words and sentences to a config file from an open terminal? \nExample: command /home/.../file.conf -add 'abcd' to the 23rd line and so on. And finally, save it. \nIs it possible to search a specific word in that config file and add new text to the next line of that config file using only the command?  \n\nA: You can also use the printf command.\nTo add lines to your file\n$ printf \"\\nThis is a new line to your document\" >> file.txt\n\nTo overwrite the file\n$ printf \"This overwrites your file\" > file.txt\n\n\nA: I usually do this way when I am programming my script to do same what you are asking but programmatically.\necho \"Hello you!\" >> myfile.txt\necho \"this is 2nd line text\" >> file.txt\necho \"last line!\" >> file.txt\n\nVoila! You got it.  Important to note >> means adding new line to existing file meanwhile > just simply overwrite everything.\n\nA: Adding words and sentences to a config file from open terminal can be easily achieved with sed.\nsed -i '23iabcd' file.conf\n\ninserts at line 23 the text abcd into file file.conf \n-i does the modification directly to file file.conf. \nIf you want to use awk then:\nawk -v n=23 -v s=\"abcd\" 'NR == n {print s} {print}' file > file.conf\n\nThe following adds one line after SearchPattern.\nsed -i '/SearchPattern/aNew Text' SomeFile.txt\n\nIt inserts New Text one line below each line that contains SearchPattern.\nTo add two lines, you can use a \\ and enter a newline while typing New Text.\n sed -i '/pattern/a \\\nline1 \\\nline2' inputfile\n\n\nA: awk '{if ($1 ~ /regex/) print $1 \"content to be added\"; else print $1}' < inputfile > outputfile\n\nNotes:\n\n\n*\n\n*regex is a regular expression (also known as regex), it defines the search criteria. Regular expressions allow for very customizable searches and the syntax understood by awk is in the manual. In the simplest case - search a string \"as it is\", character by character - just put a backslash before special characters (see manual for the list of special characters)\n\n\nHow it works:\n\n\n*\n\n*open inputfile for reading the input lines, clear outputfile and open it for writing the output lines\n\n*for each line, run the block in braces:\n\n*\n\n*if the line matches the regular expression, then output the line with content appended\n\n*otherwise, output the very same line.\n\n\n\nA: I found a solution to my own question using the ed command\ned -s /home/.../abc.conf <<< $'23i\\ntext\\n.\\nwq'\n\nText can contain 27 lines. You can copy 27 lines from a text file and paste 27 lines to your config file. But I need to run the ed command simultaneously in order to add more text to the same config file. \n", "Q: How do I make a WebView transparent? Consider the following QML snippet:\nPage {\n    WebView {\n        id: webView\n        anchors.fill: parent\n    }\n}\n\nI then attempt to load some HTML in the WebView using the following JavaScript:\nwebView.loadHtml('<b>test</b>');\n\nHowever, the WebView has a white background:\n\n(Ignore the fact that the text is too small.)\nIs there a way to make the background transparent?\n\nA: You could try QtWebKit.experimental. If you add import QtWebKit.experimental 1.0 to your QML files, your WebView objects will have access to experimental attributes:\nimport QtQuick 2.0\nimport QtWebKit.experimental 1.0\nimport Ubuntu.Components 0.1\n\n\nMainView {\n    id: main\n    width: units.gu(100)\n    height: units.gu(75)\n\n    Page {\n        id: mypage\n        Rectangle {\n            color: \"green\"\n            anchors.fill: mypage\n            WebView {\n                id: webView\n                anchors.fill: parent\n                experimental.transparentBackground: true\n            }\n        }\n\n        Component.onCompleted: webView.loadHtml(\"<p>Hello</p>\");\n    }\n}\n\nObviously you'll get this kind of warning:\n\nWARNING: The experimental API will change from version to version, or\n  even be removed. You have been warned!\n\n", "Q: Is it possible for Adobe Flash to kill my GPU? The question\nIs it possible that Adobe Flash in Ubuntu 12.04 on Firefox could damage my GPU?\nHistory\nSo... there I was, using my beloved Ubuntu 12.04, Doing some PHP/Javascript/HTML development in Firefox. I was testing using the JQuery SWFObject plugin on some dynamic content....and it had been wokring fine.\nThen, testing some of the logic that removes old content and refreshes, I triggered an onclick event to do this to Flash content. There were bugs in my code, causing it to try and instantiate Flash in a DIV that already had Flash content.\nMy PC froze. Rhythmbox was still playing, but everything else was frozen.\nI rebooted, and horror. Black Screen. After much messing around, I was able to get a 640x480 display on main monitor and not detect the second. Reinstalled graphics drivers and so on... but nothing would work. So I upgraded distro to 12.10 and reinstalled the nvidia 331 drivers. Got one session out of it, and since then although Ubuntu will boot with mouse and wallpaper, I have no Unity and not even able to Ctrl-Alt-F1 terminal. Nothing.\nWindows is still working, but in windows I'm now getting the (very occasional) message about my display adapter encountering a problem.\nIt all seems a little too coincidental to me.....? But is it possible?\n\nA: Not sure if this helps, but I had a failed GPU fan, and so my computer would hang whenever I did anything which was GPU intensive (the temperature would reach 90-100 degrees and auto poweroff).  Flash can be GPU intensive, are you sure your GPU is working ok?\n\nA: I don't think so. In fact, the GPU helps to have a better video RAM memory and allows RAM to be used in other processes, instead of the integrated video processors in most of the motherboards, which spend some of RAM memory for video. \nNote that if you have opened a heavy adobe flash app, if would affect the performance of CPU (strongly, if you have opened several flash apps simultaneously).\n", "Q: How do I transfer a casper-rw file to a partition? I am using a 16GB live USB with persistence so I can work from several computers.\nThis was working great for me until my persistence file on the USB Flash Drive got filled. As FAT32 is limited to <4GB file size, I would like to use a much larger (ext2/ext3/ext4) partition for casper-rw instead of just enlarging the file. The drive has over 8GB free space.\nI know how to use Gparted to make that partition, and where my casper-rw file is. \nMy issue is, how do I transfer the contents of the existing casper-rw file to the new partition? \nI don't want to lose all of the settings and installed programs I've added. I just want more space (unlimited by FAT32) for persistence.\n\nA: There are 2 ways of copying casper-rw contents.\nUse dd command\nsudo dd if=/path/to/casper-rw of=/dev/<partition>\n\nThen resize new partition with Gparted or resize2fs\nUse cp command\nsudo mkdir /mnt/casper-rw /mnt/target\nsudo mount -o loop /path/to/casper-rw /mnt/casper-rw\nsudo mount /dev/sdbX /mnt/target\ncp -r /mnt/casper-rw/* /mnt/target\n\nThus /dev/sdbX does not need to be resized\n\nA: Use GParted to create the new partition. Mount the new partition and the original casper-rw partition with something like:\nsudo mkdir /mnt/casperx\nsudo mount /dev/sdax /mnt/casperx\n\nThen use then copy all the files from the original casper-rw partition to the new partition using nautilus or terminal:\ncp -r /mnt/original/* /mnt/casperx\n\nOnce you have all the files transferred, verify all you files are there and you could delete the original FAT partition and resize the new ext4 partition using resizefs as show here: http://www.pendrivelinux.com/how-to-create-a-larger-casper-rw-loop-file/.\n\nA: Before transfering your casper-rw file, consider checking your unmounted casper-rw filesystem using another Linux live system:\n$ sudo losetup /dev/loop0 /datas/casper-rw\n$ sudo tune2fs -l /dev/loop0 | grep stat\nFilesystem state:         not clean\n$ sudo fsck /dev/loop0 \nfsck from util-linux 2.25.1\ne2fsck 1.42.10 (18-May-2014)\ncasper-rw was not cleanly unmounted, check forced.\nPass 1: Checking inodes, blocks, and sizes\nPass 2: Checking directory structure\nPass 3: Checking directory connectivity\nPass 4: Checking reference counts\nPass 5: Checking group summary information\ncasper-rw: 94821/262144 files (0.2% non-contiguous), 829517/1048575 blocks\n$ sudo tune2fs -l /dev/loop0 | grep stat\nFilesystem state:         clean\n$ sudo losetup -d /dev/loop0\n\nNow, you can clone your casper-rw file to your chosen partition using the dd command.\n", "Q: Where can I download pfvar.h? I'm trying to compile a source code and it needs this header file 'pfvar.h'\nFrom where can I get it\nI have Ubuntu 12.04 LTS\nThanks in advance\n\nA: What are you trying from source? Usually when I have this kind of problem, it's because I don't have a -dev package installed for one of the dependencies. For example if XnetX was a dependency of a program I was trying to compile, I would need the XnetX-dev package installed from the software center. Doing this will download the source files for that package thereby allowing you to use the header and src files. \n\nA: [UPDATE]\nYou're trying to compile a source for the wrong architecture, I found pfvar.h in the kFreeBSD headers for development. Basically you need a BSD-like system to build your program.\n\nnet/pfvar.h sounds like a kernel header, try to install the header files for your current kernel:\nsudo apt-get install linux-headers-generic\n\n", "Q: How to install Bad Piggies on ubuntu 12.04? I am completely new with Wine. I haven't installed any games through Wine. What are the steps to install Bad piggies on Ubuntu 12.04?\n\nA: You could try PlayOnLinux. It's available in the software center and has nice GUI menus to assist you in installing games like this. If your game is not listed, just choose the option to install a game that isn't listed.\n\nA: Using wine is not complicated but some games or Applications might not work as expected since Wine is NOT an emulator :)\nTo install normally you do\nsudo apt-get install wine\nto install application:\nwine Setup.exe\nthen if everything went ok you should have the Application/Game installed on your wine directory which as a similar layout as in Windows.\ncd ~/.wine/drive_c/\nthen go to the path of the Application/Game \ncd Program\\ Files\\ApplicationXYZ\n\nand run wine *Executable.exe*\nFor more instructions and help on Bad Piggies with Wine, follow this page which the Wine community maintain.\nEDIT\nAlso as an alternative, since Bad Piggies should not have a big 3D and CPU requirements you could also try to run it on a Virtual Machine. This is usually more easy and if you have a powerful machine you should get also a good performance.\n", "Q: Updated from Ubuntu 12.04 LTS Wubi to 13.10, won't boot now Yesterday night, I have installed Ubuntu 12.04 LTS through Wubi, since I don't want it to be on a CD or a USB. Later that night, I have updated the version from 12.04 LTS to 13.10. It asked me to reboot to complete the installation of the update, so I did that. \nAfterwards, like normal booting, it asked me which OS do I want to open. Windows 7 or Ubuntu, so I chose Ubuntu, of course, but, after I clicked on the Ubuntu button, the Ubuntu start up screen shows (the Ubuntu logo which has five grey loading dots under it) and then it disappears and turns into a black screen with a white line. The white line isn't even moving. What's going on? Please help.\n\nA: What I always do in a problem is to reinstall whatever version of Ubuntu I am using. That usually fixes the problem (Do not get into any partitioning or any complicated stuff while installing. That may cause problems while booting). Cheers! :)\n", "Q: Usb udev rule never worked for me I try to have a USB device recognized as being part of my user group. So I don't have to issue a sudo during development time when I debug my program which access those devices. Especially painful when using Netbean or Eclipse.\nThe udev rules never worked :\n$ cat /etc/udev/rules.d/40-usbio.rules\nSUBSYSTEM==”usb”, ENV{DEVTYPE}==”usb_device”, MODE=”0664”, GROUP=”odroid”,\nATTR{idVendor}==”04d8”, ATTR{idProduct}==”003f”\n\nI also tried with mod MODE=”0666” and MODE=”0777”.\nThe weirdest part is that my USB camera has the same privileges and is part of the same group(root). But it never requires a sudo when I use cheese nor camorama.\nls -l /dev/bus/usb/001/013  ---------------> camera\ncrw-rw-r-- 1 root root 189, 12 Mar 16 21:25 /dev/bus/usb/001/013\n\nls -l /dev/bus/usb/002/007 ----------------> usb device\ncrw-rw-r-- 1 root root 189, 134 Mar 16 21:32 /dev/bus/usb/002/007\n\nI also want to do the same with an arduino, but even with the proper rule file, it just does not work. Even after restarting udev or the computer.\nHow to fix this?\n\nA: I'd add a NAME=\"my_device\" in order to create the corresponding node.\nAnd check your quotes, replace ” by \". It could be just that.\n", "Q: Find matched strings in two files I have two files like this:\nFile_A:\n1  A\n2  B\n3  C\n\nFile_B:\n1 D\n2 B\n3 C\n\nSo what I want to do is find the matched rows based on column 2 and get a new file. Both of the files have a header line\n\nA: You can use:\nwhile read line; do grep \"${line##* }\" File_B; done < File_A > File_C\n\n", "Q: How can I get \"delta\" packages to optimize apt-get upgrade downloads? I have recently installed Fedora in VirtualBox and noticed that they use Delta-RPM packages, which help dramatically reduce downloading sizes. Also I heard that Gentoo uses some delta packages. Would be glad to see such deltas in Ubuntu too.\nDoes anyone know about such delta-deb packages and how do I get to use them?\n\nA: You may be looking for debdelta package.\nFrom man debdelta-upgrade:\n\nNAME\n       debdelta-upgrade  -  Downloads  all deltas that may be used to 'apt-get\n       upgrade', and apply them.\n\nSYNOPSIS\n       debdelta-upgrade [OPTION]... [PACKAGE] ...\n\nDESCRIPTION\n       This program is designed to download changes (deltas) that may be  used\n       to  apt-get upgrade all listed packages, and apply them.  If no package\n       is listed in the command line, then it will  apply  to  all  upgradable\n       packages. See debdelta(1) for more details on the delta files.\n\nHow to use\nsudo apt-get update\nsudo debdelta-upgrade\nsudo apt-get upgrade\n\nExample\n$ sudo debdelta-upgrade \nDownloaded, time  7.24sec, speed 212kB/sec, xserver-xorg-video-intel_2.99.910+git20140315.8cc1f005-0ubuntu0sarvatt~saucy_i386.deb\nDelta-upgrade statistics:                                                       \n total resulting debs, size 1539kB time 8sec virtual speed 181kB/sec\n\n", "Q: SSH session hanging the remote desktop I have been remotely connecting to my ubuntu dekstop at work using SSH, I have noticed that after some ideal time the connection hangs and on restarting the SSH, ssh does not identify my desktop on the remote side. Later I observed that the remote desktop usually hangs up when my ssh connection hangs up? Could anyone help with this?\nI usually forward ports in SSH as there is an intermediate server.\n\nA: to prevent ssh hanging up on  your, you can set up some things in your ssh setup.\nedit/or create this file \npico ~/.ssh/config\n\nadd these lines\nHost Remotehost\n Hostname myremotehost.com\n ServerAliveInterval 240\n\nalternative you can make this rule for ALL your ssh connections like this\nHost *\n ServerAliveInterval 240\n\nif you are on windows, putty also have keep alive settings.\noh, and do not forget to set the correct permission for this config file like this:\nchmod 600 ~/.ssh/config\n\nsource\n", "Q: How do I install gedit-2 I want to install gEdit 2.0 on my ubuntu 12.10. The purpose is testing a plugin that seems not to have support for 3.0 or above.\nMy current version is:\nvlad@computer:~$ gedit --version\ngedit - Version 3.6.1\n\nI tried so far looking for an older package on the internet but I didn't find anything.\nAny suggestions on how to install it would be highly appreciated.\nThanks in advance!\n\nA: For now, the only supported version of gedit on Ubuntu 12.10 are 3.6.1 and 3.6.0. You can check this with the command\napt-cache policy gedit\n\nThis gives an output\napt-cache policy gedit\ngedit:\nInstalled: 3.6.1-0ubuntu1\nCandidate: 3.6.1-0ubuntu1\nVersion table:\n*** 3.6.1-0ubuntu1 0\n    500 http://archive.ubuntu.com/ubuntu/ quantal-updates/main i386 Packages\n    100 /var/lib/dpkg/status\n 3.6.0-0ubuntu1 0\n    500 http://archive.ubuntu.com/ubuntu/ quantal/main i386 Packages\n\nversion 2.0 is very old one and is no longer supported on Ubuntu 12.10.\nThe only feasible solution for testing the plugin seems to be that you get an older version of Ubuntu which supports gedit 2.0, run it in VM and install and test the plugin there.\n", "Q: Diskless Boot with IPv6 At our work we are using around 80 diskless machines running Ubuntu. We want to make the transition to IPv6, so now I'm trying to get our diskless system to work with IPV6. The transmission of the kernel and initramfs can be still over a IPv4 connection, but once the machine is fully booted I want all network connections to be over IPv6. \nThis means that the nfsroot has to be mounted via IPv6. My research of this has shown that initramfs-tools (1.18.5-1ubuntu4.1) does NOT support IPv6. That means that neither ipconfig, that's used for interface configuration at early boot time, nor the mount mounting procedure for the nfs root are IPv6 capable.\nTo circumvent this I added two binaries to the initramfs (/etc/initramfs-tools/hooks/ipv6):\n#!/bin/bash \n. /usr/share/initramfs-tools/hook-functions\ncopy_exec /sbin/dhclient /sbin\ncopy_exec /sbin/mount.nfs4 /sbin\n\nI use these to (a) request a DHCPv6 at early boot time with \n/sbin/dhclient -6 -1 -cf /tmp/dhclient.conf -pf /tmp/dhclient6.eth0.pid -lf /tmp/dhclient6.eth0.leases eth0\n\nand (b) to configure the interface with the address I attained by executing:\nipv6=$(cat /tmp/dhclient6.eth0.leases | grep iaaddr | egrep -o \"([a-f0-9]{1,4}:){3}([a-f0-9]{0,4}:){0,4}[a-f0-9]{1,4}\")\nip -6 addr add $ipv6/112 dev eth0\n\nUsually the nfs root is mounted with the following command in/usr/share/initramfs-tools/scripts/nfs:\nnfsmount -o nolock ${roflag} ${NFSOPTS} ${NFSROOT} ${rootmnt}\n\nBut this doesn't seem to accept IPv6 addresses.\nSo I changed it to:\nmount ${roflag} -t nfs4 ${NFSROOT} ${rootmnt}\n\n$NFSROOT in this case is [2001:4ca0:2218:1::1:2]:/lb/diskless/rootfs/ubuntu_1204_ipv6.\nThe interface configuration seems to work as well as the root mounting, but when /sbin/init is executed (I think), the IPv6 is dropped again, and therefore the system freezes (because it cannot access the ubuntu root anymore). \nThe /etc/network/interfaces file looks like this:\nauto lo\niface lo inet loopback\n\niface eth0 inet manual\niface eth0 inet6 manual\n\nIs there a way to keep the interface configuration from the initramfs? Or am I doing something wrong when I configure the interface with ip?\n\nA: maybe it's off topic to you but I think that your specific problem can be avoided by rethink the service :\nwhy bother booting with NFS ? \nYou can try to boot with iscsi (in a read only mode to allow more than one connection to the image) and then use iscsi or nfs (ipv4) for the user shares if you need to. You can achieve this with the ipxe project.\nAnother way is to use squashfs+tmpfs and not to bother so much with shares during the booting process of the system and then do remounts depending on the user authentifications (however this have a higher memory consumption on the client side).\nHopes that helps you.\n", "Q: cant work out how to do \"chkconfig systat on\" & \"service systat start\" on ubuntu 12.04 Can anyone tell me how to do this in Ubutu from command line?  We have no GUI.\nchkconfig sysstat on\nservice sysstat start\nI tried installing chkconfig, and get the error:\n\"Package chkconfig is not available, but is referred to by another package...\nE: Package 'chkconfig' has no installation candidate\"\nI saw someone said you have to use \"sysv-rc-conf\", but this command:\napt-get install sysv-rc-conf\nGives exactly the same install error as chkconfig.\nSomeone else suggested using upstart, but this looks very complex and I could not work out how to use it on to do the above 2 commands.\nI also saw someone recommending \"update-rc.d\".  I have looked at this page: http://manpages.ubuntu.com/manpages/hardy/man8/update-rc.d.8.html\nBut unfortunately am still clueless how this tool can be used to do the simple automatic starting of a service.\nIn the old days we would simple edit rc2.d scripts, is this still possible?\n\nA: Sysstat is still a init script, not changed to upstart yet. If you have installed it it will normally autostart.\nTo check if it is running you can use:\nsudo /etc/init.d/sysstat status\n\nand to manually start:\nsudo /etc/init.d/sysstat start\n\nI do not know where you got the instruction to start it using upstart (which will be the new way for handling start scripts but currently both init.d (the old fashion rc scripts) and upstart are used next to each other. \nPS. For sysstat to run it should be enabled in the file /etc/default/sysstat.\n", "Q: Extended partition I am not allowed to have more than 4 partitions.During installing Ubuntu I am not allowed to have swap area because of this problem.What should I do? \n\n\nA: The 37.52 GB is the unallocated space in your hard disk. With MBR partitioning scheme, you can not create a new partition with it. So your option is to merge in some other partition.\nYour merger options:\n\n\n*\n\n*Merge the unallocated space to your 20.98 GB Ubuntu installation. [easiest and quickest]\n\n*Merge it into your Windows' install partition (the C drive in Windows), OR move the Windows' install partition [risk involved] to bring it next to your Ubuntu root / partition, thus shifting unallocated space to right of Windows' partition which would then be merged to the extended partition (the D drive). [Moving Windows' install/system partition involves risks and can take a long time to complete.]\n\nRegarding Swap space:\nYou can create one more logical partition (in the extended partition container /dev/sda4) and use it for swap.\nFor this you'll have to:\n\n\n*\n\n*Start a partition manager say GParted,\n\n*To create a new logical partition in the extended partition you'll have to shrink your current and only logical partition /dev/sda5. You can do this by right clicking the partition and selecting resize/move option. Then in the Resize/Move window that appears, you can move the slider from right end towards left (preferred option) to create an unallocated space of appropriate size that you want for your swap,\n\n(this snapshot shows a resize/move operation being selected for a logical partition.)\n\n(here I've selected a size of 2051 MB for the new partition. Make sure your Align to: option is set for MiB)\n\n*Right click the newly created unallocated space, and select New,\n\nthen set File System to linux-swap and click Add;\n\n\n*Finally click Apply All Operations button.\n\n\n\n\n*\n\n*After you've created the swap partition, you can turn it on with sudo swapon -a (-a implies turn on all available swap, check man swapon for more.)\nTo bring it in use each time you boot into your system, open the file /etc/fstab, with root privilege, using the text editor of your choice. Then add an entry like UUID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx  none  swap  sw  0  0 where xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx is replaced by the UUID of your swap partition. (You can use sudo blkid | grep swap to check your UUID.) Save and close the file.\nReferences:\n\n\n*\n\n*How to resize partitions? (askubuntu)\n\n*How to Resize Your Ubuntu Partitions! (howtogeek)\n\n*How To Resize (Shrink) an Ext4 Ubuntu System Partition! (youtube)\n", "Q: How do I load Ubuntu 13.10? I'm a novice when it comes to Ubuntu!! Tried Linux Red hat about a decade ago but couldn't get my head around the mounting and unmounting process. Stuck with what I knew and that was Windows. Got my hands on Ubuntu 10.12 I think and love it! Now I want to load 13.10. So i downloaded from the site and burned the iso to a DVD. I also tried the USB way but to no avail!! When trying the disk it keeps on giving me a \"No default or UI configuration directive found\" error. \nNothing happens when I try the USB.\nI done all the changes in the bios to detect the USB and CD-Rom as first boot devices and even removed the HDD as a boot device. Still no joy!\nIt also comes up with a command line boot: But Im not sure what to type in??\nAny related answers will be much appreciated.\n\nA: All right now what I want to know is if you used some software to create a bootable USB/ DVD for Ubuntu? I'm referring to software such as UnetBootin (it works both on windows and Linux) etc.\nIf no then kindly use that to create a bootable USB/DVD and then when you boot your system press the key that lets you get to the bios. \nThen in the bios set the default boot disk as USB (name of the usb stick vendor is usually shown, which makes it easier to identify) or the DVD drive. press F10(usually ) to save and exit\nUpon reboot, the system should automatically boot the USB/DVD drive that has OS.\nThere would also be many YouTube videos that explain the same . \nLet us know if it works or not.\n", "Q: Disable \"Semi-maximize left\" in Ubuntu 13.10 As the title says,\nHow can I disable or re-assign the \"semi-maximize left\" keyboard shortcut in Ubuntu 13.10?\nBy default it is bound to Ctrl + Super + ←\nI have tried to change the bindings for the \"put left\" action with compizconfig-settings-manager as suggested by the previous question for Ubuntu 12.04. This however no longer works in Ubuntu 13.10.\nThis question is motivated by the keyboard shortcut conflicts between the default  Unity desktop and IntelliJ IDEA.\n\nA: For 13.10\n\n\n*\n\n*Open CompizConfig Setting Manager (ccsm)\n\n*Look for Ubuntu Unity Plugin in Desktop group  → General Tab:\n\n*Disable:\n\n\n*\n\n*Key to vertically maximize the focused window to the right\n\n*Key to vertically maximize the focused window to the left\n\n\n\nOr just run:\ndconf write /org/compiz/profiles/unity/plugins/unityshell/window-right-maximize \"'Disabled'\"\ndconf write /org/compiz/profiles/unity/plugins/unityshell/window-left-maximize \"'Disabled'\"\n\nFor 14.04\n\n\n*\n\n*Open CompizConfig Setting Manager (ccsm)\n\n*Look for Grid in Window Management group  → Binding Tab:\n\n*Disable:\n\n\n*\n\n*Left maximize\n\n*Right maximize\n\n\n\nOr just run:\ndconf write /org/compiz/profiles/unity/plugins/grid/left-maximize \"'Disabled'\"\ndconf write /org/compiz/profiles/unity/plugins/grid/right-maximize \"'Disabled'\"\n\n", "Q: Sharing File between 2 ubuntu machines Sorry for asking what is most probably an already answered question.\nI have 2 machines running 12.04 (desktop and a laptop) and I want to move nearly 50gig of files from one to the other in the most efficient way possible.\nI have taken all the files I need from my laptop and saved them all inside one file on my desktop, ready to be moved over to my pc. I then plan to move them from my pc, to my external hd (that can only be connected to my desktop pc)\nThere are a few different ways for me to do this, and I have spent the last couple of hours trying to figure out which would be the best way, but have only succeeded in confusing my little n00b brain more.\nI need a guide with basic step by step instructions, including every step that I will need, but also in a format that is easy to understand and implement please.\nIm sure this has been answered before, but either I cant find the thread, or my brain is throwing spanners in the works, so your help would be greatly appreciated.\nThanks Ubuntu masters\nEDIT I have just tried using 'giver' and it seems to work for small pictures but not for larger things or folders. I used this guide succesfully; How to transfer files between Ubuntu machines? but I assume the programme isnt capable of moving 45gig folders at one time, but it should help someone wanting to move smaller files easily.\n\nA: The quickest and easiest way I found to move my files from laptop to pc was DUKTO, recommended to me by https://askubuntu.com/users/16395/rmano Thanks!\nThe link for DUKTO is here;\nhttp://www.msec.it/blog/?page_id=11\nIts simple to set up and use, and I believe its also multi platform. A drawback for some will be the lack of any security features meaning data could be sniffed but that wasn't a problem for me as I just plugged both devices straight into the router and unplugged the phoneline to create a superfast and secure network.\nTook less than 2 hours to shift about 110gig of data so Im happy, and would recommend DUKTO :) (for use in a secure network)\nThanks for contributions \nP.S. There are a number of other applications claiming to do the same or similar to DUKTO, and they might be even better\n\nA: If samba does not work, then you should try over ssh:\nfrom terminal install ssh server:\nsudo apt-get install openssh-server\n\nThen on the client computer just open nautilus and press CTRL + L and write:\nsftp://host_username@serverip\n\nThen , copy what you need.\n\nA: as I see it you only have one option, that is to plug in the external harddrive to your laptop, ubuntu do got a cloud service but it would take too long for you to move all of it\n", "Q: Why don't the commands 'sudo bash' or 'sudo -s' ask for a password? Even when I am logged in as a non-admin user, when I enter sudo bash or sudo -s, the system does not ask for any password. In the command history, I have not entered any password for sudo earlier (i.e., sudo did not cache any user credentials which might cause it to not ask for my password again in this session.)\nWhy is this strange behavior?\nAnd how do I make sure that every sudo and su command requires a corresponding password? And how to strictly ensure that any user cannot get root privileges without entering the root password?\nHere is the content of my /etc/sudoers file:\n#\n# This file MUST be edited with the 'visudo' command as root.\n#\n# Please consider adding local content in /etc/sudoers.d/ instead of\n# directly modifying this file.\n#\n# See the man page for details on how to write a sudoers file.\n#\nDefaults    env_reset\nDefaults    secure_path=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n\n# Host alias specification\n\n# User alias specification\n\n# Cmnd alias specification\n\n# User privilege specification\nroot    ALL=(ALL:ALL) ALL\n\n# Members of the admin group may gain root privileges\n%admin ALL=(ALL) ALL\n\n# Allow members of group sudo to execute any command\n%sudo   ALL=(ALL:ALL) ALL\n\n# See sudoers(5) for more information on \"#include\" directives:\n\n#includedir /etc/sudoers.d\nALL ALL=(ALL) NOPASSWD:ALL\n\n\nA: This is caused by the last line of your /etc/sudoers file, which states:\nALL ALL=(ALL) NOPASSWD:ALL\n\n...meaning \"all users can execute all commands as root without any password\".\nI don't know how that line got in there, but if you remove it you will restore the normal behavior. Note: use visudo for editing to make sure you don't get any syntax errors in there, i.e., execute the command\nsudo visudo\n\nand edit the file using the editor that pops up.\n", "Q: How to start building games on Ubuntu I, like many people, always wanted to make my own #BADA55 game. But, making a game is as time consuming as can be. But, still, its something I want to start doing when time is available. Preferably on Ubuntu.\nHow does Ubuntu hold as a game creation platform? What are the native tools available? What does Ubuntu offer, for the creation of games.\n\nA: Start off with something simple. Of course learning to program or advancing your programming and designing and managing skills is not going to be simple :-). But if you take small steps it will make it happen.\nIMHO unix/linux is very good for starting to program and write games. If you wish you can take writing games to a high level on ubuntu. Skills learned transfer to any platform.\nStart off maybe using SDL library. There are a good few examples available. Start with small examples. You can also find big SDL projects and get the source, build and hack on them for fun. You can program in c or python or more languages. SDL lib is available on linux, windows, mac, android, ios :), . . . http://www.libsdl.org/\nStart with python if you are new to programming. And start with really simple things like printing \"Hello world\". You could also start programming with graphical oo lang like scratch or blockly. \nPython SDL library is pygame. The documentation discusses python's suitability for game development. Read this: http://www.pygame.org/docs/tut/intro/intro.html\nYou can have lots of lovely shiny things and have arcade style games working perfectly with python. If you move into 3d rendering or other intensive operations  it is common to have optimised code in other languages e.g. c doing that part while a higher language like python is still used for management.\nAt the start setting up a programming environment can be tricky. Some simple things e.g. just putting a coloured pixel in a window sometimes just work easily but sometimes don't. Argh. Persist. Read the documentation. Read the internet. Make it do what you want :)\n", "Q: Advantages of using mac version of Ubuntu I was trying to use the mac alternate ISO to install ubuntu and it wasn't working out. I'm pretty sure I could fix, but I wanna know if it is worth it. What advantages does it offer for MBP 2010 15 inch.\n\nA: The mac image is designed to be compatible with most macs. The reason being that mac's have specific hardware requirements and tweaks to get things running smoothly. The Apple firmware by default uses a GPT table to boot OSX in EFI or UEFI mode. \nThe most common reason to use the Mac iso however is that they are more likely to be seen by the firmware and thus be able to boot and install on your Apple machine without issue.  \nThere is a very good explanation by Colin Watson here.   \n", "Q: PCB software available for gnome I'm looking for PCB software in Ubuntu. Ideally I want to design a circuit without needing it to be really specific. I cannot seem to find any software available. Any suggestions?\n\nA: Eagle\n\nEagle includes a layout editor, schematic editor and autorouter.\n\nTo install Eagle\nsudo apt-get install eagle\n\n\nPCB designer\n\nThis one seems to be more complex than eagle with better(complex) features like rats nest feature, design rule checking and industry standard RS-274-X(gerber)\n\nTo install PCB designer\nsudo apt-get install pcb-gtk             #maybe pcb-lesstif too\n\n\ngEDA Schematic\n\nThis one is intended to be user friendly and easy to use, similar to Eagle.\n\nTo install gEdA Schematic.\nsudo apt-get install geda\n\n\nKicad\n\nThis one seems to be overconfident.No info, No screenshot.But it's a PCB designer and comments/ratings are good.  \n\nTo install Kicad\nsudo apt-get install kicad\n\n\nFritzing\n\nIn it's Beta, this may not be one you would want to use professionally.But it's worth giving a try.Worth noting that it has something like Autocompletion.\n\nTo install Fritzing\nsudo apt-get install fritzing\n\n\nSome helpers to above\n\n\n*\n\n*Gerbv gerber file viewer\n\n*Electric\n\n*Visolate\n\n\n\nPersonally, I think Eagle would best suit your needs.All of the above are Open source and free, just to mention.\n\nA: Eagle is a good tool for schematics entry and PCB layout, as mentioned before. It is cross platform and works under Linux, Mac OS X and Windows. \nHowever, if you use the apt-get install method, the version might not be the latest and greatest. For example, Ubuntu 12.04 repositories currently host Eagle version 5.12.0, while the latest available version for download is 6.5.0.\nThis is how to get the latest version:\nGo to cadcoftusa download website here and download the latest version for Linux, for example this file:\nwget ftp://ftp.cadsoft.de/eagle/program/6.5/eagle-lin-6.5.0.run\n\nMake it executable:\nchmod +x eagle-lin-6.5.0.run\n\nThen run the installer:\n./eagle-lin-6.5.0.run\n\nand answer all the questions as needed, for example, the directory where you want it installed. Should you want to place it in the /opt/ or other global location, you may need to prepend the installation program with sudo\nAlso, you can change the license options later.\n\nA: *\n\n*gEDA Project (with pcb and gerbv tools)\n\n*KiCad\n\n*Fritzing\n\n\nAll are in Ubuntu repository.\nSee http://www.gpleda.org/\n\nA: Eagle is a commercial closed-source product.  There is a limited capability free (non-commercial use) version available, though for any non-trivial project that isn't enough.  (One schematic page and 4x6 inch 2-sided PCB doesn't get you all that far.)\nThat said, it is quite a good product, if you can live within the limitations of the free version, or are willing to pay for the less limited commercial licenses.  Among other things, defining new devices (schematic symbols and PCB footprints) is straightforward, which isn't necessarily true for other programs including some very expensive \"professional\" ones.\n\nA: I think EasyEDA will meet your need. EasyEDA is a free Web-based EDA tool which provides schematic capture, simulation and PCB design.\nIt’s a perfect tool for helping you complete your design from schematic to the finished PCB in the shortest time and easiest way. No matter you are using Mac, Linux or Windows; Chrome, Firefox, IE, Opera, or Safari, EasyEDA has all the features you expect and need to rapidly and easily take your design from conception through to production. \nEasyEDA aims to bring an easier EDA experience to every electronic hobbyist. \\There is a large amount of open projects on it. Users can access to Open Source modules developed by thousands of electronics engineers. https://easyeda.com/explore\n", "Q: Install native texlive in parallel to repo version I'm still running Ubuntu 12.04 and I would like to manually install the most recent texlive. One of the first steps for the manual installation is to get rid of existing installations of texlive. However, I want to keep my default texlive installation from the Ubuntu repositories, since I have a huge number of LaTeX documents, which sometimes may rely on version-specific modifications.\nTherefore my question is how to use a native texlive installation (or possible multiple) in parallel to the installation from the Ubuntu repositories? What steps in the manual installation change in order to account for an existing installation? And how do I tell my system which texlive distribution I want to use? \nI think answering this question will probably answer all my related questions as well, like for instance: Is the current distribution only determined by the executables which are currently in the PATH? And if so, how can I quickly switch between the distributions? It looks like the texlive binaries in /usr/bin are not symlinks but real binaries, so I'm not sure how I can hide their existence without deleting them. And what may also be challenging: How can I find out all binaries that belong to a texlive distribution (pdftex, pdflatex, luatex, xetex, ...)? Will changing the distribution automatically affect build systems/editors (like rubber/latexmk/eclipse/gedit) as well, or is it necessary to make manual changes each time?\n\nA: Disclaimer: I have found a solution and it seems to work well.\nUpdate: I can now confirm that the procedure below works as well with Texlive 2015.\nIn general it looks like working with parallel installations is easier than expected. To setup the native version I did the following:\n\n\n*\n\n*Download the net installer, and extract it in a temporary location (the net installer is an interactive command line tool, allowing to modify various settings during setup).\n\n*Run the installer portable mode, i.e., install-tl -portable. This will bring up the main menu of the installer.\n\n*In this setting menu, I simply changed the TEXDIR (by pressing D) to a path within my home, e.g., ~/bin/texlive. This automatically changes the other TEXDIR* as well. I did not change anything else (installation scheme was set to scheme-full). Overall, the installation with the net installer is very convenient.\nInspired by the documentation section \"Environment variables for Unix\" I created a file setenv.sh in the installation directory with the following content:\ndir=`cd \\`dirname $0\\` && pwd`\nexport PATH=\"$dir/bin/x86_64-linux:$PATH\"\nexport MANPATH=\"$dir/texmf-dist/doc/man:$MANPATH\"\nexport INFOPATH=\"$dir/texmf-dist/doc/info:$INFOPATH\"\n\nIn order to switch to the new texlive distribution I simply source this file. So far, it looks like everything is working well with both the existing and the new texlive distribution.\nIt looks like Kpathsea is the tool in texlive which is responsible for locating the different parts/directories of the distribution (Kpathsea path searching). I wrote the following script to check whether switching to the new distribution really changes all those TEXMF* directories:\necho \"which kpsexpand: `which kpsexpand`\"\necho \"TEXMFDIST:       `kpsexpand '$TEXMFDIST'`\"\necho \"TEXMFLOCAL:      `kpsexpand '$TEXMFLOCAL'`\"\necho \"TEXMFHOME:       `kpsexpand '$TEXMFHOME'`\"\necho \"TEXMFCONFIG:     `kpsexpand '$TEXMFCONFIG'`\"\necho \"TEXMFSYSCONFIG:  `kpsexpand '$TEXMFSYSCONFIG'`\"\necho \"TEXMFVAR:        `kpsexpand '$TEXMFVAR'`\"\necho \"TEXMFSYSVAR:     `kpsexpand '$TEXMFSYSVAR'`\"\necho \"TEXMFCACHE:      `kpsexpand '$TEXMFCACHE'`\"\n\nRunning this without sourcing my setenv.sh file gives the following output:\nwhich kpsexpand: /usr/bin/kpsexpand\nTEXMFDIST:       /usr/share/texmf-texlive\nTEXMFLOCAL:      /usr/local/share/texmf\nTEXMFHOME:       /home/bluenote/texmf\nTEXMFCONFIG:     /home/bluenote/.texmf-config\nTEXMFSYSCONFIG:  /etc/texmf\nTEXMFVAR:        /home/bluenote/.texmf-var\nTEXMFSYSVAR:     /var/lib/texmf\nTEXMFCACHE:      $TEXMFCACHE\n\nThis shows that the standard texlive from the Ubuntu repositories is in use. After sourcing, the output becomes:\nwhich kpsexpand: /home/bluenote/bin/texlive/2013/bin/x86_64-linux/kpsexpand\nTEXMFDIST:       /home/bluenote/bin/texlive/2013/texmf-dist\nTEXMFLOCAL:      /home/bluenote/bin/texlive/2013/../texmf-local\nTEXMFHOME:       /home/bluenote/bin/texlive/2013/../texmf-local\nTEXMFCONFIG:     /home/bluenote/bin/texlive/2013/texmf-config\nTEXMFSYSCONFIG:  /home/bluenote/bin/texlive/2013/texmf-config\nTEXMFVAR:        /home/bluenote/bin/texlive/2013/texmf-var\nTEXMFSYSVAR:     /home/bluenote/bin/texlive/2013/texmf-var\nTEXMFCACHE:      /home/bluenote/bin/texlive/2013/texmf-var:/home/bluenote/bin/texlive/2013/texmf-var\n\nI don't fully understand why using a different binary causes all these \"tex variables\" to change as well. I was expecting that the binary has no information that it is part of a different distribution, but fortunately it has! Note that these \"tex variables\" are no unix-like environment variables (that's why it is important to use single quotes when passing them to kpsexpand). I'm a bit surprised that I did not have to modify any of them via export -- in fact, they are all undefined. But so far everything seems to be working.\n", "Q: Is this CPU usage for TeamViewer on Ubuntu normal? If so, are there any better options? \nThis image was taken while logged in remotely via TeamViewer to my workstation.\n\n\n*\n\n*There are four TeamViewer_Desktop processes open (why?), two of them taking a large amount of CPU (why?).\n\n*I tried connecting to a Windows system, and while the memory usage is about the same (a couple of hundred Mb) that only uses about 1 % CPU on the Windows system, indicating TeamViewer runs much better on Windows.\n\n\nI am suspecting that TeamViewer for Linux is just a poorly implemented Wine bundle and that this might be expected, but I just wanted to confirm -- is this how you see TeamViewer performing as well? And if so, are there any better options that you can link guides to that accomplish the same firewall-agnostic remote desktop solution for both Windows and Linux?\n\nA: Team Viewer is a popular universal remote control application. It runs on IOS, Linux, Android, Windows, and Mac etc. It is great that this software is available for Linux, but I have also observed high CPU load when it comes to active Team Viewer sessions. The CPU load goes away when you disconnect. Part of the explanation for this could be that the CPU is used for all rendering and not the graphics card, which may be why it has a lower CPU usage in Windows and Mac. Unfortunately I have been unable to find an alternative that is a perfect match. \nAll suggestions that suggest that somehow VNC or its derivatives are somehow a substitute, are ill researched suggestions. Though you can remote control a desktop session using VNC it is not nearly as efficient as TeamViewer. NX and its derivatives are on equal par when it comes to performance, and there are even open source implementations that use RDP quire successfully. However, no other solution allows you to traverse firewalls and NAT with absolutely no configuration. Team Viewer works in the same way as Skype does in the sense that it simply auto discovers how to get to the internet and sign in, then locates all the associates to your account (computers in the case of Team Viewer). This is the main feature of Team Viewer and the main reason it has become so popular; and I am sad to see that there is no open source counterpart to team Viewer. \nAn open source implementation of Team Viewer would be a seriously useful tool in combination with Ubuntu One or something similar. \nTo mitigate the effects of high CPU use you can try to set a lower priority for the teamviewerd, and TeamViewer GUI processes. You may also be able to buy a license and then open a bug or case in regards to CPU load and see if they address the problem. Otherwise I think you are out of luck. \n\nA: May be too late to answer but I observed this on my setup Ubuntu 14.04 machine (6 cores) accesses from a Windows 10 machine using TeamViewer 11. The CPU usage would shoot up to 400% at times.\nI disabled the animation effects on Ubuntu (using compiz settings manager) and the CPU load returned to \"normal\" (~50%).\nI hope that this helps.\n", "Q: Are there alternatives to unetbootin? Is there any software like unetbootin in Ubuntu?\nI cant install or run unetbootin-494 even though I already set it to allow executing files as programs.\n\nA: There are many tools similar to unetbootin. Karel already told you to install unetbootin itself, a few other choices are:\n\n\n*\n\n*MultiSystem \n\n*LiveUSB\n\n*YUMI\nYou'll notice that all three links above are on pendrivelinux.com which has various other tools and tutorials on creating Live USBs or CDs.\n\nA: I find using Ubuntu's (and not only) built-in tool, called gnome-disk-utility, to be the most convenient way to make a bootable USB stick.\nOpen it and from the list on the left side select the device that you'd like to put the iso on (supposedly a USB stick).\n \nAfter that, click on the two gear icons and select \"Restore Partition Image...\".\nNavigate to the target ISO file and select it. Then press \"Start Restoring...\".\n\nIt will ask you for your password and additional confirmation before it actually starts transferring the file.\nNote: If you do not have the tool for some reason, you could use one of the commands below (appropriate for your system). It should be in the standard repositories for all major distributions:\nUbuntu and derivatives:\nsudo apt install gnome-disk-utility\n\nFedora:\nsudo yum install gnome-disk-utility\n\nArch:\nsudo pacman -S gnome-disk-utility\n\n\nA: Yes, there is UNetbootin itself. UNetbootin can be installed from the default Ubuntu repositories. UNetbootin from the default Ubuntu repositories will run natively in Ubuntu without any problems. UNetbootin is more versatile than you might think. Many Linux distros that are not on UNetbootin's supported list of distros can be installed successfully on a USB flash drive using UNetbootin. There is one big thing that UNetbootin can't do however. UNetbootin sometimes has trouble booting Ubuntu on certain models of older hardware. In such cases the Ubuntu Mini CD can often be used to install Ubuntu. Since the Ubuntu Mini CD is small (less than 40MB) and text only, it can often boot successfully, even when a full-sized Ubuntu DVD/USB can't boot.  \nUNetbootin has been dropped from the Ubuntu 18.04 repositories. When I tested the built-in Startup Disk Creator application as a UNetbootin replacement app with 5 non-*buntu live .iso images it worked in Ubuntu 18.04.\nReferences:\n\n\n*\n\n*UNetbootin PPA – for Ubuntu 18.04+  \n\n*Ubuntu Mini CD\n\nA: Startup Disk Creator (Click here to see original version)\n\n\n*\n\n*Insert a USB stick of appropriate capacity\n\n*Open the dash and search for Startup Disk Creator\n\n*Select the Startup Disk Creator to launch the app\n\n\n\n\n\n*Click 'Other' to choose the downloaded ISO file if it isn’t found automatically, select the file and click 'Open'.   Select the ISO\n\n\n\n5.Select the USB stick in the bottom box and click 'Make Startup Disk' and then 'Yes'\n\n\n\n*Allow process to complete and test.  \n\n\nIf you are successful with this process, then please provide feedback by upvoting.  Best of luck!\n\nA: The main task of mkusb is to wrap a safety belt around the cloning tool dd.\nmkusb works in and with all current versions and flavours of Ubuntu. It works also in and with several other linux distros, and can create boot drives with Windows 7-10. (Creating persistent live drives is limited to Ubuntu, Debian Jessie and distros with the same boot structure.)\nThe classic mkusb version 11 has many features and is polished and debugged. The next/new mkusb version 12 (alias dus with the graphical user interface guidus) has a simplified user interface, that is very easy to use. It is getting ready to become the default version very soon, after a period of testing and debugging.\nSee these links for more details,\nhelp.ubuntu.com/community/mkusb\nhelp.ubuntu.com/community/mkusb/gui#Installation\nmkUSB-quick-start-manual-11.pdf\nmkUSB-quick-start-manual-12.pdf\n\n\nA: There's also OpenSUSE Image Writer, but it's limited. However, in my experience, I've had NO PROBLEMS using it. If you are using WinBlows, you can also try Rufus.\n\nA: Download (to the same folder) the required UBUNTU installer ISO and associated SHA256SUMS (or higher) file from: http://releases.ubuntu.com/ \nVerify ISO file signature:\n$ cd [path to ISO & SHA256SUMS files] \n$ sha256sum -c SHA256SUMS 2>&1 | grep OK \n\nConfirm OK.\nInsert USB drive.\nFind out which block device the target USB drive is identified as:\n$ lsblk\nNAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nsda      8:0    0 111.8G  0 disk \n├─sda1   8:1    0   512M  0 part /boot/efi\n└─sda2   8:2    0 103.5G  0 part /\nsdb      8:16   1  28.7G  0 disk \n└─sdb1   8:17   1  28.7G  0 part /media/user/USBdrive\n\nUnmount the target USB drive (in this example I use sdb1, it may be different on your machine):\n$ sudo umount /dev/sdb1\n\nCopy the ISO from source to the PARENT USB drive block device (WITHOUT the number):\n$ sudo cp [path to iso file]/[iso file] /dev/sdb\n\nNote: This copy instruction will automatically extract the files from the ISO to the target USB drive and make it bootable.\nSynchronise cached writes to persistent storage:\n$ sync\n\nDone.\n", "Q: Conky black background on Unity I'm using Ubuntu 13.10 (and 14.04 on another computer) with Unity. Conky doesn't work like I expect. This is my config:\nalignment top_right\nbackground yes\nborder_inner_margin 0\nborder_width 0\ntop_cpu_separate yes\ndefault_color ffffff\ndefault_outline_color 000000\n#default_shade_color 999999\ndouble_buffer yes\ndraw_borders no\ndraw_graph_borders yes\ndraw_outline yes\ndraw_shades no\ngap_x 0\ngap_y 30\nmaximum_width 222\nminimum_size 222\nown_window yes\nown_window_hints undecorated,below,sticky,skip_taskbar,skip_pager\nown_window_transparent yes\nown_window_argb_visual yes\nown_window_argb_value 0\nown_window_type override\nown_window_class conky-semi\nshow_graph_scale yes\ntotal_run_times 0\nupdate_interval 5\ntext_buffer_size 1024\nuse_xft yes\nxftfont Ubuntu:size=8\n\nIn this config Conky have black background, not disappear when showing or clicking desktop. If I change own_window_type to 'desktop' Conky runs with transparency but if I click on desktop it disappear (but still working). If I change own_window_type to 'normal' it have transparency and doesn't disappear on clicking on desktop but it minimize when I click on show desktop button and doesn't recover (still running).\n\nA: \"If I change own_window_type to 'normal' it have transparency and doesn't disappear on clicking on desktop but it minimize when I click on show desktop button and doesn't recover (still running).\"\nDo not minimize on Show Desktop\nUsing Compiz: If the 'Show Desktop' button or key-binding minimizes Conky along with all other windows, start the Compiz configuration settings manager, go to \"General Options\" and uncheck the \"Hide Skip Taskbar Windows\" option. \n\nhttps://wiki.archlinux.org/index.php/conky\n\nA: I have a similar problem, I found a setting that gets it \"almost\" right, try it yourself, see if it helps\nown_window_class Conky\nown_window yes\nown_window_type normal\nown_window_argb_visual yes \nown_window_argb_value 25\nown_window_hints undecorated,below,sticky,skip_taskbar,skip_pager\n\n\nA: Try adding this lines:\nown_window_type normal\n\nown_window_hints undecorate,sticky,skip_taskbar,skip_pager,below\n\n\nA: I don't think there is a way to do this properly that works on Unity (it will on other desktop environments). However, here a workaround: use xdotool to make conky visible again after you loose it:\n\n\n*\n\n*Install xdotool\nsudo apt-get install xdotool\n\n\n*Use these settings in your ~/.conkyrc:\nown_window yes\nown_window_hints undecorated,below,sticky,skip_taskbar,skip_pager\nown_window_transparent yes\nown_window_argb_visual yes\nown_window_argb_value 0\nown_window_type desktop\nown_window_class conky\n\n\n*Now, when you loose conky, you can get it back by running this command:\nxdotool windowactivate `xdotool search  --class conky`\n\n\n*Create this little script and save it as run_conky.sh:\n#!/usr/bin/env bash\n\n## Kill any existing conoky instance\nkillall conky\n\n## Launch conky\nconky &\n\n## As long as conky is running, run the xdotool command\n## to make it visible every two seconds\nwhile true; do\n    pgrep conky && xdotool windowactivate `xdotool search  --class conky`\n    sleep 2\ndone\n\n\n*Make the script executable (chmod +x start_conky.sh) and add it to your startup applications. Basically, use the script to launch conky at login instead of running the conky command.\nThe result of this is that conky will magically appear after 2 seconds (change the sleep value to 1 to make it faster but 2 is fine and is less of a load on your system). I tested it on Unity on 13.10 and it works fine.\n", "Q: What is the best value for the bs option of dd command? I am using the dd command for the first time, so I am wary, I've reading articles in wikipedia but have some unclear part, so I am asking here, is bs option matter? If I set the wrong number, would things go wrong? Like some bite in the drive be omitted or fail to copy? What's the best value for it?\n\nA: While it is true that dd is dangerous, there is also some paranoia about it. It is dangerous because if used wrongly, you can easily overwrite the data on your disk, not because it explodes if you bump it against the wall. You shouldn't be terrified of it, just read through man dd to get an idea of how it works.\nAnyway, the bs option simply controls how many bytes dd should read at a time. The \"right\" value will depend on what you are trying to do but a \"wrong\" value will simply make the operation slower. This is not where the danger lies. As explained in info dd:\nbs=BYTES'\n     Set both input and output block sizes to BYTES.  This makes `dd'\n    read and write BYTES per block, overriding any `ibs' and `obs'\n    settings.  In addition, if no data-transforming `conv' option is\n    specified, input is copied to the output as soon as it's read,\n    even if it is smaller than the block size.\n\nThe common danger with dd is that it is simple to mistake the input file for the output file and end up wiping your drive. That is what you should look out for.\n\nThat said, for a new Linux user, it really makes much more sense to use a differfent tool to clone a hard drive. Instead of using a normal Linux distribution CD, use one that is specifically created for this task. For example http://clonezilla.org/. Just download the clonezilla ISO, burn it onto a CD and boot from it. It will present you with an interactive menu allowing you to easily make an image of your hard drive:\n\n", "Q: Dual Boot problems (Win 8.1 and Ubuntu 13.10), Boot-repair didnt work I have preinstalled Windows 8.1 and Ubuntu that I installed a week ago on my Laptop Lenovo E530. After my first installation of my Ubuntu 13.10 as Dual Boot, I could not to log in to Windows again, only Ubuntu.\nToday I decided to fix this problem with Boot-repair. I used a bootable version of my Ubuntu on my USB to log in, then I downloaded the Boot-repair via Terminal. Then in Boot-repair I choosed the Recommended repair and followed all the instructions, including confirmation of the removing my Grub 2. After that, when I restart the computer, everything what I see now is black screen with error message:\n\nerror: file '/boot/grub/i386-pc/normal.mod' not found.\nEntering rescue mode... \ngrub rescue>\n\nNow I cant log in to any operating system. Probably the Grub doesn't load.\nCan anyone help?\n\nA: Best is to reïnstall Grub with an live-cd.\nStep 1)\nFrom a live cd open an terminal \nStep 2)\nsudo mount /dev/sdXY /mnt (sdXY should by your root Example /dev/sda5)\nStep 3)\nsudo mount --bind /dev /mnt/dev && sudo mount --bind /dev/pts /mnt/dev/pts && sudo mount --bind /proc /mnt/proc && sudo mount --bind /sys /mnt/sys\nStep 4)\nsudo chroot /mnt\nStep 5\ngrub-install /dev/sdX && update-grub\nStep 6\nexit && sudo umount /mnt/dev && sudo umount /mnt/dev/pts && sudo umount /mnt/proc && sudo umount /mnt/sys && sudo umount /mnt\nReboot and here you go. \n\nA: if you have the windows disc, and the Windows Recovery option during the install.\nyou may also try the ubuntu boot disc itself and the problem with the grub will be alright!\nfor further help from windows, use this link http://support.microsoft.com/kb/927392\nyou can find the detailed description of how overwrite the grub, from the second reply of this link How to delete GRUB entirely from GRUB rescue and boot Windows only  in this case, the windows will take over the control and ubuntu will be shown as an option!\n", "Q: How to get a sid pbuilder in ubuntu Before releasing packages to Debian (and later sync them to Ubuntu) I need to test them in a sid chroot, but I get this error on a clean 14.04 system:\n$ sudo DIST=sid ARCH=i386 pbuilder create\n[sudo] password for u: \nI: Distribution is unstable.\nI: Current time: Mon Mar 17 09:37:53 EDT 2014\nI: pbuilder-time-stamp: 1395063473\nI: Building the build environment\nI: running debootstrap\n/usr/sbin/debootstrap\nI: Retrieving Release \nI: Retrieving Release.gpg \nI: Checking Release signature\nE: Release signed by unknown key (key id 8B48AD6246925553)\nE: debootstrap failed\nW: Aborting with an error\nI: cleaning the build env \nI: removing directory /var/cache/pbuilder/build//8688 and its subdirectories\n\nWhat type of keys do I have to install to avoid such failure?\n\nA: In order to get it fixed I had to install:\nsudo apt-get install debian-archive-keyring\n\nAnd then create the chroot with\nsudo DIST=sid ARCH=i386 pbuilder create --debootstrapopts \\\n--keyring=/usr/share/keyrings/debian-archive-keyring.gpg\n\n\nA: With Ubuntu 12.04 Precise you might want to check the comment #18 at https://bugs.launchpad.net/ubuntu/+source/pbuilder/+bug/599695\nIn short:\n\n\n*\n\n*The key ID 8B48AD6246925553 in the error message is for Debian 7.0 Wheezy, so...\n\n*... find the corresponding key 46925553 from http://keyserver.ubuntu.com:11371/pks/lookup?op=vindex&search=debian+archive&fingerprint=on\n\n*Save the key to <file>\n\n*Add it with\n\n\n\nsudo apt-key add <file>\n\nNow you can do\n\npbuilder-dist sid create --debootstrapopts --keyring=/etc/apt/trusted.gpg\n\nand after this you can build stuff without having to give the keyring option anymore.\nEven better would be to add the key directly to /usr/share/keyrings/debian-archive-keyring.gpg.\n", "Q: Vixiecron doesn't allow disabling of emails, how can I disable cron emails globally? Every time the cron runs there are some sendmail processes being created which take our machine to huge high loads. We have chased this problem down to cron and sendmail.\nAdding MAILTO=\"\" on top of the cron is a solution, piping each cron command to dev null is another solution but I need a global solution... some sort of configuration on cron or so.\nVixiecron DOES NOT have the following option which I believe it would fix my problems\n-m     This option allows you to specify a shell command to use for sending Cron mail  output  instead  of\n      using  sendmail(8)  This command must accept a fully formatted mail message (with headers) on stan‐\n      dard input and send it as a mail message to the recipients specified in the mail headers.  Specify‐\n      ing the string off (i.e., crond -m off) will disable the sending of mail.\n\nSo how can I globally disable cron emails completely?\n\nA: When it has to be vixie-cron adding MAILTO=\"\" on top of the cron is the solution. There is no global method (all options are stored in the respective users crontab). This \n\ncron then  wakes  up  every  minute,  examining  all  stored  crontabs,\n         checking each command to see if it should be run in the current minute.\n         When executing commands, any output is  mailed  to  the  owner  of  the\n         crontab (or to the user named in the MAILTO environment variable in the\n         crontab, if such exists).  The children copies of  cron  running  these\n         processes  have their name coerced to uppercase, as will be seen in the\n         syslog and ps output.\n\nhas no additional configuration so is executed always (it is also possible to kill the sending of mails by adding >/dev/null 2>&1 or &>/dev/null to the command itself; but that would be more work then editing all crontabs).\nThe link also states:\n\nEach user can have their own crontab, and though these are files in /var/spool/cron/crontabs, they are not intended to be edited directly. \n\nI see 3 possible options:\n\n\n*\n\n*My preferred method would to edit all the crontabs with crontab -e.\n\n*use another cron that does have a method for globally setting MAILTO (which cron and how to do this is for another question ;) )\n\n*ignore the warning and edit all files from commandline with a for/next loop. I read that as \"you can if you really really really really really really want to.\". Mind the remarks in these 2 topics about this: ubuntuforums and serverfault. As far as I can tell the only problem you face (if done correctly!) is that your change gets overwritten if someone does use crontab -e.  But if you all agree that if someone does change a crontab with crontab -e that they also HAVE to include the MAILTO='' that concern should be taken care of (since the change you made is overwritten by the new crontab but that one also includes your change).\n", "Q: Problem downloading Oracle JDK 7 I'm using Ubuntu 12.04 LTS. I'm trying to install Oracle JDK 7. When I tried to directly download the jdk-7u51-linux-x64.tar.gz from the official website, the download started and after downloading couple of MBs it stopped (you can try it as well, worked the same way for a friend).\nUsing a guide.\nled me to \nOracle JDK 7 is NOT installed.\ndpkg: error processing oracle-java7-installer (--configure):\n subprocess installed post-installation script returned error exit status 1\nErrors were encountered while processing:\n oracle-java7-installer\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nwhich is normal, as it is downloading from the same link. Exact report here\nI tried to download and install the .rpm file. I converted it to deb and installed it. It appears as installed in the Software center, but could not find it via terminal (java -version returns suggestions for installing packages). Image from the Software center here\nI tried everything here.\nand could not find anything on the internet. \n\nA: I suggest you use webup8's PPA. I use it for Java 8, but there's also for Java 7.\nSee here for Java 7\nhttp://www.webupd8.org/2012/01/install-oracle-java-jdk-7-in-ubuntu-via.html\nand here for Java 8 (both can coexist in your system)\nhttp://www.webupd8.org/2012/09/install-oracle-java-8-in-ubuntu-via-ppa.html\n", "Q: directing Ubuntu install to correct device Sorry to ask what must be an oft-asked question but I am not seeing another thread with the solution.\nI am trying to install Ubuntu 13.10 for a dual boot setup on a system that has two HDDs on it, one 149Gb the other 249Gb .\n\n\nWindows 7 is already installed on the 149Gb drive.\nWhen I just run the Ubuntu installation from USB, it defaults to the 249Gb drive. \nWHen I restart, my system goes straight into Windows 7, no Dual Boot option on startup.\nFrom my reading I think I need to push the Ubuntu install to the same device as Windows now occupies. I started down the last option in the Install (something along the lines of \"manually install by specifying partitions\") but that leads me to a partitioning type screen that I don't feel like messing with.\ncan someone advise or direct me to the step by step instructions I need.\nOr, does this problem have nothing to do with the fact that I have two physical HDDs with one OS on each? \n\nA: IN the end I just took the inelegant approach of disconnecting the 2nd HDD, and redoing the Ubuntu installation on the sole primary drive. This time it prompted me as described in the install steps to allocate space between Windows and Ubuntu.\nI reconnected the 2nd drive and on reboot, I got the Dual Boot prompt choices.\nThere must be a more elegant approach but this got the job done.\nPeter\n", "Q: Default webcam app On a fresh 12.04 install what app does ubuntu use to take initial user profile pic?\nI want to use the same app to run webcam tests.\nThanks\n\nA: Many applications are installed while Ubuntu is being installed but later removed to make the OS lighter and free from unwanted applications.\nSome of them are:\n\n\n*\n\n*gparted- the application that you see when you partition your disk during installation\n\n*cheese- the application that clicks your photo using your webcam during installation\nTo install cheese, go to your dash and type \"software center\", open the application and type \"cheese\" in the search bar on the top-right corner and click on \"Install\".\n", "Q: How do I show the outside temperature in the indicator bar? I recently moved onto 13.10. After the upgrade, the current weather was no longer displayed with an indicator. How do I get that back?\nI've seen one potential duplicate but the indicator-weather package doesn't seem to exist any more (the apt link didn't run and Software Centre says there are no items with that name). \n\nA: Indicator-Weather dev team started new series (2.0). It is available from their Stable PPA\nDaily build PPA is available too, Check team page.\n", "Q: Unable to turn on HP zd7000 Wireless on 12.04 I have installed 12.04 on a zd7000 everything is working except for the wireless.  The Broadcom STA drivers are installed and active.  Just cannot get the wireless to turn on.  \nPlease advise.\nOutput of lspci -nn | grep 0280\n02:03.0 Network controller [0280]: Broadcom Corporation BCM4306 802.11b/g Wireless LAN Controller [14e4:4320] (rev 02)\n\n\nA: I believe the Broadcom STA driver, also known as bcmwl-kernel-source, is incorrect for your device. Please get a temporary wired ethernet connection, open a terminal and do:\nsudo apt-get purge bcmwl-kernel-source\nsudo apt-get update\nsudo apt-get install b43-fwcutter firmware-b43legacy-installer\n\nAfter it finishes, detach the ethernet, reboot and let us hear your report.\n", "Q: Setting MAC addres in live Ubuntu 13.10 I'm trying to install 13.10 on a separate HDD (another HDD is running WinXP) from a USB stick. I have encountered 2 problems.\n\n\n*\n\n*When I try to connect to internet from live Ubuntu (to get help with installation), I get a message from my ISP: \"Access denied, if you have changed your network adapter please contact our support\". The support advised me to manually set my MAC address in Ubuntu.\nI used \"sudo gedit|grep HWaddr\" and Ubuntu indeed shows different MAC address than WinXP.\nQuestion: How do I set MAC address in live Ubuntu 13.10?\n\n*When I try to proceed with installation without internet connection, the installer gets to the screen where I am supposed to set my location, shows New York (I'm in Poland) and instantly quits.\nQuestion: Is there a way to install Ubuntu without internet connection?\n\nA: Easiest way to change mac address on nic is:\nsudo ifconfig eth0 down\nsudo ifconfig eth0 hw ether  xx:xx:xx:xx:xx:xx\nsudo ifconfig eth0 up\n\nWhere xx:xx:xx:xx:xx:xx represent mac address\n", "Q: How to convert to a Lighter wight Ubuntu 13.04 Desktop I am using Ubuntu 13.04 Desktop and I'm happy with it. However sometime I think the older versions were better as they were lighter or utilized less resources.\nIs there any way that, it will ask me during every boot time to choose a different settings or GUI (maybe) so that it will utilize less resources. I don't want to uninstall/loose anything permanently. \nNote: Again I am happy with my current full featured Ubuntu Desktop.\nI have read about Lubuntu, can I put it beside/within my current Ubuntu installation without loosing anything?  It will appreciate if there is any other better idea.\n\nA: Yes you can!! :D\nJust head to the software centre and type \"LXDE\" and install it. (LXDE is Lubuntu!! Consider it another name for the same thing.)\nThis will make you able to choose between \"Unity\" (which is the default desktop you know about) and LXDE which is awesome and lightweight.\n\nYou see that white circle with the Ubuntu logo in it? (above) Just click on it to choose between Unity and LXDE!!\nYou won't lose any features and you can use Unity again whenever you want! A desktop environment is just a selection of programs (such as a different windows manager, a different files manager, a different audio player and so...)\nThe one and only thing you wouldn't like is that it's ugly! XD but there are forums that describe how to make it look more similar to Unity. It's super fast and I use it by default. :)\n...ah yes! A word about Ubuntu 13.04. It's outdated and not supported anymore!! But luckily you can upgrade to Ubuntu 13.10 very simply through the update manager. (The window that usually pops up asking for updates). It'd ask you if you want to upgrade to 13.10 so you just accept the upgrade and you're totally done!! :D\n", "Q: Upload Photos in 12.04.4 I will be new to Ubuntu in a couple weeks.  I am currently a WindowsXP user.  So, my question is: Does Ubuntu 12.04.4 have a utility that will allow me to upload photos from a smartphone(BB) and a digital camera(Nikon)?  If so, how well does it work and should I be aware of any glitches?\nPlease advise.\nFranco\n\nA: You're probably looking for Ubuntu One. It's Ubuntu's cloud service and it works fine for me ^_^ You can also try dropbox but I don't know how integrated it is.\n\nMore information and downloads:\nUbuntu One: https://one.ubuntu.com/ \nDropbox: http://www.dropbox.com/\n", "Q: Graphical GRUB Menu As you know, when dual booting on OSX you get a nice looking boot menu, something like:\n\n(source: askdavetaylor.com)\nI was curious as to whether there is a way to replace the textual interface of GRUB with something a little more, \"GUI\"-ey. To an extent, to emulate the nice-looking OSX boot menu.\nTo change this:\n\nto something nicer.\nIf it is not possible with GRUB, is it possible with another bootloader?\nI have already tried using grub-customizer, but it only allows you to change the color of the text.\nDoes anything like this exist in the Linux world? Or is this Mac-only eye candy?\n\nA: Try BURG. I'm sure this is exactly the ticket. It is a themeble GUI overlay for GRUB & Grub Customizer can still administrate. \nBrand-new Universal loadeR from Grub;\nburg is a brand-new boot loader based on GRUB. It uses a new object format which allows it to be built in a wider range of OS, including Linux/Windows/OSX/FreeBSD, etc. It also has a highly configurable menu system which works in both text and graphic mode. Additional features like stream support and multiple input/output device are also planned.\n\nBut, yes, as of comment, not actively maintained. Still I am not aware of an alternative, lets hope a developer picks up the slack...\n\nA: Download a nice GRUB Theme\nsudo tar -zxvf ~/Downloads/GRUB2-DarkSquares.tar.gz -C /boot/grub2/themes\nsudo nano /etc/default/grub\n#GRUB_TERMINAL_OUTPUT=\"console\"\nGRUB_THEME=\"/boot/grub2/themes/dark_squares/theme.txt\"\nGRUB_GFXMODE=\"1024x768\"\nsudo grub2-mkconfig -o /boot/efi/EFI/fedora/grub.cfg  # Or just /boot/grub2/grub.cfg with one distro.\n\nWorks on my Fedora 32 next to Ubuntu 20.04 where update-grub is a stub for running grub-mkconfig -o /boot/grub/grub.cfg to generate a grub2 config file.\n", "Q: Upgrade Fiasco, again! In the middle of upgrade (from 13.04 to 13.10) the download stopped (for 2 hours, I was sure it was not going anywhere) and when even Firefox stopped working I was forced to reboot and, voila, my Satellite is blacked out.  I tried \"safe mode\" and \"repair damaged package\" but no effect. (I can see these screens, in that sense it is not a total blackout and Satellite is TRYing to do something and give me lots of data but they dont make much sense to me) Could anyone suggest where I can go from here?\nThis is the 3rd consecutive upgrade fiasco for me upgrading, each time it gave me headache and it is affecting my view of Linux.  Why does the upgrade have to be this \"high risk\" thing to do?  Why cant I revert to the original state if I wasn't successful?\nAnyway, any help much appreciated\n\nA: In the case of broken upgrades, booting to a Live CD or USB (doesn't really matter which version of Ubuntu) and using a terminal can sometimes rescue a borked upgrade. I have to underline that you may run into exactly the same issue as before but at this point, there's little to lose.\nAfter booting to your Live-whatever, open a terminal and run\nsudo fdisk -l\n# work out which disk/partition is your main install and use it\n#   instead of sda1 in the following:\nsudo mount /dev/sda1 /mnt\n\nfor i in dev proc sys run; do sudo mount -B $i /mnt/$i; done\nsudo chroot /mnt\n\nAt this point, for all intents and purposes you are root on your old system. Simply ask it to finish whatever package manoeuvres it was doing before it crashed:\ndpkg --configure -a\n\nAnd hopefully when that's finished you should be able to boot to it.\n", "Q: There is an alternative to launchpad for a deb repository? I'm curious to know if there is a real alternative to Launchpad for a developer who wants to build his own repository.\n\nA: A repository is just series of directories. It's commonly on a web server (over http) but it doesn't have to be. The full process of doing this is long:\n\n\n*\n\n*Create and upload a GPG signing key\n\n*Build and sign your packages\n\n*Set up a web server to host these things\n\n*Use something like Dak or Reprepro to set up the directory structure and export that to the webserver.\n\n\nThe result is a real repository that you control. The difference from a LP repo is there's no shortcut for adding your signing key to the client computers. You'll have to get them to use the old-fashioned method:\nwget -q http://path/to/key.asc -O- | sudo apt-key add -\n\nAnd then add the repo (add-apt-repository can add http://... addresses).\nAnd even after that, you need to guarantee uptime. If you can't keep the repo up you're going to cause 404 warnings on clients' machines. Nobody likes that.\nDebian has the best documentation on how to do this:\n\n\n*\n\n*https://wiki.debian.org/HowToSetupADebianRepository\n\n*https://wiki.debian.org/SettingUpSignedAptRepositoryWithReprepro\n", "Q: Installing NVIDIA GEFORCE 750M drivers Is there any way to install NVIDIA GEFORCE 750M drivers for Ubuntu?\nRight now Intel Haswell Mobile is used for graphics. Is this ok? Can I get better performance by installing NVIDIA drivers?\n\n\n\nI remember that last time when I installed something related to that, my Unity was broken. After uninstalling them Unity worked again.\n\nA: I fixed the problem by installing the tested NVIDIA drivers for Ubuntu:\n\n\n\nI can see the following details:\n\n\n\nSo, GeForce GT 750M /PCIe/SSE2 driver is installed.\n\nBTW, I switched again on the open source driver. NVIDIA drivers had important issues (overheating and sometimes the entire screen was freezing).\nAfter applying changes and rebooting Ubuntu started in low graphics mode. I pressed ALT + CTRL + F1. I deleted the following file:\n sudo rm /etc/X11/xorg.conf\n\nThen I restarted the PC:\n sudo reboot\n\nMy machine uses again the open source driver and it works fine. If you don't have big issues with the open source driver, I really recommend not to switch on the closed source one.\n\nA: Installing the drivers from NVIDIA website worked for me. just download the latest stable version for your card here.\nNow, the only problem is the graphic server have to be down to install them. Save the file .run in your desktop and switch to a tty with Ctrl + Alt + F6\nLog in and type the following commands:\nsudo service lightdm stop\nchmod +x NVIDIA*.run \nsudo ./NVIDIA*.run\n\nFollow the on-screen instructions. If it tells you something like \"pre install script for your distribution failed\" that's normal, just chose yes. When it's done, reboot with:\nsudo shutdown -r now\n\nNote that I've used the * but you could use the full name of the file, which depends on what version you download. I'd recommend you to use the latest stable, right now 334.21.\n\nA: Did you give a try to 352.41 driver?\nsudo apt-get purge nvidia*\nsudo add-apt-repository ppa:graphics-drivers/ppa\nsudo apt-get update\nsudo apt-get install nvidia-352\n\nI've the same processor, graphic card and memory (maybe same laptop? :D ). Neither bumblebee nor nvidia-331 made the trick for me, so I'm about to try 352.41 as suggested on Nvida web site.\nI'll tell you later if it gives some help or not.\n", "Q: fail2ban: Creating a custom action that gives parameters to script I'm having a few problems to understand the workflow of fail2ban.\nMy goal is the following action:\nname: pamysql\nused to: exec command with <name>, <failures>, <ip>, ... as parameters\nI created action.d/pamysql.conf with:\nactionban = wget -q -O /dev/null server.de/fail2ban/ajax.php?action=ban&jail=<name>&ip=<ip>&failures=<failures>&time=<time>&logpath=<logpath>\n\nThe wget call works, but the parameters like <name> and so on don't.\nMy jail.conf looks like this:\nmta = sendmail\nbanaction = iptables-multiport\naction_mwl = %(banaction)s[name=%(__name__)s, port=\"%(port)s\", ...]\n             %(mta)s-whois-lines[name=%(__name__)s, ...]\n             pamysql[name=%(__name__)s, port=\"%(port)s\", logpath=%(logpath)s]\naction = %(action_mwl)s\n\nCan someone explain why the parameters aren't working in pamysql.conf?\n\nA: I found it. The solution was really simple: The url for the wget call has to go between quotes.\nSo\nactionban = wget -q -O /dev/null server.de/fail2ban/ajax.php?action=ban&jail=<name>&ip=<ip>&failures=<failures>&time=<time>&logpath=<logpath>\nbecomes\nactionban = wget -q -O /dev/null \"server.de/fail2ban/ajax.php?action=ban&jail=<name>&ip=<ip>&failures=<failures>&time=<time>&logpath=<logpath>\"\n", "Q: How to transfer files to Windows Server through rdp? I am using Ubuntu, and have tested a lot of rdp clients, right now I am using \"Remmina RDC\". As a web developer I, need to transfer files to the server \"Windows Server\" and vice versa. I am new to Ubuntu, so I need help! Best option for me is a Windows-like mstsc client, but with some other options. please...\nThe server is not in the same localhost!\n\nA: If you've not already tried it, there's freerdp-x11 client.\nInstallation:\nsudo apt-get install freerdp-x11\n\nDocumented Description:\n\nRDP client for Windows Terminal Services \n\nFreeRDP is a client for Windows Terminal Services implementing the \n    Remote Desktop Protocol (RDP). \nCurrently, the following Windows Versions are supported: \n  \n  \n*\n  \n*Windows NT Server \n  \n*Windows 2000 Terminal Server \n  \n*Windows XP \n  \n*Windows 2003 Server \n  \n*Windows Vista \n  \n*Windows 2008 Server \n  \n*Windows 7 \n  \n  \n  This package contains the X11 based client.\n\nHomepage: http://www.freerdp.com\n", "Q: Why is a repository still in /etc/apt/sources.list.d after removing it with add-apt-repository --remove? I am trying to remove a repository in 12.04, like so\nsudo add-apt-repository --remove ppa:cassou/emacs\nsudo apt-get update\n\nbut when I run the command \nls /etc/apt/sources.list.d\n\nI get the name of ppa mentioned in the list\ncassou-emacs-precise.list\ncassou-emacs-precise.list.save\n\nWhy so?\n\nA: add-apt-repository --remove doesn't actually remove the repository but disables it. If you want to remove the repository along with any package it may have installed you can by using ppa-purge:\nsudo ppa-purge ppa:cassou/emacs\n\nhttp://www.webupd8.org/2012/11/install-ppa-purge-with-multi-arch.html\nNOTE: This will downgrade any packages you might have installed from the PPA to the version available in the main repositories. As explained in man ppa-purge:\nNAME\n   ppa-purge - disables a PPA and reverts to official packages\n\n\nA: The repositories have been removed, if you check the contents of those files, you will find them empty. I don't know why they were not removed and I would call that a bug in add-apt-repository unless empty files are removed by default on reboot or similar.\nIn any case, for future reference, you can always simply delete the files manually:\nsudo rm /etc/apt/sources.list.d/cassou-emacs-precise.list*\nsudo apt-get update\n\n", "Q: `rm -rf ...` hangs on large directory Using Ununtu 12.04, and recently got a message that disk space is running out. Ran the Disk Usage Analyzer, which froze. After some research, I see a directory in ~ called \"9fybsyiikg\" which is 1065357312 bytes.\nI tried opening that folder in the file manager, and nothing happens. I tried lsing in, and nothing happens.\nAnd then I tried rm -rf 9fybsyiikg, and nothing happens.\nAny ideas what this directory may be, and how to get rid of it?\n\nA: The rm command will take some time; if you're not getting any errors, just let it run. If you do get errors, try some of these solutions:\n\n*\n\n*find\n find ~/ -maxdepth 1 -name 9fybsyiikg -delete\n\n\n\n*rm and wait, this might take a while (yes, I know you tried it but it might help others)\n rm -rf ~/9fybsyiikg\n\n\n\n*You might just have too many files, try this\n find  ~/9fybsyiikg -delete && rmdir ~/9fybsyiikg\n\n\n\n*If all else fails, use some Perl magic:\n perl -e 'use File::Path; rmtree \"$ARGV[0]\"' ~/9fybsyiikg\n\nExplanation\n\n*\n\n*-e : run the script passed on the command line\n\n\n*rmtree : a command from the File::PAth module that deletes whole directory trees\n", "Q: Gedit warning: GtkScrolledWindow is mapped but visible child GtkScrollbar is not mapped When I use gedit, there is warning shown: \n(gedit:3166): Gtk-WARNING **: GtkScrolledWindow 0x236cd10 is mapped but visible child GtkScrollbar 0x2307ab0 is not mapped\n\nHow can I fix it ? \n\nA: It was a bug in overlay-scrollbar which has been fixed here at launchpad. It has been fixed.\nSo just run\nsudo apt-get update\nsudo apt-get install overlay-scrollbar\n\n\nA: Until the update has been revised past 14.04, go ahead and reinstall the package:\nsudo apt-get --reinstall install overlay-scrollbar \n\nA: Reinstall overlay-scrollbar .I hope it will fixed your problem .\n\nA: Did'nt work for me either, on a fresh install of ROS & Ubuntu 14.04 using a package developed and distributed by ROS.org. @dmuk can we just ignore the messages and proceed without concern?  Thanks.\n", "Q: How do I pass command line parameters to executables run from Xwindows? Running Ubuntu 12.04.3 LTS\nIn terminal mode executable would be run as:\n../xpdp1 -i ../inp/maxwello.inp\n\nIs there a way I can click on the xpdp1 executable in Xwindows and somehow pass the -i ../inp/maxwello.inp to it?\nThanks.\n\nA: Not directly, no. You'd need to make a launcher (there are other guides too). You could either hard-code the path in or you could use something like zenity:\nsh -c '../xpdp1 $(zenity --file-selection)'\n\n", "Q: Remotely access mysql db on vm from windows as host I have ubuntu on vmware. I've installed mysql-server on it. And now I'd like to connect to this db directly from the Host(windows) machine. Ubuntu is connected to the router via bridge. I can ping it and have remote access to system. But I want to connect to the database only. How do I do this?\n\nA: You should allow remote access to mysql from command line inside your virtual machine (assuming you don't have any gui tools to connect to mysql like phpmyadmin and mysql-workbench)\n\n\n*\n\n*as root, open your /etc/mysql/my.cnf with your favorite editor\n\n*look for the [mysqld] section, and in there for the bind-address keyword. This usually is set to 127.0.0.1 -- change that to match your \"normal\" IP-address\n\n*save the file, and reload the service (e.g. using service mysql restart)\n\n\nRemember you must enable your remote users to access their database(s) from remote, by setting the appropriate GRANTs -- e.g.\nGRANT ALL ON mydb.* TO remoteuser@'%' IDENTIFIED BY 'SomePASSWORD';\n\nNote the @'%', which means \"from any host\".\n", "Q: Lenovo Y580 touchpad pointer runs away while trying to click I've just installed Ubuntu 12.04 on my Lenovo Y580. I don't have physically divided mouse buttons from my touchpad surface, so I can't manage with the issue just by clicking on physical buttons. The button surface is also touchable.\nWhile \"tapping\" the touchpad in accordance to make a click my mouse pointer is moving so sensitively that sometimes when I like to close something or just press a small button (like \"x\" to close the window) I can't manage to do this because my pointer moves away from the button area. On Windows I think it works like that: when I tap the touchpad, pointer movement is like suspended so the clicking is precise. In Ubuntu it doesn't work that way. I've checked in mouse and touchpad settings and nothing helps from there.\nHow to make the mouse pointer not move while trying to click on a tiny button?\n\nA: To get the trackpad working correctly you need to use the terminal and enter in the below commands. Make sure you press enter after each command:\nsudo -i \necho \"options psmouse proto=exps\" > /etc/modprobe.d/psmouse.modprobe\nreboot\n\nOnce the computer reboots your trackpad will be able to do left click and drag and right clicking\n", "Q: My mouse cursor is invisible in Kubuntu I'm using Ubuntu kde plasma desktop. I first installed Ubuntu, and then I upgraded to Kubuntu and have been using both for over a year now. When I upgraded kdeplasmadesktop the cursor is visible on the login screeen but cannot be seen inside Kubuntu. I have tried typing:\nsudo apt-get update\nsudo apt-get install diste-gnome\n\nin the terminal but don't know how to make it work, or if it's right, and anyway, and can not open the terminal any more, and how can I open the terminal without a mouse in Kubuntu again?\nThanks. \n\nA: I'm not sure an update will solve it, but if you want to try, just press: Control + Alt + F6\nYou'll have a tty (virtual terminal) where you can log in typing your username and your password. There, you can try:\nsudo apt-get update\nsudo apt-get install --reinstall kdeplasmadesktop\n\nYou could also try to install a different desktop interface and see if the mouse problem is KDE specific:\nsudo apt-get install ubuntu-desktop\n\nor, more lightweight:\nsudo apt-get install xubuntu-desktop\n\nTo go back, use Control + Alt + F7 or just restart the computer with:\nsudo shutdown -r now\n\n\nA: This one is caused by having gnome settings active.\nTry to change this with dconf-editor: \nGo to\norg/gnome/settings-daemon/plugins/cursor/active\n\nchange it to false\nI hope it helps\n\nA: Try sudo apt-get purge unclutter. Fixed the problem for me. You can reinstall unclutter. It doesn,t cause the problem again\n", "Q: Qt5 installation and path configuration I have installed Qt5 from the Qt5 project site, to the following directory \n/opt/Qt5 \n\nI would also like to mention that I had Qt4 installed previously, I have removed all instances of Qt4 through the software center. \nNow that I issue designer from the command prompt, the system gives the following error: \ndesigner: could not exec '/usr/lib/x86_64-linux-gnu/qt4/bin/designer': No such file or directory\n\nWhat can be done to correct this problem? \n\nA: Replace Default Qt version paths in:\n/usr/lib/x86_64-linux-gnu/qtchooser/default.conf\nor in newer releases /usr/lib/x86_64-linux-gnu/qt-default/qtchooser/default.conf:\n/opt/Qt5/bin\n/opt/Qt5/lib\n\nCheck:\nqtchooser -print-env\n\nReference: man qtchooser\n\nA: Proper path to qt default config: /usr/lib/x86_64-linux-gnu/qt-default/qtchooser/default.conf\n\nA: For all of those who didn't uninstal old version and are wondering how to change the qt directory location.\nThe correct way is to export the QT_SELECT variable and add the custom ~/.config/qtchooser/somename.conf file.\nThis will be a qt installation visible in qtchooser -l under \"somename\".\nSo that:\n QT_SELECT=somename; qtchooser -print-env \n\nWill return your custom location.\nThe downside of changing the default.conf is that it might invalidate where your old qt version is found, when I did change it to /some/path, after executing:\nQT_SELECT=qt4; qtchooser -print-env\n\nIt find the newer version on my path, however with the ~/config/qtchooser/somename.conf the earlier version is intact.\nIt is mentioned at the end of the man qtchooser help:\n\nFILES\n         /etc/xdg/qtchooser/*.conf\n                System-wide configuration files. Each has two lines, the first is the path to the binaries and the second is the path to the Qt\n  libraries. If a default.conf is provided,  the  settings\n                from it will be automatically used in case nothing else is selected.\n$HOME/.config/qtchooser/*.conf\n   configuration files\n\n\nA: I tried the answers suggesting to check the configuration in the qtchooser, but I didn't manage to get it to work. The solution that worked for me was simply to add the right qt version to PATH. 5.11 in my case.\nexport PATH=\"/opt/qt511/bin:$PATH\"\n\n", "Q: Dual booted win7 with 13.10 and seemingly I have lost the whole hard drive I seriously need help !\nI followed the instructions, and started to install Ubuntu 13.10 alongside win 7. In the middle of installation, there was an error saying some file can not be copied, after that just nothing happened for \"a long time\" , I think here I made the decisive mistake, and restarted my laptop in the middle of installation process.\nafter I turned on my laptop, in the boot options there was no HDD !! it was just DVD to boot from, I tried to reinstall 13.10 using my DVD, this time it did not ask me to install it \"alongside windows 7\", it said, there is no operating system on this computer, just install 13.10. I continued but again (this time maybe because of \"loss of HDD\") it gives error about not being able to copy files.\nI am here thanks to \"try ubuntu before installing it\" !! in the air\nWhy these things happened ?\nHow can I recover my HDD ?\nHow can I make sure there is no way, but to replace my HDD ?\nubuntu@ubuntu:~$ sudo blkid\n/dev/loop0: TYPE=\"squashfs\" \n/dev/sda5: UUID=\"2976d82f-f4c6-4eb3-ab63-bb4aa2fbeca4\" TYPE=\"swap\" \n/dev/sr0: LABEL=\"Ubuntu 13.10 i386\" TYPE=\"iso9660\" \nubuntu@ubuntu:~$ \n\n\nA: Try using the windows 7 install/repair disc. Click \"repair your computer\" and then open the command prompt. Try these 2 commands:\n\nbootrec /fixmbr\n\nand\n\nbootrec /fixboot\n\nmore info: http://www.howtogeek.com/howto/32523/how-to-manually-repair-windows-7-boot-loader-problems/\n", "Q: fan noise of dell inspirion after ubuntu 12.10 is installed alongside windows 7 How do i solve fan noise issue of dell inspirion 32 bit ubuntu 12.10 installed along side windows 7?\nI tried many options indicated in the forum but nothing seem to work. when I try touch /etc/fancontrol it says touch: cannot touch ‘/etc/fancontrol’: Permission denied\n\nA: Try the below command,\nsudo touch /etc/fancontrol\n\nNormal user can't be able to create a file inside /etc directory because it was owned by root.To create a file inside that, you need superuser do privilege or you must logged in as a root user.\n", "Q: dpkg opporations fail: Failed to run depmod, error processing linux-image-generic My Laptop had lost power a couple of times recently, and now, whenever I try to do a package operation I am getting the following error code. I tried searching for a solution on the forums, but these either required a package operation or were left unanswered. 'uname -r' tells me my kernel is 3.11.0-17-generic, but it seems like my kernel header says 3.11.0-18-generic. I tried booting old kernel versions to try to fix the issue, but I encountered the same error. Anyone know what I could do?\nsudo apt-get install -f\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\n0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n4 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nSetting up linux-image-3.11.0-18-generic (3.11.0-18.32) ...\nRunning depmod.\nFailed to run depmod\ndpkg: error processing linux-image-3.11.0-18-generic (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of linux-image-extra-3.11.0-18-generic:\nlinux-image-extra-3.11.0-18-generic depends on linux-image-3.11.0-18-generic; however:\n  Package linux-image-3.11.0-18-generic is not configured yet.\n\ndpkg: error processing linux-image-extra-3.11.0-18-generic (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of linux-image-generic:\n linux-image-generic depends on linux-image-3.11.0-18-generic; however:\n  Package linux-image-3.11.0-18-generic is not configured yet.\n linux-image-generic depends on linux-image-extra-3.11.0-18-generic; however:\n  Package linux-image-extra-3.11.0-18-generic is not configured yet.\n\ndpkg: error processing linux-image-generic (--configure):\n dependency problems - leaving unconfigured\ndpkg: dependency problems prevent configuration of linux-generic:\n linux-generic depends on linux-image-generic (= 3.11.0.18.19); however:\n  Package linux-image-generic is not configured yet.\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                 No apport report written because the error message indicates its a followup error from a previous failure.\n     No apport report written because MaxReports is reached already\n\ndpkg: error processing linux-generic (--configure):\n dependency problems - leaving unconfigured\nErrors were encountered while processing:\n linux-image-3.11.0-18-generic\n linux-image-extra-3.11.0-18-generic\n linux-image-generic\n linux-generic\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: Run these commands to remove unconfigured  packages,\nsudo dpkg -P linux-image-3.11.0-18-generic\nsudo dpkg -P linux-image-extra-3.11.0-18-generic\nsudo dpkg -P linux-image-generic\nsudo dpkg -P linux-generic\n\nThen finally run the below command to fix the package dependencies,\nsudo apt-get install -f\n\n", "Q: Failed to load package list when updating 12.10 (fresh install) Thanks in advance for your time. Please pardon if this question was answered before (I tried to look for relevant questions - but found none). I am okay to work within the terminal but with limited knowledge - basically I am a noob. So I apologize for my lack of knowledge and mistakes I have done.\nI installed 12.10 last night and unable to update it now. I tried to install medibuntu ppa to get updated codecs. However since then, I am getting the error Failed to load the package list and in details it says E:Type '<html>' is not know on line 1 in source list /etc/apt/source.list.d/medibuntu.list\nI tried to delete the file all together but no option to do that. From another post on AskUbuntu, I tried to run:\nsudo rm -r /var/lib/apt/lists/* -vf\nsudo mkdir -p /var/lib/apt/lists/partial\nsudo apt-get update\n\nTo that, I get the same response E: Type '<html>' is not known on I have already unchecked all the sources in update center to no avail.\nIs there any hope to come out of this loop?\nAny help is greatly appreciated.\n\nA: Mediubuntu doesn't exist anymore, so the best thing you could do is remove it from your ppa's list:\nsudo rm -vf /etc/apt/source.list.d/medibuntu.list*\n\nAnd try again the update:\nsudo apt-get update\nsudo apt-get upgrade\n\n", "Q: heat and fan pacing after ubuntu 12.10 is installed alongside windows 7 i tried touch /etc/fancontrol it is helpless\ni tried the following but to no avail;\ninstall mesa-utils and mesa-utils-extras and reboot\nif the problem remains let us know\n$ sudo apt-get install mesa-utils mesa-utils-extra  \n\n\nA: I went through same problem sometime back. Tried lot many things but didn't get grip over the problem. You can try whatever solutions given around over the internet. \nBut I suggest you to re-install ubuntu. But remember to use the correct usb tool to install. I mean correct software to make bootable usb. I recommend \"unetbootin\". \nThis is actually a problem which comes due to incorrect linux installation.\n", "Q: The medium can't be used as the requested device type I recently tried downloaded Kali and I don't want to run it along side my current Ubuntu 13.10. Instead I intend to run it through VM VirtualBox (downloaded from Software Centre).\nHere is what I entered into the first set-up stage:\n\n\n*\n\n*Name: Kali Linux\n\n*Type: Linux\n\n*Version: Linux 2.6 (this I am not so sure on? should it be Debian)\n\n\nAll is well in setting the RAM and disk size etc.\nBut when it comes to loading the Kali ISO (32bit) I am confronted with this perplexing error message.\n\nFailed to open the CD/DVD image /home/anonhalo/VirtualBox VMs/kali-linux-1.0.6-i386.iso.\n\nThe medium '/home/anonhalo/VirtualBox VMs/kali-linux-1.0.6-i386.iso' can't be used as the requested device type.\n\nIn my own head I am thinking it is the file location of the ISO? But I moved it to 10 different locations. And still the same error?\n\nA: You're going about this the wrong way, you are trying to add an ISO image as a CD/DVD drive. Instead, first, create the new VM, using Debian 32bit as the OS type. Then, once this has been created, go into the VM's Settings and choose the \"Storage\" tab. Once there, select the \"Empty\" item under the IDE controller:\n\nThen, click on the CD icon on the top right, and select the 1st choice, \n\nIn the dialog that will appear, select the Kali .iso, save the settings and then boot the machine. It will boot from the .iso you just selected and you should be able to istall with no problems.\n\nA: Make sure that the image file is of kind ISO disk image in the properties. I had the same problem as the kind of file was as Folder and Not ISO disk image eventhough it had iso extension. Just double click the folder and copy the disk image file into new hard disk partition. Now use this path for loading in the Virtualbox in the storage option. This method worked for me.\n", "Q: Recover Untitled Document 1 from gedit I have an unsaved document opened in gedit on Xubuntu 13.10. A bug caused gedit's main window to disappear and only the title bar is still visible, reading \"Untitled Document 1\".\nIs there a way to recover the typed text from the running but defunct session of gedit? Are \"Untitled Documents\" stored somewhere temporarily?\n\nA: The file only seemed to be stored in RAM. All attempts to find it on disk returned nothing. Here's what I did for partial recovery:\n\n\n*\n\n*Find out PID and write it down\nps -ef | grep gedit\n\n\n*Use it to dump memory of process\nsudo gcore 12345\n\n\n*Use vim and search for keywords you remember\nsudo vim core.12345\n\nThe entire file will be fragmented, can be quite big and is littered with parts you have deleted already. Since I was not programming, but wrote an actual text, I was able to find the individual fragments and recover a large part of the text.\nIronically, after I went through all of this work and wanted to close the gedit instance it asked me if I want to save the Untitled Document 1 - which I did.\n\nA: When you open a file with gedit it will create a temporary file with ~ in the name.\nso just force close gedit and you can reopen that file\ngedit /path-to-file/filename~\n\nor just go to the directory from nautilus file manager\nctrl + h will show you the hidden file then search for it and open.\n", "Q: My boot screen for Lubuntu doesn't load correctly. How can I fix that? Thanks! This would be my first post and I am not proficient in Linux, although I do use it regularly as a layperson.\nI just dual-booted my old laptop with XP and Lubuntu (I have an emotional attachment to XP). However, the boot screen for Lubuntu doesn't load correctly. How can I fix that? \n\nA: Ensuring that you have the correct graphic drivers for your hardware should fix the boot splash animation. \n", "Q: Setting up the GRUB for future use What I am currently working on is trying to set up my partitions/ grub to eventually dual-boot. Currently for partitions, I have:\n\n\n*\n\n*the Ubuntu partition, mounted to '/', also flagged 'boot'\n\n*a second, empty partition where the other linux system will go\n\n*the 'extended', and 'swap' partitions\n\n\nHow do I set up the grub to eventually handle the boot?\nResult of sudo fdisk -l:\nDevice Boot      Start         End      Blocks   Id  System\n/dev/sda1   *        2048   133627903    66812928   83  Linux\n/dev/sda2       150013950   156301311     3143681    5  Extended\n/dev/sda3       133627904   150011903     8192000   83  Linux\n/dev/sda5       150013952   156301311     3143680   82  Linux swap / Solaris\n\n\nA: Boot flag only applies to Windows, grub does not use boot flag. But a few motherboard have a BIOS that needs to see a boot flag, so we still suggest you have one on a primary partition.\nIt depends on the other system you install. Most systems will install their boot loader to the MBR overwriting you current grub boot loader in MBR. \nIf that system is another Linux with grub2 you can just boot into Ubuntu and run this to reinstall Ubuntu's grub into MBR of sda, if that is your drive.\nsudo grub-install /dev/sda\nsudo update-grub\n\nYou can also use Supergrub to boot your install or use Boot-Repair to install grub to your MBR.\nhttps://help.ubuntu.com/community/RestoreUbuntu/XP/Vista/7Bootloader\nIf other install is grub2, it may remember where it installed and on major updates reinstall its grub to MBR. You an repair again, but may be able to un-configure the reinstall locations, or originally install grub to that install's PBR or partition boot sector. The PBR will not boot on its own and is just a location, so you do not have issues.\nto get grub2 to remember where to reinstall on updates:\nsudo dpkg-reconfigure grub-pc\n\nEnter thru first pages,spacebar to choose/unchoose drive, enter to accept, do not choose partitions normally. If you do not want it to reinstall un-choose everything.\n", "Q: Why 'make gconfig' does not work while compiling the kernel? I am trying to compile vanilla Linux kernel 3.12.14 downloaded from kernel.org. When I try make gconfig, it says:\n* Unable to find the GTK+ installation. Please make sure that\n* the GTK+ 2.0 development package is correctly installed...\n* You need gtk+-2.0, glib-2.0 and libglade-2.0.\n*\nmake[1]: *** No rule to make target 'scripts/kconfig/.tmp_gtkcheck', needed by `scripts/kconfig/gconf.o'.  Stop.\nmake: *** [gconfig] Error 2\n\nNow it seems my Ubuntu doesn't have gtk+ by default, dpkg -s xxxx confirmed it. I tried installing all 3 of these using sudo apt-get install xxxx but no packages found.\nWhat can I do now! (Is pygtk an answer?)\nNOTE: xxxx is place holder for 3 missing packages named in the error.\n\nA: The message is very clear:\n* Unable to find the GTK+ installation. Please make sure that\n* the GTK+ 2.0 development package is correctly installed...\n* You need gtk+-2.0, glib-2.0 and libglade-2.0.\n*\nSo, just install the libraries you need. In most cases, these are provided by the -dev version of the packages mentioned in the error, in the case of libraries is likely that you have to add lib at the start. So, in this case:\nsudo apt-get install libgtk2.0-dev libglib2.0-dev libglade2-dev\n\nAnd done.\n", "Q: Partitioning Hard drive I will be converting from WindowsXP to Ubuntu in a couple weeks.  During the installation process, will 12.04.4 ask me what size of the partition I want to create?  Is it necessary to create a partition?  When I last installed WindowsXP on my laptop, I did not create a partition.\nThis is my laptop.  A Toshiba 1.60Ghz with 1.96GB RAM Pentium(R)M.  So again, if I create a partition size would you recommend and why?  \n\nA: Is good to create 3 partition:\n\n\n*\n\n*root [mount point / ]\n\n*home [mount point /home ]\n\n*swap [ mount point swap ]\n\n\nWhy? On root partition will be you system aka installation of OS and application. On home will be you data like user on system. This two partition is separated because in some cases when you will to change version on will to do fresh install your data will be safe on separate partition. Swap will help your ram memory.\nYou don't specify hdd size but for system is enough 20 GB, for swap 2x ram mem size in your case 4 GB. The rest is for your data aka /home partition\n\nA: Yes it is necessary to create a partition if one does not exist\nThe XP installer will of created a partition for you. \nThe Ubuntu installer will give you the option to create or reuse partitions.\nYou won't need to manually create any partitions before installing Ubuntu.\nI recommend the defaults unless you have good reason to not use them, which will create a root partition for all your files and a swap partition for memory management.\n", "Q: Provide an Xserver To Chroot Description:\nI'm using a Lubuntu 13.10 X86-64 livecd to chroot into another Lubuntu 13.10 X86-64 located on my hard drive in a folder called chroot. I've had no trouble using the terminal to chroot in, and I can launch gui applications on my current xserver from the chroot after using \"xhost +\" on the livecd, but I need provide the chroot it's own X output. I've googled, searched askubuntu, and typed every command under the sun and moon all to no avail. I would love a solution, but would even be happy for a guess if you've got one. I've backed up the chroot so I can restore if it gets messed up. I've also tried using Xnest but it doesn't want to work either. I would like to run the lxde desktop environment in the chroot, if possible logging in as a specific user.\nDetails:\nBelow are the commands I used to commence the chroot.\nsudo mount --bind /dev /media/lubuntu/os/chroot/dev\n\nsudo mount --bind /proc /media/lubuntu/os/chroot/proc\n\nsudo mount --bind /sys /media/lubuntu/os/chroot/sys\n\nsudo cp /etc/resolv.conf /media/lubuntu/os/chroot/etc/resolv.conf\n\nxhost +\n\nsudo chroot /media/lubuntu/os/chroot\n\nI would also have typed \"export DISPLAY=:0.0\" in the chroot, but it worked without it.\nTest Results:\nTest #1:\nDescription:\nI get a black screen on all outputs (control+alt+Fkeys), and I cannot type anything. I'm forced to kill the computer by hand.\nDetails:\nIn chroot terminal type\nexport DISPLAY=localhost:1\n\nIn chroot terminal type\nstartx -- :1\n\nTest #2:\nDescription:\nI get a black screen for F1, pressing \"control + alt + F7\" gets me back to my normal desktop. I cannot type anything on the black screen. When I enter \"gksu leafpad\" in the chroot terminal on F7 I get an error that it \"cannot open display localhost:1\". When I switch to F1 it now shows a terminal prompt for the livecd not the chroot.\nDetails:\nIn chroot terminal type\nexport DISPLAY=localhost:1\n\nIn livecd terminal type \nsudo startx -- :1\n\nTest #3: [Edited In]\nDescription:\nI get a blank black window, just as I would for Xnest. When I try to launch xterm I get an error stating \"could not resolve hostname lubuntu: Name or service not known\". I've also tried installing \"openssh-server\" in the chroot, and on the livecd. When I use the same commands on the livecd only and attempt to launch xterm from the livecd I do not get the same error. Instead I get a password prompt. The livecd user \"lubuntu\" has no password. If I leave the password blank I get error \"permission denied. If I create a user account a retry it I get error \"permission denied, please try again\" when entering the correct user password. The \"could not resolve hostname lubuntu\" error experienced with the chroot also occurs when using apt-get in the chroot, though I can and have installed things from apt.\nDetails:\nIn livecd terminal type\nXephyr -ac -screen 1024x768 -br -reset -terminate 2> /dev/null :1 &\n\nIn chroot terminal type\nDISPLAY=:1.0\n\nI also tried \"DISPLAY=:1.0\" in the livecd terminal.\nIn chroot terminal type\nssh -XfC -c blowfish root@lubuntu xterm\n\nI also tried \"user@server\" and \"root@localhost\" in the chroot terminal.\nAdditional Information\nAnything else you want to know? I'll try to add it here.\n\nA: Use Xephyr\nsudo apt-get install xserver-xephyr\n\nStart Xephyr\nXephyr -ac -screen 1280x1024 -br -reset -terminate 2> /dev/null :1 &\n\nThe \":1\" = your display (displays are numbered starting with 0)\n-ac = disable access control restrictions= allow you to forward X\n-screen 1280x1024 = screen size\n-br = black background\n-reset -terminate= Xephyr should automatically close when the last X client is killed, does not always work.\n2> /dev/null redirects error messages.\nSet your display (for X)\nDISPLAY=:1.0\n\nssh into your chroot (you may need to install ssh server, you may also wish to look at LXC )\nssh -XfC -c blowfish user@server xterm\n\nor use any other graphical tool you wish.\nSee also \nhttp://ubuntuforums.org/showthread.php?t=620003\nhttps://help.ubuntu.com/lts/serverguide/lxc.html\n\nA: Mounting /tmp/.X11-unix inside the chroot filesystem should work:\nmkdir /media/lubuntu/os/chroot/.X11-unix\nmount --rbind /tmp/.X11-unix /media/lubuntu/os/chroot/.X11-unix\nchroot /media/lubuntu/os/chroot\nxterm\n\n", "Q: .desktop files: how to specify the icon path I had a look at the .desktop files on my 12.04 Ubuntu system, and many of them do not have a full path specification for their icon file.  It is rather something like:\nIcon=anjuta\n\nor\nIcon=vlc\n\nor \nIcon=application-x-clementine\n\nIs there a common path where icons can be stored so that this can work ? If not, how does this work ? If I try to do the same thing with my own icons I have to specify the full path.\ne.g.\nIcon=/usr/local/share/my-icon.png\n\nworks fine, but\nIcon=my-icon.png\n\nwill fail.\nAny kind of help is welcome!\n\nA: I have experience with just emblems, not icons, but that should work: \nmkdir -p $HOME/.icons/hicolor/48x48/\n\nput the icon in that directory, let's suppose it is myicon.png\ncp  myicons.png $HOME/.icons/hicolor/48x48/\n\nAdd the description file: \ngedit $HOME/.icons/hicolor/48x48/myicon.icon\n\nwith content: \n[Icon Data]\n\nDisplayName=myicon\n\nand now your Icon=myicon line should work. It works with emblems if you put them in an \"emblems\" subdirectory:\n\nThanks to @Oli now I know why it works :-) \n\nA: Yeah the lookup is pretty complicated. Here are the freedesktop icon specifications on directory layouts:\n\nIcons and themes are looked for in a set of directories. By default,\n  apps should look in $HOME/.icons (for backwards compatibility), in\n  $XDG_DATA_DIRS/icons and in /usr/share/pixmaps (in that order).\n  Applications may further add their own icon directories to this list,\n  and users may extend or change the list (in application/desktop\n  specific ways).In each of these directories themes are stored as\n  subdirectories. A theme can be spread across several base directories\n  by having subdirectories of the same name. This way users can extend\n  and override system themes.\nIn order to have a place for third party applications to install their\n  icons there should always exist a theme called \"hicolor\" 1. The data\n  for the hicolor theme is available for download at:\n  http://www.freedesktop.org/software/icon-theme/. Implementations are\n  required to look in the \"hicolor\" theme if an icon was not found in\n  the current theme.\nEach theme is stored as subdirectories of the base directories. The\n  internal name of the theme is the name of the subdirectory, although\n  the user-visible name as specified by the theme may be different.\n  Hence, theme names are case sensitive, and are limited to ASCII\n  characters. Theme names may also not contain comma or space.\nIn at least one of the theme directories there must be a file called\n  index.theme that describes the theme. The first index.theme found\n  while searching the base directories in order is used. This file\n  describes the general attributes of the theme.\nIn the theme directory are also a set of subdirectories containing\n  image files. Each directory contains icons designed for a certain\n  nominal icon size, as described by the index.theme file. The\n  subdirectories are allowed to be several levels deep, e.g. the\n  subdirectory \"48x48/apps\" in the theme \"hicolor\" would end up at\n  $basedir/hicolor/48x48/apps.\nThe image files must be one of the types: PNG, XPM, or SVG, and the\n  extension must be \".png\", \".xpm\", or \".svg\" (lower case). The support\n  for SVG files is optional. Implementations that do not support SVGs\n  should just ignore any \".svg\" files. In addition to this there may be\n  an additional file with extra icon-data for each file. It should have\n  the same basename as the image file, with the extension \".icon\". e.g.\n  if the icon file is called \"mime_source_c.png\" the corresponding file\n  would be named \"mime_source_c.icon\".\n\nThe full specifications are much more exhausti{ve,ng} than this but the crux of it is: there are set directories you can just stuff icons into and the desktop will find them. Which of those best applies to you depends on your problem and your patience :)\n\nA: If you put icons in /usr/share/icons/ (for system wide) or in your home ~/.icons, then you can use only the icon file name without the extension in the .desktop file. E.g.\nIcon=vlc\n\nIf not, then you must to use the absolute path for the icon in the .desktop file. E.g.\nIcon=/usr/local/share/my-icon.png\n\n", "Q: How to get Clean and Build in netbeans to work again? I don't know if this is a netbeans or Ubuntu or Java problem. But I'm running Ubuntu 13.10 64bit, and trying to create a jar file from my java application that I've created with Netbeans IDE 7.0.1.\nThis is what happens when pressing the \"Clean and Build\" button\ninit:\ndeps-clean:\nUpdating property file: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/built-clean.properties\nDeleting directory /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build\nclean:\ninit:\ndeps-jar:\nCreated dir: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build\nUpdating property file: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/built-jar.properties\nCreated dir: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/classes\nCreated dir: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/empty\nCreated dir: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/generated-sources/ap-source-output\nCompiling 11 source files to /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/classes\nNote: Some input files use or override a deprecated API.\nNote: Recompile with -Xlint:deprecation for details.\nNote: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/src/Connect.java uses unchecked or unsafe operations.\nNote: Recompile with -Xlint:unchecked for details.\nCopying 17 files to /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build/classes\ncompile:\nCreated dir: /home/jeggy/Skjøl/NetBeansProjects/KTEditor/dist\nCopying 1 file to /home/jeggy/Skjøl/NetBeansProjects/KTEditor/build\n/home/jeggy/Skjøl/NetBeansProjects/KTEditor/nbproject/build-impl.xml:990: The following error occurred while executing this line:\n/home/jeggy/Skjøl/NetBeansProjects/KTEditor/nbproject/build-impl.xml:834: copylibs doesn't support the \"excludeFromCopy\" attribute\nBUILD FAILED (total time: 0 seconds)\n\nCould someone explain or help me to get this fixed?\n\nA: It's just a simple Netbeans bug file.\nClick on the link on the second to last line which is\n/home/jeggy/Skjøl/NetBeansProjects/KTEditor/nbproject/build-impl.xml:834:\nRemove the attribute of excludeFromCopy – not the whole line, only the piece of code associated with it!\n", "Q: 13.10 image burn issue I downloaded the Ubuntu 13.10 32-bit release to burn to a DVD on my Windows 7 machine, and then install on an old XP machine. I am having trouble writing the image to a DVD with this error:\nThe disc image didn't burn successfully because an error occurred (Error Code: 0x080004005)  \n\nEvery time I used the Windows image burner on Windows 7 and I have also tried an external burner with no luck. \nFrom what I have read, the DVD doesn't need to be formatted correctly. \nIs there something simple I am overlooking? \n\nA: Hmm... It seems to be a problem with windows image burner. \nI may recommend you two alternative ways to preceed:\na) Change your burning software. Could be Nero burning rom, or other of your preference. In my time on windows the burnings with the embedded software often gave me random problems. My first choice will be the open-source solid as a rock http://www.imgburn.com/ or if you want to check for more, you might be interested in this article: http://www.techsupportalert.com/best-free-cd-dvd-burning-software.htm \nor b) Don't burn it in a DVD! The dvd burning is really old-fashioned. You may find several positive sidekicks on creating a bootable usb drive: you will avoid reading errors because of the disc or the disc-reader failure, it's a LOT faster, and finally you have the possibility to write data on the disc (which is a super handy feature when you run a live session to install Ubuntu). Check this section of Ubuntu's website if you choose this way: http://www.ubuntu.com/download/desktop/create-a-usb-stick-on-ubuntu\n", "Q: Dash search does not find all of my files For example:\nI create the file X.odt and then export it as pdf.\nAfter I click on dash search (the files filter is active) X.\nThe X.odt appears with no problem but the X.pdf does not.\nThat happens always. What should I do?\n\nA: To fix this, run sudo updatedb in terminal. It will take a couple of minutes to finish but at the end you will have your x.pdf file show up in the dash without logging out, restarting unity or erasing the zeitgeist databases which will make you lose all you activity information.\nSource: https://answers.launchpad.net/ubuntu/+source/unity/+question/195718\nAnother interesting question I found is Dash search gives no result.\n", "Q: Disable password authentication in ssh I followed the following guide:\n\n\n*\n\n*help.ubuntu.com/community/SSH/OpenSSH/Configuring\nBut it is still possible to ssh into the machine by entering a password (tried on win with putty)\nAny advice?\n\nA: After you replaced the line:\n#PasswordAuthentication yes\n\nwith the line:\nPasswordAuthentication no\n\nin /etc/ssh/sshd_config and you saved the file, you have to restart your ssh server using the following command in terminal:\nsudo service ssh restart\n\nor:\nsudo restart ssh\n\n\nA: Before disabling ssh password authentication please make sure your access with private key works as expected. Once confirmed, you can disable password authentication.\nI'd suggest following changes to secure the server even more.\nEdit file with: sudo nano /etc/ssh/sshd_config\nPlease make sure you have following values enabled in the file:\nPermitRootLogin no\n\nPasswordAuthentication no\n\nChallengeResponseAuthentication no\n\nUsePAM no\n\nSave file and then restart ssh service\nsudo service ssh restart\n\nor\nsudo systemctl restart ssh\n\nEdit:\nThere is a question what these parameters do. Let's go through them one by one.\nFor the most current version you can alway go to manual page OpenSSH SSH daemon configuration file\n1. PermitRootLogin\n\nSpecifies whether root can log in using ssh(1). The argument must be “yes”, “without-password”, “forced-commands-only”, or \"no”. The default is “yes”.\nIf this option is set to “without-password”, password authentication is disabled for root.\n\n\nIf this option is set to “forced-commands-only”, root login with public key authentication will be allowed, but only if the command option has been specified (which may be useful for taking remote backups even if root login is normally not allowed). All other authentication methods are disabled for root.\n\n\nIf this option is set to “no”, root is not allowed to log in.\n\nNot permitting 'Root login' using password is considered stronger security than allowing it. That said, you should not be logging into root at all, unless no other method (sudo, etc.) will work.\n2. PasswordAuthentication\n\nSpecifies whether password authentication is allowed.  The default\nis “yes”.\n\nThis is basically it. If this is \"no\", you are not allowed to login using login and password but ... you can bypass it with other options so please read on.\n3. ChallengeResponseAuthentication\n\nSpecifies whether challenge-response authentication is allowed (e.g. via PAM).  The default is “yes”.\n\n4. UsePAM\n\nUsePAM  Enables the Pluggable Authentication Module interface.  If set to “yes” this will enable PAM authentication using ChallengeResponseAuthentication and PasswordAuthentication in addition to PAM account and session module processing for all authentication types.\n\n\nBecause PAM challenge-response authentication usually serves an equivalent role to password authentication, you should disable either PasswordAuthentication or\nChallengeResponseAuthentication.\nThe default is “no”.\n\nAnd in the end some info from Ubuntu manual linked above.\nThe defaults may vary so if you want to secure your server, I'd recommend to use set those options mentioned at the top explicitly.\n\nNote that the Debian openssh-server package sets several options as standard in\n/etc/ssh/sshd_config which are not the default in sshd(8). The exact list depends on whether the package was installed fresh or upgraded from various possible previous versions, but includes at least the following:\n\n*\n\n*ChallengeResponseAuthentication no\n\n*X11Forwarding yes\n\n*PrintMotd no\n\n*AcceptEnv LANG LC_* Subsystem sftp /usr/lib/openssh/sftp-server\n\n*UsePAM yes\n\n", "Q: Cannot play YouTube videos in Firefox - Opera works? Since a couple of days it is not possible for me to watch YouTube videos in Firefox - nevertheless I installed Opera and tried it successfully to play videos with it.\nWhat I tried so far (and did not work / change anything):\n\n\n*\n\n*started Firefox in safe mode\n\n*reinstalled flash package sudo apt-get install flashplugin-installer\n\n*switched to HTML5 mode on youtube\n\n*I also tried cd; rm -r .adobe .macromedia\n\n*I enabled / disabled hardware acceleration\n\n\nAlways same result: Either error message \n\nan error occured\n\nor only black screen with spinning wheel.\nCan anybody please help?\nOutput of lsb_release -a; uname -a; dpkg -l | egrep 'flash|gnash|swf|lightspark'\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 13.10\nRelease:    13.10\nCodename:   saucy\nLinux architect 3.11.0-19-generic #33-Ubuntu SMP Tue Mar 11 18:48:34 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\nii  flashplugin-installer                       11.2.202.346ubuntu0.13.10.1                   amd64        Adobe Flash Player plugin installer\n\nAnd also tried with adobe package:\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 13.10\nRelease:    13.10\nCodename:   saucy\nLinux architect 3.11.0-19-generic #33-Ubuntu SMP Tue Mar 11 18:48:34 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\nii  adobe-flash-properties-gtk                  11.2.202.346-0saucy1                          amd64        GTK+ control panel for Adobe Flash Player plugin version 11\nii  adobe-flashplugin                           11.2.202.346-0saucy1                          amd64        Adobe Flash Player plugin version 11\n\n\nA: I was also affected (Ubuntu 12.04). To me it looks like the combination of Firefox and invoking YouTube videos using https fails. If you have HTTPS Everywhere installed, deactivate it for YouTube. But beware: Manual https requests on YouTube videos will still fail, plain http will work.\nCheers.\n", "Q: Manually Uninstall GDAL I followed a ./configure, make, make install approach when I originally installed GDAL on my Ubuntu machine, but now I want to upgrade to 1.10.\nUnfortunately, I want to use apt to perform the upgrade, but after performing an apt-get install I run gdal-config --version I still get a version of 1.9.\nI've tried manually renaming the .so files in /usr/local/lib and /usr/lib but I still am unable to manually uninstall GDAL.\nHas anyone else had success doing this?\n\nA: I don't know if this will help, but it worked out for me. I was looking to upgrade GDAL, and since I had installed it manually from source, I wanted to uninstall the old version first. So I read somewhere (sorry but I had so many tabs open that I can't find it now) that I should just install the latest package and that would override the previous. And I read another comment saying next time instead of using sudo make install I should use sudo checkinstall which creates a deb package wich is uninstallable later running sudo dpkg -r <name_of_your_package> so I just installed the version I had with sudo checkinstall (overriding what I had, and creating the package) and then I uninstalled that using sudo dpkg -r gdal. I know it's not the most elegant thing, but it worked for me.\n\nA: You need to locate your manually installed binary:\n$> which gdalinfo\n/usr/local/bin\n\nAnd then you have to locate other manually installed binaries and remove them (BEWARE BEFORE REMOVING COMMAND: you certainly have other manually installed binaries here)\n$> ls /usr/local/bin\ngdal-config gdal_contour gdal_grid gdal_rasterize gdal_translate gdaladdo gdalbuildvrt gdaldem gdalenhance gdalinfo gdallocationinfo gdalmanage gdalserver gdalsrsinfo gdaltindex gdaltransform gdalwarp ogr2ogr ogrinfo ogrlineref ogrtindex\n\nWhen you manually install GDAL, you also install local lib, they should be here: /usr/local/lib/ with the libgdal* wildcard and inside gdalplugins. You'll want to remove them also.\n", "Q: Problem after update: blue screen with only the mouse cursor My Ubuntu 12.04 was normally updated through the Update Manager, something about gtk. Then I rebooted and now all that shows after the splash screen is a blue screen that only shows the cursor.\n\nA: I experienced the same issue. After a lot of painful efforts, solved the problem in my box.\nDoing the below steps fixed the problem in my machine:\n* press ctrl+alt+f1 and login as root in the tty1\n* cd /usr/lib/*arch-name*/gdk-pixbuf-2.0/\n* find *some-version-number*/loaders/ > ~/pixbuf-files\n  *(not the pkg-version,try ls cmd,only one dir would list out)*\n* vim ~/pixbuf-files and delete 1st line\n* cat ~/pixbuf-files | xargs -n1  gdk-pixbuf-query-loaders > *the-version-number-in-step-3*/loaders.cache \n* reboot\n\nin my case: \n* press ctrl+alt+f1 and login as root in the tty1\n* cd /usr/lib/x86_64-linux-gnu/gdk-pixbuf-2.0/\n* find 2.10.0/loaders/ > ~/pixbuf-files\n* vim ~/pixbuf-files and delete 1st line\n* cat ~/pixbuf-files | xargs -n1  gdk-pixbuf-query-loaders > 2.10.0/loaders.cache \n* reboot\n\n", "Q: Can't install software due to broken isc-dhcp-server dependency while trying to setup hotspot i have messed up with the dhcp server setting , i do not know what went wrong but i am getting following error while installing anything :\nErrors were encountered while processing:\n isc-dhcp-server\n dhcp3-server\nplease help me to reset the setting to defaults as it were on a fresh ubuntu install.\nfollowing is the error while updating firefox :\ninstallArchives() failed: (Reading database ... \n(Reading database ... 5%%\n(Reading database ... 10%%\n(Reading database ... 15%%\n(Reading database ... 20%%\n(Reading database ... 25%%\n(Reading database ... 30%%\n(Reading database ... 35%%\n(Reading database ... 40%%\n(Reading database ... 45%%\n(Reading database ... 50%%\n(Reading database ... 55%%\n(Reading database ... 60%%\n(Reading database ... 65%%\n(Reading database ... 70%%\n(Reading database ... 75%%\n(Reading database ... 80%%\n(Reading database ... 85%%\n(Reading database ... 90%%\n(Reading database ... 95%%\n(Reading database ... 100%%\n(Reading database ... 526048 files and directories currently installed.)\nPreparing to replace firefox 27.0.1+build1-0ubuntu0.12.04.1 (using .../firefox_28.0+build2-0ubuntu0.12.04.1_i386.deb) ...\nUnpacking replacement firefox ...\nPreparing to replace firefox-globalmenu 27.0.1+build1-0ubuntu0.12.04.1 (using .../firefox-globalmenu_28.0+build2-0ubuntu0.12.04.1_i386.deb) ...\nUnpacking replacement firefox-globalmenu ...\nPreparing to replace firefox-locale-en 27.0.1+build1-0ubuntu0.12.04.1 (using .../firefox-locale-en_28.0+build2-0ubuntu0.12.04.1_i386.deb) ...\nUnpacking replacement firefox-locale-en ...\nProcessing triggers for bamfdaemon ...\nRebuilding /usr/share/applications/bamf.index...\nProcessing triggers for desktop-file-utils ...\nProcessing triggers for gnome-menus ...\nProcessing triggers for man-db ...\nSetting up isc-dhcp-server (4.1.ESV-R4-0ubuntu5.9) ...\nstart: Job failed to start\ninvoke-rc.d: initscript isc-dhcp-server, action \"start\" failed.\ndpkg: error processing isc-dhcp-server (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of dhcp3-server:\n dhcp3-server depends on isc-dhcp-server; however:\n  Package isc-dhcp-server is not configured yet.\ndpkg: error processing dhcp3-server (--configure):\n dependency problems - leaving unconfigured\nSetting up firefox (28.0+build2-0ubuntu0.12.04.1) ...\nNo apport report written because MaxReports is reached already\nNo apport report written because MaxReports is reached already\nPlease restart all running instances of firefox, or you will experience problems.\nSetting up firefox-globalmenu (28.0+build2-0ubuntu0.12.04.1) ...\nSetting up firefox-locale-en (28.0+build2-0ubuntu0.12.04.1) ...\nErrors were encountered while processing:\n isc-dhcp-server\n dhcp3-server\nError in function: \nSetting up isc-dhcp-server (4.1.ESV-R4-0ubuntu5.9) ...\nstart: Job failed to start\ninvoke-rc.d: initscript isc-dhcp-server, action \"start\" failed.\ndpkg: error processing isc-dhcp-server (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of dhcp3-server:\n dhcp3-server depends on isc-dhcp-server; however:\n  Package isc-dhcp-server is not configured yet.\ndpkg: error processing dhcp3-server (--configure):\n dependency problems - leaving unconfigured\n\nbelow is the output of sudo apt-get install -f\n$ sudo apt-get install -f\n[sudo] password for parashar: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages were automatically installed and are no longer required:\n  liblaunchpad-integration1.0-cil libboost-iostreams1.46.1 libtommath0 openjdk-7-jre-lib\nUse 'apt-get autoremove' to remove them.\n0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n2 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nSetting up isc-dhcp-server (4.1.ESV-R4-0ubuntu5.9) ...\nstart: Job failed to start\ninvoke-rc.d: initscript isc-dhcp-server, action \"start\" failed.\ndpkg: error processing isc-dhcp-server (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of dhcp3-server:\n dhcp3-server depends on isc-dhcp-server; however:\n  Package isc-dhcp-server is not configured yet.\ndpkg: error processing dhcp3-server (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                                                                                                          Errors were encountered while processing:\n isc-dhcp-server\n dhcp3-server\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: this solved my issue :\nsudo apt-get purge  dhcp3-server    \nsudo apt-get purge isc-dhcp-server\n\n", "Q: ctrl+alt+f7 and ctrl+alt+f8 not changing back into the X session! I have Ubuntu 12.04 lts and I want was opening my pc and after the grub menu, the screen went purple. Ubuntu didn't load after that and the hard drive activity stopped. So I restarted the pc inti recovery with Linux and ran dpkj and fsck to check file system.  It doesn't help, so I clicked on recovery ( the last option on the grub menu). It replied:\nError: file not found\nError: file not found\nError: load kernel first\n\nI don't have windows or any other OS. So in recovery mode I enabled networking and when it finished, it directed me to tty1 so I pressed ctrl+alt+F7 and F8 but nothing happened. Now it always directs me to the tty1 and I cannot access the GUI or X mode.\nPlease help.  I am really in trouble with this.  \n\nA: It's because you don't have a X session running, try to start a fresh one with\nstartx\n\nAlternatively try to start the display manager (as suggested by user31389)\nservice lightdm start\n\n\nA: There can be many things wrong here. You have to find the source of the problem. I suspect something happened to the boot partition and/or root partition. Try\n\n*\n\n*enter recovery mode and check the partitions mounted:\n\nroot@localhost:# df\n  \n*you should see something like:\n  \n  \n Sist.fichs     1K-blocos      Ocup    Livres Uso% Montado em     \n /dev/sda1       39241336  30366172   6858756  82% /              \n /dev/sda3      433336096 178292700 233008148  44% /home          \n\n\n\n\n*\n\n*the first column shows the partitions\n\n*\n\n*/dev/sda1 is my first partition on my first disk\n\n*/dev/sda3 is my third partition on my first disk\n\n\n*the last column shows where the partitions are mounted\n\n*\n\n*/ OS partition\n\n*/home users  home directories partition\n\n\n\nYou probably have a different partitions layout, but what's important is that you need to be able to:\n\n\n*\n\n*load and boot the kernel (GRUB needs to know where it is)\n\n*mount the OS partition\n\n*mount other partitions that may exist, especially the /home partition\n\n\nIf what you problem is the GRUB you can check the Boot-Repair wiki page for more info. But if not, you need to check if you can mount the partitions (if not already mounted) with mount /dev/sdX# /\nIf you can manually mount the partitions, it's possible that the /etc/fstab is broken and you need to correct it. Check Fstab for more info.\nGood luck\n\nA: From the virtual terminals, try just Alt+F7, no control.  That might work for you provided the X server is still running.  \n", "Q: Can ssh onto server using PuTTY, but not ssh from terminal I have a very simple Ubuntu server with a couple of git repos on it, nothing special.\nAt home I used a Windows PC, and use the PuTTY program to interact with the server. At work however I have a Mac, and using ssh to login to the server I am getting a timeout message each time.\nI know the server is up and running, because I am able to access it via a built in console function on my hosting website (Digital Ocean).\nExample:\nMacBook-Pro: documents jmr$ ssh jmr@XXX.XXX.XXX.XXX\nssh: connect to host XXX.XXX.XXX.XXX port 22: Operation timed out\n\nI've searched around quite a bit for solutions to this specific issue but have yet to find anything that addresses this. Any help is appreciated, thanks a lot!\n\nA: Make sure your port is open at work! Some companies block certain ports, and port 22 would be a great first candidate!  \nYou can test that with telnet for example:\ntelnet you.rse.rve.rip 22\n\nYou could also use portquiz.net :\n$telnet portquiz.net 22\nSSH-2.0-OpenSSH_6.0p1 Debian-4\n\nIf your request is timing out too than your port is most probably being blocked.\n", "Q: How to work around \"Something wicked happened resolving\" errors after this string in terminal - sudo apt-get install apache2 - it gives me errors\nFailed to fetch http://archieve.ubuntu.com/ubuntu/pool/main/a/apr-util/libaprutil\n1_1.5.2-1_amd64.deb Something wicked happened resolving 'archieve.ubuntu.com:http' (-5 - No adress associated with hostname)\nWhat to do ???\n\nA: This is to help people setup and install a LAMP (Linux-Apache-MySQL-PHP) server in Ubuntu, including Apache 2, PHP 5 and MySQL 4.1 or 5.0 : https://help.ubuntu.com/community/ApacheMySQLPHP\nI hope it be useful.\nIf it don't work you can use this way ( add repository:ppa ) :\nsudo apt-add-repository ppa:ptn107/apache\n\nthen install apache :\nsudo apt-get install apache2-mpm-worker\n\nAnd to check it you can use:\napache2 -v\n\n", "Q: Trying to install rdpdesk-3.0 I believe I have installed all the prerequisites that the manual listed...For Building under Linux:\nDownload RDPDesk source\ng++\nautotools-dev\nlibxt-dev (>=1.0.6-0)\nlibgtk2.0 (>= 2.18.0)\nlibglib2.0 (>=2.22.0-0)\nx11proto-core\nlibwxbase2.8 (>= 2.8.9)\nlibwxgtk2.8 (>= 2.8.9)\nlibssl-dev\n\nI then ran these commands in the location where I unpacked the RDPDesk files\n./autogen.sh\n./configure\n\nI believe these go through fine, but If you want me to post the results, I can.  Last, but not least, I ran these commands\nmake\nsudo make install\n\nbut it errors out.  Result below...\nrdpdesk-FRDPOptionsDialog.o rdpdesk-  FRDPKeyboard.o rdpdesk-autoupdate.o rdpdesk-CatcherWindowID.o -pthread -Wl,-Bsymbolic-functions -Wl,-z -Wl,relro  -L/usr/lib/x86_64-linux-gnu -lwx_gtk2u_richtext-2.8 -lwx_gtk2u_aui-2.8 -lwx_gtk2u_xrc-2.8 -lwx_gtk2u_qa-2.8 -lwx_gtk2u_html-2.8 -lwx_gtk2u_adv-2.8 -lwx_gtk2u_core-2.8 -lwx_baseu_xml-2.8 -lwx_baseu_net-2.8 -lwx_baseu-2.8 -lglib-2.0 -lssl -lcrypto -lXaw -lz -ljpeg -pthread\n/usr/bin/ld: rdpdesk-RDPConnection_nix.o: undefined reference to symbol 'gtk_widget_reparent'\n/usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0: error adding symbols: DSO missing from command line\ncollect2: error: ld returned 1 exit status\nmake[3]: *** [rdpdesk] Error 1\nmake[3]: Leaving directory `/home/fmccrary/Downloads/rdpdesk-3.2/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory `/home/fmccrary/Downloads/rdpdesk-3.2/src'\nmake[1]: *** [all] Error 2\nmake[1]: Leaving directory `/home/fmccrary/Downloads/rdpdesk-3.2/src'\nmake: *** [all-recursive] Error 1\n\nAny help would be greatly appreciated.\n\nA: gtk_widget_reparent is part of the GtkWidget class. If you're missing that, you're missing some GTK development files. Their packages tend to have a -dev tag on the end. You probably just need:\nsudo apt-get install libgtk2.0-dev\n\n", "Q: DVD's won't play with 13.10 DVD's used to play with 12.04, but since I upgraded to 13.10 I can't get any type of dvd to read. I have tried Totem and VLC. I have also installed the following:\nsudo apt-get install gstreamer0.10-plugins-ugly gstreamer0.10-ffmpeg libxine1-ffmpeg gxine mencoder libdvdread4 totem-mozilla icedax tagtool easytag id3tool lame nautilus-script-audio-convert libmad0 mpg321\n\nand\nsudo /usr/share/doc/libdvdread4/install-css.sh\n\n\nA: I believe you just need to install the restricted formats, should be as easy as\nsudo apt-get install ubuntu-restricted-extras\n\n", "Q: trouble finding/installing cpu driver for AMD FX 8350 I'm very much new to Linux, but I've hunted for days and can not find any solution to my problem. I'm trying to use cpufreq to control the throttle on my cpu (AMD FX-8350, 64-bit), but I apparently do not have drivers for the cpu:\ngalaxy@MilkyWay:/$ cpufreq-info\ncpufrequtils 008: cpufreq-info (C) Dominik Brodowski 2004-2009\nReport errors and bugs to cpufreq@vger.kernel.org, please.\nanalyzing CPU 0:\n  no or unknown cpufreq driver is active on this CPU\n  maximum transition latency: 4294.55 ms.\nanalyzing CPU 1:\n  no or unknown cpufreq driver is active on this CPU\n  maximum transition latency: 4294.55 ms.\nanalyzing CPU 2:\n  no or unknown cpufreq driver is active on this CPU\n  maximum transition latency: 4294.55 ms.\nanalyzing CPU 3:\n  no or unknown cpufreq driver is active on this CPU\n  maximum transition latency: 4294.55 ms.\n\nI think the drivers I have available to try are:\ngalaxy@MilkyWay:/$ ls /lib/modules/$(uname -r)/kernel/drivers/cpufreq/\namd_freq_sensitivity.ko  p4-clockmod.ko  speedstep-lib.ko\n\nBut modprobe can't see them?:\ngalaxy@MilkyWay:/lib/modules/3.11.0-18-generic/kernel/drivers/cpufreq$ sudo modprobe amd_freq_sensitivity.ko\nFATAL: Module amd_freq_sensitivity.ko not found.\n\nThe same thing happens with any of the three. I've tried some various other tweaks on modprobe and every time I get a FATAL. I must being making some silly mistake. Are these even the right drivers? Help!\nEDIT: I don't know if this matters, but I have Ubuntu running inside a VirtualBox.\n\nA: Yes, it does matter if you run cpufrequtils  on a virtual machine vs. on bare metal.\nVirtual Box and other virtualization software will use the real CPU but not all features of the host CPU are exposed to the guest.\nControlling the CPU frequency is one of the CPU feature that is not available in a virtual machine created with Virtual Box. CPU settings you make from the host OS will likely be respected in the guest.\n", "Q: Could I make Automatic Backup Folder For All new files I create or download? I want to make a folder for all the new files I create , some times I create them at different places (e.g Desktop , Download , Document   etc )\nThe Question Why would I do that ?\nand The Answer Is \nI always Try a New Things Especially new OS and because I always write the observation and notes every where on that new Os , as an example I may write a doc at desktop then I may write and save another one At Document Folder and I may Download a doc or learn pic at any time , some times and suddenly some thing goes wrong and my OS fall , so I start to get all what I made out of that OS and of course that take time and not 100% accurate \nBecause Of that I want To make an Idea To make a Folder at another partation to contain another copy for all what I make work automatically without a single click waste of time  \nNote \nI don't want to make a backup for all OS because I may forget to make before OS fail \n\n\nA: You could in setting you can chosen a automatic backup, and all so of specified folders like document, download and desktop daily, weekly or months, am folders all so  push setting and backup, and then manged backup by you self, and it might work fine this way.\n", "Q: Lost password, recovery mode doesn't help A friend of mine has a old Ubuntu laptop that he wants to put back into use, but since it has been some time since he used it he has forgotten his password. \nI've looked up how to change but none of them will work. I have also tried using the recovery mode, but using the root mode is locked also and requires a password. (We can not reformat the disk due to some pictures on it.)  \nThank you in advance! :)\n\nA: You can boot the laptop with a live CD and chroot into the system and then change the password of any user. I have made this with the minimal installation CD from Gentoo. \n\n\n*\n\n*Download this ISO image (or Ubuntu Live CD) and burn it or make boot-able USB with:\nhttp://distfiles.gentoo.org/releases/amd64/autobuilds/current-iso/install-amd64-minimal-20140313.iso\n\n*You need to find out the partitions on the old laptop. Assuming that you have an IDE hard drive with only root, boot and swap partitions you do this\nmount /dev/hda3 /mnt/gentoo/\nmount /dev/hda1 /mng/gentoo/boot\nswapon /dev/hda2\n\n\n*Then you need to mount proc,dev and sys\nmount -t proc proc /mnt/gentoo/proc\nmount --rbind /dev /mnt/gentoo/dev\nmount --rbind /sys /mnt/gentoo/sys\n\n\n*Then you chroot\nchroot /mnt/gentoo /bin/bash\n\nAfter this you can change your password with passwd\nI hope this help\n", "Q: GParted merge unallocated space to ext4 partition \nHere I want to merge unallocated space to ext4 partition. But during running in Ubuntu it is not allowed. Am I right? It has key picture. I must do that Ubuntu DVD booting from it and selecting try Ubuntu there with GParted, I must merge this unallocated part by right clicking on ext4 partition and then selecting shrink. Am I right? \nThen for swap area I want to take 5GB from extended partition (which is now called D on Windows). Can I format this partition in Windows or should I use GParted? But in GParted it has key picture. Or in the same way should I do this during trying Ubuntu to merge unallocated space to ext4? Thank you for your answers.\n\nA: The steps:\n\n\n*\n\n*Start GParted in live Ubuntu session,\n\n*Unmount (if it's mounted) the partition that will be involved in the resize/move operation, here /dev/sda2 (by right clicking and selecting unmount from the context menu),\n\n*Now right click your /dev/sda2 partition and select Resize/Move option, and drag the slider right to cover the entire unallocated space. And then click the Resize/Move button,\n\n\n*After specifying the resize options, from the menu select Edit -> Apply All Operations or click the Apply button in the toolbar. Wait patiently for the operation to complete.\n\nA: You can boot from Ubuntu's LiveCD and use GParted on it or download GParted's LiveCD .iso, burn it to a CD and boot into it. The key icon beside a partition means that said partition is mounted and thus cannot be modified. Booting to a LiveCD should resolve this issue. If it does not, use umount to unmount a partition.\nSince the unallocated space is to the left of the ext4 partition you wish to resize, you'll first need to move the partition to the left of the unallocated space, which might cause boot error. Follow GParted's instructions on moving partitions.\nThen right-click on the ext4 partition and select \"resize\". Expanding it will shrink the unallocated space and expand the partition's free space. Leave 5GB unallocated and use it to create a swap area.\n", "Q: What's the best way to make a Qt executable program run as a service in Ubuntu I've written my Qt code for an embedded system which is running on Ubuntu.\nI want to run my program as a service in Ubuntu so I can stop or start it using monit. I've seen some people creating a new file in /etc/init.d and adding their executable file path in there.\nBut I want to know what's the best way to run my program as a service ? Thanks\n\nA: In Ubuntu, Most init services were replaced with upstart jobs.\nHere is place where to start http://upstart.ubuntu.com/getting-started.html .\n\nA: Programs started from /etc/init.d (or, rather, from /etc/init in case of upstart) are called daemons and they usually run as background processes with all their output redirected to a logfile. Daemons are often started on system boot and don't depend on a GUI session running, or on user logging into their account etc.\nNormal, \"user space\" graphical programs are quite different - Qt applications are usually started from within an X session, and technically are \"children\" of the X process, so when X exits the application is terminated. Conceptually, there may be multiple X sessions running on a machine at the same time, with a separate copy of your application running in each one, so the idea of adding your app's startup script to /etc/init.d wouldn't cut it even in principle.\nIt is possible to do something similar to what you want by configuring X that it automatically starts your application on startup. Going further, you may use a minimalistic window manager which would only run your application maximized fullscreen. This is called \"kiosk mode\" - you can find a few tutorials on the web. For example, here's a quersion on Unix&Linux: Debian based system, only one gui program, nothing else\n", "Q: Customize KDE tiling grid In KDE, when the user is moving a window around with the mouse and she touches a border of the screen, a shadow appears showing the position the window will occupy if the user drops it there.  \nWhen the mouse is against the top border, the whole screen is offered, if it's against left or right borders near the middle, half of the screen is offered.  It it's against those borders but near the top or the bottom, a quarter of the screen is offered.\nWhat I want is a way to configure that feature so the left side offers 4/5 of the screen and the right side offers 1/5 only.\nOn Windows XP I used to do it with GridMove: \nhttp://jgpaiva.dcmembers.com/gridmove.html\nThis particular utility allows the user to define drop zones that are linked to (usually similar) target areas where the window would appear positioned.\n\nA: What I finally did is to create three shell scripts:\n$ cat ~/bin/win1\nwmctrl -r :ACTIVE: -b remove,fullscreen\nwmctrl -r :ACTIVE: -b remove,maximized_vert,maximized_horz\nwmctrl -r :ACTIVE: -e 0,0,0,1350,800\nwmctrl -r :ACTIVE: -b add,maximized_vert\n\n$ cat ~/bin/win2\nwmctrl -r :ACTIVE: -b remove,fullscreen\nwmctrl -r :ACTIVE: -b remove,maximized_vert,maximized_horz\nwmctrl -r :ACTIVE: -e 0,1355,0,315,800\nwmctrl -r :ACTIVE: -b add,maximized_vert\n\n$ cat ~/bin/win3\nwmctrl -r :ACTIVE: -b remove,fullscreen\nwmctrl -r :ACTIVE: -b remove,maximized_vert,maximized_horz\nwmctrl -r :ACTIVE: -e 0,300,1400,615,300\nwmctrl -r :ACTIVE: -b add,maximized_vert,maximized_horz\n\nThe first one puts current window in a big area at the left of my main screen (desktop monitor I have above the laptop display).  Let's call it \"area 1\".\nThe second one puts current window in a thin area at the right of that same screen.  This would be \"area 2\".\nThe combination of area 1 and area 2 covers the whole main monitor.\nThe third screen maximizes the current window at the notebook display below.\nObviously I defined the sizes using the numbers on the scripts because that's the grid I wanted.  You can define your own grid, see man wmctrl to find out how.\nNext, I added those scripts to the KDE start menu.  You can open the KDE Menu Editor by right clicking on Application Launcher, then Edit Applications.\nLast, I configured a different shortcut key for each one of them, right there in the KDE Menu Editor, under the \"Advanced\" tab.  I also unchecked \"Enable launch feedback\" under the \"General\" tab to get rid of the bouncing icon.\nThe shortcuts I used were Ctrl+Shift+1, Ctrl+Shift+2 and Ctrl+Shift+3.\nI think that's pretty much it.\n", "Q: Lubuntu download/upgrade have the alternate ISO downloaded.32 bit.i could not download torrent.now i seem to have to download more and more just to get into the files.i simply want the best way to install this operating system without a bunch of b.s.i am doing my best to get this right the first time.i am new to linux and i am sure i am missing something,i get that.next will i need something i am missing such as drivers or something?i am trying to ask good questions.my ultimate goal is to completely erase/delete windows xp from my inspiron 1500 notebook(present from mom,not getting rid of it!)and using lubuntu. plz b patient.i am a troglodyte(knuckledragger),i work in the construction&oilfield industry.thankyou.b blessed.\n\nA: Once you have downloaded the iso don't use any programs to try and open or unpack it. \nYou need a usb stick (preferably between 2 and 8GB) and then follow this easy three step guide here:\nhttp://www.ubuntu.com/download/desktop/create-a-usb-stick-on-windows \nto load the iso onto your usb stick and make it bootable.\nAfter that just reboot your notebook and select the usb stick as the boot device.\n", "Q: In grub went into system settings and changed priority of boot drives, now only booting to grub rescue. Help? Whenever I power on I get this screen, where I can enter commands:\nerror: no such device: e9e6b763-5dcc-821b-acc69c2eaaee.\nEntering rescue mode...\ngrub rescue>\n\nI have seen some other posts of similar problems, where the answerer told them to boot a liveCD and then do a boot repair. The problem is I don't know how to do that from here, if that's even possible.\nI did an ls command and the output was:\n(hd0) (hd1) (hd1,gpt1) (hd2) (hd2,gpt9) (hd2,gpt8) (hd2,gpt7) (hd2, gpt6) (and so on...) (hd2,gpt1)\n\nI'd like to get some help in figuring out how to boot my linux LiveCD from this menu. Thanks!\nEDIT: This problem has officially been solved, but my low reputation means I cannot answer my own question for an other 8 hours. I will post what I did after that time.\n\nA: Okay I don't know anything about this grub rescue, but I was able to fix the damage I had done. For any future people that have this problem:\nI turned off the laptop. Then I turned on the laptop using the alternative power button that I guess overrides something and enables you to go into BIOS. I then chose to enter BIOS and then rearranged my booting priority to what it was before.\nI hope this helps!\n", "Q: Ubuntu For Android. Is it available to the average Joe? Ok so i was poking around on the internet looking to dual boot my laptop (windows 7 and ubuntu) and saw the ubuntu for android page and was super excited. I want to install the ubuntu full desktop os on my LG Optimus G Pro, but have a few questions. i poked around for answers but none were answered by the ubuntu site or forums i could find. \n\n\n*\n\n*Is ubuntu for android something that can be added to existing phones, or is it something pre-installed on phones at purchase? \n\n*Where does one get the necessary docking device for the phone to connect to a monitor? Or again is it something that comes with specific phones? \n\n*I see lists of required specs EVERYWHERE but nothing saying how to actually get ubuntu for android. \nIm a little frustrated about the lack of information on the main site about who, how, and when people can obtain ubuntu for android. I was pumped up for it by the page, but was a little disappointed that i could not find out how (or if) i can install it. i would really appreciate if someone can fill me in on ubuntu for android's status. Thanks!\n\nA: *\n\n*It's not pre-installed on phones (yet).  There have been announcements of phones with Ubuntu pre-installed, but not with the desktop switching mode, just with the Ubuntu Touch experience (for now).\n\n*Not out yet.\n\n*Here's a list of devices! Since Ubuntu on phones is still really in pre-release mode, it's not really in average-Joe mode yet.  You could still have a stab at it if you have a supported device, though; here is the install guide.\n\n\nSo, Ubuntu for Android isn't where you want it to be right now.  The idea of having your current Android phone then plugging it into a dock and you have a full desktop is great, but it's not here yet.  You'll probably see Ubuntu phones hit the market early next year.\n", "Q: 12.04 Radeon HD 4200 crap graphics I am stuck with 1024x768.  Display comes up as a laptop.  It's a Philips 17\"\nI have no composition, 2D and fuzzy lines going up the screen.\nI used the software centre to install the ATi X.Org binary driver. Useless!\nIt loads Catalyst.  If I click on Catalyst Control Centre, I get:\n\nThere was a problem initializing Catalyst Control Center Linux edition.   It could be caused by the following.\nNo AMD graphics driver is installed, or the AMD driver is not functioning properly.\n  Please install the AMD driver appropriate for you AMD hardware, or configure using aticonfig.\nThere was a problem initializing Catalyst Control Center Linux edition.  It could be caused by the following.\nNo AMD graphics driver is installed, or the AMD driver is not functioning properly.\n  Please install the AMD driver appropriate for you AMD hardware, or configure using aticonfig.\n\nsudo lshw -c video gives:\n    *-display UNCLAIMED     \n    description: VGA compatible controller\n    product: RS880 [Radeon HD 4200]\n    vendor: Hynix Semiconductor (Hyundai Electronics)\n    physical id: 5\n    bus info: pci@0000:01:05.0\n    version: 00\n    width: 32 bits\n    clock: 33MHz\n    capabilities: pm msi vga_controller bus_master cap_list\n    configuration: latency=0\n    resources: memory:e0000000-efffffff ioport:1100(size=256) memory:f0100000-f010ffff memory:f0000000-f00fffff\n\nIf I do it in terminal, it says missing dependancies and crashes..\nI though I hadn't installed it, but:\n\nfglrx is already the newest version.\nfglrx-amdcccle is already the newest version.\nfglrx-amdcccle set to manually installed\n\ndoing:sudo aticonfig --initial\n\naticonfig: No supported adapters detected\n\nIt's driving me mad!\nI just want my 1280 back and Docky not complaining about compositing all the time.\n\nA: Unfortunately your card (Radeon HD 4200) is too old for the fglrx driver available in the ubuntu repositories to work. \nYou can try and install the legacy drivers from the AMD website: http://support.amd.com/de-de/download/desktop/legacy?product=Legacy2&os=Linux%20x86_64\nbut note that these only work up to linux kernel 3.4.x !\nSo if the output of the terminal command uname -r shows a number higher than 3.4.x you cannot use that one.\nIn that case you need to uninstall the fglrx and amdcccle drivers that you installed by typing sudo apt-get purge fglrx amdcccle and then install the old open-source drivers again.\nsudo apt-get install --reinstall xserver-xorg-video-radeon\n", "Q: Can I dd a larger drive to a smaller one? I have resized the partition of the larger drive with GParted. \nCan I do \nsudo dd if=/dev/LargerDrive of=/dev/SmallDrive\n\n?\n\nA: No this isn't okay to do, you will lose data if you do it. The problem basically is that the data isn't stored in the first part of the disk necessarily. dd / cat copies from the start to the end. Including the blank regions of the filesystem.\nIf you did this the dd / cat will only copy the size of the target filesystem from the source. This may be a problem if there is any data on the last areas of the disk, additionally the filesystem data will be incorrect on the copy of the disk. \nIf however you are only interested in data stored in the first part of the disk - for example the boot / root partition, this may well be okay to do. (I have done this before for example with boot partitions from iso images).\nIf your data fits inside the smaller disk, then one option is to resize the filesystem on the larger disk. The procedure would be something like this:\n0) Make a backup of the partition table (print out fdisk data using p and save it to a file). If you've deleted a disk partition, provided you do not format the disk, you can repartition the disk in exactly the same way as before and recover most, if not all of the data. If you want to backup the larger disk onto smaller disks, one option may be to dd / cat the source partition into an iso file onto the smaller drive - if it fits. If all your source partitions are smaller than your target drives, such a backup is possible. \n1) Unmount the drive totally including all partitions. \n2) e2fsck the partitions to make sure there are no errors.\n3) resize2fs the partitions on the source disk. \n4) shrink the partitions to an appropriate size that contains your data (delete and recreate original partitions). Do not change the starting positions of any of the source partitions. Changing the starting point of the partition would be dangerous because the data would stay in the same place, but the relative offsets against the starting position of the partition would not stay the same, the consequences of this would be that your entire partition could become unreadable. It is fine to have gaps between your partitions, the operating system doesn't mind.\n5) partition your target disk so that the partitions are the same size as the source partitions. \n6) dd or cat the source partitions onto the target partitions. \n7) e2fsck the target partitions.\n8) Pray. \nThis is a very risky procedure, and i don't recommend it. Particularly if there is no backup of the source disk. Having said that, i've done worse things when drunk and i'm still here, with most of my data. \nBefore doing this, practice with some expendable data. \nSummary: by resizing the filesystems you can force the data together and squeeze out the empty space on each partition, then you can copy the data between drives, copying the partitions one at a time using dd or cat, then using filesystem checking on the target system you should be able to resolve any irregularities on the partitions. In practice, you'd have to have balls bigger than Chuck Norris to attempt such a thing. \n\nA: It depends. (Assuming you want to copy the entire drive with any and all partitions, not just a single partition.)\nOf course, the “surplus” space at the end of the bigger disk cannot be occupied by partitions, else the data will not fit. So, as you have already done, you will need to resize your partitions and move them to the start of the drive.\nThe second factor to consider is the partition table. An msdos partition table resides at the start of the drive. Hence, once you’ve taken care of partition sizes, dding the drive and cutting off the unused space is fine. I have successfully copied several drives that way.\nIt’s a little more complicated if a gpt partition table is involved. In this case, the partition table is stored in two places: at the beginning and at the end of the drive. The copy at the end will be lost if the new drive is too small—I have tried that and GParted did not recognize any partitions on the destination drive after that. What has worked for me is to first create a new partition table of type gpt on the destination drive (using GParted), and then copying the individual partitions over with GParted. That way, GParted will take care of updating the partition table entries.\n\nA: Yes, as long as the partitions will fit so do not need to be resized by dd.\ni.e. the size of the drive isn't the issue.\n(Note that all the below should be done by booting your original installation DVD and using the LiveCD option so the drives in question are not mounted.)\nHere is an over-simplified answer, where I either never used gparted to resize the partition, or I did but now have done it again to bring it back down to size.\nFor instance, if you take a 160 GB drive (/dev/sda) and copy it to a 750 GB drive (/dev/sdb) - which I did to get faster booting on a 7200 rpm drive.  You might be doing this simply for backup.\n\n/dev/sda (160GB boot drive) is plugged into SATA port 0\n/dev/sdc DVD drive is in SATA port 1\n/dev/sdb (750 GB drive) is plugged into SATA port 2\n\nStart by collecting info\nsudo fdisk -l\n\n/dev/sda is your original 160 GB drive with partitions.\nThen ideally, it will show that /dev/sdb has no partition table.\nIf /dev/sdb shows partitions but you want to use it anyway, you can wipe the MBR and partition table from it with the following command:\nsudo dd if=/dev/urandom of=/dev/sdb bs=512 count=24\n\nwhich will wipe the MBR and partition tables guaranteed.\nIt will appear as if it was a new, blank drive.\nProceed to back up your boot drive to the larger one:\nsudo dd if=/dev/sda of=/dev/sdb\n\nThis will take some time.  I am writing this 3 years after you posted the question and mine takes 8000 seconds (about 2.5 hours) to do the backup.\nIn my case, I then removed the original boot drive and set it aside as the backup.  That causes my system to boot from the first hard drive it finds, which is the 750 on SATA port 2.\nBut in your case, you are removing the 750 and setting it aside as the backup, thus setting the stage to answer your question specifically.\nTHEN LATER -- AND MORE TO THE POINT OF YOUR QUESTION:\nSay your boot drive fails, or you decide to replace it with a 160 GB SSD drive like I just did.  I have not used more of the 750 GB drive.  It still contains just the original 160 GB partitions from before\nThe new SSD is also a 160 GB ($50 on eBay) so it is large enough to hold the partitions.\nThe original /dev/sdb is still plugged into the same motherboard SATA socket as before, so now I plug the SSD into SATA port 0, and the SSD is now /dev/sda\n(/dev/sdc is the LiveCD I am booting from)\nOpen a terminal window and check things out:\nsudo fdisk -l\n\nto verify that the 160 GB (/dev/sda) has no partition table.  If it does,  you can wipe the MBR and partition table from it with the following command:\nsudo dd if=/dev/urandom of=/dev/sdb bs=512 count=24\n\nThen proceed with the dd:\ndd if=/dev/sdb of=/dev/sda\n\n(It will take the same length of time as before - a couple of hours)\nMake sure to do a clean shutdown of the liveCD.\nsudo init 0\n\nIt will eject the CD then prompt you to press enter so it can flush the remaining buffers.\nRemove the 750 which was /dev/sdb.\nAnd voila, it can now boot onto the smaller drive just fine, because the size of the partitions allowed it to fit.\n\nIf you do this with a SSD like I just did, put on your seatbelt before booting.\nIt is so fast you won't even get a full draw from the coffee mug before it is asking for your password.\n\nIn my particular case, I opted to leave the 750 HDD in as a secondary drive that I mount by UUID in the fstab under /mnt for backups and data collection.\n\nSo there you have it.  An answer from July 2017 using Ubuntu 14.04 Install/LiveCD\n\nA: Yes, but you need to specify the partition if you're just copying the partition.\nSo if the partition number on the larger drive is 1, then\nsudo dd if=/dev/LargerDrive1 of=/dev/SmallDrive bs=4M\n\nYou can give a number for the small drive if you want it to write over an existing partition or not.\nAlso, consider adding a block size to the command, it speeds things up.\n", "Q: Why wont my computer boot Ubuntu from my flash drive? I have a windows 8 Gateway desktop PC and I was wanting to install Ubuntu (13.10) on it.\nFirstly I created a bootable USB using PenDriveLinux, the process was successful, and when I plug the flashdrive in using windows 7 AND 8, it is no longer recognized as TOSHIBA 8GB, but Install Ubuntu (H:), whenever I go into the BIOS of the Gateway PC, I set my removable disk as the first boot priority, and disable secure boot, and Launch CSM was set to always, and even after all these setting changes I still boot into windows 8.\nI did notice that the motherboard in the Gateway PC was an exclusive motherboard, I don't know if that means anything but it is very frustrating and I would like some help to resolve this issue.\nThanks in advance,\nGage\n\nA: This is a problem in Windows 8 because of the UEFI system. Boot into win8 and browse to the CD. Start the wubi installer and do as it says. It will then install Ubuntu. Cheers!\nNote: Use the wubi installer only if you have upgraded from an older windows system.\n", "Q: Adding white space to a shutter screen shot I have a taken a screenshot with Shutter, and I wish to annotate the screenshot, so I click on edit. How do I add white space around the screenshot to put my annotations?\n\nA: After you have clicked on edit, in the edit window you see small square handles around the picture. Drag these handles to create a canvas around the picture. You can also drag the picture within the canvas to position it. Right click on the canvas to choose the background color. After that you can annotate your screenshot.\n\n\nA: It is not possible, not easily at least\nThe inbuilt editor in shutter is meant to be easy and simple, not full featured one.So it misses out many features that other image editors like GIMP have.\nYou can still get a white space around the image, but that would include a lot of painstaking steps, like enlarging the background, cutting the image, adding a white rectangle and again pasting the image.\nThe simpler solution would be to change shutter settings, so that it would open the image in your favorite image editor.Then you may edit the image there.\n\nHOW TO CHANGE DEFAULT EDITOR\n\n\n*\n\n*Go to Edit->Preferences\n\n*In actions tab, select open with\n\n\n*Select your favorite image editor here.\n\n*Close.\n\n", "Q: iMac won't boot Ubuntu I have an iMac and I installed Ubuntu because Lion was causing my computer problems. But I still wanted a Mac OS so I brought it into the genius bar at Apple and they plugged it in and said they could dual boot the two operating systems (Ubuntu and Mountain Lion), but needed me to backup my files on Ubuntu and overwrite with OS X then reinstall Ubuntu. I brought it home to do the file backup and it won't turn on. I called Apple and they said bring it back in, but they don't know how it works and can't figure it out.\nAll I'm getting is a white screen and there is a bootable ISO on a CD in the drive that might be causing the problem, but I can't get it out. Finally I got the CD out by pressing F12 on startup, but it still won't turn on. Now I'm getting a flashing Icon of a folder with a question mark on it. I really don't want to lose my files on Ubuntu. I have month's worth of projects that I really want to keep.\n\nA: I figured it out... I inserted the Ubuntu install CD and duel booted Ubuntu with Ubuntu and the computer booted fine.\n", "Q: Tab completion won't work on some PDF viewers I have a directory filled with PDF files, all with long descriptive names.  So I rely heavily on tab completion when opening any one of them.\nHowever, tab completion only works for zathura, and not for either evince or okular.  It does work for evince-previewer, though.\nHow can I fix this up so that tab completion works for all viewers?\n(FWIW: Bash shell in 12.04LTS.)\n\nA: You can add to your ~/.bashrc file the following:\ncomplete -f -X '!*.[pP][dD][fF]' evince okular foo\n\nAnd now it will autocomplete with pdf files evince, okular and foo.\nThe other way (the correct and formal one), would be to find the autocompletion files and modify them to make them work, they use to live in:\n\n\n*\n\n*/etc/bash_completion.d/\n\n*/usr/share/bash-completion/completions/\n\n\nHave fun\n", "Q: Install ubuntu on windows 8 on second hard drive without affecting setup Harddrives: 125 gb SSD with windows 8 installed, 1 tb hdd\nWhat I want to do: I want to install ubuntu on my hdd without affecting my current set up too much. Right now windows 8 boots up nice and fast and I don't want to have to choose which operating system I want to use all the time. Is there a way to download ubuntu onto my hdd and launching it from windows when I want to use it? \nThanks\n\nA: The recommended way to dual-boot your system is to install Ubuntu on a separate partition on your SSD.  The Ubuntu installer will help you do this.  It will also install a boot loader (probably GRUB) that will help you select which one you would like to boot after POST.  This will yield the best experience from both operating systems.\n\nA: You need to download VMware for windows 8 that will allow you do what you want to do, You cannot run another OS from with in Windows OS with out Virtual PC software and I works just like it would if you booted up from the drive and you can switch between the two\n", "Q: unable to generate .deb file using make deb-pkg? I am trying to build my linux source tree. I used following steps :\nsudo make clean\nsudo make localmodconfig\nsudo make menuconfig \nsudo make deb-pkg\n\nBut after completion I was not able to see any .deb package generated. I checked the parent directory also, but no luck.\nEDIT: Actually I checked the build log and it is happening because of the following error \n/home/rahul/linuxcode/linux/scripts/package/builddeb: line 65: dpkg-gencontrol: command not found\nmake[1]: *** [deb-pkg] Error 127\nmake: *** [deb-pkg] Error 2\n\nBut I am not able to find the reason, I installed the dpkg-control package also, but the error persists. \n\nA: From OPs comments\n\nAfter installing the dpkg-dev package, everything was working fine\nsudo apt-get install dpkg-dev\n\n\n", "Q: Ubuntu 13.10 NFS mounted shares keep losing permissions I have a Synology NAS box on which I keep my videos.  This folder is shared out using NFS.\nOne machine of mine, running Ubuntu 13.10 has been having problems accessing this shared folder.  None of the other machines in the network (including other 13.10 machines) are having any problems.\nLast night I did a wipe and load of the problem-proned machine, set up the shares then watched a movie.  It all worked well.  Then tonight it's back to the same errors as before.\nI try to open the share in Nautilus and I get the error \"This location could not be displayed.  You do not have the permissions necessary to view the contents of \"(name of share)\"\nAbsolutely nothing has been changed since it was all working right last night!\nIf I go to the terminal and try to do a directory listing, I get \"ls: cannot access (share name): Permission denied.\nShowmount -e (ip address) shows the correct share in the list.\nThe FSTAB command is as:\n10.42.1.95:/volume1/video /home/(user)/videosharename nfs rw,hard,intr,nolock 0 0\nThis FSTAB statement has always worked with the Synology shares (at least, since Ubuntu 13.04).\nI've done a wipe and load three times now trying to clean out any possible bugs, but I'm starting to doubt it's the configuration since it works fine, then mysteriously dies on me.\nAfter each wipe and load I install and configure Samba and NFS:\nsudo apt-get install samba samba-common\nsudo apt-get install python-glade2\nsudo apt-get install system-config-samba\nsudo apt-get install nfs-common\nI'm really not sure what else to check!  Any help would be appreciated.\n--- edit: found the problem, although I still have a hard time believing it:  I replaced the NIC card and everything has worked since.\n\nA: I am not sure if you are still encountering errors, but I had an issue with my Synology and  Ubuntu 12.04. I would loose permissions for my NFS mounts constantly. \nI enabled NFS v4 on the Synology and my fstab file now looks like this:  \n# NFS home directory\n#topher:/volume1/nfs_home    /home   nfs     nfsvers=3,nouser,rsize=8192,wsize=8192,atime,auto,rw,dev,exec,suid      0       0\ntopher:/volume1/nfs_home     /home   nfs     nfsvers=4,nouser,rsize=8192,wsize=8192,atime,auto,rw,dev,exec,suid      0       0\n\nIt seems to be more stable and I haven't lost permissions yet, which was a daily occurance before. \n", "Q: How to launch program on lock and close it on unlock Have siblings who like to \"play\" with my laptop by waking it from suspension and then typing random keys on the keyboard into the password field. Afterwards, they always deny it. I plan to install motion and only have it run while the computer is locked. After the computer is unlocked, the process should be killed. How would I go about launching motion when CTRL + ALT + L is pressed and kill motion when the correct password is entered?\n\nA: I like your idea :)\nBut it seems like a duplicate: Run script on screen lock/unlock (U&L Stack)\nIf you install motion correctly as a service, you should run service motion start at the lock-event and service motion stop at the unlock-event\n", "Q: Boot fail 12.04 on 3.5.0-47 After updating Ubuntu 12.04 LTS on my Lenovo W530 about two weeks ago, I have encountered numerous booting errors. My most recent (and default) version is 3.5.0-47 generic.\nThe screen goes to scrolling text and then locks up. Sometimes it goes through to the UI login page and freezes (although cursor can still be moved). Other times it goes to a black screen with the cursor. \nLogging in via older versions of Linux seems to work sporadically. Sometimes a 3.6 version will allow me to login, other times it won't (goes to the same scrolling text and locking up as described above). The same can be said for all other older versions that are listed.\nIn another askubuntu post, the problem seemed to stem from WLAN0 settings. According to the post once it is disabled, the system is able to boot again, although this would mean that wireless internet would be disabled. \n12.04 LTS - Recent update: Fails to boot with version 3.8.0-37 generic\nUnfortunately I do not have the option of connecting my machine to the internet via cable - it relies solely on wifi internet.\nAnother problem I have encountered since installing Ubuntu on my machine (over a year ago) is that my wifi connection is erratic and sometimes simply cannot connect to the router. My windows partition has no such problems. At first I thought that there would not be a relationship between my 12.04 wifi problems and this new booting error, however the aforementioned post's solution of disabling WLAN0 has made me think otherwise.\nI am not a tech savvy Linux user. Happy to provide more information if I can get instructions on how to provide relevant details. \nPS I have not been able to set up static IP for my W530. Setting up a static IP resolved wifi issues I was having with my nexus 7 tablet with the current router.\n\nA: Have you tried booting without the wlan? Although you cannot connect to the Internet, you at least can confirm the problem is coming from the combination including your wlan card.  \nIf this does work: (If your current wlan adapter is pci, maybe you can remove it and) borrow someone elses USB wifi-adapter and plug it in when (successfully) booted up and try to connect to the Internet than.\n\nA: Noticing that most other Ubuntu 12.04 users were using 3.8, I decided to try upgrading to that kernel as well.\nDuring the installation process I encountered a ndiswrapper error. \nI then decided to update to kernel 3.11 and encountered the ndiswrapper error again. \nI followed these instructions by Chili555:\nhttp://ubuntuforums.org/showthread.php?t=1967383\nand executed this command:\nsudo apt-get install --reinstall ndiswrapper-common ndiswrapper-utils-1.9\nI then reinstalled 3.11 and Ubuntu seems to be booting normally again. There is some scrolling text which is only shown on a black screen for approx. 1 or 2 seconds. They are only several lines, the first of which reads something like \"no caching mode found\".   \nHowever the text does not lock up, and fortunately goes through to the UI login page. \nWifi is still behaving erratically. Wicd shows that signal strength can fluctuate between 17 - 92% within a minute. \nHope this post helps others who might be encountering the same issue.\nEDIT: Wifi is behaving more erratically than before. Probably due to reinstalling ndiswrapper..... \nEDIT #2: Okay it's two days since resolving the boot error. My wifi is behaving worse than before. Disconnecting every 2 minutes and very slow when connected - new drivers have been installed for my wifi card haven't helped. HOWEVER the boot error has not returned.\n", "Q: Panel Status Icons Wrong Color Across the top of the panel, I have these status indicators: Language, Network Connection, Messaging, Volume, Time, and System. \nUpon format and fresh install of 13.10, I see that Language icon does not change from white to dark grey when switching themes from Ambiance to Radiance. But whatever, I installed Unity Tweak Tool and a custom icon theme (Flattr) and window theme (Nitrux). \nNow all my status indicators -except Time and Language- are stuck as grey, even though Niturx is a 'dark' theme. They are hardly visible. \nAnd Language is still always stuck as white. \nWhite .svg files exist for the indicator icons, and they appear when the launcher is called. \nWhat's up with the Language indicator icon? The problem existed before any applications/files were added. What's up with my icons not changing color? The theme obviously supports it, it's just not happening. \n\nA: *\n\n*Try regenerate icon cache for all themes\nsudo find /usr/share/icons/* -maxdepth 0 -type d -exec echo -e \"\\n\"{} \\; -exec gtk-update-icon-cache -f {} \\;\n\nCache file created successfully. ie OK\nNo theme index file. ie it wasn't a theme folder. Only if you think otherwise, so index.theme is missing.\nThe generated cache was invalid. ie there is a problem.\n\n*Not solved, Try reset theme preferences to defaults:\ndconf reset -f /org/gnome/desktop/interface/\ndconf reset /org/gnome/desktop/wm/preferences/theme\n\nReferences:\n\n\n*\n\n*CPU Scaling in Unity with indicator-cpufreq\n\n*man gtk-update-icon-cache\n", "Q: How to take screenshot of shutter's menu? With the application famously known as shutter, one can take screenshot of about every GUI element: like windows, hidden windows, menus, cursor tip etc.\nThe only thing shutter can't take screenshot of is itself.\nUsing the default screenshot app, we can take screenshot of shutter.But I need to take screenshot of a shutter's menu, which is not possible(as it seems to me) by either using shutter or screenshot.\nSo is there a way I can achieve this?\n\nA: Just use the default screenshot tool, (gnome-screenshot in Gnome, no idea in Unity)  and give it a delay of say, 5 seconds. Then navigate to your desired menu and wait, the screenshot will show the chosen menu. \n\nThat then allows you to take pictures like:\n\nIt's the same idea as a regular camera. To take a picture of your camera, you need to use another camera.\n", "Q: Having problems with MIDI in recording on Ubuntu I have a Yamaha P-120 model with a USB to MIDI interface that looks like this.\n \nI've decided to use LMMS because it seems like the easiest MIDI sequencer available. I'm having a lot of difficulties getting this to work.\n\n\n*\n\n*What I am trying to do: Record input from my keyboard onto LMMS\n\n*What is working: I can get my output to work, so I can control my keyboard via my computer. \n\n*What is not working: My computer isn't reading the input from the keyboard. I can't record any songs.\n\n*What have I tried: A lot. \n\n\nPorts/Any other Information\nPort     Client name                       Port name\n14:0     Midi Through                      Midi Through Port-0\n24:0     USB Midi                          USB Midi MIDI 1\n128:1     LMMS                              Default preset\n128:2     LMMS                              Default preset\n128:4     LMMS                              Default preset\n129:0     Client-129                        qjackctl\n\nLet me know if you need anything else to help. I am really trying hard to fix this problem as I would love to use my MIDI keyboard.\n\nA: The MIDI command bytes for Clock, Stop, and Active Sensing are F8, FC, and FE.\nIn binary, this would be 11111000, 11111100, and 11111110.\nThe MIDI protocol has no synchronization or error correction; this looks like noise on the MIDI data line, i.e., there is no actual MIDI signal.\nReasons for this could be:\n\n\n*\n\n*the MIDI input cable is broken;\n\n*the keyboard's MIDI output is broken; or\n\n*the \"HOST SELECT\" switch is not set to \"MIDI\".\n\n", "Q: Unable to send data to mysql database. It is not taking by my php code I am new to PHP in Ubuntu 13.10. But I am pretty much able to handle Ubuntu. However\nmy question is that I can't add any data to phpmyadmin through a PHP code, though my code is perfect. Because I have the same code in WAMP server, and it worked perfectly. But in Ubuntu I just can't add any data to the database. Below seen is the the code of php file;\n<?php\n$db_name=\"mydb\";\n$table_name=\"student\";\n$con=@mysql_connect(\"localhost\",root);\n$db=@mysql_select_db($db_name,$con);\n$sql=\"insert into $table_name (name,course,mobile,address)\".\"values ('$_POST[n1]','$_POST[n2]',$_POST[n3],'$_POST[n4]')\";\n$r=@mysql_query($sql,$con);\necho \"----Insert successfull----,<br><br><hr/>\";\necho \"<a href=index.html>Back</a>\";\n?>\n\nPlease tell me whether I am wrong or is there is any bug/problem in phpmyadmin.\n\nA: I'd try to use the mysql_pconnect(host,user,password) function to connect to the server.\nAbout your second problem it sounds to me the php library for apache is not installed or configured correctly.\nopen synaptic and look for any apache-php missing library and as minimum try to (re)install libapache2-mod-php5\nHope it'll help\nG.\n\nA: is $_POST[n2] value integer.if not then try to use $_POST['n2'] \n\nA: in deed that was my fault,when i was trying to input data in the database,in mysql table i typed \"First Name\",\"Last Name\" but after a certain time i thought the database may not be take spaces in variable name and i type \"First_Name\",\"Last_name\" and it worked.and i was trying to execute the php file directly as i told before.now i have solved it the file have to execute by localhost.\nanyways thank you guys,\n\nA: Try Changing your SQL query to this:\n$sql = \"insert into $table_name ('First Name','Last Name','Course','Address','Mobile','Date of Birth','Email') values ('\".$_POST['n2'].\"','\".$_POST['n3'].\"','\".$_POST['n4'].\"','\".$_POST['n5'].\"','\".$_POST['n6'].\"','\".$_POST['n7'].\"','\".$_POST['n8'].\"')\";\n\n", "Q: Updating packages when network access to standard repositories is blocked My college just blocked Ubuntu repositories. So is there any way to install texlive package from something like zip?\nI need to run this command, \nsudo apt-get install texlive texlive-pdf texlive-latex-extra texlive-generic-extra texlive-generic-recommended\n\nSo can anyone provide an alternate way to do the same.\n\nA: You need to select different Ubuntu mirror that is not blacklisted in your college.\nChange /etc/apt/sources.list like here:\ndeb http://mirror.fcaglp.unlp.edu.ar/ubuntu/ saucy main restricted universe multiverse\ndeb http://mirror.fcaglp.unlp.edu.ar/ubuntu/ saucy-updates main restricted universe multiverse\ndeb http://mirror.fcaglp.unlp.edu.ar/ubuntu/ saucy-security main restricted universe multiverse\ndeb http://mirror.fcaglp.unlp.edu.ar/ubuntu/ saucy-backports main restricted universe multiverse\n\nHere is the list with plenty of Ubuntu mirrors. Choose what is best for you.\n\nA: Apart of changing repositories (really?), you can use https instead. Just change all entries from http to https:\ndeb https://repository.ubuntu.com saucy main # this is a made up domain\n\nYou can also use ftp, or rsync.\n", "Q: Can't start an application as service, but running as standalone process simply works For a service although a pid file exists, but still when attempting to start service, it fails saying: \n$ sudo service cassandra start\n* could not access pidfile for Cassandra\n\nI verified folder permissions under /var/run (whose owner is root) and the subfolder cassandra is owned by cassandra user, but still the service cannot access pid file even though I verified that pid file exists. (Also pid is allocated). So why does it say it can't access pidfile?\nAnd running cassandra as a standalone process just works, but not  just using service cassandra start\n$ sudo ls -l /var/run/cassandra \ntotal 4 \n-rw-r--r-- 1 cassandra cassandra 4 Mar 18 07:33 cassandra.pid\n$ sudo su\n# ls -ld /var/run/cassandra \ndr--r----- 2 cassandra cassandra 60 Mar 18 07:38 /var/run/cassandra\n\nHow do I make this work using sudo service cassandra start ?\n\nA: You have to remove /var/run/cassandra folder hence it has wrong permissions:\nsudo rm -rf /var/run/cassandra\n\nOr you can fix permissions manually:\nsudo chmod 750 /var/run/cassandra\n\nThen start Cassandra as service:\nsudo service cassandra start\n\n\nSome explanations\nInstructions of file permissions you can find here.\n\n\n*\n\n*It is safe to delete that folder because it recreates with right permissions and content. But do not delete it once it works correct. It may result in loss of data or incorrect behavior.\n\n*chmod 750 decrypts as rwxr-x--- permissions. It allows read-write-execute to the user, read-execute to the group and nothing to others. For Cassandra, it is enough to set permissions so.\n\nA: This solution can be achieved the following way:\n$ sudo vim /etc/init.d/cassandra;\n\nFind the following line:\nCMD_PATT=\"cassandra.+CassandraDaemon\"\n\nReplace by:\nCMD_PATT=\"cassandra\"\n\nSave and stop and start again. Service will get status correctly;\nTested on cassandra 2.3\nSource here: https://www.digitalocean.com/community/tutorials/how-to-install-cassandra-and-run-a-single-node-cluster-on-ubuntu-14-04\n(check STEP 3)\n\nA: My solution for migration of Cassandra 2.0.9 to 2.1.4\nAfter upgrade with \nsudo apt-get install dsc21\n\nGo to log file:\ntail -f /var/log/cassandra/system.log\n\nYou can see you need to modify your cassandra configuration file.\n\n\n*\n\n*Stop Cassandra \nsudo /etc/init.d/cassandra stop\n\n\n*Go to Cassandra configuration file\nsudo vi /etc/cassandra/cassandra.yaml\n\n\n*Comment out these 5 lines or remove them:\n\n\n*\n\n*multithreaded_compaction: false\n\n*preheat_kernel_page_cache: false\n\n*memtable_flush_queue_size: 4\n\n*in_memory_compaction_limit_in_mb: 64\n\n*compaction_preheat_key_cache: true\n\n\n*Start Cassandra\nsudo /etc/init.d/cassandra start\n\n\n*Verify\nnodetool status\n\n", "Q: Can I install Ubuntu 13.04 on ibm thinkpad a31 I have an IBM Thinkpad and want to install Ubuntu. These are my specs:\n\n\n*\n\n*512mb ram\n\n*ATI mobility radeon 7000 graphics card\nI don't know the rest\nIs it possible to install Ubuntu 13.04 on it?\n\nA: It should work. Make sure you get the latest version of Ubuntu (13.10) or the Long Term Support version (12.04) of Ubuntu. If your laptop cannot run Ubuntu, you could try  Debain or similar Linux distribution. You can 'test' if it works by creating a Live DVD or USB\n", "Q: MESH Network on Ubuntu? I need to make a mesh network test bid using existing wifi card of laptops on Ubuntu. \nand then run any file sharing or application sharing on that mesh. \nI tried this tutorial but failed to paste the olsrd.config file to /etc folder!\nif there is any better way to make a mesh between 3-5 laptops, kindly help me out.\nfleur@ubuntu:~$ ifconfig wlan0\nwlan0\nLink encap:Ethernet  HWaddr 74:de:2b:74:d0:29\ninet addr:10.0.0.1  Bcast:10.255.255.255  Mask:255.0.0.0\ninet6 addr: fe80::76de:2bff:fe74:d029/64 Scope:Link\nUP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\nRX packets:314 errors:0 dropped:0 overruns:0 frame:0\nTX packets:330 errors:0 dropped:0 overruns:0 \ncollisions:0 txqueuelen:1000 \nRX bytes:57824 (57.8 KB)  TX bytes:41243 (41.2 KB)\n\nfleur@ubuntu:~$ iwconfig wlan0\nwlan0     \nIEEE 802.11bgn  ESSID:\"mesh\"  \nMode:Ad-Hoc  Frequency:2.457 GHz  Cell: 8E:FA:05:4E:5E:D3   \nTx-Power=16 dBm   \nRetry  long limit:7   RTS thr=250 B   Fragment thr=256 B   \nPower Management:on\n\nfleur@ubuntu:~$ sudo olsrd -d 2\n*** olsr.org -  0.6.3-git_-hash_cfd7c48ab5a78db3e70cfdece616addb  - ***\nBuild date: 2013-04-06 06:14:10 on batsu\nhttp://www.olsr.org\n\nParsing file: \"/etc/olsrd/olsrd.conf\"\nDebug level: 0\nIPv4 broadcast: 255.255.255.255\nHELLO interval: 6.00\nHELLO validity: 600.00\nTC interval: 0.50\nTC validity: 300.00\nMID interval: 10.00\nMID validity: 300.00\nHNA interval: 10.00\nHNA validity: 300.00\n\nInterface DefaultsLink quality fish eye 1\nIpVersion: 4\nClear screen enabled\nNoint set to 1\nWillingness: 3\nIPC host: 127.0.0.1\nHysteresis disabled\nLink quality level 2\nPollrate 0.10\nTC redundancy 2\nMPR coverage 5\nNo interfaces configured!\n\nBad configuration!\n\nOLSR EXIT: main\n\n\nA: You need to be root user to access /etc!\nThere are 2 ways to get superuser rights:\n\n\n*\n\n*gain root privileges by executing sudo <command>\n\n*or switch to root shell and run command there: su or sudo su\nBoth ways require entering your admin password, so be sure that you are local admin.\n", "Q: Cannot find classmap.h When i execute:\n make modules\n\ni get the error:\nmake[1]: Nothing to be done for `all'.\nmake[1]: Nothing to be done for `relocs'.\nCHK     include/generated/uapi/linux/version.h\nCHK     include/generated/utsrelease.h\nHOSTCC  scripts/selinux/genheaders/genheaders\nscripts/selinux/genheaders/genheaders.c:13:22: fatal error: classmap.h: No such file or directory\ncompilation terminated.\nmake[3]: *** [scripts/selinux/genheaders/genheaders] Error 1\nmake[2]: *** [scripts/selinux/genheaders] Error 2\nmake[1]: *** [scripts/selinux] Error 2\nmake: *** [scripts] Error 2\n\n\nA: It sounds like perhaps you are missing the kernel source code?  Maybe try installing the appropriate linux source package or linux kernel headers?\n", "Q: Ubuntu 13.10 only for 9 months? Wont i be able to use my ubuntu 13.10 after 9 months??\nBecause it is mentioned that it will be supported only for 9 months.\nIt is the only version that worked correctly in my HP Probbok 4445s.\n\nA: You will be able to use ubuntu, but you won't get any security update anymore.\nYou will have the option to upgrade to ubuntu 14.04 LTS when it's out or go back to ubuntu 12.04 wich still has 3 more years of support.\n\nA: Ubuntu 13.10 is not a log term support (LTS) release. This does not mean you will be unable to use it when support expires, it does mean that there will be no official updates courtesy of Canonical.  \n14.04 LTS will be released in April 2014, and as such your hardware will likely continue to be as (if not more) compatible should you choose to upgrade. \n", "Q: Can't view pictures from Samsung S3 I am new to Ubuntu. I have installed Ubuntu 12.04. I plugged my Samsung S3 into the laptop to see files on it however, I can't view the JPG images. \nHow can I view pictures from my S3?\n\nA: As a workaround you could copy them first locally and then view them.\nI think it is an MTP bug. I really hate this protocol.\nI have also tested this in 14.04, same bug, i can copy them but not view them locally.\n", "Q: Dependency is not satisfiable error I am a new user to Ubuntu and seeking for help on installing a mod for Nautilus. I am running 12.04 on 32 bit machine. I do not know hot to compile all these files or what I am doing wrong. I downloaded the top file and got the following message when opening the file :\n\ndependency is not satisfiable\n\nideas on how to proceed?\n\nA: I tried to install it on 12.04, with the same result. The file you mention is a .deb installer file that you can (normally) install by just double clicking. You did everything right, but it turns out that the patch cannot be installed on the latest (update of) nautilus. see this bug report.\nA quick search for a possible workaround gave me this: if you have synaptic package manager installed: search for nautilus, select nautilus, and choose package from the menu, in the dropdown menu  > package > force version. then choose the previous version of nautilus:\n\nSee also this link to hold packages of a certain version (especially the \"Introduction to Holding Packages\" - section)\n", "Q: how to set priviledge on port 21 ftp of a host i have a linux hosting working with cakephp.some sites got intrusion/hacked.i used nmap to see the open ports.\ni found 21/tcp open ftp is the port which should be restricted  and not accessible via public.\nalso i am thinking to restrict /app/config from 777 to 755 and also change databse.php file 'login' => 'root', to user. \ncan i restrict ftp port 21 to set priviledge\nif yes, what effect it will have.\nhow to set priviledge on ftp port 21 of a host.\nother ideas regarding security is also welcomed.\n\nA: Enable fw\nsudo ufw enable\n\nTo allow packets from xxx.xxx.xxx.xxx\nsudo ufw allow from xxx.xxx.xxx.xxx\n\nTo allow packets from network xxx.xxx.xxx.xxx/24\nsudo ufw allow from xxx.xxx.xxx.xxx/24\n\nallow IP address xxx.xxx.xxx.xxx access to port 21 for all protocols\nsudo ufw allow from xxx.xxx.xxx.xxx to any port 21\n\nallow IP address xxx.xxx.xxx.xxx access to port 21 using TCP\nsudo ufw allow from xxx.xxx.xxx.xxx to any port 21 proto tcp\n\n", "Q: How to install sailfin on ubuntu I want to install sailfin on ubuntu for my project.\n\nA: Installing  and implementing the MCU media server is a quite in depth process, which is far too exhaustive to answer here without duplicating most of the official installation guide.  The applications need to be configured manually based upon your own requirements and preferences.\nThe official sourceforge project page has a wealth of resources including active forums and links to source code that can assist you.\n", "Q: get current hard disk read write in ubuntu and make log file I'm writing a customized monitoring panel for Ubuntu Server.\nAt this step I need to get real time hard disk read and write rate then put it into a file as a log file.\nI used tools like Hdparm, Iotop but they did not work. I want the result in a file.\nI want a result such as:  10Kb read - 2kb write - 2014-2-13 16:40:03\nSo I can run it as Crontab and monitor every I/O rate.\n\nA: You can use iostat.\nsudo apt-get install sysstat\n\nEx:\niostat -d 2 /dev/sda\n\n", "Q: owncloud -problem installing packages I have just installed these packages for building my owncloud, but always get an installation aborted error:\nrqie@rqie-VirtualBox:~$ sudo apt-get install apache2 php5 php5-json php5-gd php5-sqlite curl libcurl3 libcurl3-dev php5-curl php5-common php-xml-parser\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nNote, selecting 'php5-common' instead of 'php5-json'\nNote, selecting 'libcurl4-openssl-dev' instead of 'libcurl3-dev'\nphp-xml-parser is already the newest version.\napache2 is already the newest version.\ncurl is already the newest version.\nlibcurl3 is already the newest version.\nlibcurl4-openssl-dev is already the newest version.\nphp5 is already the newest version.\nphp5-common is already the newest version.\nphp5-curl is already the newest version.\nphp5-gd is already the newest version.\nphp5-sqlite is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n2 not fully installed or removed.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue [Y/n]? y\nSetting up qmail (1.06-4) ...\n\nThe hostname -f command returned: $1\nYour system needs to have a fully qualified domain name (fqdn) in\norder to install the var-qmail packages.\n\nInstallation aborted.\n\ndpkg: error processing qmail (--configure):\n subprocess installed post-installation script returned error exit status 1\ndpkg: dependency problems prevent configuration of qmail-run:\n qmail-run depends on qmail (>= 1.06-2.1); however:\n  Package qmail is not configured yet.\ndpkg: error processing qmail-run (--configure):\n dependency problems - leaving unconfigured\nNo apport report written because the error message indicates its a followup error from a previous failure.\n                          Errors were encountered while processing:\n qmail\n qmail-run\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nanyone can help me ? thanks advanced\n\nA: From the logs you show with your question, you have obviously a problem with the installation of a package. But the problem is not with the packages you were asking installation : apache2 php5 php5-json php5-gd php5-sqlite curl libcurl3 libcurl3-dev php5-curl php5-common php-xml-parser.\nLook at the line containing is already the newest version. All these packages are already installed.\nThe error is left by a previous tentative to install qmail which didn't succeed because of the hostname not having a fully qualified name.\nAs said before, setup a hostname like host.domain.tld by modifying /etc/hosts and /etc/hostname.\nYou should have at least in /etc/hosts a line saying :\n<your ip>  <hostname.domain.tld> <hostname>\nIf you are on a computer with dynamic IP address, use 127.0.0.1 as <your ip>. Or use the static ip you have received.\nSo you can already play around with Apache and PHP, unless the hostname problem stops Apache from working properly.\n\nA: Your system needs to have a fully qualified domain name (fqdn) in\norder to install the qmail packages. You probably have not set a domain, only a local hostname in /etc/hosts.  Also, a computer talks to itself using a reserved network address (usually 127.0.0.1).  In actual fact this is done via the kernel, but it still uses the networking process. More info on fdqn here.  \nFirst you should stop the mail service using:\n~$ service qmail stop\n\nor:\n~$ /etc/init.d/qmail stop\n\nNext remove the qmail pkg completely:\n~ $ sudo apt-get purge qmail\n\nEdit /etc/hosts \n~ $ sudo nano /etc/hosts\n\nFind the line:\n127.0.0.1 hostname \n\nChange to:\n127.0.0.1 --fqdn www.yourdomain.com hostname\n\nNext reinstall the qmail packages remembering your domain set in hosts.\nOn next reboot check with:\nhostname \n\nhostname -f \nThis should confirm your changes.\n", "Q: how to re-enable OpenGL I was trying to speed up my tiny laptop by switching off OpenGL using Compiz.  I guess there were also whole bunch of related plugins got disabled in the process.  Then I lost the entire GUI desktop interface.\nCould someone please tell me how to get everything back through command line?\nThanks.\n\nA: ON UBUNTU 14.04\n\n\n*\n\n*Switch to tty1 using Ctrl+Alt+F1\n\n*Login to your user account\n\n*And export your Display with\nexport DISPLAY=:0\n\n\n*Add opengl to Compiz active plugins list\ndconf write /org/compiz/profiles/unity/plugins/core/active-plugins \"[`dconf read /org/compiz/profiles/unity/plugins/core/active-plugins | sed -r 's/(\\[|\\])//g'`, 'opengl']\"\n\nOr reset the key to default\ndconf reset /org/compiz/profiles/unity/plugins/core/active-plugins\n\nIf it didn't work, come back and reset all Compiz settings to defaults\ndconf reset -f /org/compiz/\n\n\n*Restart graphical display manager after one of the dconf command above\nsudo service lightdm restart\n\n\n*Switch back to tty7 (X graphic display) Ctrl+Alt+F7\nTry login again.\n\nHowever, Compiz ccsm applies changes instantly so may be it's a nice habit to make configuration backup before change.\n\n\n*\n\n*Backup before change:\ndconf dump /org/compiz/ > compiz.dconf\n\n\n*Restore if things went wrong:\ndconf load /org/compiz/ < compiz.dconf\n\n\n*Sometimes it is helpful to monitor the changes: dconf watch /org/compiz/\nReference:\n\n\n*\n\n*man dconf\n\n*What is dconf, what is its function, and how do I use it?\n", "Q: How to create a new category in the GNOME menu? I want to create a custom category menu. How can I do that?\nFor example, I want to create a category menu named \"Halogen\" like Accessories, Games, Graphics, Internet..etc\n\nA: *\n\n*Need to write an XML .menu file to be installed in /etc/xdg/menus/applications-merged/\nExample /etc/xdg/menus/applications-merged/hamradio.menu\n<!DOCTYPE Menu PUBLIC \"-//freedesktop//DTD Menu 1.0//EN\"\n \"http://www.freedesktop.org/standards/menu-spec/1.0/menu.dtd\">\n<Menu>\n  <Name>Applications</Name>\n  <Menu>\n    <Name>Hamradio</Name>\n    <Directory>HamRadio.directory</Directory>\n    <Include>\n        <Category>HamRadio</Category>\n    </Include>\n  </Menu> <!-- End hamradio -->\n</Menu>\n\n\n*A .directory file to be install in /usr/share/desktop-directories/\nExample /usr/share/desktop-directories/HamRadio.directory ([...] I removed some lines)\n[Desktop Entry]\nType=Directory\nEncoding=UTF-8\nName=Hamradio\nName[bg]=Любителско радио\nName[ca]=Radioaficionat\nName[cs]=Amatérské rádio\n[...]\nName[vi]=Truyền thành tài tử\nName[zh_CN]=业余无线电\nName[zh_TW]=業餘無線電\nIcon=CQ.png\n\n\n*Add category to Categories= in application .desktop file and should be install in /usr/share/applications/\nReference: Freedesktop Menu Specification\n\nA: Based on info from http://www.omgubuntu.co.uk/2013/05/add-categories-to-gnome-shell-dashboard and http://en.wikibooks.org/wiki/Using_GNOME/Application_menus\nYou need to open the dconf Editor (command dc)\nFrom there navigate to org > gnome > shell \nYou should see an entry called \"app-folder-categories\".\nDouble click on this and add/remove categories as you desire.\nYou can also use the gsettings tool\ngsettings get org.gnome.shell.app-folder-categories\n\nwould should you the current categories and you can use the set command write a new value (which would be a comma separated list of your categories.\nTo place you software into the new category you will need to edit the .desktop launcher files located in /usr/share/applications/ . \nThere should be one for each application, if you open one in your editor you should see an entry called \"Categories\" and you can add/remove categories (including the one you just created).\n\nA: This extension should do what you want:\nhttps://extensions.gnome.org/extension/1217/appfolders-manager/\n", "Q: LXRandR error when (un-)installing software I got this error when installing Transmission and uninstalling some unused dependencies in LXDE:\n/usr/share/menu/lxrandr: missing required tag: \"section\"\nSkipping file because of errors...\n\nIs this bad?\n\nA: As far as I can see, it's just a packaging bug. Somebody munched the debian/menu file and forgot to copy it all over to lxrandr.menu.\nThe fourth comment gives you a way to fix this with a working menu entry. sudoedit /usr/share/menu/lxrandr and fill it with:\n?package(lxrandr):needs=\"X11\" section=\"Applications/System/Monitoring\"\\\n  title=\"LXRandR\" longtitle=\"LXDE monitor configuration tool\"\\\n  description=\"LXRandR is a GUI application for the Lightweight X11 Desktop Environment (LXDE). It's a very basic monitor config tool utilizing the X extension called RandR to change the screen resolution on the fly.\"\\\n  command=\"/usr/bin/lxrandr\"\n\n", "Q: How to download torrents in ubuntu 13.10 Every time I click on \"Get this torrent\", I get a window asking to choose a application: \n\nI have qBittorrent installed but I don't know how do I select it from this windows which open when I click on \"Choose\" from the previous window.\n\n\nA: In the little Another application... browsing window, click on File System on the left, then navigate to the directory usr and then bin (this may take a while to load, there are lots of files in this folder). There you will find the application qbittorrent. Choose it and click Open.\n\nA: You can download the torrent file directly to a folder then add it directly to qBittorrent. See screenshot below.\n\n\nA: as a work around, you can drag & drop the torrent or magnet (hyperlink) TEXT onto the qbittorrent application & it will start automatically. \n", "Q: Total newbie wants to know - Ubuntu Tweak - changing the computer name I have installed Ubuntu on an old PC to try and learn it and become familiar so I can switch away from Windows, although most probably not entirely.\nI've put my machine on a network and would like to change its name. Someone in a reply to this same question by another forum member suggested the following:\n\nIf you want a GUI assisted process install Ubuntu-Tweak. Among other\n  uses of this app is the ability to change computer name through tab\n  \"Computer-Details\" -> \"Hostname\"\n\nI have downloaded and installed the latest version of Ubuntu-Tweak, however I do not see a tab named as suggested above. What am I doing wrong? What am I missing?\nThe reason I started on a new question is that this reply was over 4 years old or thereabouts.\nThank you for your answers and consideration.\n\nA: Change hostname on this way\nsudo gedit /etc/hostname\n\nAnd change name\nYou should also edit /etc/hosts and change the line\n127.0.1.1     your-old-hostname\n\n", "Q: Can Ubuntu TRIM another (NTFS) partition? I have three questions for Ubuntu and TRIM/SSD experts.\n\n\n*\n\n*I've got SSD drive (SanDisk SDSSDP128G 128Gb). \n\n*Currently, it is the only hard drive. Connected via SATA cable however in BIOS using IDE mode rather than AHCI.\n\n*Installed WinXP SP2 on the first partition (16 GiB, NTFS), and then aligned it to SSD blocks using gparted live CD\n\n*Installed Ubuntu 12.04 LTS on the second partition (16 GiB, ext4, immediately after the previous partition)\n\n*The rest of the drive is unpartitioned for now; grub is used as OS loader.\n\n*Ubuntu mounts the first NTFS partition on startup (as done by Ubuntu install, I have not touched that)\n\n*Got confirmation from hdparm that drive supports TRIM\n\n*Enabled TRIM in Ubuntu using \"fstrim /\" which runs by cron\n\n\nNow, I spent weeks trying to get this info from the web. Some sources say NTFS does support TRIM, others say Win7 supports it (while using NTFS). Some sources say fstrim TRIMs the whole physical drive while others say it only TRIMs the current partition.\n\n\n*\n\n*Is \"fstrim /\" in the scenario above applies to 16 GiB ext4 partition only, or to the whole 128Gb drive? \n\n*If it only applies to the ext4 partition, is it possible at all to TRIM the first NTFS partition (from either Ubuntu or WinXP, but only using Ubuntu native or Win built-in tools, without dodgy software.com downloads)? Could hdparm and moving/copying physical sectors do anything to help? Partition cloning whatever?\n\n*What is the worst-case scenario if TRIM is not possible for NTFS: are there any firmware garbage collectors that could do similar thing without OS commands?\nPlease do not recommend switching to Win 7 whatsoever - I'm still happy with the development environment under Win XP. I'm still happy to use \"out-of-date\" OS if it boots in 7 seconds, gives immediate response to anything you do, and loads Photoshop in 3 seconds (for the first run:)\nThank you in advance,\nYaroslav\n\nA: TRIM is a filesystem level operation. It needs to know which sectors of the disk are free so that it can inform the hardware. Neither \"Discard\" nor \"Trim\" are documented features of the ntfs-3g driver so I would suggest that no, this probably isn't possible.\nThere have also been a few separate calls for this but it's a feature that would only really affect a few people.\nMy only real long-term solutions are:\n\n\n*\n\n*Stick it in a Windows machine (or boot to Windows) once every few months (I'm not sure what your churn rate is).\n\n*Use a real filesystem. Nothing makes people jealous like a nicely formatted ext4 partition. You'll need to juggle the data though.\n\n\nA: Update, looks like NTFS-3g got fstrim support in a patch from 2014-June.\nUbuntu 15.04 worked fine with fstrim on a loopback-mounted NTFS filesystem image I wanted to make sparser.  If 15.04's version of ntfs-3g includes that patch, it should work on mounted partitions, too.\nOther than that, ntfs-3g includes an ntfswipe command, which writes zeros over all unused space.  Don't use that on an SSD, it would increase wear.  I considered using it, then running fallocate --dig-holes (to sparse-ify all 4k blocks that were all zeros).  IDK fallocate maps to discard/trim when used on a block device, but it may.  Anyway, use fstrim to discard WITHOUT writing with zeroes first, since that works now.\n\nWhat is the worst-case scenario if TRIM is not possible for NTFS: are there any firmware garbage collectors that could do similar thing without OS commands?\n\nNo, trimming the free space of an NTFS filesystem requires a tool that understands NTFS.  Nobody's crazy enough to put something like that into SSD firmware, since it's a job better done by whatever software on the computer is reading the NTFS.\n\nA: Yes, it only applies to the one partition you run it on, and it should work just fine if you run it on your ntfs partition isntead of /.\n\nA: I got as far as to understand gnulinux can do it, but only to a FAT32 partition, and mounting it somehow in something, looking to figure out how. Have Windows XP installed coincidentally (but otherwise would have just reinstalled it on the format) on Fat32 due to otherwise not working on the SSD (tip maybe!). Extra info of some use to someone may be.\n", "Q: Convert RPM file to ISO file I want to download an OS. I have two options:\n\n\n*\n\n*either downloading ISO file  directly via remote link.\nOr  \n\n*Downloading RPM package via BitTorrent\nI want to download via BitTorrent. However, I want to get an ISO file .\nThe issue is how to convert this RPM package to ISO image file.\n\nA: In Ubuntu, we don\"t use RPM (RedHat) packages but DEB (Debian) packages.\nIf you have an ISO file, you have thus a CD-ROM image you can use to install the OS on a PC where the OS is not yet installed.\nIf you have packages (one package = one software, one OS is composed of a multitude of packages), you need at least to have an running installation of the OS to which these packages belong to proceed further.\n", "Q: Recover deleted log files I know that Ubuntu saves logs and rotates them overwriting older syslog.gz files.\nIs it possible to recover overwritten logs? Perhaps with a specific software.\n\nA: Once a file is overwritten, it is lost.\nWhat you can do is to adapt the logrotation settings to hold more occurence of the logs you are interested to.\nFor log files generated by the syslogd process (I'm not speaking here of rsyslog or syslog-ng that I'm not using), the logrotation is done by a specific script installed together with the sysklogd package); By default the script is /etc/cron.daily/sysklogd. It use the command savelog to rotate all the logs created by syslog.\nIf you need to keep more archived logs, update the line looking like :\nsavelog -g adm -m 640 -u ${USER} -c 7 $LOG >/dev/null\nThe number after the -c is the number of cycle, so the number of log archived in this case will be 7. (one per day as the script is run daily).\n", "Q: How to know what version of PHP is used on my xampp? I am using xampp on my Ubuntu OS. And I need to know what version of PHP my xampp is using.\nHow do I do that?\n\nA: Try with command from terminal\nsudo /opt/lampp/bin/php -v\n\n\nA: first you have to need the version of your Xampp\nxampp -v \n\nor\nxampp --version\n\nThen you can check the php version from xampp website\nyou can't know it from command line since it's bundled inside the Xampp\n\nA: Put this in your root directory:\n<?php\nphpinfo();\n?>\n\nSave it as phpinfo.php and point your browser to it (this could be http://localhost/phpinfo.php)\n\n\n*\n\n*More information (you can get much more information than just the version).\n\n*Example (random image):\n\n\n\n", "Q: What is the difference between /dev/tty* and /dev/bus/usb/001/002? When I plug in a device that uses the LUFA USB framework (or any USB<->serial peripheral), Ubuntu creates a /dev/ttyACM* device file. It also creates a /dev/bus/usb/001/002 file and a /sys/bus/usb/devices/usb1/1-1/1-1.3/1-1.3.1/ tree. \nWhat are the differences between these? I ask because I am using pyudev, which provides device nodes such as the /dev/bus/... example, but I don't know if this is different to the tty. Is it?\n\nA: The /sys/bus/usb/devices/* tree describes the full physical USB topology, and contains metadata about each device. \nThe /dev/bus/usb/<bus number>/<device number> devices address each device in a simplified way (so you don't have to care about whether a device is connected directly or via one or more USB hubs, just pick the right bus) and allows passing raw USB packets to/from the device. With a USB serial converter, you might send a request packet and get back a response describing the current state of the serial port's handshaking lines.\nThe /dev/ttyACM* device, on the other hand, hides the complexity of the USB bus and allows you to control the serial port of the USB<->serial peripheral pretty much like  a directly-connected serial port, with all the features of a Unix-style tty driver. Because of the latencies caused by the USB bus, some things may not work as well as with a \"real\" serial port: in particular, attempts to bit-bang the control lines with precise timing might not work.\n", "Q: what is the sudo -i command What does the sudo -i command do and in which situations would it be used. read it using the man sudo command but i'm looking for a more diluted discription to help me understand better.\n\nA: sudo lets you run commands in your own user account with root privileges. su lets you switch user so that you're actually logged in as root.\nsudo -s runs a shell with root privileges. sudo -i does this as well, but also acquires the root user's environment.\nThis means that login-specific resource files such as .profile, .bashrc or .login will be read and executed by the shell.\n\nA: Basically, you use sudo -i when you know you will be running various commands that need root access and don't want to run each of them with sudo. To illustrate:\n$ whoami\nterdon\n$ sudo -i\n[sudo] password for terdon: \n# whoami\nroot\n\nSo, after running sudo -i all subsequent commands you run will be run as though you had run them with sudo. You are now logged in as root and no longer need sudo to gain privileges. \n", "Q: Why is moving directories to /dev/null dangerous? When trying to move a test_dir directory to /dev/null, I get the message\nmv: cannot overwrite non-directory ‘/dev/null’ with directory ‘test_dir/’\n\nThen why do people say \"Don't run the command sudo mv ~ /dev/null, it will move your home directory to a hole?\"\nLink\nBut /home is also a directory.\n\nA: Everything sent to /dev/null is silently discarded.\nIf you type:\necho \"Hello World\"\n\nyou get Hello World on the screen.\nIf you type:\necho \"Hello World\" >/dev/null\n\nyou don't get anything on the screen.\nBut in the case of the move command, the command mv try to replace the file /dev/null by the directory, what is not possible. Because everything is a file in Linux, /dev/null is a file. A special one of course (a device file), a special file allowing accessing piece of hardware (like disks, partitions, sound cards, serial ports, ...). In the case of /dev/null, this is not linked to any piece of hardware so the data sent to it is silently discarded. This is why \"they\" may have called it a blackhole.\n\nA: Because people assume. I was one of those people until I tested it. It's easy to understand why people assume... It looks dangerous...\n... but you can't actually move things to /dev/null — It's a special file that just absorbs redirects (and sends them into nothingness). If you try to move a directory to it, the filesystem will verbosely explode in your face and if you try to move a file to it, you will probably end up replacing it.\nThe first link will deal with directories, but  here's a separate test just for overwriting it with a file. As Rmano points out in the comments, this is probably something you shouldn't do without adult supervision. There is risk involved.\n$ echo \"this is my file\" > test\n$ cat test\nthis is my file\n\n$ sudo mv test /dev/null\n$ cat /dev/null\nthis is my file\n\n# Fix this!\n$ sudo rm /dev/null\n$ sudo mknod -m 0666 /dev/null c 1 3\n\n\nA: /dev/null is just a file, it's a \"special character\" file but it's non the less still bound by the rules that files must follow. That being said you could never run this command:\n$ mv ~ /dev/null\n\nThe mv command won't allow this since you're moving a directory to a file, that just doesn't make sense contextually and mv knows this.\nExample\n$ mkdir dir\n$ touch afile\n$ mv dir afile\nmv: cannot overwrite non-directory ‘afile’ with directory ‘dir’\n\nYou can't copy onto /dev/null either, given it's a character file, if you try to copy a regular file onto it.\n$ cp ~/bzip2_1.0.6-4_amd64.deb /dev/null\n$ ls -l |grep null\ncrw-rw-rw-  1 root root        1,   3 Mar 16 14:25 null\n\nAbout the only thing you can do to this file is copy mv over it another file or delete it.\n$ mv /path/to/afile /dev/null\n\nAfter this command, /dev/null is a regular file. The most dangerous effect of this change is that /dev/null is supposed to never output any data, so a number of shell script will assume that \n`... < /dev/null` \n\nis equivalent to say \"nothing\". Having this assumption broken can lead to random data (well, the data the last process wrote to `/dev/null')  inserted in system files all around the system --- which could lead to an utterly broken and unrecoverable system.\n\nA: You can write files or other input streams to /dev/null but not directories. If you try moving a directory to /dev/null it would report an error since /dev/null is not a directory but a file.\nHowever, since you want to experiment with /dev/null, you are first suggested to know the consequences to moving a file to overwrite /dev/null and how to recover from that situation:\n\n\n*\n\n*I can read from /dev/null; how to fix it?\nAs suggested by @Rmano in this answer to that question, in order to experiment with /dev/null we should rather create a copy of it and then do our experimentation. So, let's create /tmp/null and use it for our experimentation purposes:\nsudo mknod -m 0666 /tmp/null c 1 3\n\nNow onwards, /tmp/null is our /dev/null for all purposes:\nLet us create a test_file and a test_dir inside a directory called ask_ubuntu.\n$ mkdir ask_ubuntu\n$ cd ask_ubuntu\n$ touch test_file\n$ mkdir test_dir\n$ echo \"Let us test if we can recover our test_file.\" > test_file\n\nThe following shows the contents of ask_ubuntu directory:\n$ ls -la\ntotal 12\ndrwxr-xr-x 3 aditya aditya 4096 Mar 18 17:10 .\ndrwxr-xr-x 4 aditya aditya 4096 Mar 18 17:10 ..\ndrwxr-xr-x 2 aditya aditya 4096 Mar 18 17:10 test_dir\n-rw-r--r-- 1 aditya aditya    0 Mar 18 17:10 test_file\n\nNow try to move our test_file to /tmp/null and see the contents of ask_ubuntu:\n$ sudo mv test_file /tmp/null   # This succeeds\n$ ls -la\ntotal 12\ndrwxr-xr-x 3 aditya aditya 4096 Mar 18 17:12 .\ndrwxr-xr-x 4 aditya aditya 4096 Mar 18 17:10 ..\ndrwxr-xr-x 2 aditya aditya 4096 Mar 18 17:10 test_dir\n\nThe command succeeds and test_file is no longer available. Now try to move test_dir to /tmp/null which doesn't succeed:\n$ sudo mv test_dir/ /tmp/null \nmv: cannot overwrite non-directory ‘/tmp/null’ with directory ‘test_dir/’\n\ntest_dir is still present inside ask_ubuntu:\n$ ls -la\ntotal 12\ndrwxr-xr-x 3 aditya aditya 4096 Mar 18 17:12 .\ndrwxr-xr-x 4 aditya aditya 4096 Mar 18 17:10 ..\ndrwxr-xr-x 2 aditya aditya 4096 Mar 18 17:10 test_dir\n\nNow, let us figure if we can recover our test_file from /tmp/null:\n$ cat /tmp/null\nLet us test if we can recover our test_file.\n\nSo, it is still there and /tmp/null which was a special file has been overwritten and it has become like any other normal file. We can recover our file by copying /tmp/null just like any other file:\n$ cp /tmp/null our_test_file\n$ cat our_test_file\nLet us test if we can recover our test_file.\n\nFile recovered.\nNote:\nIf you didn't create /tmp/null and tried those commands directly using /dev/null; make sure you recover the file (if you need to) by running cp /dev/null our_test_file; and restore /dev/null for the purposes it exists on our system by running the following commands as given in the linked question as soon as possible:\n$ sudo rm /dev/null\n$ sudo mknod /dev/null c 1 3\n$ sudo chmod 666 /dev/null\n\nConclusion:\n\n\n*\n\n*So, it is impossible to move a directory to /dev/null and hence there is no question of recovering the directory from there.\n\n*As far as files are concerned, if you directly move files to /dev/null, you can still recover it as demonstrated above. However, there are two exceptions:\n\n\n*\n\n*During the period you run sudo mv test_file /dev/null and cp /dev/null our_test_file, if any root script in the system overwrites it by running echo \"Whatever text the root script wants to send to /dev/null\" > /dev/null (or other similar commands). Then we do not have any easy way to recover our file.\n\n*If you reboot the system between running those two commands. /dev/null gets re-created at boot, so our file gets lost when we shut down the computer.\n\n\n*But if you want to recover input streams like echo \"Stream this line to /dev/null\" > /dev/null, you cannot recover that since /dev/null is a special file to dispose off unwanted files and input streams and as the Wikipedia article mentions, it doesn't provide any data to a process that reads from it.\n\nReference: Wikipedia Article on /dev/null\n", "Q: python photometry tools \nAnybody has experience with photometry? I am trying to use ppt (Python Photometric Toolbox) with no success. I have two branching questions:\n\n\n*\n\n*anybody can suggest a WORKING photometry solution running under Saucy Salamander\nor\n\n*is here an experienced Python guru to help to interpret why is this message:\nFile \"/usr/lib/python2.7/subprocess.py\", line 522, in call\n    return Popen(*popenargs, **kwargs).wait()\nFile \"/usr/lib/python2.7/subprocess.py\", line 709, in __init__\n    errread, errwrite)\nFile \"/usr/lib/python2.7/subprocess.py\", line 1326, in _execute_child\n    raise child_exception\nOSError: [Errno 8] Exec format error\n\n\nA: The error looks like it's trying to run an external command (that's sort of what subprocess does) and that's breaking.\nBut why is that breaking? I see no mention of cross-platform support on the Photometric Toolbox website and all the screenshots are for Windows... I would suggest it's trying to run a Windows exe (or some such) and that's exploding (as it would).\nI'd punch this back to Lighting Analysts, Inc to confirm.\nNot having the library (or the $250 in disposable cash to buy it) I can't really help much more than to say you might be able to convince certain elements to use Wine but this is going to require substantial work for a completely unguaranteed result. I'd pick another library of fold and use it on the platform it works on.\n", "Q: Non-root users to shutdown using PAM I want to configure PAM to enable non-root normal users to be able to shutdown. how to do that? \nI'm using Ubuntu server 12.04\n\nI know how to do that with many ways such as changing permissions of the binary or adding exceptions in the sudeors....\nI don't want to change permissions\nI don't know to configure policykit\nI don't want to give permissions from sudeors\nI need only to learn how to do it by confiuring PAM not any onther method\n\nA: policykit also work on server, I'd suggest to modify (as root) the following file: \n/usr/share/polkit-1/actions/org.freedesktop.login1.policy\n\nLook at actions like this one: \naction id=\"org.freedesktop.login1.power-off\"\n\nAnd replace allow_any, allow_inactive, and allow_active values by yes to allow non root users to perform a power off without any authentication.\n", "Q: install spectrum3d on ubuntu I want to install a spectral analysis tool for Ubuntu, and thought Spectrum3d looked good. \nI've tried following the install instructions. As far as I understand, I am supposed to write:\nsudo add-apt-repository ppa:nadaeck/spectrum3d\n\nin the terminal. It doesn't work. I get the following error message:\nTraceback (most recent call last):\n  File \"/usr/bin/add-apt-repository\", line 128, in <module>\n    ppa_info = get_ppa_info_from_lp(user, ppa_name)\n  File \"/usr/lib/python2.7/dist-packages/softwareproperties/ppa.py\", line 84, in get_ppa_info_from_lp\ncurl.perform()\npycurl.error: (7, \"couldn't connect to host\")\n\nFrom my rudimentary understanding of linux, I should be able to write my sudo password here, but the characters I write are shown in cleartext. It never asks for my password\nWhen this didn't work, I tried to download it from sourceforge and compile it, I also tried searching for it in the Ubuntu Software Centre, but I couldn't find it.\nI downloaded the latest version and went to the folder and typed:\n./configure; make; make install\n\nI got the following output:\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking for gcc... gcc\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables... \nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to accept ISO C89... none needed\nchecking for style of include used by make... GNU\nchecking dependency style of gcc... gcc3\nchecking whether gcc and cc understand -c and -o together... yes\nchecking for pkg-config... /usr/bin/pkg-config\nchecking pkg-config is at least version 0.9.0... yes\nchecking for GTK3... no\nchecking for GTK2... no\nconfigure: error: GTK library (libgtk-2.0 or libgtk-3.0) is required\nmake: *** No targets specified and no makefile found.  Stop.\nmake: *** No rule to make target `install'.  Stop.\n\nSo, how do I just get this program up and running on my system?\n\nA: That PPA is too old, doesn't have packages available for 13.10 and newer, so you would need to compile the sources instead. You need some headers and tools to build the software:\nsudo apt-get install aptitude\nsudo aptitude install build-essential libgtk-3-dev libgstreamer0.10-dev libsdl1.2-dev\n\nAfter this is done, you can run ./configure and build your packages as usual:\n./configure\n[...]\nconfig.status: executing depfiles commands\n\nconfigure: If you want to use gtkglext, its version should match the gtk version (gtkglext-1.0 for gtk-2.0, gtkglext-3.0 for gtk-3.0)\n\nconfigure:      ******************************************\nconfigure:      *  Gstreamer version ...............1.0  *\nconfigure:      *  GTK version .................GTK-3.0  *\nconfigure:      *  OpenGL support...................SDL  *\nconfigure:      *  JACK support......................NO  *\nconfigure:      *  MULTITOUCH support................NO  *\nconfigure:      ******************************************\n\nThe only thing left is make && make install. I strongly recommend building a debian package instead, so you can upgrade/remove easily.\n", "Q: Ubuntu apps development - how to communicate betwen 2 pages On one Page I have displayed ListView and on child Page I creating new records.\nWhen the child Page is Closed I would like to refresh the ListView.\nIs there some Signel which inform me when page get focus or something simmilar ?\nIt's done in QML using the Page from Ubuntu.Components.\n\nA:  Connections{\n     target: pageStack\n     onCurrentPageChanged:{\n         if( pageStack.currentPage === mainPage2) {\n             print (\"back on page mainPage2\")\n\n         }\n         else {\n             print (\"exiting page mainPage2\")\n         }\n     }\n }\n\n", "Q: How to extract xyz.arc file in ubuntu? How do I extract a .ARC file in Ubuntu?\n\nA: You must install nomarch\nsudo apt-get install nomarch\n\nafter installation\nnomarch -p arhive.arc\n\nAlso you have man pages for additional options \nman nomarch\n\n\nA: Have a look to unar, it says that unar is an unarchiver for a variety of file formats. (done a apt-cache search unarc and get back this entry on a Ubuntu 13.10).\n\nA: nomarch and unar could not recognize the ARC file that my customer sent me. Probably they operate only on older versions of the archive format.\nFreeARC could extract the file though. It is not a Ubuntu package, but just unpack the Linux archive somewhere in your home folder and run \"make install\". Then you can use \"unarc x archive.arc\" to attack and conquer the ARC file.\n", "Q: I can read from /dev/null; how to fix it? I read the Wikipedia article on /dev/null and was playing around by moving files to /dev/null.\nFor this I created a test_file and put some contents in it:\n$ touch test_file\n$ echo \"This is written by Aditya\" > test_file\n$ cat test_file\nThis is written by Aditya\n\nThereafter I tried to move the file to /dev/null:\n$ mv test_file /dev/null\nmv: inter-device move failed: ‘test_file’ to ‘/dev/null’; unable to remove target: Permission denied\n\nSince, this gave me a Permission denied Error; I went ahead and used sudo as I normally do whenever I encounter a Permission denied error.\n$ sudo mv test_file /dev/null\n\nThe command succeeded and test_file is no longer present in the directory.\nHowever, the Wikipedia article says that it is not possible to recover anything moved to /dev/null and it gives an EOF to any process that tries to read from it. But, I can read from /dev/null:\n$ cat /dev/null\nThis is written by Aditya\n\nWhat did I do wrong and how do I fix /dev/null back to normal? And why did I encounter Permission denied error in the first place?\n\nA: When you run the command\n$ sudo mv test_file /dev/null\n\nyou have replaced the special file /dev/null with your text file. Subsequent attempts to read from /dev/null return the contents of your text file, and programs that attempt to use /dev/null in the normal way will probably break.\nReplacing or deleting device files in /dev/ requires superuser privileges, which is why your non-sudo attempt failed with an error.\nSee Benoit's answer for information on how to restore /dev/null manually, but since most (if not all) of the content of /dev/ is managed dynamically by udev, I suspect a simple reboot will probably fix it too.\n\nA: To answer your question of what you should have done, to remove a file, you do:\nrm test_file\n\nAs others have stated, /dev/null is a destination for the output of programs. \n\nA: There is a big difference between overwriting a file and writing to a file.\nWhen you write something to /dev/null, e.g.,\n$ echo Hello > /dev/null\n\n...it gets silently discarded. For this you need write permissions to /dev/null, which everyone has:\n$ ls -l /dev/null \ncrw-rw-rw- 1 root root 1, 3 Mar 18 13:17 /dev/null\n\nWhen you overwrite /dev/null, as you did with the mv command, you replace the special file /dev/null with whatever you moved there. Don't do this! The reason you needed root privileges to do that is because to overwrite a file, you need write permissions to the directory that contains the file, in this case /dev:\n$ ls -ld /dev\ndrwxr-xr-x 16 root root 4640 Mar 18 13:17 /dev\n\nTo restore /dev/null, issue the commands\n$ sudo rm /dev/null\n$ sudo mknod -m 0666 /dev/null c 1 3\n\n(Also see U&L StackExchange: How to create /dev/null)\n\nA: /dev/null is a file. A special file. A device file like /dev/sda or /dev/tty that talks to a piece of hardware on your system.\nThe only difference with /dev/null is that no hardware is linked to it. Any data you send to it is silently discarded. Like the following command:\necho \"Hello World\" > /dev/null\n\nwhich won't print anything on your terminal because you send the output of echo to null, to the void, a black hole thus.\nBut when you did mv test_file /dev/null you've replaced the special file /dev/null by a normal text file, holding a copy of the content of your test_file.\nIn other words, you've lost your /dev/null. \nNow, what you have to do is (to reconstruct it):\nsudo rm /dev/null\nsudo mknod -m 0666 /dev/null c 1 3\n\nYou should reconstruct it because a lot of scripts by default send output to /dev/null. If /dev/null is no more a black hole but a regular text file, it may grow, grow and fill your file-system up. And I'm sure you want to avoid this.\nAnd much more dangerous, a lot of scripts assume that reading from /dev/null will read nothing; breaking this assumption can lead to random garbage written in files all around your system... practically impossible to fix up. \nAnd remember that Linux is multi-tasking: while you are playing with /dev/null, a lot of processes are running and can wreak havoc even during a few seconds \"window of opportunity\". \nIf you want to play with /dev/null you can create a copy and experiment with it: \nsudo mknod -m 0666 /tmp/null c 1 3 \n\nWill create a /tmp/null file that works in the exactly same way of /dev/null but that you can manipulate and test without any risk for your system. \n", "Q: Installation on USB \n*\n\n*Using Universal USB installer 1.9.5.2. setup the screen states Installation done, Process is completed. However an error message states I couldn't find a configuration file.Ubuntu 12.04.4 desktop i386 is not supported.  How do I fix this? I Used my MSI U100 notebook with processor atom n270 1.60 GHz, and a Memory stick Patriot XT 16GB.  Checking the memory stick I find no new content added.    \n\n*If I install Ubuntu directly on my computer -- does it remove my Windows XP or can I switch between them ?\n\nA: *\n\n*This error message is specific to the process you are using to create the Live USB, so it's hard to know what went wrong. I suggest you try another process, there are many out there (Google). If you fail, please include more details on what commands you ran, the output etc.\n\n*If you install Ubuntu on your computer, you will get the option to resize your Windows partition (for example from 200 Gb to 100 Gb) and install Ubuntu in the newly freed up space, on a new partition. These two partitions will be seen almost as two physical disks by your system. Ubuntu will also detect your Windows XP installation and give you the option to boot it. A tip: if your computer runs XP it's probably pretty old. Run Xubuntu instead of Ubuntu as it has a lighter graphical interface. 14.04 is the next Long Term Support release and it's coming this April, so I would hold out for that release.\n\nA: I have nice experience with unetbootin and I recommend to use him for creation of boot-able usb stick. Is simple to use.\nYes you can install ubuntu and have windows on same pc. You must free some space on disk for ubuntu installation. Good guide for dual boot you can find on this link\n", "Q: Shortcut to change the gnome-terminal font size I need fast shortcut to change the terminal font size. I use gnome-terminal.\nI tried with Ctrl + + and Ctrl + - but the size is not changed.\nIs there another shortcut? Can I add a shortcut like this?\n\nA: Trick that worked for me was to use Ctrl + Shift + = or Ctrl + - but NOT on numeric keyboard.\n\nA: Remember that terminal is VERY literal! The + key Ubuntu terminal wants is on top row and requires Shift otherwise it's =. \n\nA: Ctrl++ and Ctrl+- are working fine for me. Maybe you have different shortcuts configured.\nTo change the keyboard shortcuts, go to Edit -> Keyboard Shortcuts... in the gnome-terminal menu, and look for Zoom In and Zoom Out:\n\n\nA: Try Shift Ctrl +for increasing \nand Ctrl - for decreasing font size.\nNote: the Shift key is needed on some systems.\n", "Q: Using Thunderbird to automatically backup my email account I use Thunderbird to backup my web-based email account: I open Thunderbird and copy the mail messages from the Inbox to a local folder. \nIs there a way to do this automatically every day, so that I don't have to open Thunderbird all the time?\nEDIT: GMVault is very useful for GMail accounts. For non-GMail account, the getmail method should probably be used.\n\nA: Thunderbird uses the IMAP protocol to download messages. There are command-line IMAP utilities with which you can automate connecting and downloading messages from your account. Look at getmail (http://pyropus.ca/software/getmail/) as a possible option. You can very easily automate this with a cron job (How do I set up a Cron job?).\nAs an example you could create a ~/.getmail/getmailrc file with something like:\n[retriever]\ntype = SimplePOP3Retriever\nserver = pop.example.net\nusername = your.username\npassword = mailpassword\n\n[destination]\ntype = Maildir\npath = ~your-username/Maildir/\n\nThen in /etc/cron.d add a file \"retrieve-email\" with something like this:\n15 10 * * * your-username getmail\n\nhis will cause getmail to download your email every day at 10:15 AM and put it in the Maildir directory.\nPLEASE don't use these examples as they are; they are incomplete and illustrative only, I haven't tested them. Read the documentation I referred to so you can understand which getmail parameters you need.\n", "Q: What does the question mark in terminal command mean? This question (How can I remove gnome from a kubuntu 12.04 install?) have the commands with question markes: \nsudo apt-get remove --purge ubuntu-desktop\nsudo apt-get remove --purge unity?\nsudo apt-get remove --purge gnome?\n\nWhat do they mean?\n\nA: Generally speaking, in Bash, a ? is a glob pattern that expands to an arbitrary character.\nFor example:\n$ echo Hello1 > foo1\n$ echo Hello2 > foo2\n$ cat foo?\nHello1\nHello2\n\nIt is akin to a *, but a * expands to 0 or more characters, while a ? expands to exactly one (arbitrary) character.\nIn your special case though, the ? in the command was apparently a typo.\n\nA: Those are called Wildcards (globbing patterns)\n\nStandard wildcards (also known as globbing patterns) are used by various command-line utilities to work with multiple files.\n  Standard wildcards are used by nearly any command (including mv, cp, rm and many others).\n\n\n\n*\n\n*(question mark)\n\nthis can represent any single character. If you specified something at the command line like \"hd?\" GNU/Linux would look for hda, hdb, hdc and every other letter/number between a-z, 0-9.\n\n\n**(asterisk)\n\nthis can represent any number of characters (including zero, in other words, zero or more characters). If you specified a \"cd*\" it would use \"cda\", \"cdrom\", \"cdrecord\" and anything that starts with “cd” also including “cd” itself. \"m*l\" could by mill, mull, ml, and anything that starts with an m and ends with an l.\n\n\n*[ ] (square brackets)\n\nspecifies a range. If you did m[a,o,u]m it can become: mam, mum, mom if you did: m[a-d]m it can become anything that starts and ends with m and has any character a to d inbetween. For example, these would work: mam, mbm, mcm, mdm. This kind of wildcard specifies an “or” relationship (you only need one to match).\n\n\n*{ } (curly brackets)\n\nterms are separated by commas and each term must be the name of something or a wildcard. This wildcard will copy anything that matches either wildcard(s), or exact name(s) (an “or” relationship, one or the other).\n\n\nFor example, this would be valid:\n\n\n*\n\n*cp {.doc,.pdf} ~\n\nThis will copy anything ending with .doc or .pdf to the users home directory. Note that spaces are not allowed after the commas (or anywhere else).\n\n\n*[!]\n\nThis construct is similar to the [ ] construct, except rather than matching any characters inside the brackets, it'll match any character, as long as it is not listed between the [ and ]. This is a logical NOT. For example rm myfile[!9] will remove all myfiles* (ie. myfiles1, myfiles2 etc) but won't remove a file with the number 9 anywhere within it's name.\n\n\n*\\ (backslash)\n\nis used as an \"escape\" character, i.e. to protect a subsequent special character. Thus, \"\\” searches for a backslash. Note you may need to use quotation marks and backslash(es).\n\nfor more examples: visit this page\n", "Q: Ubuntu 13.10 - i am running in KIOSK train station public place, but this autoupdate window is annoying every day. How to remove it please? I need to remove this auto update notification dialog window which is very annoying and scary for public location where people is clicking the system and breaking it down to crash every day.\nI tried to remove the Autoupdate notification window with following, but still every single day its showing in the screen and its very annoying like Ubuntu Virus, very disturbing and not respecting privacy, such as i do not want it to ever show, but it keeps showing by force.\nTry: sudo sed -i 's/NoDisplay=true/NoDisplay=false/g' /etc/xdg/autostart/*.desktop\n\nTry: apt-get install dconf-editor\nexport DISPLAY=:0.0 && dconf-editor\nvia GUI > go to com->ubuntu->update-notifer-> no-show-notifications and enable it\n\nTry: Disable Auto uploader\n$ comment outall /etc/apt/apt.conf.d/50unattended-upgrades \n$ add new line /etc/apt/apt.conf.d/10periodic\nAPT::Periodic::Unattended-Upgrade \"0\";\n\nBut still the Auto-Update Notification Dialog window appears. \nI am unable to remove it for completely.\n\nA: Edit the configuration at /etc/apt/apt.conf.d/50unattended-upgrades to comment out the line:\nUnattended-Upgrade::Allowed-Origins {\n        \"${distro_id}:${distro_codename}-security\";\n//      \"${distro_id}:${distro_codename}-updates\";\n//      \"${distro_id}:${distro_codename}-proposed\";\n//      \"${distro_id}:${distro_codename}-backports\";\n};\n\nRemove the second line that ends with -security\nUnattended-Upgrade::Allowed-Origins {\n//      \"${distro_id}:${distro_codename}-security\";\n//      \"${distro_id}:${distro_codename}-updates\";\n//      \"${distro_id}:${distro_codename}-proposed\";\n//      \"${distro_id}:${distro_codename}-backports\";\n};\n\nThat should disable automatic updates since there is no location for it to pull updates from after commenting the location out.\n", "Q: Windows Boot on 2nd Hard Disc Drive I have ventured into the Ubunta world.  I decided to completely ditch Windows so I didn't do a Windows and Ubuntu install but just installed Ubuntu 12.04.  Because I can't sync my iphone I have installed a second HDD with XP on it?  How do I get the option to boot XP.  I seem to only be able to find answers with Windows on HDD1 and Ubuntu on HDD2\n\nA: If you are using GRUB as a bootloader you should be able to simply run sudo update-grub in Ubuntu , this till trigger GRUB to look for new disks and operating systems. See also update-grub man page.\nIf you are not running GRUB but the Windows bootloader, you can modify that screen with EasyBCD.\n", "Q: Can I set Internet usage quota in squid on Ubuntu 12.04 I want to set Internet usage quota in squid on Ubuntu 12.04.\nPlease suggest me the squid policy for set Internet usage quotas.\nThanks in advance\nRakesh\n\nA: This how-to has fairly detailed instructions on setting up bandwidth limit pools in squidproxy.\nYou could also go the route of a 3rd-party solution, like Squid Quota.\n", "Q: need assistance setting up wired internet on ubuntu sacy(13.10) im on a state internet and  I need a need assistance setting up my ip. On windows 7 it was easy. but on ubuntu it is a a bit difficult. My school use Alt DNS as well as DNS and my ip never changes but I have to enter it into a field but I don't know where it uses subnet and default gateway how would I enter it please help and thank you please contact if you need additional information\n\nA: Configuration of nic is thesame for win and linux. Check if your nic in win set do get data from dhcp, if yes in Network-manager set this option for nic.\nYou have configuration manual here\nMaybe you got ip param based on the mac address of nic. If answer is yes, you must change mac address.\nEasiest way to change mac address on nic is:\nsudo ifconfig eth0 down\nsudo ifconfig eth0 hw ether  xx:xx:xx:xx:xx:xx\nsudo ifconfig eth0 up\n\nWhere xx:xx:xx:xx:xx:xx represent mac addressc address of nic card.\n", "Q: ndiswrapper error I am trying to install ndiswrapper with the command sudo apt-get install ndiswrapper\nand I get the \"unable to locate package\" error.\nI run Ubuntu 12.10 and I do not have an internet connection atm on that laptop.\nI have downloaded the ndiswrapper package, which is in /home/x/Downloads/.\nPlease help, thank you.\n\nA: By default, apt-get tries to download the package from the repositories. You should instead do it with dpkg, like:\nsudo dpkg -i /home/x/Downloads/ndiswrapper.deb\nIf the package file name is different from ndiswrapper.deb change the command accordingly. \nOr you can simply double click on the .deb file -- this will open the Software Centre and there you just need to click \"Install\".\n", "Q: Sending enter in interaction mode ubuntu 13.10 I'm trying to make a basic script for deployment of ocs-inventory and I got stuck on a problem. \nWhen I issue this command:\nsudo apt-get install -y ocsinventory-agent\n\nThe interactive window appears. The only thing I need to do is press enter. \nIt's the same type of graphic prompt which you get when you are installing kerberos5.\nIs there any possibility to include the \"enter\" in script ? \n\nA: Basically you have to preseed the answer for debconf:\nsudo apt-get install debconf-utils\necho \"ocsinventory-agent ocsinventory-agent/method select local\" | sudo debconf-set-selections\nsudo apt-get install -y --force-yes ocsinventory-agent\n\nYou can obviously change local by server for your needs.\n\nA: Try the following:\n\nYou can do a couple of things for avoiding this\nFirst set the variable export DEBIAN_FRONTEND=noninteractive then you\n  can run apt-get -y install [packagename], this should do exactly what\n  you want.\n\nSource: https://serverfault.com/questions/227190/how-do-i-ask-apt-get-to-skip-any-interactive-post-install-configuration-steps\n", "Q: Second HDD from Windows as backup So I'm migrating back to Ubuntu after a long struggle with Windows specific applications for my college work. My problem is, I now have two hard drives in my laptop, an SSD and a mechanical one. I plan to install Ubuntu on my SSD (not dual boot with Windows) while my mechanical HDD would serve as a backup storage for my residual files from my Windows.\nCan my mechanical HDD then be accessible when I go into Ubuntu after the install? Or do I need to change the filesystem and what not? \n\nA: You will likely have to set the BIOS and possibly jumpers on the mechanical hard drive to be a slave drive versus the primary drive. Your Ubuntu SSD Drive should be set to be the primary, but yes all of this is able to be accomplished. The manufacturer of the hard drives should have Support online that specifies how to accomplish the change to make the drive a primary or a slave.\nOnce this has been done successfully, Ubuntu should recognise the older drive and allow the drive to be seen if you manually partition your drive during setup and provide a mount point for the other drive. However, until the master(primary)/slave relationship is established in the hardware appropriately, then the system may not boot as desired (two masters in system can not co-exist).\nIf you run into trouble, consult the drive manufacturer's website as they usually can provide the information on configuring the device as a slave. \n", "Q: Do I Need Linux Drivers For Virtual Box? I have recently fallen in love with Linux. I first decided to try out Ubuntu 13.10 a few weeks ago, but I bricked it by incorrectly installing an AMD FGLRX driver. Then I reformatted and wiped that partition to try out Linux Mint 16. I did the same thing with Mint, as well as with Fedora 20, 19, and 18 (in that order). Now I am on a stable Ubuntu 12.04 because I know how to use it vastly more than the other distros I've tried and because it seems like it has the biggest online support group.\nBecause I am now tired of reformatting and reinstalling broken distros, I thought it would be a good idea to get at least one distro stable (Precise) and to test the driver installations and other risky modifications for that distro and others with them running in Oracle Virtual Box since I don't trust my Linux skill (lack?) at the moment. This way, I optimize the distros in the Box, take a \"snapshot\" like saving a video game, and try out the risky operations. If they fail and I break the distro, I can just open the snapshot up and go back to where I was right before the risky operation. \nWhile this still seems like the best idea so far, I have noticed that the distros I have installed on Virtual Box report that I am NOT using my computer's actual hardware, and am actually using Virtual Box's \"hardware\", for instance, the \"Innotek Systemberatung GmbH VirtualBox Graphics adapter.\nBecause of that adapter, my test graphics installations do not work properly. Even the operations I know would brick the distro with a black screen are not working. \"My adapter is incompatible,\" FGLRX installation says, in the GUI version of installation (one of many methods).\nMy questions are: Can I not install these drivers inside of Virtual Box? Do I need some additional software? Is there any other virtual environment I could use for testing these distros that would result in a 100% identical virtual installation?\n\nI am using the notoriously Linux-unfriendly Acer Aspire 5553G, which has \"switchable graphics\".  Those cards are the Mobility Radeon HD 4250 and 5470. The driver's I have tested so far work in Windows 7, yet do not in Linux. \nThank you all in advance!\n\nA: The short answer is no, you don't need extra drivers for Virtual Box.\nThe Virtual Box (or any any virtual machine software) creates a virtual computer with virtual hardware that are completely compatible with Linux. This means the virtual computer will have the same virtual graphics card irrespective of the actual graphics card in your computer. In theory, you should be able to copy your virtual installation of Ubuntu into another computer with a completely different graphics card and run is there, after installing the virtual machine software there.\nIn your case, inside the Virtual Box, there is no Mobility Radeon HD 4250 and 5470. These cards don't exist in the virtual world. Only the virtual card virtually manufactured by Virtual Box is there. This virtual card has open source Linux drivers. So when you install Ubuntu inside the Virtual Box, it only sees the virtual card. Ubuntu won't install the FGLRX driver which is for AMD Radeon cards as it can't see the AMD cards that are there in the real PC, but does not exist in the virtual PC.\nThe downside of using a virtual machine is that you won't be able to use the full capability of your graphics card inside the virtual machine. The virtual graphics card inside the virtual machine is likely to be less capable.\nHope this helps.\n\nA: Short answer: Depend on what you intend with drivers. Anyway, the virtual machine will be of no use to test \"native\" graphic drivers for your physical PC. \nLong answer: \nwhen you install Virtualbox it will add a couple of drivers to your physical machine. You can see these by lsmod: \n(0)pern:~% lsmod | grep vbox\nvboxpci                22896  0 \nvboxnetadp             25636  0 \nvboxnetflt             27291  0 \nvboxdrv               285210  3 vboxnetadp,vboxnetflt,vboxpci\n\n(more or less) which are the drivers that the virtual machines will use to share the memory, network and physical resources of your real computer with the virtual machines. You cannot run VirtualBox without them. \nWhen you install a Virtual Machine (being that one a Linux one or a Windows one), VirtualBox will simulate a completely standard hardware drivers. So normally you can run the virtual machine \"out of the box\" with the standard, basic drivers that are present in any distribution. \nYour original graphic hardware is invisible from the virtual machine (as your real network driver, wifi driver, etc). So you can't test the original graphic drivers in it, sorry.(1) \nBut that way the performance of some things (graphic card, basically) will be horrible; the installed distro will use the default \"vga\" drivers which have no acceleration whatsover. So VirtualBox will prompt you to install the \"VirtualBox Additions\" in the virtual machine. Do that if you want a reasonable graphic performance; these drivers will not touch your physical computer. \nReferences: https://www.virtualbox.org/manual/ch04.html\nNotes: (1) the only exceptions is for USB devices that you can  \"pass\" transparently to the virtual machine (you need the non-free extension pack to handle USB 2.0, though).\n\nA: The only option for your scenario (testing graphic card drivers) is to be having a hypervisor with GPU Passthrough so that the virtual machine can actually use the physical display card.\nHowever, for virtualbox you can install virtualbox additions and enable VM to use 3D acceleration and rechek.\nThere is also an experimental feature for passing a PCI Card to the VM that you can also try (works with few graphic cards only)\n", "Q: Firefox renders wrong colors I've got the following problem:\nI'm developing an website, so while I was testing around I've noticed that firefox and chromium display an css bar in different colors. When I switched between several machine I could come to the conclusion that firefox for ubuntu is the problem. On all other devices I've tested the website. It's perfectly fine. \nDoes someone knows why this is and came up with a solution? \n\nA: Very strange, probably is an old Firefox bug already noted on Bugzilla's Bug 629312.\nThe solution might be to set the Firefox gfx.color_management.mode option in about:config to 0.This may solve the problem in your computer but not - obviously - in other machines: to mitigate the problem on remote machines use Web Safest Colors or Web Safe Colors.\nFor the images, you can use GIMP to change the colour's hue; there is also a web safe image mode in Image -> Mode -> Indexed... that may solve the problem for some images (it's ugly but works). \nPlease note that using only those safe colors will enhance the accesibility of your website, it's always a good practice; you'll need an extra bit of patience, the world is full of software bugs.\nComment under here if you need more help and don't forget to press the up arrow if I'm of any help.\nHave a nice evening.\n", "Q: Unable to install Rhipe package for R version 3.0.2 in ubuntu-12.04 I have ubuntu 12.04 OS with R 3.0.2 version. My problem is I am getting message like \"Rhipe packages is not available for R version 3.0.2\".\nPlease let me know in case you have a workaround or any solution for installing Rhipe in R 3.0.2 (for Ubuntu).\nRegards,\n\nA: Yes, the package is not available from CRan apparently. However, a quick search gives the Rhipe home page that has the very clear instructions reproduced bellow:\n\n\n*\n\n*Install Hadoop\n\nPrior to doing anything else, it is critical to ensure that the cluster on which RHIPE will be installed has a working Hadoop cluster. RHIPE works with Apache Hadoop 1.0.x (0.20.x)\nThe following are useful references on installing Apache Hadoop on a single and multi-node cluster. Alternatively, one might wish to have a more streamlined install, which can be accomplished with the Cloudera distribution's installation manager.\nIt is good to ensure the Hadoop works prior to installing RHIPE. A simple test is to run an example job and see if it completes without errors. To run a minimal example, run the following from the hadoop directory (assuming hadoop version 1.0.3).\n\nhadoop jar hadoop-examples-1.0.3.jar pi 10 100\n\n\n*R must be installed as a shared library, I will not include the details since you presumably already have it installed. See the Rhipe link above for more info.\n\n*Install protocol buffers\nwget http://protobuf.googlecode.com/files/protobuf-2.4.1.tar.gz\ntar -xzf protobuf-2.4.1.tar.gz\ncd protobuf-2.4.1\n./configure # --prefix=...\nmake\nmake install\n\n\n*Set up environment variables\n\nPKG_CONFIG_PATH: make sure this contains a path to where the protobuf*.pc files are located.\nLD_LIBRARY_PATH: points to the path where R.so and Rhipe.so are located (typically something like PREFIX/lib64/R/lib).\nHADOOP: points to the Hadoop installation directory. It is expected that $HADOOP/bin contains the Hadoop shell executable hadoop.\n\n\n*Install Rhipe\nwget http://ml.stat.purdue.edu/rhipebin/Rhipe_0.73.1.tar.gz\nR CMD INSTALL Rhipe_0.73.1.tar.gz\n\n", "Q: uptart and gnokii and chroot I try to run this upstart script.\n#\ndescription     \"\"\nauthor          \"\" \n\nstart on runlevel [2345]\n stop on runlevel [!2345]\n\n#chroot /home/ubuntu/\n\nrespawn\nrespawn limit 1 1\nexec sudo smsd -u cable -p akses -d cab -c localhost -m mysql -b SM -f     /var/log/smsdaemon.log\n\nbut smsd used to find configuration in my home folder.\nand when I uncomment chroot(where is config) part it fails:\nstart: Job failed to start\n\n\nA: Hi I just needed to export my home folder.\nenv HOME=/home/ubuntu/\nexport HOME\n\nAnd it finds configuration.\n", "Q: What is the equivalent of locales-all from Debian? On Debian, I can have a package depend on locales-all to ensure that all locales are installed/available. There is no such package in Ubuntu.\nIt used to have belocs-locales-* which appeared to do the same; alternatively, one could depend on various localisation packs (e.g. just de+en+fr for most of Western Europe, which is of limited use; sometimes, software does in fact require all standard locales). These packages disappeared between hardy and precise, AFAICT.\nSo, what Ubuntu package can I Depends on to have all locales available?\nEdit: this is not the same as the locales package, which merely provides data files needed to generate the locales; merely installing the locales-all package in Debian makes those locales available immediately, and all of them. (It contains a pack, in recent versions, saving much space too.) This way, the user does not have a knob in which they can (accidentally) disable necessary locales.\n\nA: I found the following solution on https://docs.moodle.org/dev/Table_of_locales\n   sudo ln -s /usr/share/i18n/SUPPORTED /var/lib/locales/supported.d/all\n   sudo locale-gen\n\n\nA: Unless I'm reading your wrong, this is just locales now.\nIt's part of the minimal^ task requirements as well as by ubuntu-minimal directly so this should always be installed. You shouldn't need to depend on anything to guarantee its presence but if you need something, pick ubuntu-minimal or something else you need that also depends on ubuntu-minimal. That's a pretty sane default.\n\nLooking at the contents of Debian's locales-all I can see a lot of files like this that aren't in the standard Ubuntu locales package (see dpkg -L locales):\n/usr/lib/locale/am_ET/LC_ADDRESS\n/usr/lib/locale/am_ET/LC_COLLATE\n/usr/lib/locale/am_ET/LC_CTYPE\n/usr/lib/locale/am_ET/LC_IDENTIFICATION\n/usr/lib/locale/am_ET/LC_MEASUREMENT\n/usr/lib/locale/am_ET/LC_MESSAGES/SYS_LC_MESSAGES\n/usr/lib/locale/am_ET/LC_MONETARY\n/usr/lib/locale/am_ET/LC_NAME\n/usr/lib/locale/am_ET/LC_NUMERIC\n/usr/lib/locale/am_ET/LC_PAPER\n/usr/lib/locale/am_ET/LC_TELEPHONE\n/usr/lib/locale/am_ET/LC_TIME\n\nI searched packages.ubuntu.com for similar files and couldn't find any. This means they're either not packaged, they've got drastically different names, or they extract on install (rare but possible).\nThe only exception I can see are the locales installed by libc-bin into /usr/lib/locale/C.UTF-8/.\n\nOoo, I might have been on the money with the extraction. The locales package includes a locale-gen application which generates these sorts of files. See the wiki for more information on locales.\n\nA: I know that's an old question, but did you try install all language packs through apt-get? I could solve a similar problem where I would need lots of different locales in a server and solved it running sudo apt-get install language-pack-*. It downloaded all the files (about 2GB when finished unpacking) and generated all the available locales.\n", "Q: Completely black screen after disconnecting external display except when booting in recovery mode When trying to connect an external screen (video projector) to my laptop (Dell Latitude E6530), I tried to switch to the external display using Settings Manager -> Display.  I changed a setting, but I don't remember exactly which.  Then, both screens went blank.  Since then, after booting and logging in to gdm, the display is completely black.  I am able to switch to the text console and applications appear to be running.  The Ubuntu wiki Blank screen troubleshooting page states that:\n\nIf it occurs after entering your password on the login page, you have some different class of issue, such as an issue with 3D / DRM. Try disabling compiz (sudo chmod a-x /usr/bin/compiz), logging in as a different user, or turning off DRI.\n\nI am not using compiz.  I am able to log in as a guest user.  No file in /usr/share/X11/xorg.conf.d has a recent modification date.  I am able to log in successfully in recovery mode, although I get once again a blank screen if I resume from suspension.  Unlike other problems reporting blank screens after login (1, 2, 3, 4, 5), I have no mouse cursor.  When in recovery mode, I can't change any settings through System Manager -> Display.\nHow do I repair my \"normal boot\" display configuration?  Evidently nothing was changed in /usr/share/X11/xorg.conf.d; where else should I search?  What can I look for to investigate the cause in more detail?\n\nA: I found the solution in this comment by user @elf12 to an answer by @Xophmeister to their own question:\n\nI had this problem with new Xubuntu 13.10 after unplugging a second display at my Laptops vga-out and restarting. In my case rm ~/.config/xfce4/xfconf/xfce-perchannel-xml/displays.xml did it!\n\n", "Q: Can wlan0 & wlan1 both be active at the same time or will they interfere with each other? I recently installed Lubuntu on an HP Pavilion which had previously been running Windows XP.  The internal Broadcom wireless card was experiencing some drop off issues & is under Lubuntu as well.  Stuck a new Ralink external wireless adapter into the the USB port & now the wireless is working very well.\nUninstalled the b43 firmware so the BCM4306 card won't work but it still shows up under the wireless device list as wlan0 along with the Ralink adapter which is wlan1.  Not very good with linux so not sure if there's a \"device manager\" or the like to disable the Broadcom card.  Will it hurt to leave both wlan0 & wlan1 active even tho wlan0 will never be used?\nOr can someone help me disable the internal Broadcom card?  Found this command = \"sudo ifconfig wlan0 down\"  but I'm not really sure what I'm doing here.  Does this command only bring wlan0 down for the current session & will wlan0 then reappear after the next restart?\nthanks\n\nA: Does wlan0 disappear if you unload the driver?\nsudo modprobe -r b43legacy\nifconfig\n\nIf so, blacklist the driver:\nsudo -i\necho \"blacklist b43legacy\"  >>  /etc/modprobe.d/blacklist.conf\necho \"blacklist ssb\"  >>  /etc/modprobe.d/blacklist.conf\nexit\n\n\nA: You can have both interfaces up, that doesn't mean that they're active. Actually they're active when they have an ip address, wich in your case, it doesn't seem to be happening.\nIf you really don't want to have both interfaces up, you can take one down with the command you gave:\n\nsudo ifconfig wlan0 down\n\nIf you want it up again, just do\n\nsudo ifconfig wlan0 up\n\nI would suggest you don't mind with both cards being up, as you are currently using the wlan1.\n", "Q: Accidentally deleted /etc/fstab file I accidentally deleted my /etc/fstab file by running sudo rm /etc/fstab. Without realising what I'd done, I shut down my Ubuntu OS.\nNow I'm not able to boot.\n\nMy screen looks like this. In some cases, a purple screen appears. Please give me some solutions.\n\nA: You have to recreate a new fstab file inside /etc directory and add  an entry for your root partition, so that your Ubuntu os will boot.\nMethod 1:\nRecreating /etc/fstab file via Recovery mode\n\n\n*\n\n*Boot into Recovery mode and then drop to root shell.\n\n*Run sudo blkid command to know the UUID of your /(root) partition.It will show something like this,\n/dev/sda1: UUID=\"52e062e0-716c-4828-9bf1-05b93fdaef93\" TYPE=\"ext4\"\n/dev/sda1: UUID=\"2F4DAFCF02D7EBEB\" TYPE=\"ntfs\" \n/dev/sda3: UUID=\"039E0CF305398945\" TYPE=\"ntfs\" \n/dev/sda5: UUID=\"C68C57908C5779BF\" TYPE=\"ntfs\" \n\n\n*From the sudo blkid output, identify your root ext4 partition and note down its corresponding UUID.\n\n*Now mount your / partition in Read Write Mode by running the below command.Please note that the simple mount / command for mounting your root partition won't work because of the deletion of /etc/fstab. So, if your / was /dev/sda1, run this command:\nmount -t ext4 -o rw,remount /dev/sda1 /\n\n\n*The above command will mount your / partition in read write mode.Run the below command to create a new fstab file inside /etc with the appropriate line to mount your /. In the example above, my / has UUID=52e062e0-716c-4828-9bf1-05b93fdaef93, so I would run:\necho \"UUID=52e062e0-716c-4828-9bf1-05b93fdaef93 / ext4 errors=remount-ro 0 1\" > /etc/fstab\n\n\n*Exit from the root shell and boot your Ubuntu OS, it will surely bootup.\nMethod 2\nRecreating /etc/fstab file via Ubuntu live disk\n\n\n*\n\n*Boot ubuntu live disk.\n\n*Run sudo blkid command and note the installed Ubuntu partition's device id and the UUID.\n\n*Mount your root partition,\n sudo mkdir /media/ubuntu\n sudo mount /dev/sdaX /media/ubuntu\n\n\n*Now go into the /media/ubuntu via nautilus and create a fstab file inside /etc.\n\n*On that fstab file, add an entry for your root partition like below.\n UUID=52e062e0-716c-4828-9bf1-05b93fdaef93 / ext4 errors=remount-ro 0 1\n\n\n*Save that file.And boot into your installed Ubuntu.\nNote: My root partition's UUID was given above.Please give your's.After booting into your installed Ubuntu OS, don't forget to add fstab entry for your swap partition.\n", "Q: unable to change 64bit architecture to 32 bit architecture while using dpkg command i am using ubuntu 12.04 64 bit architecture.\ni want to install skype in order to do this first i need to convert 64 to 32 bit architecture.. \nso i type the command sudo dpkg --add-architecture i386 and it not working..\nand showing like this...\n(satyam@satyam-Vostro:~$ sudo dpkg --add-architecture i386\n [sudo] password for satyam: \n dpkg: error: unknown option --add-architecture\n\n Type dpkg --help for help about installing and deinstalling packages [*];\n Use `dselect' or `aptitude' for user-friendly package management;\n Type dpkg -Dhelp for a list of dpkg debug flag values;\n Type dpkg --force-help for a list of forcing options;\n Type dpkg-deb --help for help about manipulating *.deb files;\n\nOptions marked [*] produce a lot of output - pipe it through less' ormore' !)\nplz help me out to fix this problem...\n\nA: In 12.04 the option is\n--force-architecture\n\nThe\n --add-architecture \n\nwas added in 12.10. \n\n\n*\n\n*man dpkg 12.04.\n\n*man dpkg 12.10.\n\n", "Q: How to find \"only\" IP addresses in a Local Area Network sudo arp-scan --interface=eth0 --localnet\n\nI know the above command works fine but it outputs everything like MAC address etc, etc.\nBut I need to find only IP addresses. Is it possible ?\n\nA: I would do this using just grep:\n$ sudo arp-scan --interface=eth0 --localnet | grep -oP '^[\\d.]+'\n192.168.0.1 \n192.168.0.2 \n192.168.0.3 \n192.168.0.10    \n192.168.0.23    \n192.168.0.72    \n192.168.27.1    \n192.168.27.14\n192.168.27.30\n\nExplanation:\nThe -P tells grep to use Perl Compatible Regular Expressions, where \\d matches any number. The -o means \"print only the matching part of the line\". The regular expression I used means match the longest string (that's what the + means)  of consecutive numbers (\\d) or dots (.) that are at the beginning of the line (^).\n\nA: I just used awk,tail and head to achieve what you want:\nsudo arp-scan --interface=eth0 --localnet| awk '{print $1}'|tail -n +3|head -n -2\n\nthis gives the output as \n192.168.1.1\n192.168.1.3\n\nas I have only these two in my Lan.\nHere awk '{print $1}' prints the ip address which is situated in the first column.\ntail and head removes unnecessary stuff like the header and just shows the ip addresses. \n\nA: Here is a one liner to get the IP address using the ifconfig command:\n~$ ifconfig eth0 | grep 'inet addr:' | cut -d: -f2 | awk '{ print $1}'\n192.168.1.10\n\nDoes that do what you wanted?  Or did you need the arp-scan command?\n\nI re-read and see I missed the point of the question. arp-scan shows the local IP addresses for the network and I only showed the IP of the machine with ifconfig. Below is a version of the above terdon solution only not using the PCRE library. Ubuntu had an issue with pcre and grep when I tried it.\n$ sudo arp-scan --interface=eth0 --localnet | grep -o ^[0-9.]*\n\n\nA: another option to simplify @Stormvirux answer is to use the --quiet or -q and --plain or -x arguments provided with arp-scan instead of piping to head and tail commands the final command will be simpler as it will pipe only to awk :\narp-scan -qx --localnet | awk '{print $1}'\n\nand here is a much detailed explanation from arp-scan --help :\n--quiet or -q       Only display minimal output. No protocol decoding.\n            If this option is specified, then only the IP address\n            and MAC address are displayed for each responding host.\n            No protocol decoding is performed and the OUI mapping\n            files are not used.\n\n--plain or -x       Display plain output showing only responding hosts.\n            This option suppresses the printing of the header and\n            footer text, and only displays one line for each\n            responding host. Useful if the output will be\n            parsed by a script.\n\n", "Q: Why auto complete does not work for directories in terminal ? \nI am using Ubuntu 13.10. While i was using previous versions of Ubuntu, I was able to auto-complete the directories names, even multiple times in a single command. I am not able to the same now. As shown in screen-shot, I am writing this command and then I press Tab. But nothing happens, while I am having a directory at that level , named 'addons'. Can I have solution for this problem I am facing ? \nThanks.\n\nA: The filepicker autocomplete path stub needs to be separate from any other string. In your example:\ncommand --argument=/path/stub<TAB>\n\nBash is just going to see the --argument and bug out. You could probably improve it by making it parse through that but that's not entirely trivial.\n\nA: First make sure you have the bash auto completion package installed on the system.\n sudo apt-get install bash-completion\n\nNext for Ubuntu 13.10 to enable smart completion, edit your /etc/bash.bashrc file to enable it. Uncomment the following lines, by removing the # in the beginning of the lines:\n#if [ -f /etc/bash_completion ]; then\n# . /etc/bash_completion\n#fi\n\nClose your session and re-open it for it to take effect.\n", "Q: Ubuntu on a Gigatbye Brix Pro? are there any one in here that has tried to install ubuntu on a Gigabyte Brix Pro? I think it is the same as the steam box that comes later this year\n\nA: I have a Gigabyte Brix Pro (GB-BXi7-4770R) with G.Skill 16 GB DDR3-1866 Kit (F3-1866C10D-16GRSL, Ripjaws) and a Mushkin Atlas Deluxe (MKNSSDAT240GB-DX) 240GB SSD currently running Ubuntu 14.04 (dualboot with Arch Linux).\n\nWith 14.04 everything works out-of-the box, older Ubuntu versions encountered (disk)problems during installation (file corruption).\nMy Brix Pro has an Intel Iris Pro 5200 GPU, Gigabyte has also announced an Brix Gaming which is AMD-based (GB-BXA8G-8890).\nThe Brix-based Steambox will, IMHO, most-likely have a Nvidia GPU.\n", "Q: How can I remove an entry from a list in a shells script? I have the following script:\n#!/bin/bash\n# Bash Menu Script Example\n\nPS3='Please enter your choice: '\noptions=(\"Option 1\" \"Option 2\" \"Option 3\" \"Quit\")\nselect opt in \"${options[@]}\"\ndo\n    case $opt in\n        \"Option 1\")\n            echo \"you chose choice 1\"\n            ;;\n        \"Option 2\")\n            echo \"you chose choice 2\"\n            ;;\n        \"Option 3\")\n            echo \"you chose choice 3\"\n            ;;\n        \"Quit\")\n            break\n            ;;\n        *) echo invalid option;;\n    esac\ndone\n\nMy problem is that I don't know how to remove a choice from the list after it has been selected. Is that possible? How?\n\nA: The simplest way is to use unset:\n$ options=(aa bb cc dd)\n$ echo ${options[@]}\naa bb cc dd\n## Remove the 3d element of the array (arrays start at 0)\n$ unset options[2]\n$ echo ${options[@]}\naa bb dd\n\nFor more details, see help unset:\nunset: unset [-f] [-v] [name ...]\n    Unset values and attributes of shell variables and functions.\n\n    For each NAME, remove the corresponding variable or function.\n\n    Options:\n      -f    treat each NAME as a shell function\n      -v    treat each NAME as a shell variable\n\n    Without options, unset first tries to unset a variable, and if that fails,\n    tries to unset a function.\n\n    Some variables cannot be unset; also see `readonly'.\n\n    Exit Status:\n    Returns success unless an invalid option is given or a NAME is read-only.\n\n", "Q: How can one change login screen resolution with propreitary graphic driver installed? I installed the latest AMD BETA driver from this site . The installation was perfect. But now I am not able to see my login screen(where you type your password, as you know). My monitor displays \"OUT OF RANGE\" when I am on my login screen . But I can type in my password and enter into my Desktop without any problem. Probably the login screen resolution is beyond the resolution of my monitor. If that is the case, then how can I change the resolution of the login screen alone? (BTW, my graphic card is ATI Radeon 5570 HD. I have DELL monitor with maximum resolution of 1366x768. Also I can view my desktop without problems.) \nPS:- This question is very much similar to this question. But none of the solutions solve the problem in 14.04 which I am using. Note that the problem stated above was also present in Ubuntu 13.10.\n\nA: After searching I found the answer in launchpad. This is an issue with xorg.conf file actually. One can generate the xorg.conf file by using the command \nsudo aticonfig --initial\n\nif one is having the AMD driver. Else one may try\nsudo nvidia-xconfig\n\nif one has nvidia graphic driver.\nThen one needs to open the xorg.conf file by running the below command,\nsudo gedit /etc/X11/xorg.conf\n\nIn the command above one can use one's favorite text editor instead of gedit. In the xorg.conf file one must edit the screen section which is this:\nSection \"Screen\"\n Identifier \"aticonfig-Screen[0]-0\"\n Device \"aticonfig-Device[0]-0\"\n Monitor \"aticonfig-Monitor[0]-0\"\n DefaultDepth 24\n SubSection \"Display\"\n  Viewport 0 0\n  Depth 24\n EndSubSection\nEndSection\n\nTo something like this:\nSection \"Screen\"\n Identifier \"aticonfig-Screen[0]-0\"\n Device \"aticonfig-Device[0]-0\"\n Monitor \"aticonfig-Monitor[0]-0\"\n DefaultDepth 24\n SubSection \"Display\"\n  Viewport 0 0\n  Depth 24\n  Modes \"1366x768\"\n EndSubSection\nEndSection\n\nOne can give whichever resolution is compatible with one's monitor after Modes instead of 1366x768. This solves the problem. \nCredits to this answer here from launchpad. \n", "Q: Can't apply partition table on pen drive and create partition I have pen drive that shows unloacted.I have tried many tools as gparted,fdisk,gpart,testdisk etc. but i can't make it usable.\nHere is my test results:\nFdisk:\n$ sudo fdisk -l\n....\nDisk /dev/sdc: 8010 MB, 8010194944 bytes \n247 heads, 62 sectors/track, 1021 cylinders, total 15644912 sectors \nUnits = sectors of 1 * 512 = 512 bytes \nSector size (logical/physical): 512 bytes / 512 bytes \nI/O size (minimum/optimal): 512 bytes / 512 bytes \nDisk identifier: 0xd0e2392f \nDisk /dev/sdc doesn't contain a valid partition table \n\nSo this device size is correctly identified as 8010MB (8GB) and is located at /dev/sdc. Interestingly, fdisk has reported that this device is not having a valid partition table. So something has happened to the partition table and I wanted to fix it with the help of fdisk command as follows \n$sudo fdisk /dev/sdc \nDevice contains neither a valid DOS partition table, nor Sun, SGI or OSF     disklabel \nBuilding a new DOS disklabel with disk identifier 0x4c9b7827. Changes will  remain in memory only, until you decide to write them. \nAfter that, of course, the previous content won't be recoverable. \nWarning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite) \nCommand (m for help): w \n\nThe partition table has been altered! Calling ioctl() to re-read partition table\n\nThen i have tried to partition the pendrive\n#sudo fdisk /dev/sdc \n... \nWarning: invalid flag 0x0000 of partition table 4 will be corrected by w(rite) \nCommand (m for help): n \nPartition type: primary (0 primary, 0 extended, 4 free) extended Select (default p): p \nPartition number (1-4, default 1): 1 \nFirst sector (2048-15644911, default 2048): Using default value 2048 \nLast sector, +sectors or +size{K,M,G} (2048-15644911, default 15644911): Using default value 15644911 \nCommand (m for help): w \nThe partition table has been altered! \nCalling ioctl() to re-read partition \n\nAfter doing this my pen drive still unlocated.Then i try to solve using gparted.\nGparted results:\nI used \"gparted\" tool to add a partition table. As shown in above image, gparted shows this device at /dev/sdc with Partition=unallocated and FileSystem=unallocated, so it also identified that there was an issue. So I tried adding a partition table [by Device -> Create Partition Table...] of msdos type, but GUI displayed an error message as \"Error while creating partition table\". Command line also had some issues listed as below\n$sudo gparted\n====================== \nlibparted : 3.1\n====================== \n/dev/sdc: unrecognised disk label \n/dev/sdc: unrecognised disk label\n\nNow how can i solve the problem. thanks in advance.\n\nA: You might try zeroing out the drive as mentioned in the comments by running...\n# dd count=1 bs=512 if=/dev/zero of=/dev/sdx && sync\n\n... where sdx is the drive you're wanting to format.\nBE VERY CAREFUL TO ENSURE THAT YOU ARE DOING THIS AGAINST THE RIGHT DRIVE!\nThen create a new partition table...\n# cfdisk /dev/sdx\n# mkfs.ext4 /dev/sdx1\n# e2label /dev/sdx1 USB_STICK\n\nThis combined with running gparted with...\ngksudo gparted\n\n...worked for me. I had a USB stick that I dd'd an iso on to ot use for booting then had trouble recovering it. These were the steps I took and it as usable again.\n", "Q: Skip if server needs a password in Local Area Network I have a list of IP's for computers in my LAN, I don't want to enter password for computers that require password, So I would like to skip such PC's.\ngvfs-mount smb://servername\nI'm using the above command for mounting, So how to skip PC's that require password from trying to mount..\nI had a script which consists of a list like gvfs-mount smb://servername1, gvfs-mount smb://servername2, gvfs-mount smb://servername3 ...\nand when I run the script I would like to skip PC's with password\n\nA: Remove the hosts that require a password, from your script. If you're going to skip them anyway, then there's no need to have them there.\nAlternatively, save the passwords permanently in your keyring, when the dialog pops up to ask for the passwords, and you won't be asked in the future, unless the password is changed on the server, when you run the script while logged in. Or you can encode the passwords in the URLs you're passing to gvfs-mount inside the script, but that is not as secure.\n", "Q: Partitioning: Shrink Ubuntu (extended), Expand Windows I have backups up everything, but I'm still uneasy about the process and would like confirmation. I'd rather do this one time correctly.\nI want to shrink /dev/sda6/ by 200GB and reallocate it to /dev/sda2.\nI boot a LiveCD and turn off LinuxSwap (locked otherwise). I've been reading that it is very hard to move \"left\" when partitioning and other AskUbuntu threads are confusing me. Do I need to resize /dev/sda6 by 200GB \"preceding\" (rather than \"following\"), and then resize /dev/sda4 by 200GB?\nA little guidance would ease my nerves of messing everything up. Thank you ahead of time.\n\n\nA: Here's the outline of what you should do:\n\n\n*\n\n*Unmount the devices/partitions concerned;\n\n*Shrink the logical partition /dev/sda6 by the amount you want i.e. 200 GB (right click the partition, select resize/move and drag the slider to right creating the unallocated space to the left of sda6), and then move sda5 to right over the unallocated space so that the entire free space will lie to left of sda5;\n\n*Shrink the extended partition /dev/sda4 creating free space immediately next to sda3;\n\n*Move /dev/sda3 towards right so that the entire 200 GB unallocated space would now lie next to /dev/sda2 (Note: moving /boot may result in boot failure, and in that case you'd boot-repair disk can be handy.);\n\n*Resize /dev/sda2 to cover the unallocated space;\n\n*Apply all operations, and wait patiently till the tasks are completed!\n\n", "Q: How can I recover my data after formatting ubuntu with ubuntu? I blew up everything while installing ubuntu 13.04 in a machine with ubuntu 12.04 installed in it. I erased the whole data accidentally. I had a separate space called backup in older OS.\nHaving ubuntu 13.04 currently installed, I want my previous data with ubuntu 12.04 back. I came through How can I recover my data after replacing Windows with Ubuntu? [duplicate], but in my case it's ubuntu 13 replaced by ubuntu 12. \nIn a live mode of ubuntu 13.04, I downloaded and run testdisk.\nSTEP 1 : I proceeded with a media(/dev/sda) from list\nSelect a media (use Arrow keys, then press Enter):\n>Disk /dev/sda - 640 GB / 596 GiB - WDC WD6400BEVT-22A0RT0\n Disk /dev/sdb - 4022 MB / 3835 MiB - SanDisk U3 Cruzer Micro\n\nSTEP 2 : Then I selected Intel as partition and then Analyse  category\nSTEP 3 : I only see following partitions\nDisk /dev/sda - 640 GB / 596 GiB - CHS 77825 255 63\nCurrent partition structure:\n Partition                  Start        End    Size in sectors\n\n 1 * Linux                    0  32 33 77345  77 44 1242550272\n 2 E extended             77345 110 12 77825  70  5    7708674\n 5 L Linux Swap           77345 110 14 77825  70  5    7708672\n\nSTEP 4 : I chose to go Quick search\nDisk /dev/sda - 640 GB / 596 GiB - CHS 77825 255 63\n Partition               Start        End    Size in sectors\n>* Linux                    0  32 33 77345  77 44 1242550272\n P Linux Swap           77345 110 14 77825  70  5    7708672\n\nSTEP 5 : In first partition of the list (Linux), I only see currently installed files. (As 'm looking for older backup folder there.)\n>drwxr-xr-x     0     0      4096 15-Mar-2014 23:59 .\n drwxr-xr-x     0     0      4096 15-Mar-2014 23:59 ..\n drwx------     0     0     16384 15-Mar-2014 23:55 lost+found\n drwxr-xr-x     0     0     12288 18-Mar-2014 22:59 etc\n drwxr-xr-x     0     0      4096 18-Mar-2014 22:41 media\n drwxr-xr-x     0     0      4096 16-Mar-2014 00:01 bin\n drwxr-xr-x     0     0      4096 16-Mar-2014 00:02 boot\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:51 dev\n drwxr-xr-x     0     0      4096 15-Mar-2014 23:58 home\n drwxr-xr-x     0     0      4096 16-Mar-2014 00:01 lib\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:47 lib64\n drwxr-xr-x     0     0      4096 19-Apr-2013 14:48 mnt\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:46 opt\n drwxr-xr-x     0     0      4096 19-Apr-2013 14:48 proc\n drwx------     0     0      4096 16-Mar-2014 00:11 root\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:51 run\n drwxr-xr-x     0     0     12288 16-Mar-2014 00:02 sbin\n drwxr-xr-x     0     0      4096 12-Jun-2012 00:21 selinux\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:46 srv\n drwxr-xr-x     0     0      4096 30-Jan-2013 18:43 sys\n drwxrwxrwt     0     0      4096 18-Mar-2014 22:59 tmp\n drwxr-xr-x     0     0      4096 24-Apr-2013 22:46 usr\n drwxr-xr-x     0     0      4096 18-Mar-2014 22:59 var\n lrwxrwxrwx     0     0        29 15-Mar-2014 23:59 vmlinuz\n lrwxrwxrwx     0     0        33 15-Mar-2014 23:55 initrd.img.old\n lrwxrwxrwx     0     0        32 15-Mar-2014 23:59 initrd.img\n drwxr-xr-x     0     0      4096 15-Mar-2014 23:58 cdrom\n\nSTEP 6 : In a Deeper search,\nAnalyse Cylinder 2041/77824 02%\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                    0  32 31    60 206 16     974848\nLinux                    0  32 31    60 206 16     974848\nLinux                    0  32 31    60 206 16     974848\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                   60 238 51 12218 100 42  195309568\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                   60 238 51 12218 100 42  195309568\nLinux                   60 238 51 12218 100 42  195309568\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                   60 238 51 12218 100 42  195309568\nLinux                   60 238 51 12218 100 42  195309568\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                   60 238 51 12218 100 42  195309568\nLinux                  854  98 13   924 127 35    1126400\nLinux                    0  32 33 77345  77 44 1242550272\n\nWhen I press Enter, I get something like following in the list\nDisk /dev/sda - 640 GB / 596 GiB - CHS 77825 255 63\nPartition               Start        End    Size in sectors\n>  Linux                    0  32 31    60 206 16     974848\nLinux                    0  32 33 77345  77 44 1242550272\nLinux                   60 238 51 12218 100 42  195309568\nLinux                  854  98 13   924 127 35    1126400\nLinux                 1596 214 27  1666 243 49    1126400\n* Linux Swap           77345 110 14 77825  70  5    7708672\n\nWhen I list files for the same partition, I get following message, \nLinux                    0  32 31    60 206 16     974848\nCan't open filesystem. Filesystem seems damaged.\n\nI Want experienced answers. \nReferences\nTest Disk - How to Recover Files from a Faulty Hard-Drive\n\nA: Finally, most of data is recovered properly using R-studio, a paid tool.\nHow it works\nWhy R-Studio\nR-Data Recovery Studio Guide: How To Recover Data,  youtube video\n", "Q: Gnome 3 Nautilus - Custom bookmarks I'm just upgrading to Ubuntu 13.10 with Gnome 3 Classic.\nCould you say me how I can create bookmark [link or signet] on the left navigation panel of Nautilus ?\nBefore upgrading I had a bookmarks option in main menu... \nBut I didn't find it in this new version ...\n\nA: It's under the \"gear\" at the right: \n\n\nA: In Ubuntu 16.04 (Files 3.14.3), you just drag the item from the right side to the left sidebar. You'll see a new row appear called \"New Bookmark\". Drop the item on the \"New Bookmark\" area.\n", "Q: How to login in terminal as root anytime when I open terminal? I don't want to type sudo and my password everytime.I think it is really annoying.Is there any command or option which will consider you root user when you open terminal,everytime When you open terminal.\n\nA: Type:\nsudo visudo\n\nGo to the end of the file and type:\n<username> ALL=NOPASSWD: ALL\n\nPress Ctrl+X to exit, and press Y to save the changes.\nNow open System Settings->Keyboard in that go to the Shortcut tab.\nLaunch terminal, press Space and Backspace; it will disable it.\nNow go to Custom Shortcuts and click the plus (+) button at the bottom.\nGive the name as terminal and the command as sudo gnome-terminal, then click Apply.\nThen just go to some other location and come back to Custom Shortcuts.\nClick terminal, press Space and now press Ctrl+Alt+T.\nClose the window.\nThat's it!\nNow whenever you open the terminal through Ctrl+Alt+T, it will open as root.\nEnjoy!\n\nA: I am really against root being used as a default login.  This is a really really really BAD idea.\nHowever, in cases where I'm working on something that requires a root terminal session with lots of sudo commands again and again it can get tiring to type sudo.\nYou can create a root session using the sudo -i command and enter your password once. When you are finished with whatever operations require root you can then exit and get back to a user level account.\nmcgarrah@localhost:~$ sudo -i\nroot@localhost:~# id\nuid=0(root) gid=0(root) groups=0(root)\nroot@localhost:~# \n\nAgain, running as root at all times is a really bad idea. Root allows for more access than a standard user needs and many of the features that make Linux more secure are no longer working for you. One example is running a web browser as root is insane.\n", "Q: Ctrl-l, Ctrl-a, Ctrl-e do not work any more I accidentally deleted some files (do not remember what files), then Ctrl-l, Ctrl-a, Ctrl-e do not work anymore on my mac. I tried to reinstall bash using brew install bash. But the problem is still there. \n\nA: You've probably ended up in 'vi' mode.\nType set -o emacs at your shell prompt and those Ctrl keys should work again. Put it in your ~/.bashrc to make it permanent.\n", "Q: I cannot clear syslog but I can remove it? Why doesnt sudo /dev/null > /var/log/syslog and sudo > /var/log/syslog work, while sudo rm /var/log/syslog works?!\n\nA: truncate -s 0 /var/log/syslog\nworking for me on 18.04. Got it from here:\nhttps://ubuntuforums.org/showthread.php?t=2191156\n\nA: truncate: The truncation process basically removes all the contents of the file. It does not remove the file itself, but it leaves it on the disk as a zero byte file.\nClear ALL Content of Syslog with:\nsudo truncate -s 0 /var/log/syslog\n\nA: There are two main problems.\nOne problem is that /dev/null isn't a command, so running sudo /dev/null can't succeed. You need sudo [a command]. In this case, you probably want sudo cat /dev/null.\nThe other problem is that > separates things into a full command on the left and a file on the right, so the full command on the left is sudo cat /dev/null, and sudo's job is now done once it runs cat /dev/null.\nThat means that the > is running as your user, not under sudo. Your user doesn't have permission to write to /var/log/syslog, so this will fail.\nYou need some way to run the entire line cat /dev/null > /var/log/syslog under sudo. Well, > isn't a command or anything. It's something the shell handles, so you need to have a shell handle that redirection symbol properly. You can do that with sh's -c option: sh -c 'cat /dev/null > /var/log/syslog'.\nNow that you have everything together as one command, you can have sudo run the entire thing:\nsudo sh -c 'cat /dev/null > /var/log/syslog'\n\n\nA: The command you are thinking of is probably\n> /var/log/syslog\n\nNothing else is needed. In bash and other shells, the > will immediately truncate the file, emptying it. However, when you run this:\nsudo /dev/null > /var/log/syslog\n\nThe system is attempting to run /dev/null as a command and you will get this error:\nsudo: /dev/null: command not found\n\nNote, however, that despite this, /var/log/syslog has actually been emptied because, as I said above, the > is enough, no command is necessary.\n\nA: Another way to do this is\nsudo tee </dev/null /var/log/syslog \n\nOr if you prefer a useless use of cat:\ncat /dev/null | sudo tee /var/log/syslog\n\n", "Q: How do I edit all autostart applications? In Ubuntu 13.10 only very few applications are managed by the Startup Applications application:\n\nHow do I access for example the bluetooth indicator?\n\n\nIs there a gui alternative to editing the config files in\n/etc/xdg/autostart/\n\nand\n ~/.config/autostart/\n\n?\n\nA: Show Hidden Startup Apps:\nsudo sed -i \"s/NoDisplay=true/NoDisplay=false/g\" /etc/xdg/autostart/*.desktop\n\n4 Tricks to Speed Up Ubuntu\nhttps://www.youtube.com/watch?v=vwBoHZuauL8\n", "Q: Delete directory indirectly inside of itself I have a directory inside itself. How do I delete it.\n~/.local/share/Trash/files$ ls devices/\nreg-dummy\n~/.local/share/Trash/files$ ls devices/reg-dummy/\nsubsystem\n~/.local/share/Trash/files$ ls devices/reg-dummy/subsystem/\ndevices\n\nAlso\n~/.local/share/Trash/files$ find devices/ | head -n 20\ndevices/\ndevices/reg-dummy\ndevices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices\ndevices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy/subsystem/devices/reg-dummy\n\nAlso, although my brain can't solve the halting problem, it appears that sudo rm -rf devices goes on forever without producing output.\n~/.local/share/Trash/files$ sudo rm -rf devices\n^C~/.local/share/Trash/files$\n\nSame thing for perl -e 'use File::Path qw(remove_tree); remove_tree(\"$ENV{HOME}/.local/share/Trash/files/devices\")'.\nSame thing for du -s devices/. Same thing for du -sch ~/.local/share/Trash/\nOther commands\n$ cd ~/.local/share/Trash/files/devices/reg-dummy/subsystem/devices/\n$ ls -ldi \n8131921 drwxr-xr-x 3 theking theking 4096 Mar 17 19:43 .\n$ cd reg-dummy/subsystem/devices/\n$ ls -dli\n8131926 drwxr-xr-x 3 theking theking 4096 Mar 17 19:43 .\n\n\n$ find .local/share/Trash/files/ -maxdepth 1 -delete\nfind: cannot delete `.local/share/Trash/files/devices': Directory not empty\nfind: cannot delete `.local/share/Trash/files/': Directory not empty\n\nI don't want it stuck in my trash forever!\nNote: I was making a crude backup of a computer by simply using scp, and but I ran out of space and then this happened.\n\nA: The output of ls -ldi will show the inode number of the directory.  If the directory within the directory really has the same inode number as its ancestor, rather than just the same name, then your filesystem is corrupt and you will need to boot into rescue mode and fsck it.\n\nA: I still think that rm -rf will work if you give it enough time but if not, one or both of these should:\nperl -e 'use File::Path qw(remove_tree); \n        remove_tree(\"$ENV{HOME}/.local/share/Trash/files/devices\")'`\n\n \nfind .local/share/Trash/files/ -delete\n\nYou can make sure that something is happening if you use rm -rfv ~/.local/share/Trash/files/devices at least that will let you know that files are being deleted.\nAnyway, this can't be a hardlink problem (despite my very wrong comment) because directories can't be hardlinked under Linux. In general, when you have infinite recursion, as can happen with softlinks, you will get a message to that effect, that does not appear to happen.\nThe other possibility I can think of is that the Trash folder is some strange system of its own. I don't really know how it works, I never use it. However, you might have better luck deleting the top level files directly instead of targeting the problematic directory:\nrm -rf ~/.local/share/Trash/* \n\nYou should also try emptying the Trash folder from the GUI, just select Trash and click on \"Empty Trash\", see if that works.\n\nA: (I am confident this will work and as I am going to travel right now, I will leave this as an answer that I can delete in the future if it does not work.)\n\n\n*\n\n*First, to be safe, run\nfind ~/.local/share/Trash/files/devices/ -exec echo {} \\;\n\n\n*Second, if the output of \"1\" did not show any important file, then run\nfind ~/.local/share/Trash/files/devices/ -exec rm {} \\;\n\n\n*The final step would be\nfind ~/.local/share/Trash/files/devices/ -empty -type d -delete\n\n", "Q: How can I format my USB drive in Lubuntu? I have created a bootable USB drive to install Lubuntu. Now I would like to format the drive so I can use it normally. How can I do that?\n\nA: In Lubuntu the terminal might be the fastest way to format a USB drive. \nFind the usb partition: lsblk\nalvaro@GNUM4600:~$ lsblk\nNAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT\nsda      8:0    0 465.8G  0 disk \n├─sda1   8:1    0 457.9G  0 part /\n├─sda2   8:2    0     1K  0 part \n└─sda5   8:5    0   7.9G  0 part [SWAP]\nsdb      8:16   0 238.5G  0 disk \n└─sdb1   8:17   0 238.5G  0 part \nsdc      8:32   1   1.9G  0 disk /media/alvaro/68A2-E93E   <--------------- This is it *\nsr0     11:0    1  1024M  0 rom  \n\nUnmount it:\numount /dev/sdc\nalvaro@GNUM4600:~$ umount /dev/sdc\n\nMake the file system on the entire device:\nsudo mkfs.vfat -I /dev/sdc \nalvaro@GNUM4600:~$ sudo mkfs.vfat -I /dev/sdc\n\n\nA: There are several options, but assuming you want something \"standard\" - I would use mkfs.vfat /dev/[MY-USB-DRIVE]. You can run whatever FS you want on there, but vfat is what they usually ship with (e.g. will work on Windows).\n\nA: use gparted\nIf it shows a lock next to the partition you'll need to unmount before removing it (right click - unmount)\nhttp://www.howtogeek.com/howto/17001/how-to-format-a-usb-drive-in-ubuntu-using-gparted/\n", "Q: Ubuntu Terminal \"Shortcut-Key\" I just changed the \"Short-Keys\" in Ubuntu. I set Ctrl+c for Copy. My fault ... so now I can't use Ctrl+c for killing the process in the terminal. But it is necessary for me to do this.\nHow can I change the shortcut key? Maybe so that Esc is for killing the process, or some other combination?\n\nA: You can't really, the Ctrl + C has nothing to do with the graphical environment, it is a much more basic command and involves sending a particular signal (SIGINT).\nThese can't really be modified by the user. I mean they can, but you would need to modify the source of /usr/src/$(uname -r)/include/linux/signal.h and recompile your kernel probably. \nJust don't use Ctrl + C for copy.\n", "Q: Audio player that supports ZIP archives Is there anything better than rhythmbox, which does not support navigation between tracks inside archives?\n\nA: DeaDBeeF (http://deadbeef.sourceforge.net/) via this plugin can play music tracks from RAR, 7z and Gzip archives.\nVisit this link for a short video showing this feature.\nDeaDBeeF can be installed from this ppa\n", "Q: Help me fix my improper removal of files please Upon opening terminal I get a notification: \nbash: /home/kylekroeck/Public/ccp4-6.4.0/bin/ccp4.setup-sh: No such file or directory\nMy /.bashrc file:\n# ~/.bashrc: executed by bash(1) for non-login shells.\n# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)\n# for examples\n\n# If not running interactively, don't do anything\ncase $- in\n    *i*) ;;\n      *) return;;\nesac\n\n# don't put duplicate lines or lines starting with space in the history.\n# See bash(1) for more options\nHISTCONTROL=ignoreboth\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\nHISTSIZE=1000\nHISTFILESIZE=2000\n\n# check the window size after each command and, if necessary,\n# update the values of LINES and COLUMNS.\nshopt -s checkwinsize\n\n# If set, the pattern \"**\" used in a pathname expansion context will\n# match all files and zero or more directories and subdirectories.\n#shopt -s globstar\n\n# make less more friendly for non-text input files, see lesspipe(1)\n[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n\n# set variable identifying the chroot you work in (used in the prompt below)\nif [ -z \"${debian_chroot:-}\" ] && [ -r /etc/debian_chroot ]; then\n    debian_chroot=$(cat /etc/debian_chroot)\nfi\n\n# set a fancy prompt (non-color, unless we know we \"want\" color)\ncase \"$TERM\" in\n    xterm-color) color_prompt=yes;;\nesac\n\n# uncomment for a colored prompt, if the terminal has the capability; turned\n# off by default to not distract the user: the focus in a terminal window\n# should be on the output of commands, not on the prompt\n#force_color_prompt=yes\n\nif [ -n \"$force_color_prompt\" ]; then\n    if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then\n    # We have color support; assume it's compliant with Ecma-48\n    # (ISO/IEC-6429). (Lack of such support is extremely rare, and such\n    # a case would tend to support setf rather than setaf.)\n    color_prompt=yes\n    else\n    color_prompt=\n    fi\nfi\n\nif [ \"$color_prompt\" = yes ]; then\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\nelse\n    PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ '\nfi\nunset color_prompt force_color_prompt\n\n# If this is an xterm set the title to user@host:dir\ncase \"$TERM\" in\nxterm*|rxvt*)\n    PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1\"\n    ;;\n*)\n    ;;\nesac\n\n# enable color support of ls and also add handy aliases\nif [ -x /usr/bin/dircolors ]; then\n    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n    alias ls='ls --color=auto'\n    #alias dir='dir --color=auto'\n    #alias vdir='vdir --color=auto'\n\n    alias grep='grep --color=auto'\n    alias fgrep='fgrep --color=auto'\n    alias egrep='egrep --color=auto'\nfi\n\n# some more ls aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\n\n# Add an \"alert\" alias for long running commands.  Use like so:\n#   sleep 10; alert\nalias alert='notify-send --urgency=low -i \"$([ $? = 0 ] && echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&|]\\s*alert$//'\\'')\"'\n\n# Alias definitions.\n# You may want to put all your additions into a separate file like\n# ~/.bash_aliases, instead of adding them here directly.\n# See /usr/share/doc/bash-doc/examples in the bash-doc package.\n\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\n# enable programmable completion features (you don't need to enable\n# this, if it's already enabled in /etc/bash.bashrc and /etc/profile\n# sources /etc/bash.bashrc).\nif ! shopt -oq posix; then\n  if [ -f /usr/share/bash-completion/bash_completion ]; then\n    . /usr/share/bash-completion/bash_completion\n  elif [ -f /etc/bash_completion ]; then\n    . /etc/bash_completion\n  fi\nfi\n\n# Added by CCP4 package manager:\nsource /home/kylekroeck/Public/ccp4-6.4.0/bin/ccp4.setup-sh\n\nI had installed a program suite called CCP4 but was having issues with some of the programs. I thought I had removed the files in an acceptable manner but when I open terminal I get this error message at the top and I think this is preventing the proper install of this program. \n\nA: At the end of your .bashrc, you have these lines:\n# Added by CCP4 package manager:\nsource /home/kylekroeck/Public/ccp4-6.4.0/bin/ccp4.setup-sh\n\nLines that begin with # are ignored, they are just comments that you write so you can remember what each line is for. However, the next one is looking for the file /home/kylekroeck/Public/ccp4-6.4.0/bin/ccp4.setup-sh and attempts to source it,  essentially read the file and execute any commands in it. Since that file no longer exists, bash is giving you an error.\nAll you need to do is to delete that line or just add a # at the beginning to make it into a comment. Once you've done that, the errors will disappear.\n\nA: Look for the program in your bash startup files:\ngrep ccp4 ~/.profile ~/.bash*\n\n", "Q: Install netgear wireless adapter with no internet Just installed ubuntu 12.04 LTS and I have a netgear wireless adapter A6200.\nI have the disk but I need to work out a way to get the .INF files on to the machine. I DO NOT have the ability to access the internet via Ethernet on the Ubunti machine.\nlsusb command - Bus 003 Device 002: ID 0846:9050 NetGear, Inc.\nI have a laptop next to me with wireless access and a USB stick so I can download packages ans transfer across.\nPlease tell me how I can do this?\nEDIT:\nI have now installed some A6200 drivers using ndiswrapper and I can use modprobe ndiswrapper which loads the driver and I can see the wireless network, however it doesn't except the wireless key.\nit's 100 percent the correct key but it just tries to connect for around 2 minutes and then the box pops back up asking for the authentication key again...\n\nA: If you are having problems logging in, make sure that the encryption is correct. Go to the connection, go to security settings, and make sure that you chose the correct form of security encryption (WPA, WEP, etc.). Also, I know this may seem obvious but you might want to disconnect and reconnect to the network or restart the router.\nSee if that gets you anywhere.\n", "Q: Audio on Firefox doesn't work after using Hydrogen I am new to Ubuntu and just installed Ubuntu Studio. After Googling a previous audio problem regarding no sound on Youtube, I uninstalled pulseaudio. Audio works fine both on Youtube and Hydrogen on their own. But I've found that after using Hydrogen, the audio is cut off from everything else after closing it. (Skype, Firefox)\nHow do I go about troubleshooting this?\nThank you\n\nA: Try to restart pulseaudio and alsa...To restart pulseaudio through \npulseaudio --start\nand \nsudo alsa force-reload\n\nThere also may be a problem with Jack if you are using it. Jack and pulseaudio often run into conflict with eachother when they both try to hit the same soundcard at the same time. I would suggest checking this if you are using Jack along with pulseaudio.\nhttp://jackaudio.org/pulseaudio_and_jack\nHope this helps.\n", "Q: Wrapping workspaces in Cinnamon environment I'm running Ubuntu 12.10 with the Cinnamon environment. I'm wondering if it's possible to make it so I can wrap workspace switching (so when I reach the last workspace, shifting right again will bring me to the first workspace). This would be far less tedious...\nEdit as per terdon's observing: my Cinnamon version is 2.0.14\n\nA: So go to system settings > workspaces and activate \"Allow cycling through workspaces\"\n\nIf you don't see that option, you may have to click on the \"Switch to Advanced Mode\" button on the lower left (the one that says \"Switch to Normal Mode\" in the screenshot above). \n", "Q: grunt installation error in 12.04 I tried to install grunt using npm, which errors out, without giving me much detail into the reasoning.. reproducing the log here.\nnpm -v\n1.1.4\n\nsudo npm install -g grunt-cli\nnpm http GET https://registry.npmjs.org/grunt-cli\n\nnpm ERR! Error: failed to fetch from registry: grunt-cli\nnpm ERR!     at /usr/share/npm/lib/utils/npm-registry-client/get.js:139:12\nnpm ERR!     at cb (/usr/share/npm/lib/utils/npm-registry-client/request.js:31:9)\nnpm ERR!     at Request._callback (/usr/share/npm/lib/utils/npm-registry-client/request.js:136:18)\nnpm ERR!     at Request.callback (/usr/lib/nodejs/request/main.js:119:22)\nnpm ERR!     at Request.<anonymous> (/usr/lib/nodejs/request/main.js:212:58)\nnpm ERR!     at Request.emit (events.js:88:20)\nnpm ERR!     at ClientRequest.<anonymous> (/usr/lib/nodejs/request/main.js:412:12)\nnpm ERR!     at ClientRequest.g (events.js:156:14)\nnpm ERR!     at ClientRequest.emit (events.js:67:17)\nnpm ERR!     at HTTPParser.parserOnIncomingClient [as onIncoming] (http.js:1256:7)\nnpm ERR! You may report this log at:\nnpm ERR!     <http://bugs.debian.org/npm>\nnpm ERR! or use\nnpm ERR!     reportbug --attach /home/raghav/npm-debug.log npm\nnpm ERR! \nnpm ERR! System Linux 3.5.0-47-generic\nnpm ERR! command \"/usr/bin/nodejs\" \"/usr/bin/npm\" \"install\" \"-g\" \"grunt-cli\"\nnpm ERR! cwd /home/raghav\nnpm ERR! node -v v0.6.19\nnpm ERR! npm -v 1.1.4\nnpm ERR! message failed to fetch from registry: grunt-cli\nnpm ERR! \nnpm ERR! Additional logging details can be found in:\nnpm ERR!     /home/raghav/npm-debug.log\nnpm not ok\n\nTried to confirm if the server i actually accessible, and here it is - \nping registry.npmjs.org\nPING a.sni.fastly.net (103.245.222.162) 56(84) bytes of data.\n64 bytes from 103.245.222.162: icmp_req=1 ttl=50 time=243 ms\n\n\nA: As @geon noted over on StackOverflow:\nI used apt-get to install node. Npm was not included in that package, so it had to be installed separately. I assumed that would work, but apparently the npm version in the Ubuntu distribution was outdated.\nThe node wiki has this instruction:\nObtaining a recent version of Node or installing on older Ubuntu and other apt-based distributions may require a few extra steps. Example install:\nsudo apt-get update\nsudo apt-get install -y python-software-properties python g++ make\nsudo add-apt-repository ppa:chris-lea/node.js\nsudo apt-get update\nsudo apt-get install nodejs\n\nAfter that, npm was already included and worked perfectly.\n", "Q: UEFI and \"reserved bios boot area\" I purchased a new notebook, which has a pre-installed Windows 8 (upgraded to Windows 8.1).\nConfiguration:\n\n\n*\n\n*UEFI\n\n*Secure Boot\n\n*SSD + HDD\n\n\nI downloaded Kubuntu 13.10, prepared a bootable USB stick and made some free disk space to setup a dual-boot system.\nIn order to boot from the USB stick I had to turn-off Secure Boot and switch to \"CSM\" (\"Compatibility Support Module\"; Legacy mode)!??\nNow in the \"Prepare partitions\" (manual) step of the installer, /dev/sda (HDD) is pre-selected for \"Device for boot loader installation\".\nAs far I can see, the EFI partition is /dev/sdb1 (SSD; fat32) however.\nI tried \n\n\n*\n\n*/dev/sdb1 \n\n*/dev/sdb \n\n*/dev/sda\n\n\nbut I always get an error about \"reserved bios boot area\".\nNow as I understand, this \"reserved bios boot area\" is not needed for UEFI. So what should I do?\n\nA: You've booted in BIOS/CSM/legacy mode, so the installer is trying to set up a BIOS boot loader, not an EFI/UEFI boot loader.\nI recommend you go back and find a way to boot in EFI/UEFI mode. One thing that might help with this is using an EFI-only boot medium. Unfortunately, the Ubuntu installation discs are Frankenstein-monster conglomerations of half a dozen more-or-less incompatible different systems that are made to work, after a fashion, through technical trickery. The trouble is that, although this sort of thing works much of the time, it fails sometimes, and when it does fail it becomes harder to disentangle everything.\nThe easiest thing to try is likely to be to create a second USB flash drive with my rEFInd boot manager. Insert both it and the Ubuntu boot medium in your computer and tell the computer to boot to rEFInd. If you're lucky, it will present a boot option for the Ubuntu installer and that will work. I can't promise that luck will be with you, though; you may need to go digging through firmware boot options or take some other radical steps to get it to work.\nOh, and you may also want to read my page on doing EFI-mode installs. It doesn't directly address the problem you're having, but it covers a lot of potential EFI installation and boot problems.\n", "Q: Problem installing Ubuntu on older PC I am trying to install Ubuntu 13.10 32 bit on older PC with only 256MB of RAM but every time it gets to the screen where choice needs to be done between demo and install it just hangs and I can not go any further. Sometimes it hangs even sooner on the purple screen. The mouse get sluggish and clicking on buttons does not do anything.\nIs it possible to run this OS on this older PC and if so what steps should I take to get it installed??\nIf I can not use Ubuntu on this PC can someone recommend another Linux OS which can be used??\nJust trying to move away from Windows XP.\n\nA: The best option you have to get the familiar feel in linux on an older pc is to get Lubuntu. You can download the torrent file from here. I assume you know what to do next ;) :)\n\nA: Xubuntu 12.04 LTS uses the PAE-required kernel as per How can I tell if a machine has PAE? and How can I install on a non-PAE CPU? (error \"Kernel requires features not present on the CPU: PAE\") so may I ask you try Lubuntu 13.10 which will work without PAE.\n", "Q: Looking to change GPUs I currently have a Radeon HD 7970 GPU installed and I am looking at buying a NVIDIA GTX770.\nI would like to know if the NVIDIA one is better, in particular to WINE gaming, and Blender rendering I know NVIDIA is better, but would like to know how well the Nvidia cards work on Linux, I have only used AMD cards so far.\n\nA: Whether Nvidia graphics cards are better in Ubuntu than AMD graphics cards is a matter of opinion, but Nvidia graphics cards are more fully supported in Blender than AMD graphics cards.\nCycles is a new render engine available since Blender 2.61. It is still under development, and intends to become a render engine with a focus on interactivity and ease of use, while still supporting many production features. Nvidia CUDA is supported for GPU rendering with Nvidia graphics cards starting from GTX 4xx. Cycles requires recent Nvidia drivers and NVIDIA CUDA toolkit to be installed.\nIn Ubuntu 14.04 there is a new CUDA package that is not available in Ubuntu 13.10 called libcudart5.5. libcudart5.5 is the NVIDIA CUDA runtime library. libcudart5.5 requires the nvidia-331 or more recent graphics driver.\n\nCUDA enabled in Blender in Ubuntu 14.04\n", "Q: Problem installing applications on ubuntu gnome 14.04 I just installed beta version of ubuntu gnome 14.04 and apparently i can't install any old applications such as:\nSopcast 0.8.5\nhttp://linuxg.net/how-to-install-sopcast-0-8-5-on-ubuntu-13-1013-04-linux-mint-1615-and-pear-os-8/\nor \nAcestream player\nhttp://forum.torrentstream.org/index.php?topic=1933.0\nis there a way to install these applications or should i wait until they start supporting 14.04 ?\n\nA: Short Version:-\nYou can wait until they release a version for 14.04.But you can also port the apps to 14.04 by compiling and building them on Ubuntu14.04.\nLong Version:-\nUbuntu 14.04 is still in it's beta.It has been provided only for the reason that beta testers could find and report bugs in it and consequently the developers could fix them.This would give the end users more stable release.\nMost developers would not release packages for beta releases because it is highly probable that the softwares won't work properly and that there would be close to no users who would seriously want the apps on a beta release.\nSo for now, you can either wait or build the software for yourself.\n", "Q: Ubuntu 13.10 unity not loading Ok. Here's the situation. The only thing that will load is the wallpaper and the icons I had on my desktop. The launcher on the left dos not load, and the taskbar on the top does not load. The final things I did on my Laptop before unity died that I remember are as such: uninstalled libreoffice 4.2 so I could install 4.2.2, installed adobe flash player, installed (i think its called) gimp photo editor, installed gnash. Icons started dissapearing off my left side launcher that i had locked to it, the terminal would not led me cd to the libre 4.2.2 folder. the spotify icon became a question mark. my home folder crashed randomly. my backup failed. so i restarted my pc. when it came to the log on screen it did not show me the option to change desktop enviroments (gnome fallback, unity, etc) and when i logged on all thats there is my background and the desktop icons i had on it. steam is just a white square. I need to install libre. and i need my computer to work for school tomorrow. Please help me to get my pc to work\nPS i installed that tool to change graphic settings to see if i could enable the unity plugin but i could not find it. I think its called something like ccsm or something like that. it did not work. Help please\n\nA: The answer in the post below described how to make sure the unity plugin is enabled, it may help with what you're seeinh\nUnity doesn't load, no Launcher, no Dash appears\nload-no-launcher-no-dash-appears\n", "Q: Sort millions of text files in a folder using unix sort I am trying to sort a lot of files (millions ie approx 2.5m) .txt files in a folder called NZParsed.\nAll the files in the folder are named like 1.txt 2.txt and so on till 25xxxxx.txt\nAfter running the following command in eclipse :\nos.system(\"sort -k1,1 -k3,3n -k4,4n -y 1048576 /home/viraj/NZ/NZParsed/* -o /home/viraj/NZ/SplitIndex/abcd.txt\")\n\nI get an error:\nsh: 1: sort: Argument list too long\n\nCan anyone tell me any other way I could sort all these files into 1 file and split them using the following command in eclipse:\nos.system(\"split -C 200m /home/viraj/NZ/SplitIndex/abcd.txt /home/viraj/NZ/SplitIndex/\")\n\n\nA: The problem has nothing to do with eclipse or python. You are hitting the ARG_MAX limit, for more details see here but briefly, this is the limit of how many bytes the list of arguments to a command can be.\nSo, to avoid this, you need to sort in a way that does not list the files. For example:\nfor i in /home/viraj/NZ/NZParsed/*; do cat \"$i\" ; done |\n    sort -k1,1 -k3,3n -k4,4n -y 1048576 > /home/viraj/NZ/SplitIndex/abcd.txt\n\nThe command above will cat each file and then pass the contents of all files through your sort command. That way, the files are never listed and you won't have the ARG_MAX problem.\nAnother approach would be to use find's -exec option:\nfind /home/viraj/NZ/NZParsed/ -type f -name '[0-9]*.txt' -exec cat {} + | \n    sort -k1,1 -k3,3n -k4,4n -y 1048576 > /home/viraj/NZ/SplitIndex/abcd.txt\n\n", "Q: Why does my umask keep resetting to 000? When I login anew my umask is 002. At least for a while. Then at some point, and I'm not sure when, it reverts to 000. This is very inconvenient and I'm now constantly living in fear of dropping files and folders with strange permissions across my home directory.\nThe reversion to 000 can happen after minutes of use, or after days. A few weeks after I first installed ubuntu it happened quite a lot, then it cooled down, and just in the last few days this issue has reared its ugly head again.\nI can set it back to 002 with $ umask 002 but this only works for the current shell (as expected).\nSome more information:\n\n\n*\n\n*The tty at ctrl-alt-f2 has a umask of 002 even when my f7 login is at 000\n\n*/etc/profile says that umask is now handled by pam_umask\n\n*/etc/login.defs has UMASK 022 and USERGROUPS_ENAB yes\nI'm running\nUbuntu 13.10 with XMonad and (oh-my-)zsh.\nIn case this is useful, here's my /etc/fstab\n# <file system> <mount point>   <type>  <options>       <dump>  <pass>                                    \n# / was on /dev/sdb8 during installation                                                                  \nUUID=96f989e0-ee94-4bff-9663-3fa479a83ad4 /               ext4    errors=remount-ro 0       1\n# /boot/efi was on /dev/sdb1 during installation                                                          \nUUID=7682-B8AD  /boot/efi       vfat    defaults        0       1\n# swap was on /dev/sdb7 during installation                                                               \nUUID=0d7d57af-9a31-481e-9da4-1032c94f57e9 none            swap    sw              0       0\n\nHere is an abridged version of my crontab from crontab -l\n* * * * * cd /home/miles/code/Checkin/ && ./node_modules/.bin/coffee ./client.coffee -n attercop -h secret1.com -p 8888\n* * * * * cd /home/miles/code/Checkin/ && ./node_modules/.bin/coffee ./client.coffee -n attercop -h secret2.com -p 8888\n\nclient.coffee is just a script that sends an http request.\nAnd my root crontab from sudo crontab -l reports no crontab for root\n\nA: The issue for me was caused by a Sublime Text 3 plugin called Terminal, which is used to launch terminals from sublime files. When Terminal launched the first and only window of gnome-terminal, then it inherited the umask of 000 from sublime.\nIn the hopes that this answer can be useful to those who are not having the same problem as me, I will reiterate some suggestions for how to attack this problem, garnered from the comments above:\n\n\n*\n\n*Look through your rc files (.bashrc, .zshrc) to see if there are errant umask calls.\n\n*If you're using bash, try bash -x -l -i -c 'exit' 2>&1 | grep umask to find call to umask from your rc files.\n\n*If you're using zsh, try zsh -x -l -i -c 'exit' 2>&1 | grep umask to find calls to umask from your rc files.\n\n*Check whether you are setting a umask value when mounting $HOME. Look in /etc/fstab\n\n*Check whether there is anything strange running in cron that could change your umask. \ncrontab -l and sudo crontab -l.\n\n*Perhaps try using audit to find the source of mysterious umask changes.\nsudo auditctl -A auditctl exit,always -S umask and look in /var/log/kern.log\n", "Q: How can I reset Terminology settings if the terminal is inaccesable? I’m on Ubuntu 12.04 running GTK 2.x+\nI was experimenting with new terminals and messed up terminology, I tried to do sudo apt-get autoremove terminology thinking that would remove the program and settings,  then reinstalled it sudo apt-get install terminology but when I run the program I get the same issues and this output if run via another console.\nrenamon@Gibson{~}:terminology\nERR<13620>:elementary elm_prefs.c:2139 _elm_prefs_init() prefs iface module could not be loaded, the prefs widget won't function\nERR<13620>:efreet_cache lib/efreet/efreet_cache.c:1108 on_send_register() org.freedesktop.DBus.Error.ServiceUnknown The name org.enlightenment.Efreet was not provided by any .service files\nrenamon@Gibson{~}:\n\nAny help on this issue? How do I reset terminology prefrences? Can this application even be used in Ubuntu?\n\nA: As a general rule, application-specific settings are kept either in hidden dotfiles/dotdirectories in your $HOME or in subdirectories of $HOME/.config. For example, the config file for conky is ~/.conkyrc while the configuration files for the links2 browser are in ~/.links2/ while those for vlc are in ~/.config/vlc.\nSo, have a look at the hidden files in your $HOME, look for any whose name contains terminology. You can do this with this command:\necho .terminolog* ./config/terminology*\n\nThat should list the config files/dirs of terminology and deleting them (or moving them) should get the program back.\n\nRemember that even if you have removed the default terminal, you can still run xterm or  always drop to a cirtual console with Ctrl + Alt + F2 (get back to your GUI with Ctrl + ALt+ F7, or F8 depending on your system).\nAlternatively, you can list the files in the file browser if you enable \"show hidden files\".\n\nA: *\n\n*sudo apt-get remove --purge terminology\n\n*sudo apt autoremove\n\n*find $HOME -name \"*erminology*\"\nNow you know that config files are here (or?)\n/home/dx/.config/terminology\n\n\n*rm -r ~/.config/terminology\n\n*sudo apt-get install terminology\n\n*Profit!\n\n\nPS.:\nThis answer is based on this AskUbuntu answer.\n", "Q: avconv - Filter drawtext doesn't work I' going to add some text to a video segment using -vf but it doesn't work. Here is what I tried\navconv -ss 00:00:20 -i input.mp4 -t 00:00:10 -vcodec copy -acodec copy \\\n  -vf \"drawtext=fontfile='/usr/share/fonts/truetype/ttf-dejavu/DejaVuSans.ttf':text='hello world':x=0:y=0:fontsize=24:fontcolor=black\" output.mp4\n\nBut the text doesn't show up. I know that -t argument should appear after -i or the duration won't be set. I wonder if I misplace -vf in this case. Would anyone tell me how to make it?\nP.S. I install it with apt-get install ffmpeg. Software info:\navconv version 0.8.9-6:0.8.9-0ubuntu0.13.04.1, Copyright (c) 2000-2013 the Libav developers\n  built on Nov  9 2013 19:09:48 with gcc 4.7.3\n\n\nA: In case we want to add text to our video using the drawtext filter we can not make use of the copy video codec.\nAdding text to a video will change the video data. Therefore we have to re-encode the video stream using any codec other than copy.\n\nA: The following command worked for me:\navconv -i input.mp4 -vf \"drawtext=fontfile='/usr/share/fonts/truetype/ttf-dejavu/DejaVuSans.ttf':text='hello world':x=0:y=0:fontsize=24:fontcolor=black\" output.mp4\n\ntested on this mp4 sample file.\n", "Q: Unable to resume after suspend I'm using Ubuntu 12.04 & everything about it is great except that it just won't resume after suspend. I've tried the suggestions listed in this thread Entire system freezing after pressing \"Suspend\" but none worked. I'm using Lenovo Y510P. I'm new to Ubuntu, or unix for that matter, so please let me know if there's anymore  information that I should be posting. Thanks.\nupdate\nI tried the suggestion by Dima on this post How to enable hibernation?. The machine wakes up from hibernation but immediately the screen gives a screen like this \n\nWondering if this is an issue with the graphics card or something. \n\nA: A lot of graphic resume problems could be solved by doing the suspend/resume from the virtual console, so that after the resume a \"refresh\" is forced by the graphic drivers. \nCheck if the system suspend correctly from a virtual console: \n\n\n*\n\n*switch to a virtual console with CtrlAltF1\n\n*login with your user and password \n\n*suspend the system (either using the suspend key-combo for your system, or issuing the command sudo /usr/sbin/pm-suspend)\n\n*resume -> you should have a working prompt (exactly the same screens as before), otherwise see FAIL\n\n*switch to the graphic console with  CtrlAltF7\n\n*if all is ok, problem solved! You can follow the instruction below (from this answer)  to make the switch automatic; otherwise, see FAIL\nIf something is still wrong...\nFAIL: So the problem is another one --- I do not have that laptop so I can't really help a lot more. Maybe studying the content of file /var/log/pm-suspend.log can shed some light. \n\nHow to make the switch automatic  \n\n\n*\n\n*edit/create the file \ngksudo gedit /etc/pm/sleep.d/01_switchvt\n\n*Put  this content in it:\n#!/bin/sh\n\n# Switch to a VC before suspending and back after resume\n\ncase \"$1\" in\n    resume|thaw)\n        chvt 7\n    ;;\n    suspend|hibernate)\n        chvt 1\n    ;;\nesac\n\n\n*save and exit\n\n*make it executable: \nsudo chmod 755 /etc/pm/sleep.d/01_switchvt \nNotice in step 2, most of the installations will need the command chvt 7 --- this is the same as pushing ctrl-alt-F7 to go back to the graphic screen. If you need another key combo, change the \"7\" there accordingly. \n", "Q: Is it better to install software through software center or compile it myself? This is kind of a general question about installing stuff and remove as well. I've never compiled any software from source but I'm wondering, is it better? What are the pros and cons of each ways of installing software.\nBy the way, I'm currently using Ubuntu 13.04.\n\nA: Manual compilation\npros:\n\n*\n\n*if you are developer, you can change anything you want and implement new features in the software\n\ncons:\n\n*\n\n*You shold be developer, that's not easy.\n\n*And you should well understand alien code and know programming languages\n\n*And you should track your software manually\n\nCommand line\npros:\n\n*\n\n*more informative installation process\n\n*shows errors in the case if they appear. You can simply copy them and search solution in the Internet.\n\n*possible to manually remove locks\n\ncons:\n\n*\n\n*you should know the exact name of the package\n\n*you should type commands and know what are you doing\n\n*you should track self-compiled packages manually\n\nGUI\npros:\n\n*\n\n*You have a big choice of available packages\n\n*Easy to learn\n\n*Shows a lot of information about packages\n\n*Handles all packages automatically\n\ncons:\n\n*\n\n*progress is less informative\n\n*in case of errors you should do a screenshot and optionally edit it in graphic editor before posting to forums.\n\n*if some installation left lock inside directories /var/lib/apt/lists, /var/lib/dpkg, /var/cache/apt/archives you should use Terminal\n\n*some software is not accessible and you should search for it in the Internet\n\n\nA: There is no difference, but in the general use case the Ubuntu Software Center is better because it shows a package description, screenshot(s) if the package is a GUI application, and most importantly it also shows the package's add-ons, if there are any, that can be installed at the same time that you install the package. This feature of the Ubuntu Software Center can save you a lot of time.  \nIn the particular use case where you want to install a long list of packages, I prefer to use the terminal instead of the Ubuntu Software Center, because I can install several packages with one command of the form:\nsudo apt-get install package1 package2 ... last-package-in-the-list \n\n", "Q: Unable to access auto-mounted partition from Steam Before I start, I am using Ubuntu 13.10 64-bit, I have all the latest updates (including the latest Steam Beta Client).\nUsing the Steam client I have been unable to install or run games from another partition on my drive.  Previously, the partition with the games would mount into the /media/willc folder (and steam could read/write here, I installed and ran Left 4 Dead 2) but I would have to mount it by opening it in the file system or via the terminal before hand; I wanted to automate this process.\nI followed the directions from Akshit Baunthiyal on this question to make Ubuntu mount the partition seperately.  It essentially just adds a line to /etc/fstab.  The line I added was \nUUID=<uuid> /home/willc/SteamLibrary ext2 user,exec,sync,auto,rw 0 0\n\nand I double checked the info, the uuid and filesystem are correct and the mount point is where I want it.\nAfter this modification, logging in or running sudo mount -a\n successfully mounts the directory automatically.  The problem I am now encountering is that the Steam client gives me the error \n\nNew Steam Library Folder must be on a filesystem mounted with executable permissions.\n\nSo, after looking around at fstab options I noticed that the option \"user\" (any user can mount) also implies the option \"noexec\" (binaries are not executable), so I added the \"exec\" option after user to override this.  However, I still get this error.  I also tried to run chmod -R 777 SteamLibrary just in case permissions were the problem but it persists even after that.\nIs there a missing option I need for fstab or is there something else entirely I might be missing?\n\nA: Found the answer to my own question with a little more digging.  Doing what I did in the question gave me permission to read/write all the files/directories, but I did not have permissions set for the partition itself.  To illustrate, ls -l $HOME showed me that the partition was owned by root and had no read/write permissions for \"other\".  To correct it I issued this:\nsudo chown -R -v <my_username>:<my_username> SteamLibrary\n\nSteamLibrary here is the mount point for the drive, -R recursively applies this to folders and files, -v outputs additional information.  In this case I set the owner and groups to my username since I will be the only one accessing it, but changing the second username to \"users\" should allow any user on the computer to access it.  Running the same ls command as before I now get the line\ndrwxrwxrwx  5 willc willc  4096 Mar 18 22:46 SteamLibrary\n\nThis shows me I now own the drive and have full permissions.  Now not only can I access the drive, but applications like steam are able to read/write as well.\n", "Q: Play on Linux not showing League of Legends I am using the following:\nUbuntu 12.04\nPlayOnLinux 4.0.14 (henceforth referred to as `POL)\nInstalled POL today, trying to get League of Legends running.  Everything seems to install smoothly, but when I go to the install button in the GUI (as in running POL), League isn't listed. Not in testing or games, or in search.  I've hit refresh, rebooted. \nShould I attempt to re-install POL?  Manually add league?  Anything would be helpful.\n\nA: Uninstall playonlinux and then go install the latest version by hand from the website. I notice that the Ubuntu apt-get repo version is outdated.\n", "Q: Remove previously flashed vbios splash screen I am new to linux and have recently installed and have ubuntu 13.10 working. Something weird is going on though. Back when I first got my aw17 I was all into benchmarking and I flashed my vbios and that caused me to have this splash screen at startup even before the bios. Well I had to completely repartition and restore my hard drive and now this is happening, it must have been saved in the restore somehow. I figured it would be erased after the new OS. Anyone mind helping me read through my boot log to find this and remove it please! I will post any results to instructions asap.\n\nA: By vbios, I take it to mean your video bios. The video bios exists on a chip on your video/graphics adapter much in the same way that your Motherboard's bios is stored on a chip. Both your video bios and motherboard bios are read and executed every time at boot. You could have multiple and different OS's or no OS at all, but the bios still executes. It's what gives your system its basic functionality (and is responsible for letting you know when there are problems with your system, like when there is no OS installed, for example) and what eventually loads your chosen OS after all the hardware checks out.\nSpecifically, your video bios sets up the complicated components that make up your video card. It contains things like clock speeds, fan settings, operating modes, capabilities, and even the model information. It does mostly all the same things your motherboard bios does, but only for the video card and its components. \nSo all the long-windedness aside, all I'm trying to say is that all of your bioses are indepenent of any OS you choose to install. Whenever you flash one, it's permanent (until you flash it again). Adding/removing hard drives, wiping your OS, etc will not change your bioses.\nA video bios can contain a splash screen. Most don't because they are annoying and usually introduce a delay in your boot process to give the user time to \"admire the artwork\". But after booting the same PC the first 100 times, the effect starts to wear off. And then, to top it off, you still have to sit through your motherboard's bios splash screen (if enabled, of course). (After all, we wouldn't want the thousands of dollars the company who made the card spent on making a 64-128kB image which is pixelated and an eyesore to go to waste). \nAnd generally, the vbios is not user-configurable in any way. So you likely would not be able to turn of the video splash even if you wanted to. (And why would you? That art is phan-see!)\nSo here's what you can do: However you managed to flash your vbios, do it again. But this time, use a different version. Maybe the original one that was on it? A good practice is to make a backup of the original bios before you go flashing a new one. So I'm hoping you have one stashed somewhere. Different versions of a vbios you choose to use may have the splash feature disabled.\nBonus: This chip's architecture is of a kind that is called Complimentary Metal-Oxide Silicon or CMOS. Does CMOS sound familiar? The name comes from the manufacturing processes and techniques that went into making it.\nAlso, nowadays, with modern OS's anyways, many video card vendors are writing unified drivers for their products. Part of the advancements made with this driver model is that the driver should have more direct control over the hardware. Thus the vbios has been rendered impotent as it's really only used during boot and the driver loaded in the OS handles all of the configuration that vbioses handled previously. So in most situations, flashing your vbios does not gain you much of anything unless your card has secret cuda or shader cores that a hacked vbios can enable. Heck, even video card vendors have stopped releasing vbios updates, as they are all but useless anymore.\n", "Q: Edit the USB mass storage driver I want to edit the USB MSD, to show a message whenever i plug a device (like a flash drive) to my computer. How do i do it? Which file exactly is to be edited and how?\n\nA: The driver has nothing to do with this, it just manages the device and allows the kernel to communicate with it. What you want is a much higher lever function.\nThe way to do this is using udev, the device manager for the Linux kernel:\n\n\n*\n\n*Create a script that will send the notifications. Save the following lines in a file in your home directory, for example ~/usbnotify.sh:\n#!/bin/bash\nexport DISPLAY=\":0\"\nnotify-send \"New device plugged in: $@\"\n\nMake the script executable by running chmod +x ~/usbnotify.sh \n\n*Create a new file called /etc/udev/rules.d/95-usbnotify.rules with the following contents (adapted from here):\nKERNEL!=\"sd[a-z]*\", GOTO=\"media_by_label_auto_mount_end\"\nACTION==\"add\", PROGRAM!=\"/sbin/blkid %N\", GOTO=\"media_by_label_auto_mount_end\"\n\n# Get label\nPROGRAM==\"/sbin/blkid -o value -s LABEL %N\", ENV{dir_name}=\"%c\"\n# use basename to correctly handle labels such as ../mnt/foo\nPROGRAM==\"/usr/bin/basename '%E{dir_name}'\", ENV{dir_name}=\"%c\"\nENV{dir_name}==\"\", ENV{dir_name}=\"usbhd-%k\"\n\nACTION==\"add\", ENV{dir_name}!=\"\", RUN+=\"/home/akshay/usbnotify.sh %c\", GOTO=\"media_by_label_auto_mount_end\"\n\n# Exit\nLABEL=\"media_by_label_auto_mount_end\"  \n\nMake sure to use the correct path to the script, I used /home/akshay/usbnotify.sh but edit to point to your home directory.\nSave the script and that's it. You should now receive a notification for every device that you plug in that is mounted as a drive. This will probably not work for cameras and the like but any storage device that is attached as /dev/sd* should work.\n", "Q: Is it safe to remove a process folder from /var/run/? Is it safe to remove a process folder from /var/run/ if I think it has got wrong permissions, will it be recreated by process as before?\nDo I lose any information by deleting /var/run/<process folder> when the process is not running?\nAfter deleting if it works/runs, does that mean it has not lost any data?\n\nA: It depends on the process. In most cases, a reboot should clear out the whole folder, but to be on the safe side, stop the process before deleting the folder.\n", "Q: Can i Use the DE as in 13.04 on 12.04 i want to use 13.04 Desktop Environment(DE) in 12.04 is it possible without upgrade.i am using 32 bit ubuntu.\nPlease tell me if this is possible or not.\nThanks in Advance. :)\n\nA: You can install Y PPA Manager and search for \"unity\"\n", "Q: make mistake in setting IP I have a device that has Linux Ubuntu OS. I use SSH for connecting to it.\nmy Linux version is like below when typed cat /proc/version command:\nLinux version 3.2.40-g996c4d7-dirty (sysmocom@vagrant-ubuntu-precise) (gcc version 4.6.3 20111117 (prerelease) (GCC) ) #1 PREEMPT Mon Oct 7 8:28:29 CEST 2013.\n\nI change the IP setting with vi command (vi /etc/network/interfaces), but I made a mistake in writing the word \"address\". I typed it \"adress\".\nNow I don't see the device in the network and I don't know what is it's IP.\nHow i can connect to it again?\n\nA: You can use netdiscover to get a list of local ip adresses. It gives you a list like:\n 5 Captured ARP Req/Rep packets, from 5 hosts.   Total size: 300               \n _____________________________________________________________________________\n   IP            At MAC Address      Count  Len   MAC Vendor                   \n ----------------------------------------------------------------------------- \n 192.168.0.1     aa:bb:cc:dd:ee:ff    01    060   Sitecom Europe BV \n 192.168.0.101   aa:bb:cc:dd:ee:ff    01    060   Unknown vendor               \n 192.168.0.104   aa:bb:cc:dd:ee:ff    01    060   Somedevice, INC.         \n 192.168.0.116   aa:bb:cc:dd:ee:ff    01    060   Another Device\n\nIt is a command line application, run it by sudo netdiscover. If you run the command, it will offer you to install it if you haven't installed it before.\n\nA: from your question i assume this is your own network so If you have the MAC of this device , you may use software for sniffing the MACs on the network \n\nA: I don't think that you can connect to your machine anymore by any means, the nic adaptor does not have an ip in this state. \nYou have to get to the console (physical monitor attached to the machine), login  and then correct the networking file. \n", "Q: uninstall windows server 2008 and add disk space to ubuntu 12.04 I have windows 2008 and Ubuntu 12.04 installed. I want to remove windows server 2008 and add space to Ubuntu 10.04?How can i do this?\n\nA: The first rule of making alterations to the primary hard drive is \"Make a backup\".\nThe Second rule of making alterations to the primary hard drive is \"Make a backup\".\nThere are three ways to do this, you can delete the windows drive using Gparted then expand the Ubuntu partition to include to resulting empty space.  I'm not sure how well this will work as I have never done it that way round. (I have moved Ubuntu and expanded windows and Ubuntu partitions to fill the drive).  Give it a try, if it all goes wrong you can go back to your backup.\nOr, you can delete the windows partition and reformat the space as ext4 and mount it for use in your Ubuntu file system.\nFinally, re-install with the latest version and copy the settings from your backup.\nDid I mention that you should do a backup?\n", "Q: Resizing media Partition, safe? I recently switched to Ubuntu 12.04. I have two storage drives, my SSD with Ubuntu and the root filesystem installed on it, and my 1TB HDD with movies and other large data files.  I wiped the SSD on the installation, but I kept the media drive as is (for the installation).\nI decided I wanted to use ext4 format instead (mostly because Plex has issues with NTFS and the permissions not being there).  Because the amount of data took up ~200GB of space, I don't have another drive to move it onto temporarily, so I created a 700GB partition on the unused portion of my HDD, formatted to ext4, moved my data over (fixed the permissions), and currently deciding on how to continue.\n\n\n*\n\n*I can directly resize the current ext4 partition to fill the HDD, but because the data is sitting in the middle it wants to move it to the start of the partition.  So I get a warning.  How dangerous is it to go this route?  I can't back up the HDD. \n\n*My other option is to format the old NTFS to ext4, move the files back to that partition, delete the second ext4 partition and resize the one I just formatted to fill the HDD.  I'm not %100 certain that my files would be safer as they wouldn't need to be moved but it would seem like it.\nAm I correct?\nTL;DR:\nHave a 1TB HDD with two partitions, an empty one (no format) take up the first ~300GB of the drive, and one with my data files (~200GB) in ext4 that fills the rest of the HDD.  The data starts at the begining of the second partition so resizing the second to fill the HDD would require moving the files while being formatted (I assume).  Is this safe? If not I'll just go the second route, more time consuming is all (took nearly an hour for my files to be moved last time).\n\nA: It is much more safe to go second route.\n\n\n*\n\n*if something goes wrong, you'll have at least one copy of data intact\n\n*if something goes wrong while formatting & moving data (the first route) you will end up with half-moved data and broken partition table.\n\n*it will take almost the same time to copy 200 GB from one partition to another (the same amount of data needs to be moved)\n\n\nA: If you want to be safe you could just format the unused space as another drive, so you have two partitions, then use one for music and the other for video. It's a safe option.\nI have had problems expanding a partition towards the start of the drive (I assume because it moves the file pointers) but no trouble expanding the partition towards the end of the drive.  So, if you realy needed to use all of the space, I would create a new partition in the free space at the start of the drive, copy the files over, and then delete the old partition and expand the new partition towards the end of the drive.\nIf you can live with the setup you have you may want to go with option one until the price of drives drops to the point that you can afford a backup drive before doing anything. \n", "Q: Update QJSON on Ubuntu 12.04? I currently have libqjson-dev 0.7.1-6 installed on 12.04 via package manager. I need 0.8.0 in order to run an app I like. I have little experience compiling from source, less with cmake. I assume there's no backport. \nCan someone please help me install 0.8.1 from SourceForge?  I know that Ubuntu 13.10 comes with a higher version of QJSON. I'm hoping that they'll be no issues with QJSON 0.8 on Ubuntu 12.04.\nThanks! \n\nA: If I were you I'll try to install the 13.10 deb package by hand, dependencies of libqjson0 are exactly the same for 0.7.1-6 (Ubuntu 12.04) and 0.8.1-2 (Ubuntu 13.10).\nFor amd64 arch, I'd download the following deb files:\n\n\n*\n\n*http://packages.ubuntu.com/fr/saucy/amd64/libqjson-dev/download\n\n*http://packages.ubuntu.com/fr/saucy/amd64/libqjson0/download\nand then run in the folder where you downloaded the deb files:\nsudo dpkg -i libqjson0_0.8.1-2_amd64.deb libqjson-dev_0.8.1-2_amd64.deb\n\n\nA: Have you tried the instructions on the \"readme.md\" file?\n\"For Unix/Linux/Mac:\nmkdir build\ncd build\ncmake -DCMAKE_INSTALL_PREFIX=_preferred_path_ ..\nmake\nmake install\n/sbin/ldconfig #if necessary\n\n\"\n", "Q: No sound from speakers Just installed a new Kubuntu 13.10. It seems the Intel HDA sound card are recognized as a HDMI(Digital) output rather than both an analog output and a digital one. AlsaInfo is here\nAny ideas how to fix this?\n\nA: First thing is to start play an video or audio file and let it play to know when your sound will start working\nJust open the terminal and run alsamixer and then using arrows browse through playback devices and unmute muted (M key) devices until you hear a sound.\n", "Q: How do I get the pcap lib on Ubuntu? I have a programming assignment where I need to use the pcap lib.\n#define _BSD_SOURCE\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <pcap.h> // <-- missing include\n#include <netinet/ip.h>\n#include <netinet/tcp.h>\n\nvoid logpacket( unsigned char* payload, struct ip* ipheader, struct tcphdr* tcpheader )\n{\n    //...\n}\n\n\n\nint main(int argc, char* argv[] )\n{\n    //...\n}\n\nHow can I get the library files I need to compile this program?\n\nA: For Ubuntu 12.04, 12.10, 13.10, 14.04 and onward open the terminal and type:\nsudo apt-get install libpcap0.8-dev  \n\n\nA: You can install them. Try with command\nsudo apt-get install pcap*\n\nI guess that you need dev lib. On my pc list is:\nxxxxx@xxxxx ~ $ sudo apt-get install pcap*\n[sudo] password for darkstar: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nNote, selecting 'libchipcard-dev' for regex 'pcap*'\nNote, selecting 'libchipcard-pcsc-card-perl' for regex 'pcap*'\nNote, selecting 'libpcapnav0' for regex 'pcap*'\nNote, selecting 'python-ipcalc' for regex 'pcap*'\nNote, selecting 'libchipcard-tools' for regex 'pcap*'\nNote, selecting 'sipcalc' for regex 'pcap*'\nNote, selecting 'pcal' for regex 'pcap*'\nNote, selecting 'pcaputils' for regex 'pcap*'\nNote, selecting 'libdate-pcalc-perl' for regex 'pcap*'\nNote, selecting 'libpcap0.7-dev' for regex 'pcap*'\nNote, selecting 'lua5.1-coxpcall' for regex 'pcap*'\nNote, selecting 'libmlpcap-ocaml-dev' for regex 'pcap*'\nNote, selecting 'libmlpcap-ocaml' for regex 'pcap*'\nNote, selecting 'libpcap0.8' for regex 'pcap*'\nNote, selecting 'libmlpcap-ocaml-7zxa8' for regex 'pcap*'\nNote, selecting 'python-pcapy' for regex 'pcap*'\nNote, selecting 'libpcap0.8-dbg' for regex 'pcap*'\nNote, selecting 'libmlpcap-ocaml-dev-7zxa8' for regex 'pcap*'\nNote, selecting 'pcalendar' for regex 'pcap*'\nNote, selecting 'libghc-pcap-prof' for regex 'pcap*'\nNote, selecting 'python2.7-libpcap' for regex 'pcap*'\nNote, selecting 'libpcap0.8-dev' for regex 'pcap*'\nNote, selecting 'libchipcard6' for regex 'pcap*'\nNote, selecting 'ulogd-pcap' for regex 'pcap*'\nNote, selecting 'apcalc-common' for regex 'pcap*'\nNote, selecting 'libghc-pcap-prof-0.4.5.2-a3d5c' for regex 'pcap*'\nNote, selecting 'libghc-pcap-dev-0.4.5.2-a3d5c' for regex 'pcap*'\nNote, selecting 'liblua5.1-coxpcall0' for regex 'pcap*'\nNote, selecting 'apcalc-dev' for regex 'pcap*'\nNote, selecting 'libghc-pcap-dev' for regex 'pcap*'\nNote, selecting 'libpcapnav0-dev' for regex 'pcap*'\nNote, selecting 'libchipcard-data' for regex 'pcap*'\nNote, selecting 'python2.7-pypcap' for regex 'pcap*'\nNote, selecting 'apcalc' for regex 'pcap*'\nNote, selecting 'libnet-pcap-perl' for regex 'pcap*'\nNote, selecting 'udpcast' for regex 'pcap*'\nNote, selecting 'libpoe-component-pcap-perl' for regex 'pcap*'\nNote, selecting 'pcapfix' for regex 'pcap*'\nNote, selecting 'libchipcard-libgwenhywfar60-plugins' for regex 'pcap*'\nNote, selecting 'lua-coxpcall' for regex 'pcap*'\nNote, selecting 'python-pypcap' for regex 'pcap*'\nNote, selecting 'libpcap-dev' for regex 'pcap*'\nNote, selecting 'libghc-pcap-doc' for regex 'pcap*'\nNote, selecting 'python-libpcap' for regex 'pcap*'\nNote, selecting 'python2.7-pcapy' for regex 'pcap*'\nNote, selecting 'ulogd2-pcap' for regex 'pcap*'\nNote, selecting 'ipcalc' for regex 'pcap*'\nNote, selecting 'libchipcardd0' for regex 'pcap*'\nNote, selecting 'dispcalgui' for regex 'pcap*'\nNote, selecting 'python2.7-ipcalc' for regex 'pcap*'\nNote, selecting 'libghc-pcap-dev' instead of 'libghc-pcap-dev-0.4.5.2-a3d5c'\nNote, selecting 'libghc-pcap-prof' instead of 'libghc-pcap-prof-0.4.5.2-a3d5c'\nNote, selecting 'libmlpcap-ocaml' instead of 'libmlpcap-ocaml-7zxa8'\nNote, selecting 'libmlpcap-ocaml-dev' instead of 'libmlpcap-ocaml-dev-7zxa8'\nNote, selecting 'libpcsc-perl' instead of 'libchipcard-pcsc-card-perl'\nNote, selecting 'lua-coxpcall' instead of 'lua5.1-coxpcall'\nNote, selecting 'python-ipcalc' instead of 'python2.7-ipcalc'\nNote, selecting 'python-libpcap' instead of 'python2.7-libpcap'\nNote, selecting 'python-pcapy' instead of 'python2.7-pcapy'\nNote, selecting 'python-pypcap' instead of 'python2.7-pypcap'\n\nTry adding one by one with dependency \n\nA: On \"Trusty Tahr\" following is worked for me:\n\nλ ~ cat /etc/issue\nUbuntu 14.04.2 LTS \\n \\l\nλ ~ sudo apt-get install libpcap-dev\n\n", "Q: I need to update my opengl drivers to play counter strike source ubuntu 13.10 I get an error glgeterror when I launch counter strike source. Normal counter strike runs fine, this is all through steam.\nI've done some digging and I need to get newer opengl drivers, My laptop has GPU 945gm intel and 1.4 opengl from what I can see.\nHere are the sites\nubuntu forum and launchpad\nI'm stuck at the /etc/X11/xorg.conf. Ubuntu 13.10 doesnt have this ?\nAlso from the graphics driver guide I'm not sure which of these I should be using\nTo force the use of gallium i915 driver:\n$ LIBGL_DRIVERS_PATH=/usr/lib/dri-alternates glxgears -info\n\nTo force the use of gallium llvmpipe software render:\n$ LIBGL_ALWAYS_SOFTWARE=1 glxgears -info\n\nTo force the use of old non-gallium software render:\n$ LIBGL_ALWAYS_SOFTWARE=1 LIBGL_DRIVERS_PATH=/usr/lib/dri-alternates glxgears -info\n\nAny help would be great\n\nA: to get the latest openGL 3.3 compliant drivers and all the latest updates for them you should install the oibaf ppa.\nsudo apt-get install ppa:oibaf/graphics-drivers\nrun that from the command line or include the oibaf ppa as a update source in the software sources.\n", "Q: Not able to change permission of files/folder shared in samba I am trying to change permission and change the group permission of the folders which are shared through SAMBA (Samba PDC). Commands are as follows:\n# chmod 766 /mnt/Format\n\nbut nothing changed.\nPlease help.\n\nA: The problem is because you use POSIX-specific command (chmod) to change non-POSIX-compliant filesystem (NTFS). The chown command also does not work on such filesystems. To change permissions on NTFS shares you should use mount options.\nFrom man mount.ntfs:\n\nOPTIONS\n       Below is a summary of the options that ntfs-3g accepts.\n\n       uid=value and gid=value\n              Set the owner and the group of files and directories. The values\n              are  numerical.  The defaults are the uid and gid of the current\n              process.\n...\n       permissions\n              Set  standard  permissions  on  created  files  and use standard\n              access control.  This option is set by default when a user  map‐\n              ping file is present.\n\n\nSo, instead of using\nchmod 766 /mnt/Format\n\nuse\nmount -o uid=UID,permissions,remount /mnt/Format\n\nSee man mount.ntfs for further help. There is nice EXAMPLES section which helps understanding how mounting works.\n", "Q: Type @ symbol with alt+64 I wanted to know if there is a way to type an @ symbol by pressing Alt+64 like in Windows. I use both Spanish and English keyboard layouts so I find it useful.\n\nA: Like Windows uses the Alt-Combos for ASCII, Ubuntu knows a similar input method for Unicode characters.\nTo enter the @ sign, which would be Unicode U+40 (hexadecimal!), press and hold Ctrl+Shift and then press U,4,0.\nThis works the same for all Unicode chars, like U+2744 for a snowflake.\n", "Q: Unity application lens removed, no local apps now I was removing all of the Unity web result lenses, and somehow I've now got no local app results. This is what I did to remove them:\nsudo apt-get purge unity-lens-music\nsudo apt-get purge unity-lens-applications\nsudo apt-get purge unity-lens-shopping\n\nWhat should I do to get back my local apps without recommendations?\n\nA: Use\nsudo apt-get install unity-lens-applications\n\nTo restore Applications Lens\nTo turn off software recommendations, use UnSettings\n\nJust turn off the \"Apps for download\" switcher.\nUnsettings download page.\n", "Q: Problem installing QtOctave First I installed MATLAB and I got stuck here:\nNo MATLAB executables were found in the directories you specified.\nThis package requires at least one local installation of MATLAB.\n\nI was unable to know what actually are the MATLAB executables.\nSecondly I installed QtOctave as an alternative to MATLAB, but again the same error mentioned above appeared.\nI also tried some answers from this site, but I was unable to install it.\n\nA: First try to fix the broken installation of MATLAB:\nsudo rm /var/cache/debconf/*.dat \nsudo dpkg-reconfigure -phigh -a\n\nAlternatively you can remove matlab-support since you now want to install qtoctave:\nsudo apt-get --purge remove matlab-support\n\nFinally re-run the qtoctave installation:\nsudo apt-get install qtoctave\n\n", "Q: How to install Eclipse which I have already downloaded with Android Development Kit? I have downloaded the full Android Development Kit (ADK) from the official Google Developers website. It is a .zip file which contains Eclipse and other ADT tools.\nI want to install the Eclipse application which is in that .zip file. I don't want the trouble of going every time to that particular directory and running Eclipse from there.\nIs there any command which lets me install the version of Eclipse which I have downloaded with ADK?\n\nexport PATH=$PATH:/home/amol/Downloads/adt-bundle-linux-x86_64-20131030/sdk/tools\nexport PATH=$PATH:/home/amol/Downloads/adt-bundle-linux-x86_64-20131030/sdk/platform-tools\nexport PATH=$PATH:/home/amol/Downloads/adt-bundle-linux-x86_64-20131030/eclips\n# ~/.bashrc: executed by bash(1) for non-login shells.\n# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)\n# for examples\n\n# If not running interactively, don't do anything\ncase $- in\n    *i*) ;;\n      *) return;;\nesac\n\n# don't put duplicate lines or lines starting with space in the history.\n# See bash(1) for more options\nHISTCONTROL=ignoreboth\n\n# append to the history file, don't overwrite it\nshopt -s histappend\n\n# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)\nHISTSIZE=1000\nHISTFILESIZE=2000\n\n# check the window size after each command and, if necessary,\n# update the values of LINES and COLUMNS.\nshopt -s checkwinsize\n\n# If set, the pattern \"**\" used in a pathname expansion context will\n# match all files and zero or more directories and subdirectories.\n#shopt -s globstar\n\n# make less more friendly for non-text input files, see lesspipe(1)\n[ -x /usr/bin/lesspipe ] && eval \"$(SHELL=/bin/sh lesspipe)\"\n\n# set variable identifying the chroot you work in (used in the prompt below)\nif [ -z \"${debian_chroot:-}\" ] && [ -r /etc/debian_chroot ]; then\n    debian_chroot=$(cat /etc/debian_chroot)\nfi\n\n# set a fancy prompt (non-color, unless we know we \"want\" color)\ncase \"$TERM\" in\n    xterm-color) color_prompt=yes;;\nesac\n\n# uncomment for a colored prompt, if the terminal has the capability; turned\n# off by default to not distract the user: the focus in a terminal window\n# should be on the output of commands, not on the prompt\n#force_color_prompt=yes\n\nif [ -n \"$force_color_prompt\" ]; then\n    if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then\n    # We have color support; assume it's compliant with Ecma-48\n    # (ISO/IEC-6429). (Lack of such support is extremely rare, and such\n    # a case would tend to support setf rather than setaf.)\n    color_prompt=yes\n    else\n    color_prompt=\n    fi\nfi\n\nif [ \"$color_prompt\" = yes ]; then\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\nelse\n    PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ '\nfi\nunset color_prompt force_color_prompt\n\n# If this is an xterm set the title to user@host:dir\ncase \"$TERM\" in\nxterm*|rxvt*)\n    PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1\"\n    ;;\n*)\n    ;;\nesac\n\n# enable color support of ls and also add handy aliases\nif [ -x /usr/bin/dircolors ]; then\n    test -r ~/.dircolors && eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"\n    alias ls='ls --color=auto'\n    #alias dir='dir --color=auto'\n    #alias vdir='vdir --color=auto'\n\n    alias grep='grep --color=auto'\n    alias fgrep='fgrep --color=auto'\n    alias egrep='egrep --color=auto'\nfi\n\n# some more ls aliases\nalias ll='ls -alF'\nalias la='ls -A'\nalias l='ls -CF'\n\n# Add an \"alert\" alias for long running commands.  Use like so:\n#   sleep 10; alert\nalias alert='notify-send --urgency=low -i \"$([ $? = 0 ] && echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&|]\\s*alert$//'\\'')\"'\n\n# Alias definitions.\n# You may want to put all your additions into a separate file like\n# ~/.bash_aliases, instead of adding them here directly.\n# See /usr/share/doc/bash-doc/examples in the bash-doc package.\n\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n\n# enable programmable completion features (you don't need to enable\n# this, if it's already enabled in /etc/bash.bashrc and /etc/profile\n# sources /etc/bash.bashrc).\nif ! shopt -oq posix; then\n  if [ -f /usr/share/bash-completion/bash_completion ]; then\n    . /usr/share/bash-completion/bash_completion\n  elif [ -f /etc/bash_completion ]; then\n    . /etc/bash_completion\n  fi\nfi\n\n\nA: Run the below command on terminal to give execute permission to the eclipse file,\nsudo chmod +x ~/Documents/android/adt-bundle-linux-x86_64-20131030/eclipse/eclipse\n\nIf you wan to run eclipse directly from terminal, then add the below line to ~/.bashrc file.To open ~/.bashrc, run this command gedit ~/.bashrc.\nexport PATH=$PATH:~/Documents/android/adt-bundle-linux-x86_64-20131030/eclipse\n\nSource ~/.bashrc file to make it work,\nsource ~/.bashrc\n\nRun the eclipse file directly by,\nsudo eclipse\n\n", "Q: URIs for linux-image-3.11.0-15-generic I'm using Ubuntu desktop (Linux version 3.11.0-15-generic (buildd@allspice)). I tried to get linux source code by command:\nsudo apt-get source linux-image-3.11.0-15-generic\n\nThen I saw this error:\nhome@ubuntu:~$ sudo apt-get source linux-image-3.11.0-15-generic\n\nReading package lists... Done\n\nBuilding dependency tree       \n\nReading state information... Done\n\nE: You must put some 'source' URIs in your sources.list\n\nI can't find the suitable URI link to add in /etc/apt/sources.list.\n\nA: Use\nsudo software-properties-gtk\n\n\nEnable \"Source code\" checkbox on tab \"Ubuntu Software\". Then run\nsudo apt-get update\n\nto get sources lists.\n", "Q: Some noob questions I'm pretty new to Ubuntu and I've had some issues which I want to make sure are OK.\n\n\n*\n\n*Whenever I boot I get two lines of text. It's hard to read because it flashes very fast, however it's something about edac and not being able to locate the sbridge.  \n\n*I also have an Nvidia GTX 650 graphics card and I'm not sure which proprietary driver to install since they all have the same name and no dates. Which one should I install?  \n\n\nThanks in advance :)\n\nA: It's up to you which driver you install. Usually it is safer to install the latest tested driver such as \"Nvidia-319\".\nYou can find a list of available drivers in your 'Software and Updates' app.\n", "Q: Ubuntu one on a single computer with Windows and Ubuntu I have a single laptop with Ubuntu and Windows 8 in different partitions. All my important files are in the Windows partition so they can be accessed from both environments, and uploaded to Skydrive when I'm on Windows.\nThe thing is, I use Ubuntu much more often than Windows so I need to migrate my cloud service and it seems that Ubuntu One would be the obvious choice.\nNow, I'd like my files to be synchronized in Ubuntu One regardless of the OS I'm running (the same set of files). Can I achieve this without having to duplicate my files in my HD?\nThanks!\n\nA: I am not familiar with SkyDrive. It appears to be a Windows specific service. If it is, presumably you cannot run it in Ubuntu.\nWith for instance DropBox you can specify the folder that you want to be synchronized with the cloud. If your Windows folder is accessible in Ubuntu, you can specify it for synchronization. Then you would not duplicate your files locally.\n\nA: The answer is no.\nIf you use ubuntu one on your linux and windows distro the files will be duplicated on your HD, as a ubuntu one folder will be created on both distros and then synchronized.\n", "Q: sm-msp-queue says: unable to qualify my own domain name (xxx) -- using short name Every 20 minutes, for days, sm-msp-queue (something related to sendmail, I guess) writes a message in my ubun that goes like that:\n\nunable to qualify my own domain name (ubun) -- using short name\n\nwhere ubun is the network node hostname (output of uname -n and contents of /etc/hostname).\nThe contents of /etc/mail/local-host-names include two lines: localhost and ubun.\nThe file /etc/hosts begins with two lines:\n127.0.0.1 localhost\n127.0.0.1 ubun\n\nThe file /etc/cron.d/sendmail contains one cronjob that is set to run every 20 minutes:\n*/20 *    *    *    *   smmsp test -x /etc/init.d/sendmail && /usr/share/sendmail/sendmail cron-msp\n\nHowever, I don't know what the command smmsp should do; I can't run it alone, also with sudo (I get sudo: smmsp: command not found). Running sudo /usr/share/sendmail/sendmail cron-msp seems to be doing nothing.\nAny ideas?\n\nA: If you have a fully qualified domain name for your server, this message should go away.\nIn /etc/hosts, you can define a FQDN like ubun.somedomain.tld :\n127.0.0.1 localhost\n127.0.0.1 ubun.example.com ubun\n\nTo apply the new host name without rebooting the system type (after having changed the /etc/hosts file) :\n$ sudo hostname ubun.example.com\n\nThen check you have the FQDN :\n$ hostname -f\n\nsmmsp at the place you show it (in /etc/cron.d/sendmail is not the command name but the username to use to run the command that follows. The rest of the line is the command (testing if sendmail is present and executable and then run it with a specific option for executing actions to do in crontab).\nIf run at the terminal the command seems to do nothing (print nothing on the screen) this doesn't mean that she doesn't do something. \nBy the way, this command is run at regular interval to do the submission of mails waiting in the queues of Sendmail. So if you disable it, mails will never be delivered.\n", "Q: How to revert to legacy switching layout method? I'm using XNeur to quickly switch between input languages (Russian and English). Since Ubuntu 13.10 implemented new method of switching keyboard layout it is not possible for this software to operate correctly now.\nHow can I revert back to legacy keyboard switching method?\nSome screenshots:\n\n\n\nA: The problem is solved by editing properties of XNeur:\n\nAlso, do not forget to update XNeur from PPA:\nsudo add-apt-repository ppa:andrew-crew-kuznetsov/xneur-stable\nsudo apt-get update\nsudo apt-get install gxneur\n\nThis command might be needed if you want to set gXNeur's icon visible:\ngconftool-2 -s -t string /apps/gxneur/rendering_engine AppIndicator\n\nOr, install unity-systrayfix.\n", "Q: Is there an alarm-clock / timer for Ubuntu 13.10? I'd like to use a timer / alarm-lock for Ubuntu 13.10, that appears next to or within the dropdom-menu of the clock in the top-Panel.\nI tried e.g. \"gnome-shell-timer\", \"alarm-clock\", but both seem not to work within the unity desktop environment (and result in system crashes).\nIs there not timer for unity available?\n\nA: Timer applet is what I reccomend. It does have a limit of 48 hours the exact program name is Timer-applet Another one is Alarm-clock alarm clock is less limited and it is the best choice. Also there is a widget here (http://www.toggl.com/public/widgets) This is a similar post to another. \n", "Q: NVIDIA GT610 card with KSP I have new graphics card for my PC, it's ASUS branded NVIDIA Geforce GT 610 with 1 GB RAM. PC is three years old ASUS motherboard without any extras, just dual core CPU with 6 GB RAM plus hd and DVD drive. I want to get KSP working on this. It has been running, but was very slow and after some while did crash the machine. I run Ubuntu 12.04 LTS in 32-bit mode for compatibility and stability reasons, at least I hoped them to be better than newer versions and 64-bit version.\nI bought graphics card to improve the performance, but found new problems. I got it installed, BIOS does recognice new card and I got drivers installed thanks to help from \nTrying to install Proprietory Nvidia Graphics Drivers\nIt seems to be there as command 'glxinfo | grep renderer' returns:\nOpenGL renderer string: GeForce GT 610/PCIe/SSE2\nI assume that GPU is not used as System Settings > Additional Drivers shows few NVIDIA drivers activated but not currently used. Playing video loads CPU between 30 to 50%, as earlier. \nAfter installation KSP stopped to launch, instead it crashes when loading \"Squad Parts\"\nAny ideas what to do next? Changing NVIDIA card to other manufacturer might not do miracle, based on what I read...\nIs there any sw to test graphics card functionality? Have seen Cuda graphic demos mentioned, but did not found them (easily) :(\n\nA: Your graphics card is not fully compatible with the driver that you installed. Instead install the tested graphics driver from Additional Drivers:\n\n\n*\n\n*Open Additional Drivers from your menu.\n\n*Select the topmost driver. It should have tested in parenthesis.\n\n*Hit install and wait for the driver to install\n\n*Reboot your computer.\n\n", "Q: unable to find except package when I try the command  \nsudo apt-get -y install gcc make linux-headers-$(uname -r)  except \n\nI get the following error message \nE: unable to locate package except.\n\nHow to resolve it?\n\nA: It is \"expect\" not except\ntry apt-get install expect \nit is there in ubuntu/debian. I did same but it was misspelled by me, :)\n", "Q: Install Ubuntu 13.10 in VirtualBox I want to install ubuntu-13.10-desktop-i386 in Oracle VirtualBox on my HP laptop,\nwhich has Windows 7 32-bit installed. I tried to install it, but it has problems like:  \n\n\n*\n\n*Internal error when I login in to my system.\n\n*After the installation is completed, it asks me to restart. When I restart, VirtualBox suddenly stops working and the whole process crashes.\n\n\nA: The question is too general since you did not provide the Internal error detail's\nHowever you could try to download ubuntu images from the virtualboxes website. \nhttp://virtualboxes.org/images/ubuntu/\n", "Q: How do I list commands a package provides? I'm curious what commands a certain package provides my system with. By command, I mean an in-path executable that I can run from the command line (ls, grep, sed, etc).\nI'm not trying to work out the package from the command, which can be done with:\ndpkg -S `which command`\n\nI want the opposite, a list of commands from a package.\n\nA: The following little loop will handle this with installed packages.\n$ for f in $(dpkg -L login); do [[ $(type -P \"${f##*/}\") == \"$f\" ]] && echo ${f##*/}; done\nnologin\nlastlog\nnewgrp\nfaillog\nsu\nlogin\nsg\n\nHow it works:\n\n\n*\n\n*dpkg -L package generates a list of all the files in a package which we iterate through.\n\n*We strip off the directory name with a little bashism: ${f##*/} and\n\n*Using the bash-builtin type -P command we see if that command is both in the path and that its path equals the file we started with.\n\n*We finish by pumping out the shortened command.\n\n*[[ condition ]] && command is just a bash shorthand for an if..then statement.\n\n\nIt's important to note that not all packages contain the commands you would expect them to. Apache is split out over multiple packages (with -common and -bin subpackages) and the vlc command isn't in the vlc package, it's in vlc-nox. There are many examples like that.\n\nThis can be adapted per Gilles's idea, doing a string match instead of actually checking, but keeping it all in one bash process (and still using the whole path).\nfor f in $(dpkg -L login); do [[ $f =~ ^${PATH//:/|} ]] && echo ${f##*/}; done\n\nThe major difference here is the [[$f =~ ^${PATH//:/|} ]]. That's an in-Bash regex search. The ${PATH//:/|} part is taking the contents of $PATH and is hacking them into a dirty little regex. The condition should check the string begins with part of the path.\n\nA: List the files in the package which are in a directory in the PATH. You only have to consider the default PATH, not any user customizations, since packages only use standard directories.\ndpkg -L PACKAGE-NAME… | sed -n 's!^\\(/s\\?bin\\|/usr/s\\?bin\\|/usr/games\\)/!!p' | sort\n\nRemove the s\\? parts if you only want the programs intended for ordinary users without sudo.\nIf the package isn't installed, replace dpkg -L by apt-file -F list.\nThis misses a few programs because they are provided via alternatives. For example, for the ftp package, only netkit-ftp and pftp are provided, but this package actually provides the ftp command, because /usr/bin/ftp is a symbolic link to /etc/alternatives/ftp which is a symbolic link to one of the ftp implementations on the system, potentially /usr/bin/netkit-ftp. The following command (which isn't an example of good programming, just a big one-liner) lists the commands provided by a package via the alternatives mechanism, as currently configured.\nperl -lwe 'foreach (`dpkg -L @ARGV`) {chomp; ++$p{$_}} foreach (</bin/* /sbin/* /usr/bin/* /usr/sbin/*>) {$e = readlink; next unless defined $e and $e =~ m!^/etc/alternatives/!; $t = readlink $e; print if $p{$t}}' PACKAGE_NAME…\n\nIf you want to list the commands that could be provided via an alternative which is currently configured to point to a different package, you need to parse the files in /var/lib/dpkg/alternatives.\nSymbolic links and configuration files that implement the alternatives mechanisms are not registered in packages but registered automatically in postinst, which makes it difficult (and in fact technically impossible if a package's installation script doesn't follow conventions) to query the alternatives provided by an uninstalled package.\n\nA: My other answer is fairly certain but only works for installed packages. Here's a crack at a version that works for packages not yet installed (but ones that are only available in the main repositories)\nexport PACKAGE=\"login\"; source /etc/lsb-release; source <(dpkg-architecture); for f in $(wget -qO- \"http://packages.ubuntu.com/$DISTRIB_CODENAME/$DEB_BUILD_ARCH/$PACKAGE/filelist\" | sed -n '1,/<pre>/d;/<\\/pre>/,$d;p'); do [[ $f =~ ^${PATH//:/|} ]] && echo ${f##*/}; done\n\nIt's horrifically more complicated so I'll write a broken down version:\nexport PACKAGE=\"login\";\nsource /etc/lsb-release;\nsource <(dpkg-architecture);\n\nURL=\"http://packages.ubuntu.com/$DISTRIB_CODENAME/$DEB_BUILD_ARCH/$PACKAGE/filelist\"\n\n# We grab the packages.ubuntu.com version of the file list (and strip it with sed)\nfor f in $(wget -qO- \"$URL\" | sed -n '1,/<pre>/d;/<\\/pre>/,$d;p'); do\n\n    # We then compare every file provided in the package with every path stub\n    [[ $f =~ ^${PATH//:/|} ]] && echo ${f##*/};\ndone\n\n\nA: An easier method is just querying the web:\nrelease=$(lsb_release -sc)\narch=$(uname -m)\npackage=$@\n\nfor i in $package; do\n   printf \"List of files in $i package\"\n   curl http://packages.ubuntu.com/$release/$arch/$i/filelist 2>/dev/null | grep -oP '/[\\w\\d/.]+$\ndone\n\nThis has the advantage that you would only need curl and sed (what Ubuntu system doesn't have them) and you can change it with wget easily if necessary. It queries several packages with a single command which is a plus.\n\nAny equivalent with other programing language + html parser should work better and less likely to break if something change in the package list.\nChanging the host you can also query Debian database.\n", "Q: 'apt-get upgrade' getting stuck When trying to install updates after checking with sudo apt-get update, sudo-apt get upgrade is not installing them.\nusername@username:~$ sudo apt-get upgrade\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following packages have been kept back:\n  linux-headers-generic-lts-raring linux-image-generic-lts-raring\nThe following packages will be upgraded:\n  gir1.2-gtk-3.0 libgail-3-0 libgtk-3-0 libgtk-3-bin libgtk-3-common sudo\n  tzdata update-manager-core\n8 to upgrade, 0 to newly install, 0 to remove and 2 not to upgrade.\nNeed to get 0 B/3,634 kB of archives.\nAfter this operation, 47.1 kB disk space will be freed.\nDo you want to continue [Y/n]? Y\nReading changelogs... Done\nGet:1 Changelog for libgtk-3-common (http://changelogs.ubuntu.com/changelogs/pool/main/g/gtk+3.0/gtk+3.0_3.4.2-0ubuntu0.7/changelog) [189 kB]\ngtk+3.0 (3.4.2-0ubuntu0.7) precise-security; urgency=medium\n\n  * SECURITY UPDATE: fix regression from librsvg CVE-2013-1881 security fix\n    - debian/patches/CVE-2013-1881-compat.patch: embed payload in a data:\n      uri to work around rsvg loader security fix in gtk/gtkicontheme.c.\n    - CVE-2013-1881\n\n -- Marc Deslauriers <marc.deslauriers@ubuntu.com>  Fri, 14 Mar 2014 10:11:57 -0400\n\nGet:1 Changelog for sudo (http://changelogs.ubuntu.com/changelogs/pool/main/s/sudo/sudo_1.8.3p1-1ubuntu3.6/changelog) [47.4 kB]\nsudo (1.8.3p1-1ubuntu3.6) precise-security; urgency=medium\n\n  * SECURITY UPDATE: security policy bypass when env_reset is disabled\n    - debian/patches/CVE-2014-0106.patch: fix logic inversion in\n      plugins/sudoers/env.c.\n    - CVE-2014-0106\n  * debian/sudo.sudo.init, debian/sudo-ldap.sudo.init: Set timestamps to\n    epoch in init scripts so they are properly invalidated. (LP: #1223297)\n\n -- Marc Deslauriers <marc.deslauriers@ubuntu.com>  Tue, 11 Mar 2014 07:56:53 -0400\n\nGet:1 Changelog for tzdata (http://changelogs.ubuntu.com/changelogs/pool/main/t/tzdata/tzdata_2014a-0ubuntu0.12.04/changelog) [37.3 kB]\ntzdata (2014a-0ubuntu0.12.04) precise; urgency=medium\n\n  * New upstream release, with updated Turkish DST (LP: #1290193)\n  * Remove solar87, solar88, solar89, following upstream removal.\n\n -- Adam Conrad <adconrad@ubuntu.com>  Thu, 13 Mar 2014 17:44:33 -0600\n\nGet:1 Changelog for update-manager-core (http://changelogs.ubuntu.com/changelogs/pool/main/u/update-manager/update-manager_0.156.14.12/changelog) [230 kB]\nupdate-manager (1:0.156.14.12) precise-proposed; urgency=medium\n\n  * debian/source_update-manager.py: create a DuplicateSignature by\n    replacing the tmpdir name in the Traceback (LP: #1289580)\n\n -- Brian Murray <brian@ubuntu.com>  Mon, 10 Mar 2014 10:40:57 -0700\n\n~\n~\n~\n~\n~\n~\n\nAny idea why it is stopping here?\n\nA: You have apt-listchanges installed so APT shows you the changes when upgrading packages using default pager (less).\nPress q to quit less to continue.\n", "Q: exim4, dovecot, gmail We are trying to set up a mail server for outgoing mails using gmail. The application is based on java. in config file smtp.gmail.com and port 587 is added same port is added in exim4-config file. But when mail is checked it throws an error as \"com.sun.mail.smtp.SMTPSendFailedException:530 5.7.0 must issue a STARTTLS command first.\nCan someone pl. help to sort out this error. Do we need to add any configuration in our tomcat/conf/server.xml file. If mail is sent directly through squirrelmail client it delivers in gmail account but the above error comes through tomcat. Anyhelp is greatly appreciated.\n\nA: Usual smtp mail server communicate on port 25. In your configuration you use secure port 587 for smtp witch is for tls secure connection, but do not config TLS. \nI find manual for exim configuration here \nTry maybe help\n", "Q: USB ports fried? How to diagnose/fix? i've just run into a probably serious problem.\nWas working on a hardware project where a short circuited component was involved and it's possible i've fried two usb ports with a 12V on my laptop since when i connect the mouse or my phone they don't work as they should, however my phone thinks like it's connected to a charger.\nWhat happened: Connected that component to one of the two usb 3.0 ports on the laptop and as soon as i connected the power, laptop immediately shut down obviously protecting itself.\nAfterwards, booted up normally but those two ports won't work as before.\nRestarted many times etc, but still nothing. Mouse won't work and the phone thinks it's connected to a charger instead of a computer, so there's still some current running there.\nran this:\n\ndmesg | grep -i USB\n\nbut couldn't detect any \"movement\" in those two usb ports.\nSo, how do i know if USB ports can be revived? I could only found various instructions in Windows but nothing in Ubuntu. Is there something i can do in general?\n\nA: Sounds like hardware damage. I don't think anything via software will fix this if you tried to connect something that is 12V to a 5V USB port. \n", "Q: How to find all the available commands in a package before installing it? This question clearly explains about how to find all the commands which are provided by a particular installed package.\nMy question is, how to find(or lists) all the available commands which are provided by a particular package before installing that package via terminal ?\n\nA: You can use apt-file (is not installed by default in Ubuntu). Before of the first use, run apt-file update to fetch contents files from apt-sources.\nHere is an example:\napt-file -F list geany | egrep -w \"(s|)bin\"\ngeany: /usr/bin/geany\n\nAnd an example with a package with more commands:\napt-file -F list mesa-utils | egrep -w \"(s|)bin\"\nmesa-utils: /usr/bin/glxdemo\nmesa-utils: /usr/bin/glxgears\nmesa-utils: /usr/bin/glxheads\nmesa-utils: /usr/bin/glxinfo\n\nIn this case the commands are, evidently: glxdemo, glxgears, glxheads and glxinfo.\n", "Q: Is there any PowerPoint alternative? Is there any PowerPoint alternative? I'm not looking for just a viewer but also a presentation maker.\n\nA: Well, There are many programs to make Presentation:\n\n*\n\n*OpenOffice/LibreOffice,\n\n*KOficce,\n\n*GnomeOffice\n\n*Microsoft Office(using Wine) !\n\nyou can also use\nGoogle Docs (Web: Free)\n\nGoogle Docs Updates Presentations With Real-Time Collaboration, New\nThemes, Transitions and More Google Docs has rolled out a new version\nof its presentations tool with over 50 new features, including,\nsimultaneous editing, a series of new slide… Read… Google Docs'\npresentations module used to be fairly lackluster, but they've updated\nit recently to make it more compatible with people coming over from\nMicrosoft Office, or people who want a more robust presentations tool.\n\nBeamer (LaTeX) (Windows/Mac/Linux: Free)\n\nIf you're a fan of LaTeX, or just remember having to apply it for your\ngraduate thesis, you'll love Beamer. Where other presentation tools\ngive you a GUI where you drag in elements you want to use like images\nand video and then tweak text boxes to include the information you\nwant on screen, Beamer requires you to build your presentation in a\ncustom markup language that works for just about any LaTeX document.\n\nhttp://lifehacker.com/5888189/five-best-powerpoint-alternatives\n\nA: Impress is a truly outstanding tool for creating effective multimedia presentations. Presentation edition and creation is flexible, thanks to different editing and view modes\nhttp://www.libreoffice.org/discover/impress/\nOpenLaszlo is an open source development platform for web applications. It's main target today is generating macromedia flash files (swf)and AJAX/DHTML for use on web pages and sites.\nhttp://www.openlaszlo.org\nKPresenter is the open source presentations part of the KOffice suite. Excellent for combining text and graphics into slides either for on-screen presentation and handouts.\nhttp://www.kde.org/applications/office/kpresenter/\n\nA: First hit would be LibreOffice Impress.\nWeb based (but quite good for some purposes) - Prezi\n\nA: LibreOffice Impress\nUse LibreOffice Impress for create a presentation, it's an default presentation program for Ubuntu.\nGoogle Presentation\nGoogle's web application is used to create presentations.\nNEW !! Microsoft PowerPoint online\nNow microsoft office opened on the web !!! Visit this site for PowerPoint online\nThanks\n\nA: OpenOffice.org is also a good alternative.\n", "Q: search google from terminal How to add search google in my terminal?\nSame like this picture. I'm using ubuntu 12.04.\n\n\nA: Open Ubuntu Tweak, go to “Source Center”, enable “Google Terminal with Google search support”,  Click “Refresh”. You can get it so easily!\n\nIf you are interested in the code, you can visit here: https://code.launchpad.net/~tualatrix/ibentu/gnome-terminal\n", "Q: Use one PPA in another PPA I would like to create a PPA for package that is not in Ubuntu yet. It has a dependency on another piece of software which isn't in the official repository either, but available from another PPA.\nIs it possible to source that PPA into mine without manually copying over the packages for every new upload?\n\nA: If you don't need the PPA users to install that package and you only need it as a build dependency, you can add that other PPA as a dependency for your PPA. \nTo do this, go to the PPA page on Launchpad, click \"Edit PPA dependencies\" and there, add the PPA from which you need the dependency:\n\n", "Q: \"ztemtvcdromd: no process found\" when removing crossplatformui When I am doing sudo apt-get update or sudo apt-get install (any software) then this is showing in terminal\nExtracting templates from packages: 100%\n(Reading database ... 146237 files and directories currently installed.)\nRemoving crossplatformui ...\nztemtvcdromd: no process found\ndpkg: error processing crossplatformui (--remove):\n subprocess installed post-removal script returned error exit status 1\nErrors were encountered while processing:\n crossplatformui\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\n\nA: When you remove that package it's looking for a process called ztemtvcdromd as part of the postrm scripts, and since it doesn't find it it fails. This is a bug of the maintainer of the package which should have used || exit 0 so the process never returns different code of 0.\nTo fix this you need to edit the /var/lib/dpkg/info/crossplatformui.postrm and modify the line sudo killall -p ztemtvcdromd to sudo killall -p ztemtvcdromd || exit 0, then you can remove it.\n\nA: the best to fix this is removing the files of crossplatformui from /var/dpkg/info directory  \ncd /var/dpkg/info\nls | grep crossplatformui\n\noutput is similar :\ncrossplatformui.conffiles\ncrossplatformui.list\ncrossplatformui.md5sums\ncrossplatformui.postinst\ncrossplatformui.postrm\n\nremove all the files \nsudo rm crossplatformui.* \n\ncheck if there is package by name of crossplatformui \nsudo dpkg --remove --force-remove-reinstreq crossplatformui\n\nissue the command to unstuck the package to be installed\n   -f is for fixing  \nsudo apt-get install -f \n\nCheers \nAcutal source : http://shekher-techprobs.blogspot.in/2012/03/removing-crossplatformui-ztemtvcdromd.html \n\nA: Its very simple as suggested by @Braiam.\nJust open the file crossplatformui.postrm with administrative privilege . Type in terminal\ngksudo gedit /var/lib/dpkg/info/crossplatformui.postrm\n\nType your root password and enter. \nFind the line sudo killall -9 ztemtvcdromd .Now replace it with sudo killall -9 ztemtvcdromd || exit 0. ( In my case it is 9 ztemtvcdromd,in your case it may vary like \" p ztemtvcdromd \". Then modify accordingly. Now save the file and close it. Done! \nGo to synaptic manager, search for crossplatformui, check for complete removal, then apply! That is all crossplatformui will be removed completely!\n", "Q: Ubuntu GUI is not launching after updating from 12.04 to 12.10 I've got a little problem after updating from 12.04 to 12.10.\nI've updated ubuntu from update manager, and then reboot it.\nAfter the reboot I discovered that GRUB has crashed. After I repaired it, the another problem appeared, the GUI doesnt start.\nIn a moment it promts that kvm:disabled by bios four times and then text login screen appears and says:\nUbuntu 12.10 Marky-UB tty1\n\nMarky-UB login: _\n\nHow to fix it? Help me please.\n\nA: You have been dropped to a tty console instead of GUI environment. You would first need to login using tty console and then enter the GUI.\nEnter your username where it says Marky-UB login:. Thereafter it would ask for your password. Enter your password as such. Now you have logged into Ubuntu using the console. To start the GUI environment, run the following command:\nsudo service lightdm start\n\nThis would start your Unity session. From next reboot onwards, you should be automatically logged into Unity instead of tty console.\n", "Q: Lenovo S540, \"The system is running in low graphics mode\" I've just installed Ubuntu 13.10 through the installer on a Lenovo Thinkpad S540. I had no problems with the graphical installer.\nHowever, after rebooting, X doesn't start. I just get a \"The system is running in low graphics mode\" error.\nThe graphics card is a \"Intel Corporation Haswell-ULT Integrated Graphics Controller\".\nI've tried updating from the X-swat PPA as per instructions here: https://askubuntu.com/a/218095/258364. Made no difference.\nIt also fails if I reboot in \"failsafe\" mode.\nAny ideas on what I can try? Thanks.\n\nA: I've had the same issue on my ThinkPad S540 after installed Ubuntu 13.10. The solution for me was to create /etc/X11/xorg.config file which was somehow missing:\nsudo cp /etc/X11/xorg.config.failsafe /etc/X11/xorg.config\n\nand then restart.\nIf you stuck on \"The system is running in low graphics mode\" page and Ctrl+Alt+F1 does not work to enter terminal mode then try to play with Enter / Tab / Windows+Left / Windows+Right shortcuts until the terminal mode appears ;)\n", "Q: Apt keeps trying to connect to a non-existent proxy I have an apt proxy on my home network which is running squid-deb-proxy, all my Ubuntu machines are linked to it with a 02proxy file in their apt directorys.\nThe problem is one of my Ubuntu machines sometimes tries to connect to an IP which doesn't even exist on my network when installing or updating software.\nThe IP address of my proxy machine is 10.1.1.31 yet the client Ubuntu machine sometimes (not always) tries to connect to 10.1.1.8, I have no idea what's causing it to do this.\nAny help is much appreciated.\n\nA: I found the problem, squid-deb-proxy-client was acting extremely weird so I removed it and now it works fine.\n", "Q: 12.04 server, All external services not connecting after reboot I have just updated my server and rebooted and now my SSH, apache and some other services will not allow connection from external clients. I have disabled UFW and turned off modsecurity but neither of these make any difference. I have tried a tcpdump on port 80 and my custom ssh port and both show that the nic is receiving the packets. My apache logs show no indication that any external requests are hitting apache, but then as I can't connect over SSH I don't think this is an apache issue. \nI recently applied security measures as described here : Securing Ubuntu\nI also performed these measures on 2 other 12.04 servers and they are still responding to external requests. Luckily this is a VM so I can access the terminal via vSphere.\nI am relatively new to linux so I have come to the end of my knowledge and do not know what to try next.\nPlease help :)\nMany thanks.\nBev.\n\nA: I sorted this issue in the end by purging UFW from the system and then re-installing it. My rationale was that considering ALL ports and services were affected it had to be a firewall/network layer issue.\nHope this helps someone else.\n", "Q: How to check the disk activity of my hard-drive? I had a problem in Windows 8 where my hard-drive activity was reaching 100% all the time and the system was very slow. Now I've switched to Ubuntu Gnome and want to check if this is still a problem on Ubuntu. Is there a way to check this? \nI am not looking for how much space I have on my HDD! I know how to find CPU and RAM usage as well. I am looking to find out the disk activity of my drive. For example, using  Windows Task Manager it reports the disk activity as 0.04%. This is what I am looking for:\n\n\nA: I use System Load Indicator for a GUI solution. which is in the indicator-multiload package. It's available in the Universe repository for all currently supported versions of Ubuntu and can be installed either through the software center or via the CLI with sudo apt-get install indicator-multiload\nIt is a system load monitor capable of displaying graphs for CPU, IOwait, ram, cache, and swap space use, plus disk and network traffic. It puts a display on the top menu bar that looks like this. \nRight clicking on it provides a drop down menu with live info regarding the following: CPU, Mem, Net, Swap, Load, and Disk as seen below:\n\nConfiguration is accomplished via the Preferences option on the same menu The colors are adjustable as well as the monitor width and update interval. Here's an example:\n\nFor CLI solutions see: How to monitor disk activity?\n\nA: You can try to use nmon — a command line program. Install it by running:\nsudo apt-get install nmon\n\nThen run it as nmon. You would get the following screen:\n\nSince you want to view disk activity, you need to press d to toggle the statistics for it. Upon pressing d, you would be presented with the following screen which shows your disk activity:\n\nPress q to exit the program.\n\nMore information about this tool can be found at IBM developerWorks.\n\nA: *\n\n*System Monitor Utility will give the exact results of your cpu and RAM usage.\n\n\n*Search for System Monitor in dash and run it.\n\nOR\nRun this command on terminal to install and run iotop which shows the disk usage,\nsudo apt-get install iotop && sudo iotop\n\n", "Q: Flash player sometimes works, but sometimes doesn't I am on Ubuntu 12.04. I've been using Firefox and when I opened for example a Youtube link, the screen where the video is supposed to be is black and it displays an error. When I click on some recommended link for that video, and return back to the video with the error it starts playing normally.\nI thought it is some problem with flash, so I installed Chromium (I found out it provides Flash), but there is the same problem again.  I have the Flash player plugin installed, also tried restricted extras, and HTML5 is enabled in Youtube...\n\nA: What you need to make flash-player work in Ubuntu 12.04 is not present in the official repositories. You need first to open Synaptic Package manager, go to Synaptic - Settings - Repositories - Other Software, and once you're there you should check 'Canonical Partners' entry and 'Independent' entry. There is no need to also check the Source Code packages for the same sources.\nClose Software Sources window, and reload Synaptic repositories with the Reload button. Next look for and install adobe-flashplugin and adobe-flash-properties-gtk. Or you can close Synaptic and run this code in a terminal:\nsudo apt-get install adobe-flashplugin adobe-flash-properties-gtk\n\nRemove first the other flash player related packages like flashplugin-installer or similar.\nIf you don't really want to use flash-player you can use Mozilla Firefox which has 2 nice addons to play video without flash. One is 'VideoWithoutFLash' addon, and the other one is 'Open With' addon. You need to configure these addons after restarting Firefox otherwise they won't work as expected. 'Open With' addon, for instance, has a list of default applications which it uses when streaming video is to be played. I for one use VLC, and you can add VLC player or other player (mplayer2, xine) in the list, delete all other entries, and this way you'll be able to watch videos with vlc as an embedded player.\n\nA: This is a weird possibility but is your flash grabbing a sound card? Flash will show some things normally but will stop working if it cannot find what sound card you are using. If your aplay -l output from terminal is not listing anything, then there is no soundcard to grab. If your sudo aplay -l gives you an output, then you have user/group permissions to configure. Hope this helps.\n", "Q: Sound card doesn't support format requested using signalgen I want to generate a PWM signal on Ubuntu. My first try was to use siggen package. Upon launching signalgen I have the following error: \n$ signalgen -v sin 120\nsignalgen  Ver. 2.3.10 (May 2008)   Digital Signal Generator\n/dev/dsp : DAC Opened for output\n22050 mono, signed 16 bit, little endian, samples/sec.\n8192 bytes per DAC buffer.\n[signalgen] Invalid argument : Sound card doesn't support format requested.\n$ sudo signalgen -v sin 120\nsignalgen  Ver. 2.3.10 (May 2008)   Digital Signal Generator\n[signalgen] Input/output error : /dev/dsp\n\nWhat is wrong ?\n\nA: The last Ubuntu release with /dev/dsp support was 10.04. After that support for /dev/dsp was removed.\nTo still be able to use older software that rely on /dev/dsp there is a compatibility wrapper padsp which redirects sound output meant for dsp to a running pulseaudio server. We may use this wrapper with the following terminology:\npadsp [options] APPLICATION [arguments ...]\npadsp signalgen -v sin 120\n\nBy this we may be able to also play the output of signalgen to our soundcard. The OSS complatibility layer will be installed as a dependency with siggen .\nIf we do not want to output the sound directly we can use signalgen to directly write a raw audio file to then play this file through ALSA using aplay\nsignalgen -w filename -t 5 sin 120 & aplay filename\n\nNote that signalgen will exit if filename already existed.\n\nA better approach to generate waves without the need of a compatibility layer would be applications that are able to directly address ALSA or PuleAudio.\nSox .\nSox will install the command line utility play which will not only play sound files but can also generate audio waveforms and can add effects to them:\nplay -n synth sine 120.0 gain 0.0\n\n", "Q: Laptop turns off on its own in 13.10? I recently upgraded to 13.10 from 12.10. It's now showing the battery info wrong and it keeps turning off even with 60% of power remaining, and without warning. When I resboot the PC, it works fine for 30 minutes or so and then the same thing over again.\nI didn't had this problem with 12.10. Also, I have installed TLP, but that's not helping either.\nThe hardware:\n\n\n*\n\n*PC: HP 2000-2116tu\n\n*CPU: Intel i5 (3rd generation)\n\n*Graphics: Intel HD4000\n\n\nA: \nmake sure you haven't changed anything in power settings.\n", "Q: how to solve \"wodim no such file or directory.cannot open scsi driver\" in 12.04LTS I'm created a shell script to burn a cd, which was running successful in ubuntu terminal, but it not running if I call this script from php and also I found an error in log file like,\nwodim: No such file or directory. \nCannot open SCSI driver!\nFor possible targets try 'wodim --devices' or 'wodim -scanbus'.\nFor possible transport specifiers try 'wodim dev=help'.\nFor IDE/ATAPI devices configuration, see the file README.ATAPI.setup from\nthe wodim documentation.\nTOC Type: 3 = CD-ROM XA mode 2\n\nIf I look wodim --devices in terminal\n-------------------------------------------------------------------------\n 0  dev='/dev/sg1'  rwrw-- : 'TSSTcorp' 'CDDVDW SH-S202J'\n------------------------------------------------------------------------\n\n-\nif I look wodim -scanbus in terminal\nscsibus4:\n    4,0,0   400) 'TSSTcorp' 'CDDVDW SH-S202J ' 'SB01' Removable CD-ROM\n    4,1,0   401) *\n    4,2,0   402) *\n    4,3,0   403) *\n    4,4,0   404) *\n    4,5,0   405) *\n    4,6,0   406) *\n    4,7,0   407) *\n\nPlease help me to find a solution.\n\nA: What wodim command exactly did you run when the error appeared ?\nThe fact that wodim --devices lists /dev/sg1 is somewhat strange. I would expect\na sg address with kernels older than 2.6. On newer kernels the address should\nbe like /dev/sr0.\nThe most plausible difference between shell and PHP would be a lack of permissions\nwith PHP (other user id?). A burn program on Linux needs rw-permission to the\ndevice file.\n", "Q: How to get rid of the Gallium 0.4 on llvmpipe (LLVM 0x300) driver? INTEL needed Ubuntu 12.04 LTS only runs 2D mode after changing MB and CPU. It appears using the wrong video driver: \"Gallium 0.4 on llvmpipe (LLVM 0x300)\" rather than the required \"Intel\" G43 version from the \"xserver-xorg-video-intel\" driver package. \nThe new motherboard is a MSI Z87-G43 with a i7 CPU.\nI tried lots of things and checked out about all I could find on the web. \nI removed the VMware drivers, nvidia en ATI divers and their configuration files without result. Creating an etc/X11/xorg.conf file with \"intel\" assigned to be used, the system became instable. I even did a fresh Ubuntu 12.04 install on an old HD, finding out that the meant \"Intel\" driver appeared to be used! \nNow I'm stuck!\nWhat should I do to get it right for my existing Ubuntu 12.04 LTS system?\n\nA: The xserver-xorg-video-intel package provides the basic Xorg driver which is used for 2D drawing, etc. llvmpipe is the software renderer for 3D operations, if you install the libgl1-mesa-dri package, then you should have the Mesa DRI Intel(r) ... renderer.\nNote that the original drivers shipped with 12.04 are quite old, you are suggested to install the LTS Enablement Stack to get more recent versions for the graphics subsystem and kernel.\n", "Q: Battery led blinking red on Asus N550JV with Ubuntu 12.04 Model: Asus N550JV\nOS: I have a dual boot Win8 and Ubuntu 12.04 64bit. UEFI boot\nProblem: The battery is not recharging anymore. It means the computer works as usual but once I plugged off the charger the battery level only goes down. Even if I plug in the charger, the battery level stays the same. As a result there is a red light blinking in the battery led.\nHereunder there are some details\nThe (battery) red light is blinking when:\n\n\n*\n\n*computer off, charger plugged in\n\n*computer on, charger plugged in\n\n*computer on, charger plugged of\n\n\nWhen the red light started blinking the first time happened the following:\n\n\n*\n\n*(previously there is no problem)\n\n*I turned on the computer and, for some unknown reasons, since the beginning the two fans were running at 100%.\n\n*once I logged in, the operating system (OS) didn't recognize the battery, like my pc was a desktop and not a notebook (the two fans were still running at 100%)\n\n*I turned off and turned on the PC: fans are ok, but the battery red light is blinking as above.\n\n\nMy best guess is that it's an hardware problem, however I gave back my computer to repair (it is under warranty) and they gave me the another computer (same model) as substitution, moving the HD from one PC to the another. Even in the second PC now I have the same problem.\nHere it is my Boot repair info log: http://paste.ubuntu.com/7119508/\nHere it is my dmesg: http://paste.ubuntu.com/7119802/\nI'm open to any suggestion and to provide you any details.\nThanks in advance\n\nA: This is probably a manifestation of the same problem I had:\nMouse and keyboard input stutter 13.10 only on AC power\nIt seems to be triggered by plugging any externally-powered device into the USB port by the MiniDisplay port on the ASUS N550JV. \nTo fix this, reset the battery by powering off the computer with the power button, but hold down the power button for 5-10 seconds after the computer shuts off. The battery light will be dark the whole time, but after booting again, the problem is resolved.\nAlternatively, a much more invasive fix:\n1. Remove the T5 Torx screws from the bottom to access the battery.\n2. Remove the battery.\n3. Plug in the AC power and turn on the laptop.\n4. Shutdown the laptop and put the battery pack back in and you are good to go.\n\n\nA: I have an ASUS X550L and my battery light started suddenly blinking too. It had nothing to do with the power management settings. I switched off the machine and for the first time removed my battery. It has two locks that you drag to each side to remove it. I saw that on one of the locks there is a red stripe underneath the lock when you drag it to the side. So I removed the battery. I waited for 5 min and then I but it back. When I locked it I saw that you are not suppose to see any red stripe when it is properly locked. So I understood that as I had twisted my laptop on the desk the previous day one of the locks got accidentally opened. That's it, make sure you have locked the battery properly in place at both sides. You are not supposed to see any red stripe on either side. Worked for me. Enjoy! \n", "Q: Ubuntu 12.04 LTS Brightness I'm using Ubuntu 12.04 LTS but the brightness won't work. Not from settings, not from the hotkeys. Is there anything I can do to fix this? I have Dell Inspiron 15.\n\nA: Is your video card a GeForce GT 525M or GeForce GT 520M? You can download linux driver for Ubuntu 64 bit from here. Installing the driver can be a pain in the back but if you are familiar with installing video driver it should not be such a big problem:\nhttp://www.nvidia.com/download/driverResults.aspx/73666/en-us\nhttp://www.nvidia.com/download/driverResults.aspx/73966/en-us\nIf you are using Ubuntu 32 bit you need the Linux 32bit video drivers from Nvidia.\n", "Q: Problem building an rtl8723 driver We all know the problems with RTL8723 wireless card and some people achieved to install but i can't. I have Ubuntu 12.10. When I do the make in terminal, it gives me this error\nmake -C /lib/modules/3.8.0-37-generic/build M=/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012 modules\nmake[1]: Entering directory `/usr/src/linux-headers-3.8.0-37-generic'\nCC [M]  /home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.o\nIn file included from /home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c:39:0:\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/pci.h:245:15: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘__attribute__’ before ‘rtl_pci_probe’\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c: In function ‘_rtl_init_mac80211’:\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c:320:6: error: ‘IEEE80211_HW_BEACON_FILTER’ undeclared (first use in this function)\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c:320:6: note: each undeclared identifier is reported only once for each function it appears in\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c: In function ‘rtl_action_proc’:\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c:870:25: error: ‘RX_FLAG_MACTIME_MPDU’ undeclared (first use in this function)\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c: In function ‘rtl_send_smps_action’:\n/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.c:1432:16: error: ‘struct <anonymous>’ has no member named ‘sta’\nmake[2]: *** [/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012/base.o] Error 1\nmake[1]: *** [_module_/home/adrian/Desktop/rtl_92ce_92se_92de_8723ae_linux_mac80211_0006.0514.2012] Error 2\nmake[1]: Leaving directory `/usr/src/linux-headers-3.8.0-37-generic'\nmake: *** [all] Error 2\n\n\nA: i had the same problem the fix was simple just upgrade the kernel\nyou need the latest kernel version i suggest 3.12\n\n\n*\n\n*Go here: http://kernel.ubuntu.com/~kernel-ppa/mainline/\n\n*Download 3 (maybe 4) debs to a folder somewhere:\n\n\nlinux-headers-VERSION-NUMBER_all.deb\nlinux-headers-VERSION-NUMBER_amd64.deb\nlinux-image-VERSION-NUMBER_amd64.deb\nlinux-image-extra-VERSION-NUMBER_amd64.deb   # if available\n3.Install the debs with whatever package manager front-end you use (is gdebi still around?), or use these commands:\ncd /path/to/folder/where/you/put/the/debs\nsudo dpkg -i *.deb\n", "Q: How to fix boot issue ? VFS: cannot open root device \"mapper/x\" or unknown-block(0,0) I've got ubuntu 12.04 running as a virtualserver on virtualbox.\nLast night there was a power surge and this morning I can't boot my virtual server.\nI get a long error message. I picked this up:\nVFS: cannot open root device \"mapper/ubuntu--server-root\" or unknown-block(0,0): error -6\nwhen I do:\nls /dev/mapper\nI get>\ncontrol\nubuntu--server-root\nubuntu--server-swap_1\nI can mount manually by doing \n'mkdir /foo;mount /dev/mapper/ubuntu--server-root /foo'\nI don't know what to do but I installed a tool and extracted this log http://paste.ubuntu.com/7119904/\n\nA: Your most recent kernel, 3.5.0-47-generic, is missing its corresponding initrd image.  Pick the previous kernel version from the boot menu and once the system comes up, run sudo update-initramfs -c -k 3.5.0-47-generic to create the initrd, and sudo update-grub.\n", "Q: Where place executables and how show them in the menu? I want to install a software (Modelio 3). I have a folder with an executable and I can launch the app with that exe . \nBut what I want to know is if I there is a folder like \"Application\" on Mac where I should paste the Modelio folder... and so the program will appear in the Application Menu.\n\nA: Using gnome-desktop-item-edit\nFor this you need gnome-tweak-tool or gnome-shell installed\nUse ALT+F2 and type\ngnome-desktop-item-edit --create-new ~/Desktop\n\nThis will open the dialog Create Launcher\n\nYou can put this .desktop file in /home/<username>/.local/share/applications/ to make it appear in the dash\nUsing alacarte\nFor this method, you need alacarte installed.Do it by\nsudo apt-get install alacarte\n\nAnd use ALT+F2 and type in alacarte\nYou will get this dialog:\n\nSelect the category you want and click \"New Item\"\nYou will get this dialog\n\nClick OK . It will appear in the dash\n\nSources:\nBruno Pereira's answer\nBinarylife's answer\nKikixx's answer\n\nA: RAW text-files .desktop are used to start an application under Ubuntu. \nThose .desktop files are stored in /usr/share/applications/ and ~/.local/share/applications.\n\nTypical .desktop file construction : \n[Desktop Entry]\nTerminal=FALSE OR TRUE (MOST OF THE TIME 'FALSE')\nIcon=PATH/TO/THE/ICON\nType=Application\nCategories=CATEGORIES\nExec=COMMANDLINE TO START THE APPLICATION\nMimeType=MIMETYPES WHICH WILL USE THIS PROGRAM WHEN CLICKED\nName=APPLICATION'S NAME\nComment=COMMENT TO DETAIL WHAT THE APPLICATION DOES\nKeywords=SOME KEYWORDS SEPARATED BY ';' TO HELP THE DASH \n\n", "Q: Creating multiuser chatroom in XMPP client I am using the Profanity XMPP client to create a multiuser chatroom in the terminal.\nMy understanding of the XMPP protocol is that when you join a chatroom with a new name like\n/join NewChatRoom \nit automatically creates the new chatroom. It doesn't do this for me, and I don't know why. I'm wondering if it has to do maybe with the default domain name the client assigns to the new chatroom, like NewChatRoom@conference.gmail.com\n\nA: Profanity will append the domain as you showed if one is not supplied.  You can supply one if it is different from the default.\nIt will also only allow you to create a room if no room configuration is required.\nFor more information on the join command see: http://www.profanity.im/rooms.html\nAnd room configuration is planned for a future release: https://github.com/boothj5/profanity/issues/169\n", "Q: Saving an excel file on a windows shared folder using wine I'm not sure if anyone can help with this particular scenario but here goes. I am currently running MS Office 2010 (Home and Business) on Ubuntu 13.10 using PlayOnLinux. I'm able to open excel files locally and save them locally just fine with no issues.\nI can also open and view files on a windows shared folder just fine as well however, if I save the file, I get the following warning popup:\nThe document was saved successfully, but Excel cannot re-open it because of a sharing violation. Please close the document and try to open it again.\nWhen I look at the file permissions on the shared drive now, they are changed from -rwxrwx--- to ---------- and no one is able to reopen the file.\nOne more thing, I mounted the drive in the fstab with the following options:cifs rw,nosetuids,noperm 0 0\nThis is probably a MS Office issue but I thought I'd ask here first to see if anyone else has experienced this or know how to fix it.\nThanks!\n\nA: I know this is an old thread, but I had the same problem and determined that it was because of a change I had made to my SAMBA configuration =.\nI use a Mac to access files on a Linux server via SAMBA, and wanted to block the typical \"dot\" files that Mac creates (._something and .DS_STORE). So, I added a line to my smb.conf that would prevent those files from ever being created as follows:\nveto files = /._*/.DS_Store/\nWhen you open an Office file, it creates a temporary file in the location where you opened the file from, and that file starts with ._$\nSince .$ will be matched by .* the file will be disallowed and you're operating without a temporary file. Remove the \"veto files\" entry (or remove the ._* portion), restart SMB, and you'll be fine.\n", "Q: TFTP trouble: timeout before file found I've installed TFTP to the best of my knowledge and am trying to perform a basic function test of:\nget uImage\n\nWhen run as a normal user, I get permission denied. When using sudo it replies back \nTransfer timed out.\n\nWith the verbose mode on, it gives me:\ngetting from localhost:uImage to uImage [netascii]\nTransfer timed out.\n\nI have no idea what's gone wrong.\n\nA: Try on this way. Work for me.\nInstall following packages.\nsudo apt-get install xinetd tftpd tftp\n\nCreate /etc/xinetd.d/tftp\nand put this entry\nservice tftp\n{\nprotocol        = udp\nport            = 69\nsocket_type     = dgram\nwait            = yes\nuser            = nobody\nserver          = /usr/sbin/in.tftpd\nserver_args     = /tftpboot\ndisable         = no\n}\n\nCreate a folder /tftpboot this should match whatever you gave in server_args. mostly it will be tftpboot\nsudo mkdir /tftpboot\nsudo chmod -R 777 /tftpboot\nsudo chown -R nobody /tftpboot\n\nRestart the xinetd service.\nsudo /etc/init.d/xinetd restart\n\n", "Q: How to recover permanant deleted files from ext4 hey Guys I am kind of new in ubuntu and I need help. i permanently deleted my important files and I need to recover them. Please tell how to recover files in GUI way or command line way . thanks :) \n\nA: Maybe this link can help you. Basically you need to install one or more data recovery programs in a terminal or with Synaptic Package Manager, The programs are testdisk,  scalpel and/or foremost. Code:\n sudo apt-get install testdisk scalpel foremost\n\nUse the detailed instructions from the provided link to learn how to recover your lost/deleted data.\n", "Q: Assign website to ip address I have a server with 2 ip addresses. All the websites are in separate folders in /var/www/. For example /var/www/website1 and /var/www/website2.\nThe nameservers point some of the websites on ip address 12.34.56.78 and some on ip address 90.78.56.34. All the websites on ip address 12.34.56.78 work but the websites on ip address 90.78.56.34 don't. How do I configure the websites to be on ip addres 90.78.56.34? \n\nA: You must change VirtualHost configuration\nListen 90.78.56.34:80\nListen 12.34.56.78:80\n\n<VirtualHost 90.78.56.34:80>\nServerName www.example2.com\nDocumentRoot /www/website2\n</VirtualHost>\n\n<VirtualHost 12.34.56.78:80>\nServerName www.example1.com\nDocumentRoot /www/website1\n</VirtualHost>\n\nEdit 1\nListen 90.78.56.34:80\nListen 12.34.56.78:80\n\n\n<VirtualHost 90.78.56.34:80>\nServerName example2.com\nServerAlias www.example2.com\nDocumentRoot /var/www/website2\n</VirtualHost>\n\n<VirtualHost 12.34.56.78:80>\nServerName example1.com\nServerAlias www.example1.com\nDocumentRoot /var/www/website1\n</VirtualHost>\n\nI correct path for DocumentRoot and add ServerAlias\nAlso you change /etc/hosts\nsudo nano /etc/hosts\n\n12.34.56.78   example1.com\n90.78.56.34   example2.com\n\n", "Q: installing python-appindicator in 13.10 I'm trying to install python-appindicator in Ubuntu 13.10 but I'm receiving not found error:  \nE: unable to locate package python-appindicator\n\nHow can I install python-appindicator in 13.10 ?\n\nA: python-appindicator is present in the ubuntu repository for 13.10. See this.\nSo just run \nsudo apt-get update\nsudo apt-get install python-appindicator\n\n\nA: sometimes will face issues while running \n\nsudo apt-get update && sudo apt-get install python-appindicator\n\nas like \n\nYou might want to run 'apt-get -f install' to correct these:\n  The following packages have unmet dependencies:\n   python-appindicator : Depends: libappindicator1 (= 12.10.1+13.10.20130920-0ubuntu4.1) but it is not going to be installed\n  E: Unmet dependencies. Try 'apt-get -f install' with no packages (or specify a solution).\n\nso in this case run \n\nsudo apt-get -f install\n\nwill resolve issue and will build dependencies packages\nGreetings,\nPandy\n", "Q: Ubuntu 12.04 randomly freezes Hello. I use Ubuntu 12.04 with wubi.\n\nThe problem is that ubuntu randomly freezes when i move the mouse cursor. The system doesent have to restart i just have to press (ctrl+alt+f1) and then (ctrl+alt+f7) this works and i can use ubuntu a bit more but then it freezes again. I am using Asus k53sm laptop with 4gb ram, intel i5 processor and nvidia gt 630m. Is there a way to fix this problem?\n\nIm sorry if this is a duplicate, i dident find a ubuntu freeze problem like this.\n\nA: try using the proprietary nvidia driver and see if that helps. It may be related to the nvidia video drivers.\nsudo apt-add-repository ppa:xorg-edgers/ppa \n\nsudo apt-get update && sudo apt-get install nvidia-current nvidia-settings\n\n", "Q: pkill not killing I have a Script named PirateRadio.py That I am writing a script for. \nI need to kill and reload the script. Possibly with the same PID. I thought SIGHUP was a sure thing.  when i run #pkill -1 PirateRadio.py\nNothing happens. Radio keeps on going. Ok, I tried #pkill -9 PirateRadio.py\nstill nothing, radio keeps right on. \nps aux | grep Pir\nroot    987 45.7 10.8 1266088 433868 ?      Sl   Mar15 2728:13 /root/PirateRadio.py\nroot    24924  0.0  0.0   4388   800 pts/0    S+   11:13   0:00 grep PirateRadio.py\n\nso then I tried #kill -s 1 987\nnothing happens.\n#kill -s 1 987\nthen, system hang. So I dont want that, i guess. So then I use:\n#kill -s 9 987\nwhich kills the script well enough.\nI’ve used pkill on my other desktops, What is going on here? \nwhere can I look to find out what pkill is or isn’t doing?\nI looked in dmesg, but saw no change after running pkill\nI saw no verbose option in pkill man pages..\n\nA: From the  pkill manpage:\n\nThe process name used for matching is limited to the 15 characters\n  present in the output of /proc/pid/stat.  Use the -f option to match\n  against the complete command line, /proc/pid/cmdline.\n\nSo try\npkill -1 -f PirateRadio.py\n\n", "Q: What is the easiest way to fix a mixup of 32-bit and 64-bit? I have a machine which I have accidentally install 32-bit 12.04 LTS on.\n(Yes, accidentally. I can't recall how I managed that.)\nWhat is the easiest way to fix this? Mucking about with the kernel files or axing it with a reinstall?\nIs it possible and safe to have a dual boot of 32 and 64-bit 12.04 LTS?\n\nA: \nWhat is the easiest way to fix this? Mucking about with the kernel files or axing it with a reinstall?\n\nJust reinstall. The way to fix it would be immensely time consuming and complex.\n\nIs it possible and safe to have a dual boot of 32 and 64-bit 12.04 LTS?\n\nAs long as you have a 64-bit CPU, there will be no conflict between dual-booting. The two installations will be completely isolated from each other and will perform independently.\n", "Q: font problem in firefox i have some unusual problem in firefox, the font in firefox is not working properly, it become narrow then rest of the windows font, sometimes it looks very small, i have tried default settings of font in firefox, but it was not helpful, pleas if someone can help me it would be a great pleasure for me,,, i am giving a link to visualize the situation,\n\n\nA: Seems like you might be missing a font-package. For example, in ubuntu-minimal, I do not have any extra packages so the terminal font overlaps each other. I used sudo apt-get install ttf-ancient-fonts and that did the trick for the terminal. This may also work for firefox, if not, try other font families. These font packages can be found here\nHope this helps. \n", "Q: Wifi is not conneting I had installed Ubuntu 13 10 my ethernet is working fine. But when I want to connect with my Wi-Fi it ask me a key after entering the key it again ask me for the key but its not connecting to my Wi-Fi network.\n\nA: Try setting your router to an passwordless network and see if you can connect. If you can, then trying a different encryption type/agbn. If you can't, then it is likely your wifi card is the culprit and you would need to find new drivers or find specific answers to your specific card. \n", "Q: Trying to resolve “Cannot open shared object file libudev.so.0”? Getting too many levels of symbolic links problem I was trying to solve the problem highlighted here:\nBut whenever I execute\n ln -s libudev.so.1 libudev.so.0\n\nor even\n ln -s libudev.so.0 libudev.so.1\n\nI get Too many symbolic links error.\nI know i'll have to redo the symbolic links, but how?\n\nA: First try to find which libudev you have and where it is:\nsudo find / -name \"libudev.so*\"\n\nIf you find libudev.so.1, note its path, and link:\nsudo ln -s <libudevpath>/libudev.so.1 <libudevpath>/libudev.so.0\n\nDo not try to link the other direction!\nln -s file1 file0 creates a symbolic link between two files. Whenever an application looks for file0 (which doesn't really exist!), it will follow this link and use file1 instead.\nLet me know if I was helpful enough.\n", "Q: Need help to make this file work in iptables I came across the following example of how to use iptables to block internet access when the VPN connection is terminated abruptly:\niptables -A INPUT -i lo -j ACCEPT\niptables -A OUTPUT -o lo -j ACCEPT #allow loopback access\niptables -A OUTPUT -d 255.255.255.255 -j ACCEPT #make sure you can communicate with any DHCP server\niptables -A INPUT -s 255.255.255.255 -j ACCEPT #make sure you can communicate with any DHCP server\niptables -A INPUT -s 192.168.0.0/16 -d 192.168.0.0/16 -j ACCEPT #make sure that you can communicate within your own network\niptables -A OUTPUT -s 192.168.0.0/16 -d 192.168.0.0/16 -j ACCEPT\niptables -A FORWARD -i eth+ -o tun+ -j ACCEPT\niptables -A FORWARD -i tun+ -o eth+ -j ACCEPT # make sure that eth+ and tun+ can communicate\niptables -t nat -A POSTROUTING -o tun+ -j MASQUERADE # in the POSTROUTING chain of the NAT table, map the tun+ interface outgoing packet IP address, cease examining rules and let the header be modified, so that we don't have to worry about ports or any other issue - please check this rule with care if you have already a NAT table in your chain\niptables -A OUTPUT -o eth+ ! -d a.b.c.d -j DROP # if destination for outgoing packet on eth+ is NOT a.b.c.d, drop the packet, so that nothing leaks if VPN disconnects\n\nI have installed iptables-persistence and would like to know how to use the above to work with iptables.\nAny help would be much appreciated.\nP.S.: I do not have much IT knowledge and even less of Ubuntu. Could someone explain to me how does one obtain the value 192.168.0.0/16 ?\n\nA: This is called CIDR notation, see: http://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing\nThe 192.168.0.0/16 means all addresses from 192.168.0.0 to 192.168.255.255, which is all of the addresses in the private network IP range. If you put 192.168.0.0/24, it is only 192.168.0.0 to 192.168.0.255.\nThe number after the / corresponds to the number of fixed bits in the address, where there are 8 bits per number (2^8=256), or octet, so 32 bits per address. The rest of the 32 bits correspond to the number of bits that are part of the range.\nIn the case of 192.168.0.0/24, the 24 means that the first 24 bits of this address are fixed. This corresponds to the first three octets (8 bits each), or 192.168.0. And 32-24=8, so only the last octet is part of the range. This gives 8 bits of range, or 0-255.\nIn the original question, 192.168.0.0/16, the 16 means that the first 16 bits of the address are fixed, or 192.168 (2 octets, 8 bits each, 8+8=16). And 32-16=16 bits, so the last two octets are the range. This gives 16 bits of range, which is two octets (8 bits each) of 0-255. \n", "Q: How would I tell the last time Apache served a file? I'm trying to figure out how to tell the last time a .php file was served by Apache.\nI have written an application on an Ubuntu Lamp stack with Mysql & PHP. I have 1000s of files and I'm trying to \"clean House\". I'd like to know how to list all the files in the folder by the last time Apache actually served it.\nIt this even possible?\nUPDATE\nSorry, I should have been a little more detailed.\nI'm looking for all files that would include every file that was included with a php script like <?php include \"i_cant_see_this_file_in_the_logs.php\"; ?>\nHopefully that shines a little more light.\nThank you.\n\nA: You might be able to use auditctl or some sort of unix file-system auditing tool, but probably not retroactively. You would probably want apache to be running under a different user account, and then use the filesystem audit tool to track file-reads. A different solution that I'd be more comfortable using would be to add some debugging code to each php file (obviously not manually) which simply logs the name of the file and the date to a single file somewhere. I'd also create a subversion or git patch file after making this change so you can apply it and revert it as needed. After doing a full suite of testing, you can check the log file to see which files are absent (this can also be automated; I'd write a script compare the output of ls (sorted by name) with the log file (sorted by name and unique'd).\n", "Q: Cloning Ubuntu 13.10 I have 200 windows 7 laptops that were just delivered.  I have a test laptop that I have setup with ubuntu.  What is the best way to clone the new laptops to exactly match the identical ubuntu ( setup the way I want ) laptop.\nI've tried many things:\n1) DRBL will not load because it cannot find the imp file ( I had great hopes for this one )\n2) FOG will not run on ext\n\nA: I clone many machines in my work and I have great success with simply using tar from the command line.\nMount the partition of the source hard drive to (say) /mnt.\ntar cvfpz /home/me/documents/mybackup.tar.gz /mnt\nI recreate the partitions on the new HDD. Untar my Tarball to the new partition and re install grub.\nMount new hard drive to /mnt\ncd /\ntar xvfpz /my back up.tar.gz\nAll in all it is relatively quick and painless.\n", "Q: i want to install java on Ubuntu 13.04, but i got this type of problem during installing java problem is that:\napt-get install default-jre\nE: Could not get lock /var/lib/dpkg/lock - open (11: Resource temporarily unavailable)\nE: Unable to lock the administration directory (/var/lib/dpkg/), is another process using it?\n\nbefore that i 've already run update command it was ok but at last i got this type of message:\nE: Could not get lock /var/lib/dpkg/lock - open (11: Resource temporarily unavailable)\nE: Unable to lock the administration directory (/var/lib/dpkg/), is another process using it?\n\n\nA: Make sure software center is not running\n\n\n*\n\n*ps -e|grep software-center\nthen use sudo  with you apt-get command \n\n\n*\n\n*sudo apt-get update\n\n*sudo apt-get install default-jre\n", "Q: How can I remove a package I have encounter a problem when I install a package, The error message:\n$ dpkg -i 116667-Ubuntu\\ xsplash\\ clean\\ theme.deb \n(Reading database ... 265031 files and directories currently installed.)\nPreparing to unpack 116667-Ubuntu xsplash clean theme.deb ...\nmkdir: cannot create directory '/usr/share/images/ubuntu-default': No such file or directory\ncp: cannot stat '/usr/share/images/xsplash': No such file or directory\ndpkg: error processing archive 116667-Ubuntu xsplash clean theme.deb (--install):\n subprocess new pre-installation script returned error exit status 1\nrm: cannot remove '/usr/share/images/xsplash': No such file or directory\nmkdir: cannot create directory '/usr/share/images/xsplash': No such file or directory\ncp: cannot stat '/usr/share/images/ubuntu-default': No such file or directory\ndpkg: error while cleaning up:\n subprocess new post-removal script returned error exit status 1\nErrors were encountered while processing:\n 116667-Ubuntu xsplash clean theme.deb\n\n$ dpkg -l xsplash-clean message\nDesired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name           Version      Architecture Description\n+++-==============-============-============-=================================\niHR xsplash-clean  1.0          i386         (no description available)\n\nHow can I fix this error?\n\nA: Try the following command:\nsudo dpkg -r xsplash-clean\n\ndpkg man page explaining the -r option:\n\n-r, --remove, -P, --purge package...|-a|--pending Remove  an  installed  package. -r or --remove remove everything except conffiles.\n  This may avoid having to reconfigure the package  if  it  is \n  reinstalled later.\n\n", "Q: Automatically install package dependencies with terminal I have a .deb file in my downloads folder than i need to install with a bunch of dependencies.  What is a command that will install the package with the dependencies.\nI know this is probably a duplicate but i just want the command to install the package from the downloads folder and automaticly install dependencies, because i don't know much about the terminal\n\nA: The command you are probably looking for is gdebi. It should be provided by the gdebi-core package.\nGDEBI(1)                                                              GDEBI(1)\n\nNAME\n       gdebi - Simple tool to install deb files\n\nSYNOPSIS\n       gdebi [package.deb]...\n\nDESCRIPTION\n       gdebi  lets you install local deb packages resolving and installing its\n       dependencies. apt does the  same,  but  only  for  remote  (http,  ftp)\n       located packages.\n\n\nA: first run *sudo dpkg -i downloaded_package.deb*\nYou will probably get errors about missing packages (dependencies) now. Execute:\nsudo apt-get -f install\n", "Q: Installation problem with Ubuntu 12.04.4 I am trying to install Ubuntu 12.04.4 on my Dell Inspiron 5520 using wubi. It makes my machine reboot, and starts installation. The problem is - as the installation comes to the step 'preaparing to install', it shows me hourglass and freezes. I waited for 4 hours once, but it never proceeds. What should I do ?\n\nA: Try installing Ubuntu 12.04.4 32bit. Less problems when performing a wubi installation especially after you boot into Ubuntu and need to install certain packages that may or may not work in Ubuntu 64bit.\nAlso, do not allocate more than 30GB space for your Ubuntu virtual disk because as I understand 30GB is the maximum size allowed for a wubi installation.\n", "Q: Install Nvidia driver for CUDA to use \"GPU\" option in Blender (ubuntu (13.10-) 14.04) Same question as on the Blender stackexchange site.\nAs a recap:\n\n\n*\n\n*I have to install the nvidia driver but how to do it? (repository or manually? And I already had problems with both, as said)\n\n*My computer detects an other graphic card as the one that I have! (Maybe the reason why no proprietary drivers are purposed)\n\n\nEvery help is welcome!\nIt came out that the problem was that I have OPTIMUS. But in 14.04 it seems to be supported.\nSo, under 14.04 (on my external HDD) it detects my Nvidia driver OUT OF THE BOX!!!\nBut with Blender and cuda installed as said on this site and this driver:\n\nI then installed Blender from this ppa as well as the CUDA driver from the same site.\nThen, Blender detects the GPU!!!\n\nBut it says (Cycles mode with GPU rendering active):\n\nEven with Experimental on:\n\nBut on the site, thay say that Cuda < 2.0 is experimental:\n\nShould I wait, or could it help if I use another driver?\n\nA: (Please see the update below)\nFor me, I had to:\n\n\n*\n\n*Install proprietary drivers distributed by Nvidia (recommended here)\n\n*Install Blender via the ppa\n\n*Install nvidia-modprobe (recommended here), without it Blender would throw cuda cuinit: unknown error ubuntu\n\n*Reboot\n\n\nSo,\n# Proprietary nvidia\nsudo apt-add-repository ppa:ubuntu-x-swat/x-updates\n\n# PPA for Blender\nsudo add-apt-repository ppa:thomas-schiex/blender\n\n# Update..\nsudo apt-get update\n\n# Install\nsudo apt-get install nvidia-current nvidia-modprobe blender\n\n# Reboot\n\nThis was for Ubuntu 14.04, Blender 2.73,  GeForce GTX 650 Ti.\nOtherwise, using the ubuntu nvidia stuff, building blender from source, running blender from the downloaded tar ball, etc.. all failed.\nUPDATE\nThis all seemed to work until I tried to render, but then I got\nFailed loading render kernel, see console for errors\n\nThen on the console:\n Cycles shader graph connect: can only connect closure to closure (image_texture.Color to output.Surface).\n Unsupported CUDA version 5.5 detected, you need CUDA 6.5.\n\nInstalling CUDA 6.5 involved completely installing nvidia-337 (otherwise you get a lot of cuda-6-5 : Depends: .... (=....) but it is not going to be installed. (as shown here) and instead installing nvidia-340.\nTo install this nvidia-340,\n# nvidia PPA for v340\nsudo add-apt-repository ppa:mamarley/nvidia\n\n# Update\nsudo apt-get update\n\n# install nvidia and cuda\nsudo apt-get install nvidia-340 cuda-6-5\n\n# Reboot\n\nOther sites (AskUbuntu on Lubuntu, R Tutorial, etc) recommend installing from the .run, but I had no issue just using apt-get.  The process did archive (rename) my xorg.conf file which disabled my edit file, but that was simple to revert.\n\nA: You can install nvidia-modprobe. The other way is to install Nvidia driver manually from Nvidia official site:\n\n\n*\n\n*Uninstall previous Nvidia drivers:\nsudo apt-get purge nvidia-\n\n\n*Download latest version of your drever to your linux user folder, http://www.nvidia.ru/Download/Find.aspx\n\n*Install dependences:\nsudo apt-get install linux-headers-`uname -r` binutils pkg-config build-essential xserver-xorg-dev\n\n\n*Open blacklist:\nsudo nano /etc/modprobe.d/blacklist.conf\n\n\n*Add the lines to blacklists:\nblacklist vga16fb\nblacklist nouveau\nblacklist rivafb\nblacklist nvidiafb\nblacklist rivatv\n\n\n*Open xorg config file:\nsudo cp /etc/X11/xorg.conf /etc/X11/xorg.conf.backup\nsudo nano /etc/X11/xorg.conf\n\n\n*Add the lines to xorg config:\nSection \"Screen\"\n    Identifier \"Default Screen\"\n    DefaultDepth 24\nEndSection\n\nSection \"Device\"\n    Identifier \"Default Device\"\n    Driver \"nvidia\"\n    Option \"NoLogo\" \"True\"\nEndSection\n\nSection \"Module\"\n    Load \"glx\"\nEndSection\n\n\n*Stop x-server:\nsudo service lightdm stop\n\nor\nsudo service gdm stop\n\nor\nsudo service kdm stop\n\n(depends on your linux version)\n\n*Install the driver (be aware that only one copy of nvidia driver script there is in your user home directory):\nsudo sh ./NVIDIA*\n\nTrough the installing process do not agree for any automated features. Only manual things work.\n\n\n*Run x-server:\nsudo service lightdm start\n\nor\nsudo service gdm start\n\nor\nsudo service kdm start\n\n(depends on you linux version)\n\n*Run Blender and you will see CUDA option appeared.\n\nA: As per the question linked by you, you have GeForce GT 330M and ubuntu detected intel card as display driver. This concludes one thing, you have a laptop with optimus technology and you can not install nvidia drivers directly.If done, You will get a black screen.\nNow I don't know what a blender is. But I guess this is a graphics intensive app which require powerful graphics processor.\nThe driver released by Nvidia doesn't support hybrid/optimus configuration. So there is unofficial work to get the power saving and finding a way to use  nvidia card. The result is Bumblebee.\nYou can find the install & usage instruction - https://wiki.ubuntu.com/Bumblebee\nYou can go through the following question before doing anything\nIs a NVIDIA GeForce with Optimus Technology supported by Ubuntu?\nA similar question but old - Bumblebee ubuntu 12.04 blender\nmaybe helpful :\nHow can I get nVidia CUDA or OpenCL working on a laptop with nVidia discrete card/Intel Integrated Graphics?\nMore info - https://github.com/Bumblebee-Project/Bumblebee/wiki\n\nA: The NVIDIA driver has had support for Optimus on Ubuntu since 13.10. Your issue is that neither installing the NVIDIA drivers, nor installing Blender triggers the installation of the cuda toolkit. Open a terminal and issue the following command; sudo apt-get install nvidia-cuda-toolkit and it will enable the use of cuda in Blender.\n\nA: Is it not like in 12.04 (precise) that if you download blender from blender.org (yes - I mean NOT installing but downloading the tar.gz thingy) unpack it and start directly blender from this file that the problem is solved?\nI am using blender now since two years and since these two years it always worked like that. Which means: The installed blender version in ubuntu does NOT support CUDA and no update does while the downloaded and \"portable\" version of blender from blender.org does. \nBut do not ask me why that has not been changed.\n\nA: Quick sum up of the issues and their fixes:\n\n\n*\n\n*Optimus not supported by Ubuntu (13.10)\n-> Ubuntu 14.04 supports it out of the box!\n\n*Blender doesn't detect CUDA\n-> Use the proprietary driver (accessible in the additional driver panel)\n\n*Blender complains about CUDA 1.2. It only supports >=2.0\n-> Use Blender 2.96 or lower or install the CUDA toolkit\n-> AND use \"Experimental\" mode\n=> It should work! :·)\nFor more informations: https://blender.stackexchange.com/questions/10800/cuda-acceleration-with-cuda-1-2\nThanks to everybody!\n", "Q: How to reset default interface of VLC? I was playing with VLC skins downloaded from gnome-look.org. And now,I think, My VLC is bricked. It shows this error message on terminal:\n[0x1b15f08] skins2 interface error: no skins found : exiting.\nI don't wanna reinstall it either.\n~$ vlc\nVLC media player 2.0.8 Twoflower (revision 2.0.8a-0-g68cf50b)  \n[0xd6df08] skins2 interface error: no XML found in theme /home/amol/Download/AlienWareVLCInvader.zip  \n[0x7ff4e801d8f8] xml xml reader error: XML parser error (line 1) : Document is empty  \n[0xd6df08] skins2 interface error: no skins found : exiting\n\nplease help...\n\nA: The command you are after is:\nvlc --reset-config --reset-plugins-cache\n\nRun this from a Terminal window and this will reset vlc to its installation defaults...\n\nA: May I suggest you go to the Ubuntu Software Center (or Synaptic Package Manager if you prefer), search for VLC, and completely uninstall it? Then reinstall it. This will take less than five minutes, and is easier than editing the VLC configuration files.\nIf you won't uninstall/reinstall VLC, then open a terminal emulation window, do \nrm ~/.config/vlc/vlcrc\n\nand close the window.    \nThen, reopen VLC.\n\nA: I you need to change the skin of vlc, after copying files to /.local/share/vlc/skins2 simply go to preference and click at use custom skins.Then simply save and restart vlc.you do not need to choose any folder,when vlc will restart you will see that now skin is changed.Also you can change to other skins by going to change skins options in menu now.\n", "Q: Data recovery in ubuntu 12.04 I have Ubuntu 12.04 dual booted with windows 8. While I was using Ubuntu, all of a sudden my system went into a suspend mode and when I logged back in all my data was gone. It was Ubuntu in its pristine form. Though some applications like Pidgin, File Zilla, Google Chrome, Xsensors etc. still continue to work. Windows, on the other hand, is working perfectly fine. How can I recover my data? I need my data badly!\n\nA: This happened to me while dual booting with Windows 7.\nA slow but effective process in my case was to use PhotoRec http://www.cgsecurity.org/wiki/PhotoRec (it recovers most file types, not just pictures).\nGood luck!\n\nA: Maybe this link can help you. Basically you need to run the live CD/DVD which you used when you installed Ubuntu, and after you boot into the live session you need to install one or more data recovery programs in a terminal or with Synaptic Package Manager, The programs are testdisk, scalpel and/or foremost. Code:\nsudo apt-get install testdisk scalpel foremost\n\nUse the detailed instructions from the provided link to learn how to recover your lost/deleted data.\n", "Q: Why are 'source' and '.' not always the same, when they're supposed to be identical? I was under the impression that source was a synonym for . in bash. However, it seems that in the .profile file, source doesn't work. This youtube video demonstrates that when source is used in ~/.profile to source a file foo, the variable defined in that file is not exported to subsequent shells. However, if instead the file is sourced using ., the variable is exported as expected.\nNote that when I use source, the environment variable does NOT get exported, but when I use . it does.\n\nA: They are exactly the same, as explained in man bash:\n.  filename [arguments]\nsource filename [arguments]\n    Read and execute commands from filename in the current shell\n    environment and return the exit status of the last command executed\n    from filename.  If filename does not contain a slash, file names in\n    PATH are used to find the directory containing filename.  The file\n    searched for in PATH need not be executable.  When bash is not in\n    posix mode, the current directory is searched if no file is found in\n    PATH.  If the sourcepath option to the shopt builtin command is turned\n    off, the PATH is not searched.  If any argu‐ ments are supplied, they\n    become the positional parameters when filename is executed.  Otherwise\n    the positional parameters are unchanged.  The return status is the\n    status of the last command exited within the script (0 if no commands\n    are executed), and false if filename is not found or cannot be read.\n\nThe issue here is that source is a bash thing, the standard is actually .. Your .profile is only read by login shells and by some (not all) login managers. However, login managers (such as lightdm) will attempt to read (source) the file using the system's default shell, normally /bin/sh. On Debian-derived systems, /bin/sh is a symlink to /bin/dash and dash is a very simple, POSIX-compliant shell that is not bash and has no knowledge of the source keyword.\nTherefore, the command is ignored, the file is not sourced and the variable is not defined. To illustrate:\n$ cat foo\nmyvar='foo1'\n$ source foo\n$ echo $myvar\nfoo1\n\nThe same thing in dash:\n$ echo $0\ndash\n$ source foo\ndash: 11: source: not found\n$ . ~/foo  ## dash needs the full path\n$ echo $myvar\nfoo1\n\n", "Q: Deja-Dup Google Drive Support I tried to search to see if Google Drive is supported the same way Ubuntu One is supported for Deja-Dup but I haven't seen anything concrete. I don't want to store a local copy of the backed up files, but rather put it directly to the Google Drive account and prevent it from being sync'd.\n\nA: You still cannot do so using deja-dup but fortunately it doesn't matter as you can use duplicity to achieve the same purpose. Deja-dup is the gui front-end for duplicity. You can use duplicity directly from the command line and surprisingly it is simpler than using the gui of deja-dup!\nYou need to install the package python-gdata first as it is not part of the base system.\nsudo apt-get install python-gdata\n\nAfter that you can use duplicity to put a local folder directly to google drive by issuing the following command:\nduplicity localfolder gdocs://username@gmail.com/remotefolder\n\nor\nduplicity localfolder gdocs://username:password@gmail.com/remotefolder\n\nIn the second case it obviously won't ask for your gmail's password(but would still ask for the encryption passphrase).\nCommand to restore:\nduplicity restore gdocs://username@gmail.com/remotefolder localfolder\n\nIn all the above cases localfolder is a folder in your home directory and you are running the commands from your home directory.\nTwo minor caveats. Firstly, while restoring you have to ensure that localfolder doesn't exist otherwise duplicity will abort saying localfolder already exists. Secondly, I have tested the above in ubuntu 14.04 so can't comment about the other versions. \n\nA: The only solution I have come up with is to back up to a local drive using Deja Dup, then zip the folder and upload to Google Drive.\nI am hoping to find a way to create a folder with Google Cloud or Google Drive and achieve incremental backups automatically.\nCurrently I get the error:\nCannot resolve hostname when using //drive.google.com/\n\n\nA: This was reported in this bug, for which a fix has been committed. The change should be included in version 32.\nUpdate: The fix was reverted due to issues with the duplicity backend. However, duplicity can still do this. There is a question on SO about how to get it working with Google's OAuth, at least with the Duply frontend as of December 2015. This involves installing pydrive, setting up access on your Google account, and creating a settings file for duplicity.\nRelated question with other options: Backup with duplicity on Google Cloud Storage\n", "Q: Can't get my wireless worked, it keep loading I just have installed ubuntu 12.04 and the broadcom driver. When i try to connect to my wifi, it keep loading and asking for my password.\n\nA: I've had this happen on and off. Couple solutions should work unless you have a deeper problem.\n\n\n*\n\n*Simple reboot should fix this.\nbut that takes time, so a quicker way\n\n*Restart network manager in terminal sudo service network-manger restart\n\n*Or hover over the network indicator or the status bar until you get the dropdown. \nDisable wireless, disable networking, then enable networking, enable wireless. \n\nA: Most of the time when this happens to me its because of a weak signal or a configuration problem. Try setting your wifi mode to an open network and testing if your wifi connects. If it works, then try different encryption methods or wifi types (abgn). \n", "Q: How do I get my Epson Scanner working on Ubuntu 13.10 I have the Epson SX218 with a built-in scanner. The printer works fine but if I want to scan something simple scan says no scanner found.\nAny ideas what I can do?\nBy the way, how can I check the ink level of the printer??\n\nA: I'm using iscan with my epson that you can download from epson website (I checked and it's compatible with yours also).\nPlease note that if you want to connect to your printer through network and not directly (like usb) you have to install the network package (both downloads on here) and change the epkowa.conf file as explained here.\nFor any doubts or information on the installations needed you can visit epson FAQ on here.\n", "Q: When I use \"Connect to Server\", how can it remember the IP address? I don't want to type in the IP address every single time. Can it just save them to a list or something?\n\n\nA: Connect to the server, and when viewing the directory on the server in Nautilus, simply press Ctrl+D to bookmark the location. If you unmount, and then open the bookmark again, it should automatically connect, assuming you opted to store the username/password in your keyring.\n", "Q: Boot .efi files from GRUB2 I've bought a Sony VAIO with UEFI booting and came with Windows 8 preinstalled. I successfully installed Ubuntu 13.10 and Windows 7 (triple-boot) and fixed the UEFI boot so GRUB2 is loading.\nI was just wondering if I can boot .efi files from grub?\nRelated problems:\n\n\n*\n\n*I used Clover EFI to boot OS X 10.9 (which I installed to boot, can't boot it with GRUB2: AICPUPM KP) and because of it I couldn't boot to either Windows or Ubuntu.\n\n*After that I installed Android 4.4 x86 and added its boot entry and I got KP related to efivar (or something like that), so I wanted to try Gummiboot.\nMy question is:\nCan I boot .efi files such as gummiboot.efi and cloverx64.efi from GRUB2 so I can preserve it for Windows and Ubuntu booting?\n\nA: It's basically the same as booting bootmgfw.efi from Windows 8, but a bit simpler.\nmenuentry \"Gummiboot\" {\n        insmod chain\n        insmod search_fs_uuid\n        search --fs-uuid --no-floppy --set=root $UUID\n        chainloader /EFI/boot/bootx64.efi\n}\n\nJust replace $UUID with the UUID of the filesystem where you have put Gummiboot or the efi-binary you want to boot (use blkid or ls -l /dev/disk/by-uuid/ to get the UUID). For FAT filesystems the UUID should look something similar to this: 00000-0000\ninsmod chain and insmod search_fs_uuid may just be optional, I could remove them from the configuration during my quick tests and was still able to boot the binary. \nAlternatively you could add insmod ntfs or insmod ext2 if you have the binary on another filesystem like NTFS or EXT[234] (may require insmod part_msdos or insmod part_gpt if the filesystem is on a disk with a different partition table format).\n/EFI/boot/bootx64.efi is my Gummiboot file in this example, as I have it as the default bootloader of my ESP. \n", "Q: How to add paths in ubuntu I know that this is a very popular question with a lot of threads already about it, but unfortunately after trying some of the suggestions I didn't manage to solve my problem, so I am posting a new question about it.\nWhat I am interested in, is running a c++ program in terminal, the thing is, as I was always using eclipse to compile and run programs I am completely noob on this and also my ubuntu knowledge is limitated to very basic things.\nSo what I am finding difficulties in is when I want to compile a program which needs to include some header files form different directories. What I want to do is to include this libraries without needing to add in the #include \"...\" the whole path of where the library is but just it's name.\nIn Eclipse this could be done by adding paths through options, but in Ubuntu I am not really sure how to do so, following some instructions in other threads I tried to add the paths to my ~/.profile txt file but without any success.\nSo I would like to ask how is this possible to be done, i.e. where and how to add the paths of the header files needed so that I want have all the time for very new project to provide the entire path in my includes.\n\nA: You add the path with -I arguments to g++ for example,\n$ cat /home/efrisch/t/myheader.h\n#include <iostream>\n$ cat hello.cc\n#include \"myheader.h\"\n\nint main(int argc, char **argv) {\n    std::cout << \"Hello, World!\" << std::endl;\n}\n$ g++ -O -I/home/efrisch/t hello.cc -o hello\n$ ./hello\nHello, World!\n\n", "Q: My fan is not working, no active cooling system I am using Ubuntu 14.04 on my laptop and my fan is not working(with Ubuntu 12.04 and Ubuntu 13.10 it was the same). \n\nShort summary of my system\nQuanta TWH motherboard, Intel® Core™ i7-2630QM CPU\n\n I follow 3 different ways to solve my problem\n1. Using lm-sensors, pwmconfig and fancontrol to control the speed of my fan\nFirst, I try to see what was happening with lm-sensors, I even could not detect my fan. Later on, forced with modeprobe Ref1 with following command line.\n\nsudo modprobe w83627ehf-isa-fff8\n\nIt helps to get more sensors with lm-sensors-detect but they all in ALARM, I believe they are set as null because I create them artificially or not(I am not sure about what is modeprobe is doing for me)? \nHere is my sudo sensors results after that process.\nacpitz-virtual-0\nAdapter: Virtual device\ntemp1:        +61.0 C  (crit = +101.0 C)\n\nw83627ehf-isa-fff8\nAdapter: ISA adapter\nVcore:        +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\nin1:          +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\nAVCC:         +4.08 V  (min =  +4.08 V, max =  +4.08 V)  ALARM\n+3.3V:        +4.08 V  (min =  +4.08 V, max =  +4.08 V)  ALARM\nin4:          +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\nin5:          +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\nin6:          +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\n3VSB:         +4.08 V  (min =  +4.08 V, max =  +4.08 V)  ALARM\nVbat:         +4.08 V  (min =  +4.08 V, max =  +4.08 V)  ALARM\nin9:          +2.04 V  (min =  +2.04 V, max =  +2.04 V)  ALARM\nfan1:           0 RPM  (min =    0 RPM, div = 128)  ALARM\nfan2:           0 RPM  (min =    0 RPM, div = 128)  ALARM\nfan3:           0 RPM  (min =    0 RPM, div = 128)  ALARM\ntemp1:         -1.0 C  (high =  -1.0 C, hyst =  -1.0 C)  ALARM  sensor = CPU diode\ntemp2:         +0.0 C  (high =  +0.0 C, hyst =  +0.0 C)  ALARM  sensor = CPU diode\ntemp3:         +0.0 C  (high =  +0.0 C, hyst =  +0.0 C)  ALARM  sensor = CPU diode\ncpu0_vid:    +1.219 V\nintrusion0:  ALARM\n\ncoretemp-isa-0000\nAdapter: ISA adapter\nPhysical id 0:  +61.0 C  (high = +86.0 C, crit = +100.0 C)\nCore 0:         +57.0 C  (high = +86.0 C, crit = +100.0 C)\nCore 1:         +61.0 C  (high = +86.0 C, crit = +100.0 C)\nCore 2:         +57.0 C  (high = +86.0 C, crit = +100.0 C)\nCore 3:         +57.0 C  (high = +86.0 C, crit = +100.0 C)\n\npkg-temp-0-virtual-0\nAdapter: Virtual device\ntemp1:        +61.0 C  \n\nAt that point, I try to run sudo pwmconfig. Still, I am not able go further from There are no usable PWM outputs. I stack here with this way. (My computer is not Dell) \n2. Install the latest microcode for my processor\nI instal the following the steps given here, thanks to @floppy for the advise.\n\nInstalling intel-microcode and microcode.ctl packages (as @floppy suggested) are help to wake up my fan, it helps to decrease CPU temperature. Fan was working quite independent from CPU temperature. It was doing some work but still not efficient at all. \nFurthermore, sensors-detect is still not able to get my fan without that  sudo modprobe w83627ehf-isa-fff8\n\n3. BIOS Update\nOkey my CPU temperature is lower, but still not enough to perform even for the basic applications. \nI also think about to update my BIOS, but I could not convince myself it might be the reason of my problem in the beginning. I have QUANTA TWH motherbord with i7-2630qm with INSYDE QR133 BIOS. I update it with USB up-to the QR192.\n\nBIOS update decreases my CPU temperatures around 10~15 Celcius, I do not know how and why. \n\nI am still looking for alternative methods to control my fan, or/and force it to work at given/at the maximum rate all the time\n\nA: Try installing the latest microcode for your processor. According to some linux gurus  you may be able to improve the functioning of the central processor (CPU) in your computer by applying the latest Intel or AMD microcode. This will improve the functioning of your CPU, because it corrects bugs in the default microcode that it receives from the motherboard.\nVisit this page to learn how to install the microcode package for your CPU. Basically, you have to open Synaptic, and search for intel-microcode and microcode.ctl packages. I hope I am not wrong, and your CPU is from Intel. Amd CPUs can also benefit from this microcode package but it has a different name, amd64-microcode.\nMaybe after you install intel microcode, and restart you computer your fan will come to live again.\n", "Q: How to create more partitions od USB flash drive? I want to ask how to create more partitions od USB flash drive? and if is it possible under ubuntu. Will I be able to boot a live distribution from created partition?\nwhich tool should I use, I was trying it with Gparted. But with no success. \nThank you.\n\nA: Gparted should be able to partition USB flash drives. Ubuntu disk utility should be able to do it also, you need to make sure it is not mounted first. In the disk utility there is an option to unmount the device. Failing that, fdisk should definitely work if you are happy with the command line.\nI have installed Linux to USB drives before and they boot just fine. Remember to install grub to the USB drive.\n\nA: For a full install to USB I make the first partition FAT32 or NTFS so Windows can see the data, (Windows can only see the first partition on a flash drive). I then make the second partition /, the third /home and the fourth swap.\nFor a Persistent, (Live), install I make the first partition FAT32, as it is the only place a Live install will work, Windows data can be written to a folder on this partition. I make the second partition ext2 and name it casper-rw, it is where fresh installed programs go. The third partition is home-rw and is also ext2. this is like having a separate home partition.\n", "Q: Custom Server ISO cannot find kernel to install I'm trying to build a custom Ubuntu Server ISO, and am hitting a weird problem I'm hoping someone here can help with. I'm using UCK and these instructions.\nWhen I do the minimum possible to build a \"custom\" ISO, it spits out an ISO which installs and works without any issues.\nuck-remaster-unpack-iso ./ubuntu_trusty-server-amd64.iso \nuck-remaster-pack-iso \n\nHowever, I want to be able to include custom packages on my ISO too. UCK sets up the environment for you and then takes your GPG key and automatically signs everything for you:\nuck-remaster-clean\nuck-remaster-unpack-iso ubuntu_trusty-server-amd64.iso \nuck-remaster-prepare-alternate \ngpg --list-keys\nuck-remaster-finalize-alternate 60FB276F\nuck-remaster-pack-iso \n\nIt generates an ISO without any errors, however the ISO those this wonderful error:\n\nSyslog shows these (full):\nMar 19 19:37:28 base-installer: Using CD-ROM mount point /media/cdrom/\nMar 19 19:37:28 base-installer: Identifying.. \nMar 19 19:37:28 base-installer: [53fed41586d1f78a456ce051a5c87264-2]\nMar 19 19:37:28 base-installer: Scanning disc for index files..\nMar 19 19:37:29 base-installer: Found 3 package indexes, 0 source indexes, 0 translation indexes and 1 signatures\nMar 19 19:37:29 base-installer: Found label 'Ubuntu-Server 14.04 LTS _Trusty Tahr_ - Alpha amd64 (20140306)'\nMar 19 19:37:29 base-installer: This disc is called: \nMar 19 19:37:29 base-installer: 'Ubuntu-Server 14.04 LTS _Trusty Tahr_ - Alpha amd64 (20140306)'\nMar 19 19:37:29 base-installer: Copying package lists...\nMar 19 19:37:29 base-installer: gpgv: Signature made Fri 14 Mar 2014 01:18:54 AM UTC using RSA key ID 60FB276F\nMar 19 19:37:29 base-installer: gpgv: Can't check signature: public key not found\nMar 19 19:37:29 base-installer: E: Sub-process gpgv returned an error code (2)\nMar 19 19:37:29 base-installer: W: Signature verification failed for: /media/cdrom/dists/trusty/Release.gpg\nMar 19 19:37:29 base-installer: E: No CD-ROM could be auto-detected or found using the default mount point.\nMar 19 19:37:29 base-installer: You may try the --cdrom option to set the CD-ROM mount point. See 'man apt-cdrom' for more information about the CD-ROM auto-detection and mount point.\nMar 19 19:37:29 base-installer: error: error while running apt-cdrom\n\nI also tried following the instructions here but it had the same result - UCK seems to follow those instructions from looking at the source.\nAny ideas or suggestions would be appreciated.\nUpdates after more investigation:\nBreaking out to a shell after the 'bad kernel' message: When examining the keys found in /usr/share/keyrings with gpg --list-keys --keyring ./ubuntu-archive-keyring.gpg the signing key injected by UCK or manually through a ubuntu-keyring rebuild are NOT installed prior to the apt-cdrom call in the installer. As such, dists/trusty/Release.gpg fails gpg verification.\nManually running dpkg -i on the rebuilt ubuntu-keyring package installs the replacement keys correctly; both in /usr/share/keyrings and into the appropriate gpg envelope - however, exiting the shell, and reinstating the software installation at that point from the installation menu, does not fix the apt-cdrom gpg validation process - it looks as though gpg keys are getting injected from some other udeb, and ubuntu-keyring is not installed prior to the apt-cdrom check.\nUnfortunately, the error message displayed, is not reflective of the underlying problem. The problem is that that apt-cdrom cannot verify the gpg signature, therefore doesn't recognise the CDRom as a valid package source. That means that there are no kernels available to install.\n\nA: [cdrom]/install/filesystem.squashfs contains a pre-installed version of ubuntu-keyring, and the ubuntu-keyring package within /pool/ on the CD is not installed prior to apt-cdrom being executed by debian-installer - therefore apt-cdrom fails to verify the modified Release file, and apt won't touch the packages on the CD.\nSomething like this is required, in order to replace the baseline keys with your modified version:\nmkdir /tmp/CDRom\nmount -o loop /path/to/trusty.iso /tmp/CDRom\n\nmkdir /tmp/SquashFS\ncd /tmp/SquashFS\n\nunsquashfs /tmp/CDRom/install/filesystem.squashfs\ncd squashfs-root\ncp /path/to/modified/ubuntu-archive-keyring.gpg usr/share/keyrings/ubuntu-archive-keyring.gpg\nrm /path/to/FinalCD/install/filesystem.size /path/to/FinalCD/install/filesystem.squashfs\ndu -sx --block-size=1 ./ | cut -f1 > /path/to/FinalCD/install/filesystem.size\nmksquashfs ./ /path/to/FinalCD/install/filesystem.squashfs\n\napt-cdrom will then work correctly.\n\nA: It seems that you don't have to sign customized installs now.  In fact if you try it fails to install.\nI was also trying to create a custom install of the 14.04 server 64 bit and was getting the same problem with the signature verification of the Release.gpg. (public key not found). I have done this with many past releases, including the 12.04 64 bit server release.  I was using the https://help.ubuntu.com/community/InstallCDCustomization guide. Have recreated the ubuntu-keyring debs adding my keys and replaced the pool/main/u/ubuntu-keyring debs. \nTurns out the if I just don't sign the Release, the install no longer cares that I am creating my extras directory, using a customized preseed and tweaking and installing everything I want.   \n\nA: RedPhoenix's answer worked for me after I added two additional keyring files:\ncp /path/to/modified/ubuntu-archive-keyring.gpg usr/share/keyrings/ubuntu-archive-keyring.gpg\ncp /path/to/modified/ubuntu-archive-keyring.gpg etc/apt/trusted.gpg\ncp /path/to/modified/ubuntu-archive-keyring.gpg var/lib/apt/keyrings/ubuntu-archive-keyring.gpg\n\n", "Q: I loaded a program in wine and I cant find it I am running 12.04 and used wine to install Rosetta stone. It loaded correctly but now I cant find it. It did not create a desktop icon and it doe not show up when i search for it or when I pull up wine and look under the applications tab. I can see it when I go under wine uninstall a program. Any ideas? I would like to create a desktop link Thank you. \n\nA: you could try push alt + f2 and type wineremove, and then use wineremove and push tab application, and then add/remove the software from the c: drev /program files, and then delete it this should work, and then install it you can install the software again, and then you can run it from the wine application.\n", "Q: Ubuntu 12.04 boots to TTY1 Alrighty, I have perused the threads already in existence and am finding none of them seem to have the exact combination of variables I've got going.\nI'm working on a computer using Ubuntu 12.04. Currently, it boots straight into tty1\nUbuntu 12.04.4 LTS [computer name] tty1\n\n[computer name] login:\nPassword:\n\nLogin leads to:\nLast login: Wed Mar 19 13:47:11MDT 2014 on tty1\n\nWelcome to Ubuntu 12.04.4 LTS (GNU/Linux 3.2.0-32generic-pae i686\n\nThe owner of the computer stated that this issue happened after a recent update, if that gives anyone a hint as to the specific location of the graphics failure. \nI'm capable of booting into the GUI utilizing startx, but am frankly at a loss of where to go from here. Years of Windows has molded me into a GUI heavy kinda person, so, if possible, work off the assumption that I've no idea what you're talking about and break it down to the simplest of steps.\nThanks!\n\nA: I have had the same problem, and you can install the ubuntu again by typing. \n Sudo apt-get update\n Sudo apt-get install --reinstall ubuntu-desktop\n startx\n\nAnd it should work.\nEDIT: line 2 should install ubuntu-desktop (with a dash), not ubuntu desktop.\n\nA: or try to use this command: \nstartx\n\n\nA: I did this:\nsudo apt-get update  \nsudo apt-get install --reinstall ubuntu-desktop  \nstartx\n\n\nA: Check the /etc/default/grub file.  Specifically, you should have this line: GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nIf it says anything else after the equal sign , change it to the line above.  Run sudo update-grub and reboot.  \nAmong other things,  try different greeter like gdm. sudo apt-get install gdm\n\nA: You could use this command to turn the Xserver back on. \nsudo systemctl set-default graphical.target\n\nJust for future problems.\n\nA: As well as doing what the other answers have suggested, it could be a config issue pointing you to TTY1 Ctrl Alt F1 rather than the X server Ctrl Alt F7 at boot.\n\nA: You can try the following solutions\n\n\n*\n\n*If you have grub installed, you can boot to Ubuntu of an earlier version using the grub menu during boot.\n\n*You can reinstall unity or install another desktop environment such as gnome or Lxde\n\n*This may be a bit weird but you can write a shell script which is invoked whenever user logs in which runs the startx command\n\n", "Q: How do you reset your password for thunderbird? I am trying to set up a Thunderbird account, but it keeps telling me that my password is wrong. When I went to Edit/Preferences/Security/Passwords, I discovered my suspicions were correct. But I think I may be experiencing a problem that may be altogether different. When I put in my correct username and password, this is what comes up. \n \nI just don't know what this means or what it was that I did wrong. Thunderbird opens up, I just always get this error message. \n\nA: To remove existing passwords, go to edit > preferences, click on the security icon. Then the \"passwords\" tab, the \"saved passwords\" button, in the next window: \"show passwords\"\nIn the list of accounts and passwords, select your password and choose \"remove\" (down left)\nHowever, something else seems to be wrong. If the password is incorrect, you were probably offered to enter a new password. If the password is rejected again and you are sure it is correct, you should check the server settings.\nSettings should be like this:\n\nAlso check if IMAP is enabled in your Gmail account (on the Gmail webmail website), although that is unlikely to be the problem. \nSee also this reference\n\nA: Sign into your Gmail account with the password you believe is correct to test it. Also make sure that your Caps Lock is not on because the password is case sensitive.  If you are successful then you can try it again in Thunderbird.\n", "Q: Can't login after adding script to /etc/profile.d I have created a little script to add bookmarks in Nautilus to redirect users to network share. If I run the script manually, it works brillantly but as soon as I try to add it in /etc/profile.d, I can't connect to the computer. It seems that as soon as I do a loop or anything \"fancy\" like that, the script give an error. Here is an example if my currently working script :\n#!/bin/bash\n\n# Creating gtk-bookmarks if it doesn't exists\nif [[ ! -f ~/.gtk-bookmarks ]]\nthen\n        touch ~/.gtk-bookmarks\nfi\n\n# Adding bookmarks if not present\nif ! grep -Fxq \"smb://example.com/R03C01 Software:\" ~/.gtk-bookmarks\nthen\n    echo \"smb://example.com/R03C01 Software:\" >> ~/.gtk-bookmarks\nfi\n\nAs soon as I had a function like this one :\n####\n# Function find_server_by_ip()\n# Desc : This function find the server to use for the current host IP Address\n# Parameters : None\n# Return : echo Server to use\n####\nfunction find_server_by_ip()\n{\n        hostname_ip=$(hostname -I)\n        IFS=\".\"\n        set -- $hostname_ip\n\n        if [[ $3 -eq 78 ]]\n        then\n                echo \"Server A\"\n        else\n                echo \"Server B\"\n        fi\n}\n\n...login stop working. What baffles me is that running this script with *bash add_shortcut.sh* or *./add_shortcut.sh* works fine...\nIs it possible that we can't create functions, parse arrays or anything like that in a script called by /etc/profile? And in that case, where or how can I execute a login script for all the users connecting to the computer? Oh, by the way I am running Ubuntu 12.04 LTS!\nThanks in advance and sorry for my english!\nEDIT : There is a pastebin of the script. I don't add it compeletly since the script comments are in french so...well, there it is : http://pastebin.com/71XzaBk6.\n\nA: Stuff in /etc/profile.d is probably sourced by your window manager when you log in, and that probably uses /bin/sh, so target a POSIX shell, not bash, for scripts to be added there. Note that [[ is not found in the scripts that are in there now.\nSo,\n\n\n*\n\n*choose [ ... ] over [[ ... ]]\n\n*use funcname() { ... } without the function keyword\n\n\ndash is a POSIX (only) shell, so you might find the dash man page handy\n\nComments on http://pastebin.com/71XzaBk6\n\n\n*\n\n*This is the primary error: Change \nif [[ ! -f ~/.gtk-bookmarks ]]\n\nto\n if [ ! -f ~/.gtk-bookmarks ]\n\n\n*the find_server_by_ip function can be simplified:\nfindserverbyip() {\n    case \"$(hostname -I)\" in \n        *[0-9].33.9.[0-9]*) share_server=serverB ;;\n        *)                  share_server=serverA ;;\n    esac\n}\n\nAlso, this comment is misleading: the function returns nothing, it has a side effect.\n# Return : echo Server to use\n\n\n*might as well remove the shebang line: this script doesn't get executed, it gets sourced.\n", "Q: external display resolution vga output I am using a Toshiba laptop with an ati radeon graphics card.\nI have installed ubuntu 12.04 via wubi.\nI am trying to output to my external display which has a native resolution of 1280x768, but it is being recognised as an unknown display and limited to 1024x768.\nI have installed all updates and the additional drivers section in the system settings says there are no proprietary drivers available.\nWhen I use the much discussed cvt and xrandr method I get this:\n~$ xrandr\nScreen 0: minimum 320 x 200, current 1280 x 800, maximum 8192 x 8192\nVGA-0 connected (normal left inverted right x axis y axis)\n   1024x768       60.0  \n   800x600        60.3     56.2  \n   848x480        60.0  \n   640x480        59.9  \nHDMI-0 disconnected (normal left inverted right x axis y axis)\nLVDS connected 1280x800+0+0 (normal left inverted right x axis y axis) 331mm x 207mm\n   1280x800       60.0*+\n   1280x720       59.9  \n   1152x768       59.8  \n   1024x768       59.9  \n   800x600        59.9  \n   848x480        59.7  \n   720x480        59.7  \n   640x480        59.4  \nDIN disconnected (normal left inverted right x axis y axis)\n\n~$ cvt 1280 768\n# 1280x768 59.87 Hz (CVT) hsync: 47.78 kHz; pclk: 79.50 MHz\nModeline \"1280x768_60.00\"   79.50  1280 1344 1472 1664  768 771 781 798 -hsync +vsync\n\n~$ xrandr --newmode \"1280x768_60.00\"   79.50  1280 1344 1472 1664  768 771 781 798 -hsync +vsync\n\n~$ xrandr\nScreen 0: minimum 320 x 200, current 2304 x 800, maximum 8192 x 8192\nVGA-0 connected 1024x768+1280+32 (normal left inverted right x axis y axis) 0mm x 0mm\n   1024x768       60.0* \n   800x600        60.3     56.2  \n   848x480        60.0  \n   640x480        59.9  \nHDMI-0 disconnected (normal left inverted right x axis y axis)\nLVDS connected primary 1280x800+0+0 (normal left inverted right x axis y axis) 331mm x 207mm\n   1280x800       60.0*+\n   1280x720       59.9  \n   1152x768       59.8  \n   1024x768       59.9  \n   800x600        59.9  \n   848x480        59.7  \n   720x480        59.7  \n   640x480        59.4  \nDIN disconnected (normal left inverted right x axis y axis)\n  1280x768_60.00 (0x2da)   79.5MHz\n        h: width  1280 start 1344 end 1472 total 1664 skew    0 clock   47.8KHz\n        v: height  768 start  771 end  781 total  798           clock   59.9Hz\n\n~$ xrandr --addmode vga-0 1280x768_60.00\nxrandr: cannot find output \"vga-0\"\n\nEven though xrandr tells me that vga-0 is connected, if I try any commands with vga-0 it tells me that it cannot find output vga-0\nI am a complete n00b so please bear with me.\nAny advice would be much appreciated.\n\nA: I believe the displays used in xrandr are case-sensitive. I noticed you said vga-0 instead of VGA-0 so double check!\n", "Q: How do I get my computer to boot directly to Ubuntu Apologies if this is a duplicate, but I have already read several other questions and answers, first and none seem to answer my question...\nI Was running Windows XP and installed Ubuntu using the Windows Installer. When I turn my computer on now, the menu comes up asking me to select whether I want to boot Windows or Ubuntu. Is it possible to just have it automatically boot Ubuntu and not ask as I don't ever want to use XP again?\nEDITED 20/3: After closer looking, have realised that what I'm talking about it NOT the Grub menu -- it's before that -- seems like it's Windows asking me this?  Does anybody know what I'm talking about?  Thanks.\n\nA: Use  grubcustomizer https://launchpad.net/grub-customizer it has nice user interface. You can edit there boot order.\n\nA: I have an old Dell Inspiron 1000.  It, as well as many other older computers, recognize a flash drive as an additional hard drive.  That is where it will show up in the BIOS so you should be able to create a bootable flash drive with your desired version of Ubuntu (UNetbootin is my favorite program for creating it).  Move the flash drive to the top of the list.  If it will boot then you can install from it.  Caution though because everything on the computer will be erased when the hard drive is formatted.\n", "Q: Windows 8.1 and Ubuntu installation black screen I can't install Ubuntu on my new ASUS R510D laptop. I have messed with it for days. My laptop model is R510D. Its an AMD A10 Elite Quad Core. It has a Radeon HD 8670M 2GB card built in. Its running windows 8.1 64 bit and I want to run Ubuntu 64 bit along side of it. I have updated all of my video drivers and updated all of my windows drivers, i have also updated my bios to the latest version (Version 2.15.1227).\nI have shrunk my disk to have unallocated space to install Ubuntu. I made a bootable USB of Ubuntu 13.10 and have set the UEFI bios to FAST BOOT = Disabled, SECURE BOOT = Disabled. I have selected the boot device to be the bootable USB and it loads the GNU GRUB version 1.99 main screen which says \"Try Ubuntu without installing\" \"Install Ubuntu\" and \"Check disc for defects.\" \nIf I try to run or install it will just go to a black screen and do nothing more. If I press cntl+alt+dlt it will go back to the GNU GRUB menu. I can press e and edit the GRUB, so I have tried to add the line NOMODESET before quite splash to no avail. I have changed Quite splash to No splash and I see nothing. I have put NOMODESET after quite splash and even replaced quite splash with NOMODESET. I went back to the bios and tried to run it in Legacy mode by enabling LAUNCH CSM and LAUNCH PXE OpROM. This did nothing to rectify this issue either. \nNothing is working. Does anyone have any idea of what I need to do to install Ubuntu?\nP.S. I thought the USB could be the issue so I downloaded the disk image again, even tried downloading 12.04 and it still hangs on the black screen. So if you're thinking my files or disk is corrupt, thats not it either.\n\nA: You have a graphics card issue. More specifically the \"Radeon HD 8670M\" is your culprit. Hybrid graphics cards for mobile have not played well with Ubuntu in the past. Luckily, many people have this issue. Here is one fix in this thread. If it doesn't work out for you, just google \"Radeon HD 8670M ubuntu\" or anything of the source and you will find tons of information. \nHere is a launchpad thread with similar issue\nThis is a very generic solution\nGood luck! My only wish is that everything worked out of box. \n", "Q: How to fix error while sudo apt-get upgrade I am getting following error on Ubuntu 12.04 server. Everything on this machine was installed using apt-get install and tried to keep it updated as much as possible. After last update I noticed I can no longer update my machine. This is a critical machine and I am not sure if -f will break anything else. Should I use -f?\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nYou might want to run 'apt-get -f install' to correct these.\nThe following packages have unmet dependencies:\nmysql-server-5.5 : Depends: mysql-server-core-5.5 (= 5.5.35-0ubuntu0.12.04.1) but 5.5.35-0ubuntu0.12.04.2 is installed\nE: Unmet dependencies. Try using -f.\n\n\nA: Try the following command sequence:\nsudo apt-get remove mysql-server-core-5.5 mysql-server-5.5 mysql-server\nsudo apt-get update\nsudo apt-get upgrade\nsudo apt-get install mysql-server\n\nInstalling just mysql-server (without the 5.5 suffix) should work.\n", "Q: Install Ubuntu on new computer build I am going to build a new computer and don't want to install/buy Windows as the OS.  I'd like to install the latest version of Ubuntu.  Is this possible or will still need to have a copy of Windows?  And if it's possible do I just follow the Ubuntu installation guide as normal?\n\nA: Certainly.  Just download the version (and flavor - Ubuntu, Kubuntu, Lubuntu, etc) that you want.  Check the MD5Sum \nhttps://help.ubuntu.com/community/HowToMD5SUM\nBurn the ISO to a CD or flash drive at the lowest speed possible.  Boot from the result and try all the applications before you install.  If everything works choose to install.\n\nA: Ubuntu is an operating system.  It replaces other operating systems like Windows.  So no, there is no need for Windows prior to installing Ubuntu.\n\nA: Yes,it is possible to install ubuntu without installing windows.Ubuntu can replace windows.And you can follow the ubuntu installation guide as normal\n", "Q: Lost all my applets when I upgraded (to 13.10). How can I get them back? I upgraded my system to 13.10 from 13.04 and lost all the applets in the normal view of my desktop (I see that they are active when clicking on the workspace switcher, see this image:\n\nI remember that when I upgraded from 12.04 to 13.04, I could not see my applets when I briefly started X in 12.10. I thought, no matter, I'll upgrade to 13.04 first and then look for a fix if necessary. It was not necessary, the applets were back in 13.04.\nThis time, however, there is no upgrading to 14.04 yet and I was wondering if someone knew what package would need to be reinstalled to fix the problem. I am thinking that just by reinstalling something it will help. There are two reasons for that: (1) it worked for me from 12.10 to 13.04, and (2) I got such a response from the Ubuntu forum. \nHowever, what was proposed so far has not worked.\nWhat I'm wondering, also, is whether there could be logs about the problem and if so, where those logs are?\nCould it be related to the theme I'm using?\n\nA: Wow! I found out how to get my applet back. I will have to see what happens on next reload/reboot but the window is definitively here, only it is behind another window, consistently.\nFirst, list all your windows in a console screen as in:\nwmctrl -l\n\nThat gives you a list of windows as follow:\n0x01c00003  0 halk Top Expanded Edge Panel\n0x01c00015  0 halk Bottom Expanded Edge Panel\n0x01800029  0 halk alexis@halk:2014 8\n0x02400002  0 halk XdndCollectionWindowImp\n0x02400005  0 halk unity-launcher\n0x02200006  0 halk Desktop\n0x02400008  0 halk unity-panel\n0x0240000b  0 halk unity-dash\n0x0240000c  0 halk Hud\n0x04a000a0  0 halk upgrade - Lost all my applets last time I upgraded (to 13.10). How can I get them back? - Ask Ubuntu - SeaMonkey\n0x04600055  0 halk Inbox - alexis@m2osw.com - Shredder\n\nAs we can see, wmctrl command shows the name of each window. Part of the list we see: unity-panel and Top Expanded Edge Panel. If you use the -G option as well:\nwmctrl -l -G\n\nYou see the positions too (Geometry):\n0x01c00003  0 0    0    1920 24   halk Top Expanded Edge Panel\n0x02400008  0 0    0    1920 24   halk unity-panel\n\nAnd as you can see those two windows are positioned at exactly the same coordinates: (0, 0), and have the exact same size (1920, 24).\nThe Top Expanded Edge Panel is the one we want above. The unity-panel is the one obstructing our panel applets. \nwmctrl -i -r 0x01c00003 -b add,above\n\nI use the -r option with the XID and not the window title because wmctrl has problems with window names. (see Why wmctrl doesn't work for certain windows?)\nIf you make a mistake and use the wrong XID, you can remove the above property using:\nwmctrl -i -r 0x01C00003 -b remove,above\n\nThis may not be a permanent solution, but it works. All I'll have to do is run a script that finds the window and raise it. The problem probably comes from the order in which things are created when starting X-Windows.\n\nThere is a script one can use to specifically force the Top Expanded Edge Panel to the top:\n#!/bin/sh\nPANEL_XID=`wmctrl -l | awk '/Top Expanded Edge Panel/ { print $1 }'`\nwmctrl -i -r $PANEL_XID -b add,above\n\n", "Q: Sketchup was unable to initialize OpenGL I have installed Sketchup on my computer with with WineTricks, however this time I get the following error message when I start sketchup (after the intro window): \n\nSketchup was unable to initialize Open GL\n\nI googled the error and found out that to solve, as winehq puts it:\n\nIf you get the error \"SketchUp was unable to initialize OpenGL!\", run\n  regedit, open\n  HKEY_CURRENT_USER\\Software\\Google\\SketchUp6\\GLConfig\\Display, and\n  change HW_OK to 1. \"\n\nHowever this doesn't work because what I get is this when I open regedit, I cannot apply any changes because there isn't even a google folder to open!\nIt is not a hardware error because I have installed Sketchup before on this computer with the same operating system (I had to reinstall Ubuntu) and I didn't have that many issues. I have tried Installing sketchup from the main website as I had done previously but it is not working now.\nThank you.\n\nA: I had this problem too: You can find the key by doing this:\n\n\n*\n\n*In the dash, type 'wine' and amongst others it shows the icon for the winetricks program. \n\n*If you start that, you can then choose 'sketchup' in the boxes, and choose to run 'regedit' thereafter... \n\n*Once I did that I could find the key as mentioned above, and change it to a '1'. \n\n*Close it, restart sketchup, and TADA! it works :) \n\n\nA: I had the same problem-- no Google folder when running the regedit.exe found in wine \"drive:c\".  Then I found another regedit in a winetricks submenu, and there it was. I applied winehq's OpenGL fix described by Christian above. This was a Sketchup 8 installation in Mint 17.  Works fine now. \n\nA: I don't really know what I am doing BUT . . . \n\n\n*\n\n*Open the file broszer\n\n*Look for the 'playonlinuxes virtual drives' in my user root directory.\n\n*Clicked the triangle to show the contents\n\n*Saw googlesketchup8\n\n*Clicked the triangle to show the contents\n\n*Opened user.reg with the text editor\n\n*Search for \"HW_OK\"\n\n*Change the last 0 to a 1\n\n*Save and exit\n\n*this time - no opengl error.\n\n", "Q: I have forgotten my Ubuntu One password I have forgotten my Ubuntu One password.  \nHow can I reset my Ubuntu One password, without knowing the original password?\nOr do I need to start a new account?\n\nA: Go here.\nThe site walks you through the process.\n", "Q: NVIDIA drivers not working with more recent Ubuntu releases I have a late 2012/early 2013 iMac with the following graphics card (lspci)\n01:00.0 VGA compatible controller: NVIDIA Corporation GK107M [GeForce GT 640M Mac Edition] (rev a1)\n\nI have tried the latest Ubuntu releases (and even Debian Jessie) - kernels 3.{10, 11, 12, 13} -  but when I use the NVIDIA drivers, the screen goes completely dead and I have to power cycle.\nWhen I reboot into a headless console, the log files contain the error\nEVO Push buffer channel allocation failed\n\nI have been able to get the card to work using the NVIDIA 304 version of drivers and going back to Ubuntu Raring (with kernel 3.8.0) but only if I add the following to the Devices section of my /etc/X11/xorg.conf where I declare the nvidia driver.\nOption \"UseDPLib\" \"off\"\n\nI'd really like to be moving onto Saucy / Trusty (when its released) with a working NVIDIA driver... but how do I get past this apparent kernel incompatibility? I really don't want to be stuck with a non-LTS going forward.\nThere is a somewhat related thread on NVIDIA DevTalk but it's not going anywhere, although I have been told that NVIDIA have assigned internal bug number 1483494 :-(\nUPDATE: driver version 313-updates on Raring also works, which I believe is the most recent driver on that distro.\n\nA: On my Thinkpad P51 running Ubuntu 20.04 I fixed the issue by downgrading the driver to 390.\nIf you really can't get it to work, then try just using the intel driver. Sometimes it really is just the best option.\n", "Q: Swap Area partition I created a swap area with gparted successfully.How can know if swap area is created? I created the swap area after the Ubuntu installation. When i write swapon -s command to terminal there appears one table but it is empty. The \"filename option\", \"size option\" are all empty. Why?\n\nA: The swapon -s command is what you want to use to see your swap partition that are active.\nTo know whether you have a swap partition on disk, use parted.\nNow what you probably want is to use the swap partition... It should appear in your file /etc/fstab as something that looks like this:\n# swap was on /dev/md7 during installation\nUUID=4be93050-8c7c-4975-8729-7af473de4847 none            swap    sw              0       0\n\nOnce you edited the /etc/fstab, run the swapon command like this to activate your swap:\nswapon -a\n\nIf you know the UUID of your partition, it is easy to add. Assuming you created that one additional partition, you can find the list here:\nls /dev/disk/by-uuid\n\nand you should be able to deduce what UUID it is (i.e. the one that's not used anywhere else.)\n", "Q: Empathy doesn't show the message, only \"minus\" signal I'm using Empathy on my Ubuntu (13.10) and sometimes when I receive the first message, it open the windows, but doesn't show any message, only the \"-1 not readed\".\nAny idea what that means?\n\n\nA: it's a bug i believe. The workaround is to close the window, open empathy and double-click on the contact name to open a new window. The text will then show up. \nPlease, sign in on launchpad and add yourself to the bug https://bugs.launchpad.net/indicator-messages/+bug/1019609, it will add some weight so it gets fixed faster :)\n", "Q: Intellij unable to fetch from git I've cloned an existing git repository. Git is working fine when I pull using command line. However, when I try doing the same from Intellij, it says \nFetch failed. Fatal : Could not read from remote repository.\n\nVCS console log shows:\ngit fetch --progress --prune origin\njava.lang.RuntimeException: Invocation failed Server returned invalid Response.\n    at org.jetbrains.git4idea.ssh.GitSSHXmlRpcClient.askPassword(GitSSHXmlRpcClient.java:176)\n    at org.jetbrains.git4idea.ssh.SSHMain.authenticate(SSHMain.java:265)\n    at org.jetbrains.git4idea.ssh.SSHMain.start(SSHMain.java:157)\n    at org.jetbrains.git4idea.ssh.SSHMain.main(SSHMain.java:137)\nCaused by: java.io.IOException: Server returned invalid Response.\n    at org.apache.xmlrpc.LiteXmlRpcTransport.sendRequest(LiteXmlRpcTransport.java:243)\n    at org.apache.xmlrpc.LiteXmlRpcTransport.sendXmlRpc(LiteXmlRpcTransport.java:90)\n    at org.apache.xmlrpc.XmlRpcClientWorker.execute(XmlRpcClientWorker.java:72)\n    at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:194)\n    at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:185)\n    at org.apache.xmlrpc.XmlRpcClient.execute(XmlRpcClient.java:178)\n    at org.jetbrains.git4idea.ssh.GitSSHXmlRpcClient.askPassword(GitSSHXmlRpcClient.java:170)\n    ... 3 more\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\n\nI'm using ssh key pair for authentication. I'd appreciate any help on this. \n\nA: For IntelliJ 13/14, \n\n\n*\n\n*Click File-> Settings. Keyboard shortcut is Ctrl+Alt+S.\n\n*Search for \"Version Control\" \n\n*Choose \"Git\" under \"version Control\"\n\n*In the SSH executable dropdown, choose Native\n\n", "Q: How to widen \"Window List Item\" boxes in (Cinnamon) Gnome Desktop to fit? I was able to increase the size of GNOME panels that hold the Window List Item boxes by modifying the \"width\" property of the \".window-list-item-box\" CSS class of cinnamon.css (in the Cinnamon desktop), but now the label width has not expanded to fit this.  I tried tweaking the width and paddings of the same class and the window-list-item-label class to no avail... Anyone have any suggestions?  See the picture below for more details.\n.window-list-item-box {\n    color: rgba(255,255,255,1.0);\n        background-gradient-direction: vertical;\n        background-gradient-start: rgba(100,100,100,0.5);\n        background-gradient-end: rgba(50,50,50,0.5);\n        box-shadow: inset 0px 0px 0px 1px rgba(80,80,80,0.5);\n    border-radius: 4px 4px 0px 0px;\n    padding: 1px;\n    padding-left: 5px;\n    padding-right: 5px;\n    transition-duration: 100;\n    width: 400px;\n}\n\n\n\nA: I was able to hack this functionality into the code of cinnamon 2.2 running on debian 8. This should also work on Ubuntu, maybe the path is a bit different.\n\n\n*\n\n*open this file in an editor /usr/share/cinnamon/applets/window-list@cinnamon.org/applet.js\n\n*find function _getContentPreferredWidth: function(actor, forHeight, alloc)\n\n*change alloc.natural_size = 150 * global.ui_scale; to alloc.natural_size = 350 * global.ui_scale; where 350 is your desired width. \n\n\nGood luck!\n", "Q: How to rollback an \"apt-get install dist-upgrade\"? In order to get up-to-date with some kernel libraries, I tried to upgrade my Ubuntu 13.10 using sudo apt-get install dist-upgrade. However, after upgrading it the results were not satisfactory at all and, as a matter of fact, I am experiencing some performance issues now and slow booting…\nI browsed several forums and solutions in order to rollback my system as it was before upgrade. However I didn't find an official solution so far, such as apt-get rollback ... sort of.\nThe most reasonable (and smart) solution I have found it was look up at the /var/log/apt/history.log and browse the content for the latest upgrade to find the previous libraries versions and manually reinstalling each one of them (and removing the new ones prior).\nThere is a reasonable solution that helped me out to figure this workaround.  \nHowever, I was wondering if maybe someone has knowledge about any official tool to perform such rollback operation. \nDoes anyone has any ideas to rollback an upgraded system?\nI would really appreciate any efforts, thanks in advance!\n\nA: I think that short of having a backup before the upgrade and revert to it, it's almost impossible in general. \nThe upgrade can have modified config files that could possibly not work with older version... and there is normally no track of this and no automated way to go back. \nWhen brtfs will be ready for prime time, we could have snapshots before each upgrade, but for now, your idea is the most viable one. \nAlthough I suggest trying to see if you can find what caused a problem, and eventually file a bug report about it. Having \"held\" packages is a sure way to problems in the future. \n", "Q: How to uninstall Popcorn-Time installed with a script? I've installed Popcorn Time using the following command:\ncd\nwget https://raw.github.com/hotice/webupd8/master/popcorn-build\nchmod +x popcorn-build\n./popcorn-build\n\nthat I found here. \nHow can I uninstall it?\n\nA: Since this is my script (rewritten a bit by Webupd8's Andrew), this should work : \n\n\n*\n\n*uninstalling Popcorn Time :\nsudo rm -r /opt/Popcorn-Time\nsudo rm /usr/share/pixmaps/popcorntime.png\nsudo rm /usr/share/applications/popcorn-time.desktop\nsudo rm /usr/bin/popcorn-time\n\n\n*remove the NodeJS\nsudo add-apt-repository -r ppa:chris-lea/node.js\nsudo apt-get remove nodejs\nsudo rm /usr/bin/node\n\n\n*remove Ruby : \n\n\n*\n\n*if 12.04 : sudo apt-get remove rubygem\n\n*if 13.04 or higher : sudo apt-get remove ruby-compass\n\n\n*remove Git, NPM :\nsudo apt-get remove git npm\n\n\n*remove 'libudev' symlink : \n\n\n*\n\n*if 32 bits : sudo rm /lib/i386-linux-gnu/libudev.so.0\n\n*if 64 bits : sudo rm /lib/x86_64-linux-gnu/libudev.so.0\n\nOnce it's done, you can clean up : \nsudo apt-get autoremove -y\nsudo apt-get autoclean\nsudo apt-get update\n\n", "Q: What is the apt-get equivalent of this command? What is the apt-get equivalent of the following command?\naptitude -r install linux-headers-$(uname -r|sed 's,[^-]*-[^-]*-,,') <package name>\n\nThanks.\n\nA: apt-get install linux-headers-$(uname -r|sed 's,[^-]*-[^-]*-,,') <package name>\n\nFor the record, this just installs the linux headers (likely, linux-headers-generic) and any additional packages you specify.\n", "Q: CPU frequency not changing in Ubuntu 13.10 Thinkpad T440 I'm using a Thinkpad T440 with Ubuntu 13.10, and Turboboost doesn't seem to be working. The processors almost always remain at the minimum, 0.8Ghz.\nHere is the output of turbostat:\ncor CPU    %c0  GHz  TSC SMI    %c1    %c3    %c6    %c7 CTMP PTMP   %pc2   %pc3   %pc6   %pc7   %pc8   %pc9  %pc10  Pkg_W  Cor_W GFX_W\n         99.96 0.80 2.49   0   0.04   0.00   0.00   0.00   49   50   0.00   0.00   0.00   0.00   0.00   0.00   0.00   4.52   1.68  0.02\n  0   0  99.99 0.80 2.49   0   0.01   0.00   0.00   0.00   49   50   0.00   0.00   0.00   0.00   0.00   0.00   0.00   4.52   1.68  0.02\n  0   1  99.99 0.80 2.49   0   0.01\n  1   2  99.87 0.80 2.49   0   0.13   0.00   0.00   0.00   47\n  1   3  99.99 0.80 2.49   0   0.01\n\nDuring this, I'm running 4 busy loops so htop reports every core to be running at 100%.\nMy processor: Intel® Core™ i5-4300U CPU @ 1.90GHz × 4\nAnyone have any guesses why the cpu frequency doesn't update?\n\nA: You can also monitor frequency changes using my GUI , and beside that, low, high & Turbo ratios.\nYou will be surprise that standard /proc/cpuinfo is not accurate because the Base Clock is not updated. Check one of the Widgets I named System Information.\nIn the other Widget named Cores, click Task to see in real time which processes are hogging your  CPUs.\nYou can get source code and instructions at http://code.google.com/p/xfreq/\n\nA: Still not sure what was causing the problem, but I just decided to update to Ubuntu 14.04 (Beta 1) and the CPU seems to be scaling properly now.\n", "Q: Installing All Packages in a PPA How do I download all of the packages contained within a particular PPA in one command, without explicitly listing out each package?\nFor example, say I want to download all 108 or so packages contained within the Backbox PPA without having to type out each package like this:\nsudo apt-get install package1, package2, package3, package4, package5\n\nHow would I go about doing this?\n\nA: In general, you don't. If the owner of the PPA has made a meta-package, which depends on all the other packages in the PPA, then you would be able to install that package and it will pull in everything else.\nIn the case of the Backbox PPA you mentioned, this has been done via the backbox-meta source package, which provides the backbox-minimal, backbox-desktop, and backbox-server meta packages, which depend on different sets of packages in that archive. Assuming it is updated, and all three packages depend on everything else in the PPA, you can run sudo apt-get install backbox-minimal backbox-desktop backbox-server to install everything.\n\nA: I am unsure if you have found the answer, but here is what worked for me:\nsudo apt-get install backbox-tools\n\nI hope this helps.\n\nA: The work has been done for you. Use one of the following commands:\nsudo apt-get install backbox-minimal\nsudo apt-get install backbox-desktop\nsudo apt-get install backbox-server\n\nThe backbox-desktop metapackage has all of the packages, while backbox-minimal will give you a functional command-line system.\n", "Q: Is there a way to downgrade Ubuntu without losing any files? I want to downgrade ubuntu 13.10 to ubuntu 12.04 LTS without losing the installed apps and my files in the ubuntu folders.\n\nA: Downgrading is very tricky and it is very un-recommended. However if you insist, you can follow the guide from Ubuntu community page:\nhttps://help.ubuntu.com/community/DowngradeHowto\n", "Q: Firefox install I know I probably sound like a retard but I downloaded firefox earlier to replace netsurf because of stupid errors and I don't know how to open a browser that isn't netsurf. I have firefox-28.0.tar.bz2 downloaded and I need help to open it.\n\nA: Firefox is installed by default on Ubuntu. But if you're using a different variant and don't have it, you can download it using the command\nsudo apt-get install firefox\n\nthen press Enter. You will be asked to enter the privileged account password to proceed.\nFor more information about installing Firefox on Ubuntu, follow the links below\n\n\n*\n\n*HowTo Install the Latest Firefox in Ubuntu (Ultimate HowTo)\n\n*Firefox New Version - Community Help Wiki \n\n*Install Firefox on Linux | Firefox Help\n", "Q: How do I do a clean install I've been a user of version 12.04 for about 6 months with a dual boot system with Windows.  In an attempt to delete Windows, I made a mistake and needed to reformat the Hard Drive.  I had version 12.04 on a CD and tried to do a boot install.  It didn't work, probably because I needed the correct installer.  I found an old thumb drive with Ubuntu installed, and was able to load version 10.10, thinking that the update process would be easy.  Unfortunately, it wouldn't update because the support for that version ended last year. So I downloaded the current version 12.04.4 to both a DVD and to a thumb drive, but neither would install.  I tried to work with the terminal function, but have not been able to figure out the correct syntax.  Help.  Should I reformat the drive, if so, How? Or is there another way to install version 12.04 that I haven't tried?\nKen\n\nA: From a Windows machine you can download and run the USB installer recommend by Ubuntu here. You will also need the .iso file for your machine from ubuntu here. Once you have the .iso installed onto your USB pendrive (should be at least 4GB), you can configure the BIOS of your computer to boot from a USB drive and install Ubuntu fresh onto the machine. Hope this helps! \n\nA: Even from an outdated ubuntu system you can download the iso and save to your computer, then you need to create a usb installer to make a bootable usb drive.  It's pretty easy, and pretty much the same thing you would do in windows.  I also tried to save the iso directly to my usb and it didn't work.  Save to computer first, then create bootable usb.  Good luck!\n", "Q: LAN but no WAN acess I have just moved and when I did I received a new DSL modem. I have set it up as a transparent bridge as I have an internal router. It is just like I had done before, except I got rid of my static IP. I changed my Ubuntu server to DHCP. I can access any system on the LAN and even ping them. I have no WAN access. I have three other windows machines on the system and they can all use the WAN. I have the following information:\nifconfig\neth0      Link encap:Ethernet  HWaddr 90:2b:34:83:19:99  \n          inet addr:192.168.1.102  Bcast:192.168.1.255  Mask:255.255.255.0\n          inet6 addr: fe80::922b:34ff:fe83:1999/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:26551 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:3720 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:2277376 (2.2 MB)  TX bytes:315728 (315.7 KB)\n          Interrupt:41 Base address:0xa000 \n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:1152 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1152 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:340833 (340.8 KB)  TX bytes:340833 (340.8 KB)\n\nvirbr0    Link encap:Ethernet  HWaddr 6a:6b:63:67:72:ce  \n          inet addr:192.168.122.1  Bcast:192.168.122.255  Mask:255.255.255.0\n          UP BROADCAST MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nroute\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\ndefault         APT             0.0.0.0         UG    100    0        0 eth0\nlink-local      *               255.255.0.0     U     1000   0        0 eth0\n192.168.1.0     *               255.255.255.0   U     0      0        0 eth0\n192.168.122.0   *               255.255.255.0   U     0      0        0 virbr0\n\nping LAN:\n\nPING 192.168.1.1 (192.168.1.1) 56(84) bytes of data.\n64 bytes from 192.168.1.1: icmp_req=1 ttl=64 time=0.666 ms\n64 bytes from 192.168.1.1: icmp_req=2 ttl=64 time=0.652 ms\n64 bytes from 192.168.1.1: icmp_req=3 ttl=64 time=0.608 ms\n64 bytes from 192.168.1.1: icmp_req=4 ttl=64 time=0.622 ms\n\n--- 192.168.1.1 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3000ms\nrtt min/avg/max/mdev = 0.608/0.637/0.666/0.023 ms\n\nping WAN:\n\nPING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.\n\n--- 8.8.8.8 ping statistics ---\n4 packets transmitted, 0 received, 100% packet loss, time 3022ms\n\n\n/etc/resolv.conf shows:\n\n**# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\n#     **DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\nnameserver 192.168.1.1****\n\n\n/etc/network/interfaces shows:\n\n# This file describes the network interfaces available on your system\n# and how to activate them. For more information, see interfaces(5).\n\n# The primary network interface\nauto eth0\niface eth0 inet dhcp\n\n# The loopback network interface\nauto lo\niface lo inet loopback\n\ngateway 192.168.1.1\n\nAny help? I am really frustrated with this.\n\nA: Here are a few steps I would take:\n\n\n*\n\n*Check the output of iptables -L to ensure you aren't firewalling. \n\n*Ping APT which appears to be your router (192.168.1.1).  \n\n*If you have traceroute or mtr installed try using it to find out where your are blocked.  I use mtr -ni5 8.8.8.8. \n\n*Check DNS with a command like host google.com.\n\n*Check /etc/resolv.conf to ensure it has reasonable data.\n\n", "Q: After downloading ubuntu 13.10, I cannot get an internet connection, why? I have read multiple answers to this questions, but none of them apply to someone with no ubuntu experience. Please make suggestions as though you are speaking to someone with no knowledge. I have tried may of the things suggested and none have worked, but it could be because I am doing it incorrectly. Thanks!\n\nA: I believe this is because you are having a wireless card with proprietary driver, so the driver is not installed by default after installation.\nYou try plugin your computer to a wired LAN. Open the Software & Updates, browse to Additional Drivers, your driver is probably there, you just need to enable the option to install it.\n", "Q: Popular application Unetbootin executible file does nothing Grabbed unetbootin-linux-585 because I want to make an installation flash drive for Ubuntu 12.04 (13.10 is unusable with bugs). I don't normally work with downloaded executables in linux, but I followed the instructs on the website. I changed the file property to 'executable' and ran chmod +x on the file location. When I try to run the file graphically or via the terminal, nothing happens. This can't be a problem with the software; it's too widely known and used. It should do something when executed. I'm working in a fresh installation of Ubuntu 13.10. What can I do?\nEdit: the exact command, as requested: chmod +x ./Downloads/unetbootin-linux\nEverything else was done graphically. The file is checked to run as an executable and the permissions are Read and Write for Owner and Group. Nothing happens. \nI can open a terminal and type ./Downloads/unetbootin-linux-585 which returns a fresh prompt, no hanging. I rebooted my computer and downloaded a fresh copy of the file and repeated these steps. Still nothing.\nI could just use the windows version to complete this task, but I'm concerned that if something as simple as running an executable, without adding repositories or using a package manager, isn't going to work, then it indicates something more broadly wrong with my configuration. This is my second fresh install of 13.10 in as many days. Things haven't been functioning smoothly.\n\nA: Try to install unetbootin from the repository(Universe).Run the below command on terminal to install unetbootin,\nsudo apt-get install unetbootin\n\nRun the below command to enable universe repository,\nsudo add-apt-repository universe\n\nAnd don't forget to update the repositories before installing unetbootin.\nsudo apt-get update\n\n", "Q: Installation of Ubuntu 13.10 desktop from ISO file I downloaded ubuntu-13.10-desktop-i386.iso from my Ubuntu 10.04 LTS. How to install ubuntu-13.10-desktop-i386.iso from my Ubuntu 10.04 LTS\n\nA: You must write the ISO to USB or CD/DVD as an ISO image using special tools like UNetBootIn or Brasero respectively (not just like your are saving a file); ISO image must have boot record\n\n\n*\n\n*then insert your usb or cd into the machine\n\n*reboot the machine\n\n*quickly access your BIOS with hotkey on your keyboard (mine is Delete) some machines is different (you must first know what that is)\nyou can always restart your machine and hit hotkey to access bios before boot\n\n*you must find the boot selection in your BIOS \n\n\n*\n\n*(select cdrom if you have CD)\n\n*(select USB to boot is USB iso)\n\n\n*with your cd or usb in your machine at restart the installation should begin by itself, be patient for this, the screen might go blank or black for a minute \n\n*when install is complete, the program will say to restart machine\ndo not take out your disk or usb\n\n*upon restart - access again your BIOS\n\n*change boot to HDD (hard drive you have installed OS on)\n\n*let machine boot up from HD with new installation\nyou can repeat these tasks if you need to\nPractice makes perfect!!! Good Luck.\n", "Q: Zip file help Final Core I downloaded a game called Final Core and it is a zip file that I don't know how to open.\nif anybody knows please help,\nThanks\n\nA: In the GUI of Nautilius, simply double-click. It may ask you to install some packages, but it will guide you through that.\nIn the console, make sure you have the zip package installed. (Try running zip)\nIf it works:\n\n\n*\n\n*cd /path/to/the/zip/\n\n*mkdir extract (OPTIONAL, BUT RECOMMENDED)\n\n*mv file.zip extract/ (OPTIONAL, BUT RECOMMENDED) (Needed if above was run)\n\n*cd extract/ (OPTIONAL, BUT RECOMMENDED) (Needed if above was run)\n\n*unzip file.zip\n\n*Open Nautilus/whatever and browse to that folder\n\n*???\n\n*Profit.\n\n\nIf zip DOESN'T work:\n\n\n*\n\n*sudo apt-get install zip\n\n*Proceed from steps above, or Nautilus.\n\n", "Q: What is the difference between different \"compression\" systems? I've always used TAR and ZIP for compression, but recently I have heard about the *.Z compression algorithm. This brought up a question for me:\nWith all of these compression systems, which one is best for general use and compression?\nRunning a few tests, I have discovered that tar, as I discovered, does NOT really compress (unless explicitly specified). Meaning, what is it good for compared to other compression methods?\nI am already aware that ZIP is the most widely-used compression system, but should I use it instead of *.Z, *.7z, .tar, or .tar.<insert ending here>?\nPost Summary:\n\n\n*\n\n*Should I use *.tar, *.Z, *.7z, .tar, or .tar.<insert ending here> for the best compression?\n\n*If plain *.tar doesn't compress, why do we use it?\n\n\nEDIT: Not all algorithms allow storing of Linux permissions (from what I learned). Which do, and is there some sort of hack (or script) I could use to store permissions?\n\nA: The details of the algorithms are off topic here1 since they are not in any way specific to Linux, let alone Ubuntu. You will, however, find some nice info here.\nNow on to tar, as you said, tar is not and never has been a compression program. Instead, it is an archiver; its primary purpose is to make one big file out of a lot of small ones. Historically this was to facilitate storing on tape drives, hence the name: Tape ARchive. \nToday, the primary reason to use tar is to decrease the number of files on your system. Each file on a Unix file system takes up an inode, the more files you have, the fewer inodes available and when you run out of inodes, you can no longer create new files. To put it simply, the same amount of data stored as thousands of files will take up more of your hard drive than those same files in a single tar archive.\nTo illustrate, since this has been contested in the comments, on my 68G / partition, I have the following number of total and used inodes (bear in mind that inode count depends on the file system type and the size of the partition):\nInode count:              393216\nFree inodes:              171421\n\nIf I now proceed to attempt to create more files than I have inodes:\n$ touch {1..171422}\ntouch: cannot touch ‘171388’: No space left on device\ntouch: cannot touch ‘171389’: No space left on device\ntouch: cannot touch ‘171390’: No space left on device\ntouch: cannot touch ‘171391’: No space left on device\ntouch: cannot touch ‘171392’: No space left on device\ntouch: cannot touch ‘171393’: No space left on device\ntouch: cannot touch ‘171394’: No space left on device\ntouch: cannot touch ‘171395’: No space left on device\ntouch: cannot touch ‘171396’: No space left on device\ntouch: cannot touch ‘171397’: No space left on device\n\nNo space? But I have loads of space:\n$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1       5,8G  4,3G  1,2G  79% /\n\nAs you can see above, creating a few hundred thousand empty files rapidly depletes my inodes and I can no longer create new ones. If I were to tar these I would be able to start creating files again.\nHaving fewer files also greatly speeds up the file system I/O especially on NFS mounted filesystems. I always tar my old work directories when a project is finished since the fewer files I have, the faster programs like find will work. \nThere is a great answer on Super User that goes into far more detail, but in addition to the above, the other basic reasons why tar is still popular today are:\n\n\n*\n\n*Efficiency: using tar to pipe through a compression program like gzip is more efficient since it avoids the creation of intermediate files.\n\n*tar comes with all sorts of bells and whistles, features that have been designed over its long history that make it particularly useful for *nix backups (think permissions, file ownership, the ability to pipe data straight to STDOUT and over an SSH link...)\n\n*Inertia. We're used to tar. It's safe to assume it will be available on any *nix you might happen to use which makes it very portable and handy for source code tarballs. \n\n1 This is absolutely true and has nothing to do with the fact that I don't know enough about them to explain :)\n\nA: There are two distinct but related tasks.  Packing a tree of files\n(including filenames, directory structure, filesystem permissions,\nownership and any other metadata) into a byte stream is called\narchiving.  Removing redundancy in a byte stream to produce a\nsmaller byte stream is called compression.\nOn Unix, the two operations are separated, with distinct tools for\neach.  On most other platforms (current and historical) combined tools\nperform both archiving and compression.\n(gzip and other programs that mimic gzip's interface often have the\noption to store the original filename in the compressed output, but\nthis, along with a CRC or other check to detect corruption, is the\nonly metadata they can store.)\nThere are advantages to separating compression from archiving.\nArchiving is platform-specific (the filesystem metadata needing\npreserving varies widely), but the implementation is straightforward,\nlargely I/O-bound, and changes little over time.  Compression is platform-independent, but implementations are CPU-bound\nand algorithms are constantly improving to take advantage of the\nincreased resources that modern hardware can bring to bear on the\nproblem.\nThe most popular Unix archiver is tar, although there exist others\nsuch as cpio and ar.  (Debian packages are ar archives, while\ncpio is often used for inital ramdisks.)  tar is or has often been\ncombined with compression tools such as compress (.Z), gzip (.gz),\nbzip2 (.bz2) and xz (.xz), from oldest to youngest, and not\ncoincidentally from worst to best compression.\nMaking a tar archive and compressing it are distinct steps: the\ncompressor knows nothing about the tar file format.  This means that\nextracting a single file from a compressed tar archive requires\ndecompressing all of the preceding files.  This is often called a\n\"solid\" archive.\nEqually, since tar is a \"streaming\" format--required for it to be useful in a\npipeline--there is no global index in a tar archive, and listing the\ncontents of a tar archive is just as expensive as extracting it.\nBy contrast, Zip and RAR and 7-zip (the most popular archivers on\nmodern Windows platforms) usually compress each file separately, and\ncompress metadata lightly if at all.  This allows for cheap listing of\nthe files in an archive and extraction of individual files, but\nmeans that redundancy between multiple files in the same archive\ncannot be exploited to increase compression.  While in general\ncompressing an already-compressed file does not reduce file size\nfurther, occasionally you might see a zip file within a zip file: the\nfirst zipping turned lots of small files into one big file (probably\nwith compression disabled), which the second zipping then compressed\nas a single entity.\nThere is cross-pollination between the differing platforms and\nphilosophies: gzip is essentially zip's compressor without its\narchiver, and xz is essentially 7-zip's compressor without its\narchiver.\nThere are other, specialized compressors.  PPM variants and their\nsuccessor ZPAQ are optimized for maximum compression without regard to\nresource consumption.  They can easily chew up as much CPU and RAM as\nyou can throw at them, and decompression is just as taxing as\ncompression (for contrast, most widely-used compression tools are\nasymmetric: decompressing is cheaper than compressing). \nOn the other end of the spectrum, lzo, snappy and LZ4 are \"light\"\ncompressors designed for maximum speed and minimum resource\nconsumption, at the cost of compression.  They're widely used within\nfilesystems and other object stores, but less so as standalone tools.\n\nSo which should you pick?\nArchiving:\nSince you're on Ubuntu there's no real reason to use anything other\nthan tar for archiving, unless you're trying to make files that are\neasily readable elsewhere.\nzip is hard to beat for ubiquity, but it's not Unix-centric and will\nnot keep your filesystem permissions and ownership information, and\nits baked-in compression is antiquated.  7-zip and RAR (and ZPAQ) have\nmore modern compression but are equally unsuited to archiving Unix\nfilesystems (although there's nothing stopping you using them just as\ncompressors); RAR is also proprietary.\nCompression:\nFor maximum compression you can have a look at a benchmark, such as the\nenormous one at http://mattmahoney.net/dc/text.html.  This should give\nyou a better idea of the tradeoffs involved.\nYou probably don't want maximum compression, though.  It's way too\nexpensive.\nxz is the most popular general-purpose compression tool on modern Unix\nsystems.  I believe 7-zip can read xz files too, as they are closely\nrelated.\nFinally: if you're archiving data for anything other than short-term\nstorage you should pick something open-source and preferably\nwidespread, to minimize headaches later on.\n\nA: tar stands for tape archive.  All it does is pack files, and their metadata ( permissions, ownership, etc ) into a stream of bytes that can be stored on a tape drive ( or a file ) and restored later.  Compression is an entirely separate matter that you used to have to pipe the output through an external utility to compress if wanted that.  GNU tar was nice enough to add switches to tell it to automatically filter the output through the appropriate utility as a shortcut.\nZip and 7z combine the archiving and compression together into their own container format, and they are meant to pack files on a DOS/Windows system, so they do not store unix permissions and ownership.  Thus if you want to store permissions for proper backups, you need to stick with tar.  If you plan on exchanging files with Windows users, then zip or 7z is good.  The actual compression algorithms zip and 7zip use can be used with tar, by uzing gzip and lzma respectively.\nlzma ( aka. *.xz ) has one of the best compression ratios, and is quite fast at decompression, making it a top choice these days.  It does however, require a ton of ram and cpu time to compress.  The venerable gzip is quite a bit faster at compression, so may be used if you don't want to dedicate that much cpu time.  It also has an even faster variant called lzop.  bzip2 is still fairly popular as it largely replaced gzip for a time before 7zip/lzma came about, since it got better compression ratios, but is falling out of favor these days since 7z/lzma is faster at decompression and gets better compression ratios.  The compress utility, which normally names files *.Z, is ancient and long forgotten.\nOne of the other important differences between zip and tar is that zip compresses the data in small chunks, whereas when you compress a tar file, you compress the whole thing at once.  The latter gives better compression ratios, but in order to extract a single file at the end of the archive, you must decompress the whole thing to get to it.  Thus the zip format is better at extracting a single file or two from a large archive.  7z and dar allow you to choose to compress the whole thing ( called \"solid\" mode ) or small chunks for easy piecemeal extraction.\n\nA: lzo, gz, b2, lzma (.lzma2 =.xz) are \"stream\" compressors: they compress a stream of byes an don't know and don't care about files, directories and metadata like permissions. You have to use an archiver like tar to bundle all that data into a stream of bytes (a tar file) and compress that with a compressor. If it is the data of a single file you care about, you could also feed that file alone to one of these compressors.\nTar, cpio and pax are archivers: they take a bunch of files and directories and encode the data and metadata in a single file. tar is the most popular and most compatible though the technical merits between the three are minimal enough that there were religious wars about it during the dawn of time.\n7z and zip are compressors AND arcihvers: Then store all the data and meta data and compress it. However AFAICT, neither of them save unix permissions. \nZip uses the same algorithm as gzip called DEFLATE. 7z uses the lzma algorithm\nto read a single file from a tar.gz or the like, you will need to decompress the whole gz stream till the enough of the tar file is exposed so you can extract it. Zip allows you to compress and pull out each file individually. 7z can have either behavior.\nCompression ratios and speeds:\ngzip and lzo have very very fast compression and decompression speeds but low compression ratios. It also does not take much memory to compress. gzip is a little slower and gives a little better compression ratio than lzo.\nIt is so fast, it can be faster to read a gz or lzo compressed file from the disk and decompress it on the fly instead of reading the uncompressed file directly from the disk.\nLZMA (xz) gives excellent compression on general data but takes very long to compress and decompress along with taking significant amounts of memory to compress. \nbz2 used to be the high compression algorithm of choice but fell out of favour as it is both slower than lzma and takes longer to compress and decompress. However for certain kinds of data (dna sequences, files with very large runs of the same byte etc) bzip2 can beat everything else hands down. As an example, I once had to compress a 4GB file of 1's and b2 reduced i to a few 10's of kb while lzma took some 10's of MBs if I remember correctly.\n\nA: For especially large files, you can use rzip. It first looks at redundant data inside of 900 MB large blocks, encodes these, and then hands the data over to bzip2 (not really, but the same algorithms are used).\nEffect? Much faster than xz, lzma or bzip2, and in my experience its compression ratio rivals that of lzma. It is a RAM hog, though.\nhttp://en.wikipedia.org/wiki/Rzip\n\nA: gzip's compression algorithm has been the traditional best-known most-used compression algorithm a long time. (zlib is a library that implements it.)\nbzip2 was invented later and was suggested as an algorithm that frequently might give better compression ratios than gzip on the usual data, however, it was more slow (computation-costly) compared to gzip.\nbzip2 as an alternative to gzip has been recently mostly obsoleted by modern algorithms.\nFor example, xz -0 is stated in its manpage (man xz) to be \"sometimes faster than gzip -9 while compressing much better\".\nThere are also other modern algorithms that are well-suited for on-the-fly compression and decompression (apart from gzip) by having high throughput (speed) and hence are popular for use in the kernel for filesystem, block-device, and memory compression (but also for fast compression of normal files).\nlzo, lz4 and zstd comparison is nicely presented at https://github.com/lz4/lz4:\n|  Compressor             | Ratio   | Compression | Decompression |\n|  ----------             | -----   | ----------- | ------------- |\n|  memcpy                 |  1.000  | 13700 MB/s  |  13700 MB/s   |\n|**LZ4 default (v1.9.0)** |**2.101**| **780 MB/s**| **4970 MB/s** |\n|  LZO 2.09               |  2.108  |   670 MB/s  |    860 MB/s   |\n|  QuickLZ 1.5.0          |  2.238  |   575 MB/s  |    780 MB/s   |\n|  Snappy 1.1.4           |  2.091  |   565 MB/s  |   1950 MB/s   |\n| [Zstandard] 1.4.0 -1    |  2.883  |   515 MB/s  |   1380 MB/s   |\n|  LZF v3.6               |  2.073  |   415 MB/s  |    910 MB/s   |\n| [zlib] deflate 1.2.11 -1|  2.730  |   100 MB/s  |    415 MB/s   |\n|**LZ4 HC -9 (v1.9.0)**   |**2.721**|    41 MB/s  | **4900 MB/s** |\n| [zlib] deflate 1.2.11 -6|  3.099  |    36 MB/s  |    445 MB/s   |\n\n[zlib]: http://www.zlib.net/\n[Zstandard]: http://www.zstd.net/\n\nSo, as noted in https://en.wikipedia.org/wiki/LZ4_(compression_algorithm), lz4 \"gives a slightly worse compression ratio than the LZO algorithm ... . However, compression speeds are similar to LZO ..., while decompression speeds can be significantly higher than LZO\". Also, as seen from the table, zstd -1 usually gives higher compression ration than lz4 and lzo, but lower speed; as for decompression, zstd -1 compressed data decompresses faster than lzo, but slower than lz4.\nAs seen from the diagram at https://facebook.github.io/zstd/, zstd -3 can be a reasonable choice (if I'm not mistaken, it's the default value when using btrfs with zstd): it compresses better than gzip (zlib) in any mode, and faster.\n", "Q: Old AMD Linux Drivers Cannot Be Downloaded From AMD If you guys are in my boat, you may also be looking for older catalyst drivers for your card. The problem here is that while AMD does list SOME of the older drivers, half of them are not downloadable. \nWhen you click the links on the AMD website for 12.1 - 12.4, your browser will either get stuck in a pattern of freezing and loading, you will download an unusable .bin file for reason, or you will get a page full of gibberish. \nJust wanted you all to know, if you don't. \nSince this is \"Ask\" Ubuntu, I need to ask if anyone of you fine folk know where to download old drivers. If you know of a website of have them yourself, PLEASE respond. \nSo far I have found this site, which looks a bit less legit than I would like, but hey, the word \"school\" is in the link, so it must be trustworthy, right? Maybe not if it is an American site...\nhttp://****.ru/Soft/_Drivers/ATI/Linux/\nAlso, I am downloading three right now, and the projected download time is about 2 hours. So, you have that.\nThank you all in advance.\n\nA: I was able to download 12.1-12.4 from the previous releases page just fine with DownThemAll.\n\nFull links:\nhttp://www2.ati.com/drivers/linux/amd-driver-installer-12-1-x86.x86_64.run\nhttp://www2.ati.com/drivers/linux/amd-driver-installer-12-2-x86.x86_64.run\nhttp://www2.ati.com/drivers/linux/amd-driver-installer-12-3-x86.x86_64.run\nhttp://www2.ati.com/drivers/linux/amd-driver-installer-12-4-x86.x86_64.zip\n\nCould you try again? May be it was just a hiccup on AMDs servers that they fixed in the mean time.\n", "Q: Ubuntu 13.04(Raring) doesn't see my Wi-Fi networks I recently got a new HP Pavilion 17 with Windows 8 on it and decided to install 13.04 (LTS, IIRC) on it as a second OS. The install seemed to go smoothly but now I'm finding out that it's not recognizing my normal Wi-Fi connection; it doesn't even see it, in fact. I am at least able to use a wired connection, but I'd really like to be able to use my Wi-Fi as much as possible.\nI also tried sudo rfkill unblock all, and that didn't work, either.\nAlso, if any of this helps: \n\n\n*\n\n*The laptop does not have any physical Wi-Fi switches to my knowledge.\n\n*This computer came with an UEFI BIOS configuration.\n\n*I used the wired connection during a couple of Live Sessions and while I was installing the system. Could this have caused a problem? (seems unlikely to me though I didn't think it would hurt to ask).\n\n*I seem to have a RealTek network controller. When I ran lscw -C network, it also mentioned that something was \"unclaimed\":\n  \n  *-network UNCLAIMED     \n       description: Network controller\n       product: Realtek Semiconductor Co., Ltd.\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:02:00.0\n       version: 01\n       width: 64 bits\n       clock: 33MHz\n       capabilities: bus_master cap_list\n       configuration: latency=0\n       resources: ioport:3000(size=256) memory:f0200000-f0203fff\n  *-network\n       description: Ethernet interface\n       product: RTL8101E/RTL8102E PCI Express Fast Ethernet controller\n       vendor: Realtek Semiconductor Co., Ltd.\n       physical id: 0\n       bus info: pci@0000:05:00.0\n       logical name: eth0\n       version: 07\n       serial: a0:d3:c1:65:dd:17\n       size: 100Mbit/s\n       capacity: 100Mbit/s\n       width: 64 bits\n       clock: 33MHz\n       capabilities: bus_master cap_list rom ethernet physical tp mii 10bt 10bt-fd 100bt 100bt-fd autonegotiation\n       configuration: autonegotiation=on broadcast=yes driver=r8169 driverversion=2.3LK-NAPI duplex=full firmware=rtl8106e-1_0.0.1 06/29/12 ip=192.168.0.17 latency=0 link=yes multicast=yes port=MII speed=100Mbit/s\n       resources: irq:47 ioport:2000(size=256) memory:f0004000-f0004fff memory:f0000000-f0003fff memory:f0400000-f040ffff\n\n(should note that I didn't run it as a superuser, though)\nlspci tells me this:\nsteven@steven-HP-Pavilion-17-Notebook-PC:~$ sudo lspci -nn | grep -E 'Net|Eth'\n02:00.0 Network controller [0280]: Realtek Semiconductor Co., Ltd. Device [10ec:8179] (rev 01)\n04:00.0 Unassigned class [ff00]: Realtek Semiconductor Co., Ltd. RTS5229 PCI Express Card Reader [10ec:5229] (rev 01)\n05:00.0 Ethernet controller [0200]: Realtek Semiconductor Co., Ltd. RTL8101E/RTL8102E PCI Express Fast Ethernet controller [10ec:8136] (rev 07)\n\n\"Unassigned\"? \nI'm going to keep trying to look for solutions, but in the meantime if anyone can give me some clues as to how to fix this, I'd appreciate that. =)\n\nA: See for help option and for internet connections. My dongle was also not getting started. I saw the help options in mu ubuntu 10.04 it worked.\n\nA: I'm afraid you're up against a known bug, click on the link for more information.\nThe bad news is that there is probably no way to get it working on your system. The good news is tat it should work out of the box on the newer 13.10:\n\nI just booted the latest daily build of the Ubuntu 13.10 Desktop 64bit (Alpha) live CD, and wi-fi worked perfectly on the Lenova IdealCentre Q190 Model 57312246.\n\nSo, according to the bug report, this has now been fixed and should work fine on any version of Ubuntu from 13.10 onwards.\n", "Q: Reconfigure keyboard layout - 13.10, 14.04 I always modify keyboard layouts to add special characters as my needs. To modify the layout I open the codes under:\n/usr/share/X11/xkb/symbols/\nThe changes would apply after a re-login, or a reboot for the default one.\nBut now on Ubuntu 13.10 and 14.04, with the new text entry settings, the changes don’t take effect even after a reboot, if I’ve enabled them before editting.\nIs there any way to force Ubuntu to reconfigure keyboard layouts, Somewhat like dpkg-reconfigure locales for locales? The files are saved correctly!\n\nA: :D It’s simply:\ndpkg-reconfigure xkb-data\n", "Q: White screen with black strips Ubuntu 12.04 LTS after install NVidia drivers I was trying to install Steam and it get me a message about that my NVidia drivers were outdated and they recommend me to install at least the NVidia 304 drivers, so I installed and rebooted my PC, because I'm using Ubuntu with windows 7, I select the option of Ubuntu, then I get a white screen with strips, then it turn to black with white characters and it's all, the screen freeze there, I don't even got the login screen, it was working fine before the install.\nI have an NVidia geforce 7300se/7200gs.\nI'm writing this with the try Ubuntu option to use the console, but I don't know how to fix this. (I'm newbie with linux and English is not my first language so i'm sorry if I wrote something wrong.)\n\nA: You could remove the nvidia drivers by typing into the console:\nsudo apt-get remove nvidia-304*\n...then reboot once it's done ( sudo reboot ) and you will be using the open-source nvidia drivers again...\nNote: You are probably better installing Ubuntu 13.10 to run Steam so you will have the newer drivers, or you could wait until April and install Ubuntu 14.04 and have the latest LTS release instead...\n", "Q: W: Duplicate sources.list entry http://downloads-distro.mongodb.org/repo/ubuntu-upstart I want to install MongoDB on Ubuntu. I am following the official instructions from Install MongoDB on Ubuntu.\nNow when I do:\nsudo apt-get update\n\nit's giving me:\nW: Duplicate sources.list entry http://downloads-distro.mongodb.org/repo/ubuntu-upstart/ dist/10gen amd64 Packages (/var/lib/apt/lists/downloads-distro.mongodb.org_repo_ubuntu-upstart_dists_dist_10gen_binary-amd64_Packages)\nW: Duplicate sources.list entry http://downloads-distro.mongodb.org/repo/ubuntu-upstart/ dist/10gen i386 Packages (/var/lib/apt/lists/downloads-distro.mongodb.org_repo_ubuntu-upstart_dists_dist_10gen_binary-i386_Packages)\nW: You may want to run apt-get update to correct these problems\n\nI have also removed this entry manually but when I do: \nsudo apt-get update\n\nit again downloads the same files. I don't know what the issue is. I want to install the latest MongoDB. \n\nA: It seems like you still have at least one MongoDB-related entry in your apt sources list, otherwise you would not see the error message.\nTry running:\ngrep -r \"mongodb\" /etc/apt/sources.list*\n\nto see which files still reference the MongoDB apt repository.\nNote that the instructions in the MongoDB documentation tell you to put the repo definition in its own file under sources.list.d, rather than in the default sources.list file. It's a cleaner solution; I mention it in case it helps you track down your problem.\n", "Q: Not Able To Install Ubuntu With Windows 7 First of all sorry if this question seams repeated I am a rookie, I tried many links but not able to do that is not working in my case. On my laptop currently Windows 7 is installed and I want to install Ubuntu alongside it, but I am not getting that option in my Ubuntu to [install alongside of it] menu. I tried to select \"Something else\" option but I don't know how to  partition it. It is my Windows 7 disk image screen shot\n\nAnd this is screen shot for Ubuntu GPart\n\n\nA: You already have the max of four primary partitions.  You need to backup the 4th partition (the \"workspace\"), and convert it to an extended partition, which may contain many logical parittions, which are fine for Ubuntu.  Tools like Partman may allow conversion in place, but I have no experience with them.  The brute force way is to delete the last primary partition (after the backup of course), recreate it as an extended, make a logical ntfs partition to restore the backup, and make additional partitions for root and swap in the remaining space.  I usually make the partitions I want before the installation, but the installation tools should allow you to partition with the \"something else\" option.\n\nA: Regardless of how many partitions you are allowed to allocate on a dynamic disk, you have no free space on that drive for any other partitions. Something has to go.\nThe first partition is a 100mb boot partition for windows. Then you've got a C: drive where your page file and system lives. Everything else is NTFS data. You can't install something alongside a completely full disk. It's not about how much space your data is using, your partitions are kind of reserving all the available space on the disk.\nI'd remove one or more partitions in Windows itself, since the partitions are NTFS, after moving or otherwise backing up the data.\n", "Q: Nginx-to enable autostart I installed the docker container in my ubuntu 13.10. Along with this nginx webserver also \ninstalled.But every time i want to type this command \nservice nginx restart.\nso how can i autorun the nginx?\n\nA: Method 1: Start nginx at ubuntu startup\nCheck runlevel\n^_^[root@easyengine:~]# runlevel \nN 2\n\nMy ubuntu runlevel is 2 so i'm edit the following file\nmv /etc/rc2.d/K20nginx /etc/rc2.d/S20nginx\n\nNow restart the system\nMethod 2: rc.local\nAdd following line before the exit 0\nservice nginx start\n\n", "Q: About the Dual booting I am a beginner in Ubuntu, so please help me to solve this problem. I bought a new laptop with a hard disk of 500 GB. First I installed windows 7 and allocated 400 GB for that. Now I installed Ubuntu using the windows installer with a  USB pen drive in the 100 GB left for that. It worked perfectly. But I faced a problem when I reinstalled my Windows 7 OS. I am now unable to get the dual boot process back. I tried to re-install Ubuntu, too. But when I tried to do that using the windows installer, I am not able to find the partitioned space of 100 GB already containing Ubuntu OS. It shows only the space wich is allocated for Windows. \nThis is my problem. Now what should I do to get the dual boot back?\n\nA: I recommend you start by checking if you still have your Ubuntu installation on disk (as suggested by Jacob). You may have overwritten that when you re-installed Windows.\nTo verify, please boot either to Ubuntu Live CD or Live USB and run gparted. This will show you the partitions you have on your disk. You can see an example on this page with both NTFS (Windows) and ext3 / ext4 (Linux) partitions.\nIf you still have your Ubuntu partition, you can use boot repair to restore your dual boot configuration (Ubuntu bootloader).\n", "Q: Unknown type name gcc I'm trying to compile this source code http://nrg.cs.ucl.ac.uk/mptcp/mptcp_userland_0.1.tar.gz and I'm getting unknown type name 'u8' among other types (u_int, u_char, u_long....etc)\nI have Ubuntu 12.04 LTS and gcc version 4.6.3\nHow to solve this issue?\nThank you\n\nA: I solved the issue by using typedef http://www.gnu.org/software/gnu-c-manual/gnu-c-manual.html#The-typedef-Statement\nI added this typedef unsigned u8; to the beginning of the files I had errors in\nYou can find the current known integer data types here http://www.gnu.org/software/gnu-c-manual/gnu-c-manual.html#Integer-Types\n", "Q: \"wodim: Permission denied. Cannot open SCSI driver!\" how to solve? When I'm executing a cd writing command cdrecord -v -eject speed=48 dev=/dev/sg1 /tmp/newcd.iso it will output some errors in my log file like,\nwodim: Permission denied. \nCannot open SCSI driver!\n\nAny one know how to solve this issue? \nPlease help to find a solution\n\nA: It is happening because you are not root. The root account is essential to access system resources. Use\nsudo cdrecord -v -eject speed=48 dev=/dev/sg1 /tmp/newcd.iso\n\nto become root. You will be prompted for administrator password and then the process will start.\n", "Q: X11 forwarding in SSH How to run X11 GUI applications from a remote server using SSH?\nFor example: \n\n\n*\n\n*my first desktop 192.168.1.1\n\n*my second desktop IP 192.168.1.12\n\n\nI 'm sshing from my first desktop to the second and i want to run the GUI applications from the second and redirect X11 to the first.\n\nA: Try the following command to create the ssh connection:\nssh -X remote_login@192.168.1.12\n\nJust replace remote_login by your second desktop login\nssh man page:\n\n-X   Enables X11 forwarding.  This can also be specified on a per-host\n       basis in a configuration file.\n X11 forwarding should be enabled with caution.  Users with the\n ability to bypass file permissions on the remote host (for the\n user's X authorization database) can access the local X11 display\n through the forwarded connection.  An attacker may then be able\n to perform activities such as keystroke monitoring.\n\n For this reason, X11 forwarding is subjected to X11 SECURITY\n extension restrictions by default.  Please refer to the ssh -Y\n option and the ForwardX11Trusted directive in ssh_config(5) for\n more information.\n\n\n\nA: Ok, I found a way:\nssh -X user@192.168.1.12\n\nThen when I login I just easily can start whatever GUI app I need. I tried Firefox and yes I can just use Firefox from the second computer. That's really nice.\n", "Q: Unable to Delete/Modify files in the USB I am unable to delet/modify files on the USB. The usb cannot be formatted as it says disk is wirte protected. How do I change the settings.. I tried to do it but the usb does not allow me to change settings..Pls help..\n\nA: Assuming you don't have a flash drive with a hardware write-protect switch...\nIf you can access your flash drive's location (where the contents of it are), remember it and open up a terminal session and type mount. Then find your mount point (that location you remembered earlier), and check the options. If it's ro and NOT rw, you can try remounting it.\nIt will list stuff like this (this is a example of my output, running under a live USB setup, although the process for installed, non-live systems are very similar):\n/cow on / type overlayfs (rw)\n/dev/sdb1 on /media/ki2ne/FLASHDRIVE type vfat (ro,noatime,fmask=0022,dmask=0022,codepage=cp437,iocharset=iso8859-1,shortname=mixed)\n(the rest of the mount points are cut for brevity)\nI would identify /dev/sdb1 to be the device for my flash drive (although yours might be different). So I would do mount -t vfat -o rw,remount /dev/sdb1 /media/ki2ne/FLASHDRIVE.\n", "Q: Why do I get an error saying I must be privileged to use `crontab -u`? I am trying to list all the cron jobs for all the users in my Ubuntu system using the following command:\nfor user in $(cut -f1 -d: /etc/passwd); do crontab -u $user -l; done\n\nWhy am I getting the following error:\nmust be privileged to use this -u\n\n\nA: You don't have the necessary permissions to read other users' crontabs, either run as root or use sudo to invoke crontab -u, e.g.\nfor user in $(cut -f1 -d: /etc/passwd); do sudo crontab -u $user -l; done\n\nor\nawk -F: '{print $1}' /etc/passwd | xargs -n1 sudo crontab -lu\n\n", "Q: How to do bonding in ubuntu 12.04 in vmware workstation? I followed process for bonding which is given on this site: https://help.ubuntu.com/community/UbuntuBonding\nbut output is\n$ cat /proc/net/bonding/bond0 \nEthernet Channel Bonding Driver: v3.7.1 (April 27, 2011)\nBonding Mode: load balancing (round-robin)\nMII Status: down\nMII Polling Interval (ms): 0\nUp Delay (ms): 0\nDown Delay (ms): 0\n\nand \n\n$ ifconfig\nbond0     Link encap:Ethernet  HWaddr 86:df:fa:d9:19:30  \n          inet addr:172.16.71.11  Bcast:172.16.71.255  Mask:255.255.255.0\n          UP BROADCAST MASTER MULTICAST  MTU:9000  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:65536  Metric:1\n          RX packets:1314 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:1314 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:89822 (89.8 KB)  TX bytes:89822 (89.8 KB)\n\nAnd the status of other two device eth0 and eth1 shows that 'device not managed', So what should I do?\n\nA: Before applying bonding, need to close network. In my case, following command is used:\nsudo stop network-manager\n\nInstead of:\nsudo stop networking\n\nAfter editing in sudo vi /etc/network/interfaces file, need to restart network using:\nsudo start network-manager\n\nOr reboot Ubuntu.\nIts works fine, but still I don't know why it show:\ndevice not managed\n\n", "Q: The requested URL /xampp/ was not found on this server. I have a running XAMPP(lampp) in the /opt/lampp/htdocs/xampp directory.\nI have downloaded xampp 1.8.2-4 from here\nI start xampp by sudo /opt/lampp/lampp start/stop so whenever I hit localhost it redirects me to localhost/xampp\nNow the problem is when I hit localhost/xampp its showing\n\nNot Found\n  The requested URL /xampp/ was not found on this server.\n  Apache/2.4.6 (Ubuntu) Server at localhost Port 80\n\nthe problem is my localhost is now pointing to /var/www/index.html not to /opt directory\nApache is starting when I type in the terminal: \n$ service apache2 start\n* Starting web server apache2\n\nNow, after stopping XAMPP by\nsudo /opt/lampp/lampp stop\n\nwhen i hit localhost its fetching index.html from var/www directory with a message\n\nIt works!\n  This is the default web page for this server.\n  The web server software is running but no content has been added, yet.\n\nHow can I make my XAMPP responds with \nsudo /opt/lampp/lampp start\n\nHow it can be resolved?\n\nA: You must change DocumentRoot in VirtualHost\nFile is /opt/lampp/etc/extra/httpd-vhosts.conf:\n<VirtualHost *:80>\n    ServerAdmin web@your_site.com\n    DocumentRoot \"/opt/lampp/htdocs/your_site\"\n    ServerName your_site.com\n    ErrorLog \"logs/your_site.com-error_log\"\n    CustomLog \"logs/your_site.com-access_log\" common\n</VirtualHost>\n\n", "Q: iTunesToRhythm code not working? Hello I am trying to install run this iTunesToRhythm.\nThe supplied command is:\niTunesToRhythm.py -w -a iTunes\\ Music\\ Library.xml ~/.local/share/rhythmbox/rhythmdb.xml\n\nThe error I am getting after inputting this command is: \niTunesToRhythm.py: command not found\n\nEDIT - here is what I typed in console:\nfiver@LALA-LAND:~/Music/iTunesToRhythm-master$ ./iTunesToRhythm.py -w -a /media/MEDIA 1/SOUNDS/I Tunes/lybrary.xml ~/.local/share/rhythmbox/rhythmdb.xml\n\n\nA: You should use ./ (current dir) prefix when you execute a script:\ncd /home/myname/Music/iTunesToRhythm-master/\n./iTunesToRhythm.py -w -a /media/MEDIA\\ 1/SOUNDS/I\\ Tunes/Library.xml ~/.local/share/rhythmbox/rhythmdb.xml\n\nor\n./iTunesToRhythm.py -w -a \"/media/MEDIA 1/SOUNDS/I Tunes/Library.xml\" ~/.local/share/rhythmbox/rhythmdb.xml\n\nThe reason is that current dir is not included to $PATH variable, because it may cause security risks. Somebody can override system commands this way.\nThere is question on SuperUser which explains why.\nAlso you should escape space bars inside filenames with backslash \\ symbol. Simply place it before spaces. Or use double-quotes \" around the path.\n\nA: When I run Python scripts, I put python in front of the script I want to run. Kind of like putting sh before the name of a shell script you want to run.\nFor example, go to the directory where your .py script is in the command line and run it directly from there or include the path:\npython iTunesToRhythm.py -w -a iTunes\\ Music\\ Library.xml ~/.local/share/rhythmbox/rhythmdb.xml\n\nor:\npython ~/Downloads/iTunesToRhythm.py -w -a ~/iTunes\\ Music\\ Library.xml ~/.local/share/rhythmbox/rhythmdb.xml\n\nBut I'm pretty sure the command you were missing was 'python'.\n", "Q: No application menu in the Panel I've tried Macbuntu, but did not quite like it, so I uninstalled it but Ubuntu didn't restore completely.\nThere are now only close, minimize, maximize buttons in Panel, while originally there should be other application menu options like \"file, edit, view, help etc...\", which disappeared now. \nIt looks like this:\n\nI've tried reset Unity by\nunity --reset\n\nbut it does not work.\nI'm using Ubuntu Desktop 12.04.\n\nA: The problem is solved after reading another post:\nhow to restore top level menu on panel in ubuntu 13.04\nHere I quotes @user196288 's solution which works for me:\n\nUninstalling Macbuntu will remove appmenu-gtk so you have to install\n   it again: \nsudo apt-get install appmenu-gtk appmenu-gtk3 appmenu-qt indicator-appmenu\n\n\nThen log out, and log in again, everything comes back.\n", "Q: How to convert and slice jpg to psd and keep layers COPIED TO GRAPHIC & DESIGN\nI have several JPG designs of a website I'm developing. I did a pure HTML website and then did a full webpage screenshot for the design part. Now the client is asking for the PSD files, is there any way I can convert the JPG designs to PSD in GIMP or any other software?\nEDIT\nIs there any way I can slice up the JPG into the individual layers?\n\nFor confidentiality reasons, I can't upload the actual designs but here is a sample from creative market:\n\n\nA: Install imagemagick:\nsudo apt-get install imagemagick\n\nThen\nconvert image.jpg image.psd\n\nVisit imagemagick for more info.\n\nA: To convert a JPG image to PSD format in GIMP 2.6 (Ubuntu 12.04) do the following:\n\n\n*\n\n*Open the JPG file with right click and then choosing Open With > GIMP Image editor.\n\n*In GIMP open the export dialogue by following File > Save As....\n\n*In the Save As... dialogue change the file name extension to .psd.\n\n*In the All images drop down list select Photoshop image (.psd)* (see the image below).\n\n*Click Save.\n\n\n\nIn GIMP 2.8 (Ubuntu 13.10) there is a special Export dialogue that you can access through File > Export... but that works in similar way.\n\nA: The answer is simple: \nNo you can split in layer a jpeg file reliably you will have to do it on your own.  \njpeg is like a painting, the only way you could transform it into 3D would be to generate the part behind each element when you remove an element from the painting.\n", "Q: Installing Tally I have Ubuntu Server 12.4 Installed.  Later I installed Ubuntu Desktop on there.  I wanted to install Tally9 (Server component) which is a multi-user accounting SW, where centralized data base is managed and Tally Clients will access the data base to create invoices, vouchers etc So my question is How do I install Tally 9 on Ubuntu Server\n\nA: It is very easy.\n\n\n*\n\n*Install Wine\n\n*Install Tally through wine\n\n*Create a Data folder and share it on server \n\n*On client , install wine if want to run on linux.\n\n*Map the data folder\n\n", "Q: Ubuntu Server Apache2 SSL virtual host not working I have fully set up a web server on ubuntu using SSL encryption. I am trying to set up the default -SSL file to point to the correct directories. geekychicgirls works completely fine, however thepeepinghole always resolves to geekychicgirls, any help is appreciated see code below.\n<IfModule mod_ssl.c>\n<VirtualHost *:443>\n    ServerAdmin webmaster@nixcraft.com\n    DocumentRoot \"/var/www/thepeepinghole\"\n    SSLEngine on\n    SSLCertificateFile /ssl/14252798.crt\n    SSLCertificateKeyFile /ssl/private.key\n    SSLCertificateChainFile /ssl/futureretrogaming.ca-bundle\n    ServerName www.thepeepinghole.tk\n    ServerAlias thepeepinghole.tk\n    ErrorLog \"/var/www/thepeepinghole/log/error.log\"\n    CustomLog \"/var/www/thepeepinghole/log/access.log\" common\n    <Directory /var/www/thepeepinghole>\n                DirectoryIndex index.html\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n     </Directory>\n</VirtualHost>\n\n<VirtualHost *:443>\n    ServerAdmin webmaster@nixcraft.com\n    DocumentRoot \"/var/www/geekychicgirls\"\n    SSLEngine on\n    SSLCertificateFile /ssl/14252798.crt\n    SSLCertificateKeyFile /ssl/private.key\n    SSLCertificateChainFile /ssl/futureretrogaming.ca-bundle\n    ServerName www.geekychicgirls.tk\n    ServerAlias geekychicgirls.tk\n    ErrorLog \"/var/www/geekychicgirls/log/error.log\"\n    CustomLog \"/var/www/geekychicgirls/log/access.log\" common\n    <Directory /var/www/geekychicgirls>\n                DirectoryIndex index.html\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n     </Directory>\n</VirtualHost>\n\n</IfModule>\n\n\nA: The solution was to first make sure the apache2.conf includes the sites-enabled folder and not the sites-available folder. \nThen, you need to create an additional symbolic link in your sites-enabled folder that links to the ssl default file you created in the sites-available folder. Finally restart the apache2 service and you should be good to go.\n\nA: Try to put\n\nNameVirtualHost *:443\n\n<IfModule mod_ssl.c>\nNameVirtualHost *:443\n<VirtualHost *:443>\n    ServerAdmin webmaster@nixcraft.com\n    DocumentRoot \"/var/www/thepeepinghole\"\n    SSLEngine on\n...\n\nEdit 1\nOnly I can say is: now try something completely different. \nEdit /etc/apache2/ports.conf and add the following line:\nListen 443\n\nAlso comment out the following in /etc/apache2/ports.conf:\n <IfModule mod_ssl.c>\n    # SSL name based virtual hosts are not yet supported, therefore no\n    # NameVirtualHost statement here\n   Listen 443\n</IfModule>\n\nCreate a file called /etc/apache2/ssl.conf and put in all from your posted file in question without on beginning  and  at the end. \n<VirtualHost *:443>\n    ServerAdmin webmaster@nixcraft.com\n    DocumentRoot \"/var/www/thepeepinghole\"\n    SSLEngine on\n    SSLCertificateFile /ssl/14252798.crt\n    SSLCertificateKeyFile /ssl/private.key\n    SSLCertificateChainFile /ssl/futureretrogaming.ca-bundle\n    ServerName www.thepeepinghole.tk\n    ServerAlias thepeepinghole.tk\n    ErrorLog \"/var/www/thepeepinghole/log/error.log\"\n    CustomLog \"/var/www/thepeepinghole/log/access.log\" common\n    <Directory /var/www/thepeepinghole>\n                DirectoryIndex index.html\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n     </Directory>\n</VirtualHost>\n\n<VirtualHost *:443>\n    ServerAdmin webmaster@nixcraft.com\n    DocumentRoot \"/var/www/geekychicgirls\"\n    SSLEngine on\n    SSLCertificateFile /ssl/14252798.crt\n    SSLCertificateKeyFile /ssl/private.key\n    SSLCertificateChainFile /ssl/futureretrogaming.ca-bundle\n    ServerName www.geekychicgirls.tk\n    ServerAlias geekychicgirls.tk\n    ErrorLog \"/var/www/geekychicgirls/log/error.log\"\n    CustomLog \"/var/www/geekychicgirls/log/access.log\" common\n    <Directory /var/www/geekychicgirls>\n                DirectoryIndex index.html\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n     </Directory>\n</VirtualHost>\n\nAdd in an include line in /etc/apache2/apache2.conf: \nInclude \"/etc/apache2/ssl.conf\"\n\nRestart Apache2 with: apache2ctl restart\n\nA: I've created a script that you can use in order to generate and automatically install Self-Signed Certificates for Virtual Hosts configuration files already created. You can find the script by consulting this tutorial http://www.bytelinux.com/create-self-signed-certificates-enable-apache-ssl-ubuntu-14-10/ and create the a2sslcert bash script on your own server. \n", "Q: How to see the contents of a file with blank filename? drwxrwxr-x 2 ubuntu ubuntu  4096 Mar 19 07:30 xxxxx\n-rw-rw-r-- 1 ubuntu ubuntu   580 Mar 20 07:24  \n-rw-rw-r-- 1 ubuntu ubuntu 27137 Mar 20 09:10 xxx.js\n\nHere there is a file on the second line but its blank, any idea how to see the contents?\n\nA: Inodes to the rescue: first, do ls -li to list all files with their inodes. The inode is the number on the left. Note the inode number of your invisible file. Then:find . -inum xxx -exec nano {} \\; replacing xxx with the inode number, and possibly nano with the editor of your choice.\nExplanation:\nThe find command finds the file with inode number xxx, then executes a command, in this case: passes it to nano. The {} is a placeholder for the filename; the \\; at the end indicates the end of the command.\n\nA: You can do a \ngedit *\n\nto open all files (brute force approach)\nOr better\ngedit \" \"*\n\nif you are sure that the file begins with a space character.\n(you can replace gedit with your favorite editor)\n", "Q: eog does not recognize .png file format and many icons are gone I use Ubuntu 12.04 and XFCE desktop on a PC with nVidia graphics card. I ran into Segmentation fault during a Ubuntu update process. An very inconvenient consequence is that .png files cannot be recognized any more thus many programs cannot be started (e.g. gnome-commander, stardict). Also many icons are missing, as well as the min/max/close button icons. I tried open .png using eog and got \"unrecognized image file format\". I tried reinstall libgdk-pixbuf2.0-0 and librsvg and always got segmentation fault.\n... \nSetting up libgdk-pixbuf2.0-0 (2.26.1-1) ... \nSegmentation fault (core dumped) \nSetting up libgdk-pixbuf2.0-0:i386 (2.26.1-1) ...\nProcessing triggers for libc-bin ... \nldconfig deferred processing now taking place\n\nrunning gdk-pixbuf-query-loaders brings up segfaults as well (but not gdk-pixbuf-pixdata or gdk-pixbuf-csource):\n>gdk-pixbuf-query-loaders --update-cache\nSegmentation fault (core dumped)\n\nI tried logging into gnome and saw the same effect. I tried downloading libgdk-pixbuf2.0-0 package file .deb and installing from command line and got segfaults, too. Any suggestions on how to fix it?\nUpdate: I carefully checked all the dependencies' versions in the precise-update database and none of them have problems.\n\nA: After a lot of Googling and Binging I finally found a solution for me. I'm running BackBox 4.4 which is based on Ubuntu 14.04 LTS on an x86_64 machine but I had this same problem where xfce starts and works normally but images, the menus and icons were not loading. So my desktop background was blank and most icons were missing in the menu. However I remember having this same error during an \"apt-get upgrade\" as mentioned above. In short here was my fix:\nsudo dpkg-reconfigure libgdk-pixbuf-2.0-0\nsudo dpkg-reconfigure libglib-2.0-0\n\nThen logout and log in and voila! (no restart required).\nThanks for pointing me in the right direction. Other posts out there have not looked into that.\n\nA: Since my yesterday post, I cannot comment on your other question, but here is my answer on launchpad :\n\nYeah I have recovered my laptop ! (well an expert of my company did so)\nI don't know how this is related but here are his steps :\n\n*\n\n*removed a ppa that I previously added (/etc/apt/sources.list.d/webupd8team-gvfs-libmtp-precise.list)\n\n*reinstalled a few corresponding packages (gvfs, libglib2.0-0)\n\n*reconfigure libgdk-pixbuf2.0-0\n\nIt seems libglib2.0-0 was causing the problem. I don't know if this will be okay for most people, but it should help at least debug :-)\n\n\nA: Remove the ppa: sudo rm /etc/apt/sources.list.d/webupd8team-gvfs-libmtp-precise.list\nThen: sudo apt-get update\nAfter that force uninstall of the libglib library with:\nsudo dpkg -P --force-all --force-remove-reinstreq libglib2.0-0\n\nYou can then reinstall it from the regular ubuntu ppas: sudo apt-get install libglib2.0-0\nFinally you need to downgrade  glib-networking-common and gvfs-common:\nsudo apt-get install glib-networking-common=2.32.1-1ubuntu2\nsudo apt-get install gvfs-common=1.12.1-0ubuntu1.2ppa8~precise3\n\nLibraries version should be:\nlibglib2.0-0: 2.32.4-0ubuntu\ngvfs-common: 1.12.1-0ubuntu\nlibgdk-pixbuf2: 2.26.1-1\nBut apparently you already have all the correct library versions, that is really weird..\n", "Q: How do I lock screen on Live Ubuntu? I'm running Live Ubuntu 12.04. I don't see the 'Lock screen' button under the top right gear button. The shortcut Ctrl + Alt + L doesn't work either.\n\nA: Simple solution - you can't. Ubuntu Live Session User does not have password. If user does not have password, locking screen is meaningless.\nHowever, you CAN create new user, and give him a new password. I believe, if you log in as this newly created user, you should be able to lock screen.\n", "Q: adding subdomain could you please help me. I am using apache2 under ubuntu 12.4 and i want to have subdomain like exam.domain.com. For this i have edit all the config files include hosts and enabled my sub site named exam.localhost and add this line in config file.\n<VirtualHost *:80>\nDocumentRoot /var/www/site/www/exam\nServerName project.localhost\n <Directory /var/www/site/www/exam>\n AllowOverride All\n Order allow,deny\n Allow from all\n Require all granted\n </Directory>\n</VirtualHost>`\n\nwhen i type exam.localhost in browser it works but when i type like exam.domainname.com it's not working.\n    Thank you for an help \n\nA: If you want to add additional domains, or use a wildcard, you need to use ServerAlias:\n<VirtualHost *:80>\n    DocumentRoot /var/www/site/www/exam\n    ServerName project.localhost\n    ServerAlias project2.localhost\n    ServerAlias *.localhost\n    ServerAlias project.example.com\n    ServerAlias project2.example.com\n    ServerAlias exam.example.com\n    ServerAlias *.example.com\n    <Directory /var/www/site/www/exam>\n        AllowOverride All\n        Order allow,deny\n        Allow from all\n        Require all granted\n    </Directory>\n</VirtualHost>\n\n", "Q: ubuntu 13.10 how to change nautilus title bar color I would like to know if I need to change the file nautilus.css in gtk3 theme folder or metacity.xml in metacity theme folder\nI use ubuntu 13.10 in flashback mode\nThank You\n\nA: Modifying the metacity xml files will apply your changes not only to nautilus but to all your windows.\nTo tweak nautilus elements, modify its css file in the active gtk3 theme folder.\n", "Q: Why do I get 'error while loading shared libraries: libGL.so.1: wrong ELF class: ELFCLASS64' when I run Mercury? Using native OpenGL\n/home/software/Mercury_3.3/c_linux/bin/mercury.x: error while loading shared libraries: libGL.so.1: wrong ELF class: ELFCLASS64\n\n\nA: Looks like your application is a 32 bits application but is trying to load a 64bits library.\nOn a 64bits installation, you can have both version (32 bits and 64 bits) of any libraries installed. 32bits can be found under /usr/lib32 and 64bits under /usr/lib64.\nOn Linux, libraries are search using a path sequence, a little bit like the PATH variable list all the directories to look for the executable you want to run when no path is given.\nThis sequence to search for libraries is defined in a variable called LD_LIBRARY_PATH.\nThe problem is that the directory for the 64bits versions comes before the directory with the 32bits versions. And usually the name of the library is identical for the 32bits and 64bits version.\nYou can overcome this problem by creating a small startup script for your application like this one :\n#!/bin/bash\n\nexport LD_LIBRARY_PATH=/usr/lib32:/usr/lib64:$LD_LIBRARY_PATH\n\n<your binary> $*\n\nIf there is already a script to start this application, you can just add the line\nexport LD_LIBRARY_PATH=/usr/lib32:/usr/lib64:$LD_LIBRARY_PATH\n\nto it, near the top.\nI'll prefer the first method, creating a specific script, as any startup script provided by the package will be probably overwritten in case of update.\n", "Q: Failed to create thumbnail error fills gnome-session.log.1 to 50 GB! Yesterday I got a message that my /home partition was full so I moved a 10 gb folder to a external hdd. now I got the message again so I did the Disc Usage Analyzer, and I found a 50 GB file in /home/.cache/upstart named gnome-session.log.1.\nI I could not read the file so I deleted the file now and it immediately starts filling up with this message\n(nautilus:2930): GnomeDesktop-WARNING **: Failed to create thumbnail /home/wouter/.cache/thumbnails/large/13b82fd16426ec5a8f99f1aa286de1f1.png.92B5CX: Fatal error in PNG image file: Write Error\n\nI don't really get what is going on here, the file 13b82fd16426ec5a8f99f1aa286de1f1.png does exist, but I don't think I have used it today anywhere.\nHow do I prevent this log from filling up again?\n\nA: Possible solutions:\n1. CLEAR THUMBNAIL CACHE\nRun the following commands to clear your thumbnails cache.\nrm -r ~/.thumbnails\nkillall nautilus\n\n2. Install Samba\nIf you don't have samba installed, you can try installing it.\nsudo apt-get install samba\n\n3. Disable 'file manager' plugin in GEdit\nOpen Gedit and go to \"Edit >Preferences > Plugins\" and turn off the File Browser pane.\nSource: http://ubuntuforums.org/archive/index.php/t-2123796.html\n", "Q: Graphics Issue for Lenovo g580 I recently installed Ubuntu 13.10. Everything was fine till I ran inxi and found the following -\nSystem:    Host: kaustuv-Lenovo-G580 Kernel: 3.11.0-18-generic x86_64 (64 bit) Desktop: Gnome Distro: Ubuntu 13.10\nMachine:   System: LENOVO product: 2189 version: Lenovo G580\n           Mobo: LENOVO model: INVALID version: 31900003WIN8 STD MLT Bios: LENOVO version: 5ECN92WW(V8.04) date: 09/14/2012\nCPU:       Dual core Intel Core i3-2328M CPU (-HT-MCP-) cache: 3072 KB flags: (lm nx sse sse2 sse3 sse4_1 sse4_2 ssse3 vmx) \n           Clock Speeds: 1: 800.00 MHz 2: 800.00 MHz 3: 800.00 MHz 4: 800.00 MHz\nGraphics:  Card-1: Intel 2nd Generation Core Processor Family Integrated Graphics Controller \n           Card-2: NVIDIA GF108M [GeForce GT 635M] \n           X.Org: 1.14.5 drivers: (unloaded: fbdev,vesa) FAILED: nouveau,intel Resolution: 1366x768@60.0hz \n           GLX Renderer: Mesa DRI Intel Sandybridge Mobile GLX Version: 3.0 Mesa 9.2.1\nAudio:     Card: Intel 7 Series/C210 Series Family High Definition Audio Controller driver: snd_hda_intel \n           Sound: Advanced Linux Sound Architecture ver: k3.11.0-18-generic\nNetwork:   Card-1: Qualcomm Atheros AR8162 Fast Ethernet driver: alx \n           IF: eth0 state: down mac: b8:88:e3:8b:e5:4d\n           Card-2: Broadcom BCM4313 802.11bgn Wireless Network Adapter driver: wl \n           IF: eth1 state: up mac: c0:14:3d:cc:35:e1\nDrives:    HDD Total Size: 500.1GB (75.3% used) 1: id: /dev/sda model: ST500LT012 size: 500.1GB \nPartition: ID: / size: 25G used: 5.4G (23%) fs: ext4 ID: swap-1 size: 1.07GB used: 0.00GB (0%) fs: swap \nRAID:      No RAID devices detected - /proc/mdstat and md_mod kernel raid module present\nSensors:   System Temperatures: cpu: 69.0C mobo: N/A gpu: 66.0 \n           Fan Speeds (in rpm): cpu: N/A \nInfo:      Processes: 227 Uptime: 2:05 Memory: 1396.3/7849.2MB Client: Shell (bash) inxi: 1.9.12 \n\nUnder the graphics section I found FAILED: nouveau,intel . I looked around a bit but did not find any solution sepecific to my hardware. Can anybody suggest me how I can fix this. \nThanks in advance\n\nOk...So after trying Emili's answer, my inxi -Gff looks like this\n CPU:       Dual core Intel Core i3-2328M CPU (-HT-MCP-) cache: 3072 KB \n           Clock Speeds: 1: 800.00 MHz 2: 800.00 MHz 3: 800.00 MHz 4: 2200.00 MHz\n           CPU Flags: acpi aperfmperf apic arat arch_perfmon avx bts clflush cmov constant_tsc \n           cx16 cx8 de ds_cpl dtes64 dtherm dts eagerfpu epb ept est flexpriority fpu fxsr ht lahf_lm \n           lm mca mce mmx monitor msr mtrr nonstop_tsc nopl nx pae pat pbe pcid pclmulqdq pdcm pebs \n           pge pln pni popcnt pse pse36 pts rdtscp rep_good sep ss sse sse2 sse4_1 sse4_2 ssse3 syscall \n           tm tm2 tpr_shadow tsc tsc_deadline_timer vme vmx vnmi vpid x2apic xsave xsaveopt xtopology \n           xtpr \nGraphics:  Card-1: Intel 2nd Generation Core Processor Family Integrated Graphics Controller \n           Card-2: NVIDIA GF108M [GeForce GT 635M] \n           X.Org: 1.14.5 drivers: intel (unloaded: fbdev,vesa) Resolution: 1366x768@60.0hz \n           GLX Renderer: Mesa DRI Intel Sandybridge Mobile GLX Version: 3.0 Mesa 10.0.0\n\nAnd in the about this computer section it says I have \"Intel® Sandybridge Mobile\" running  in the graphcs section. \nNow, this doesn't seem very powerful. It can't even display the 3D windows using Compiz. Or is it my graphics card is not powerful enough?\nThanks in advance. :)\n\nA: Try installing a generic graphic driver \nlike bumblebee:\nsudo apt-get install bumblebee bumblebee-nvidia\n\n", "Q: Install Wine 1.7 on 12.04 I can't install wine1.7 on ubuntu 12.04. \n$ sudo add-apt-repository ppa:ubuntu-wine/ppa\n$ sudo apt-get update\n$ sudo apt-get install wine1.7 winetricks\nLecture des listes de paquets... Fait\nConstruction de l'arbre des dépendances       \nLecture des informations d'état... Fait\nwinetricks est déjà la plus récente version disponible.\nwinetricks passé en « installé manuellement ».\nCertains paquets ne peuvent être installés. Ceci peut signifier\nque vous avez demandé l'impossible, ou bien, si vous utilisez\nla distribution unstable, que certains paquets n'ont pas encore\nété créés ou ne sont pas sortis d'Incoming.\nL'information suivante devrait vous aider à résoudre la situation : \n\nLes paquets suivants contiennent des dépendances non satisfaites :\n wine1.7 : Dépend: wine1.7-amd64 (= 1:1.7.14-0ubuntu1) mais ne sera pas installé\n           Dépend: wine1.7-i386 (= 1:1.7.14-0ubuntu1)\nE: Impossible de corriger les problèmes, des paquets défectueux sont en mode « garder en l'état ».\n\nAnd if i try to install the dependences :\n$ sudo apt-get install wine1.7-amd64\nLecture des listes de paquets... Fait\nConstruction de l'arbre des dépendances       \nLecture des informations d'état... Fait\nCertains paquets ne peuvent être installés. Ceci peut signifier\nque vous avez demandé l'impossible, ou bien, si vous utilisez\nla distribution unstable, que certains paquets n'ont pas encore\nété créés ou ne sont pas sortis d'Incoming.\nL'information suivante devrait vous aider à résoudre la situation : \n\nLes paquets suivants contiennent des dépendances non satisfaites :\n wine1.7-amd64 : Dépend: wine1.7:any (= 1:1.7.14-0ubuntu1)\nE: Impossible de corriger les problèmes, des paquets défectueux sont en mode « garder en l'état ».\n\n\n$ sudo apt-get install wine1.7-i386\nLecture des listes de paquets... Fait\nConstruction de l'arbre des dépendances       \nLecture des informations d'état... Fait\nCertains paquets ne peuvent être installés. Ceci peut signifier\nque vous avez demandé l'impossible, ou bien, si vous utilisez\nla distribution unstable, que certains paquets n'ont pas encore\nété créés ou ne sont pas sortis d'Incoming.\nL'information suivante devrait vous aider à résoudre la situation : \n\nLes paquets suivants contiennent des dépendances non satisfaites :\n wine1.7-i386:i386 : Dépend: liblcms2-2:i386 (>= 2.2+git20110628-2) mais ne sera pas installé\nE: Impossible de corriger les problèmes, des paquets défectueux sont en mode « garder en l'état ».\n\n\nA: You have dependency problems.\nFire up the terminal by using Ctrl + Alt + t.\nHere are the commands you should use:\nsudo apt-get clean\n\nsudo apt-get -f install\n\nthen run:\nsudo dpkg --configure -a\n\nagain:\nsudo apt-get -f install\n\nIf you still have a problem please add a comment to this question or edit you answer.\n", "Q: Is there an Ubuntu version of Windows' 'System Refresh' option? Windows 8 allows users to reinstall the operating system without removing documents, music, and pictures (basically, without removing the home folder); is there a similar function available in Ubuntu?\nWindows defines their System Refresh option:\n\"If your PC isn't performing as well as it once did, and you don't know why, you can refresh your PC without deleting any of your personal files or changing your settings.\"\nDon't care about losing settings. Do care about losing files. Is there a way I might be able to move files to a partition, or something workaround-ish like that?\n\nA: From https://help.ubuntu.com/community/UbuntuReinstallation\n\nSince Hardy it is possible to reinstall Ubuntu without losing the\n  content of the /home folder (the folder that contains program\n  settings, internet bookmarks, emails and all your documents, music,\n  videos and other user files). This can be done even if /home is not on\n  a separate partition (which is the case by default if you did not\n  manually separate it when installing Ubuntu originally).\n\nFrom the installer you get the option to reinstall. \nIf I remember correctly the installer states  documents, music etc will be kept, software will be kept where possible and system wide settings will be cleared.\n", "Q: not able to install google chrome i have tried all the answers on this site but it doesnt help nothing works and\nit gives this following error:  \nUnpacking google-chrome-stable:i386 (from .../google-chrome-stable_current_i386.deb) ...\ndpkg: dependency problems prevent configuration of google-chrome-stable:i386:google-chrome-stable:i386 depends on xdg-utils (>= 1.0.2).\ndpkg: error processing google-chrome-stable:i386 (--install):\n    dependency problems - leaving unconfigured\n    Processing triggers for desktop-file-utils ...\n    Processing triggers for bamfdaemon ...\n    Rebuilding /usr/share/applications/bamf.index...\nProcessing triggers for gnome-menus ...\nProcessing triggers for man-db ...\n\nDoes someone has ay clue ?\n\nA: Just install Ubuntu Tweak and under the apps tab, you will find a link to install Google Chrome directly.  \n\nEDIT \nCheck images below:\n\n\nThough now in your case, you will have to check the checkbox and then click install.\nHope it works out.\n\nA: If you have downloaded a .deb package containing Chrome and try to install it by doing a sudo dpkg -i <my deb file>, the command dpkg will not be able to handle the dependencies. In your case, you will have to manually install the xdg-utils package prior to installing your Chrome package :\n$ sudo apt-get install xdg-utils\n\nthen\n$ sudo dpkg -i <chrome deb package>\n\nOr as said by many others you simply install chromium with apt-get from the default Ubuntu repository, managing automatically all the dependencies. You will have the advantage to be able to easily update to new releases.\n\nA: Instead Google Chrome which not that different compare to the open source project Chromium You should intall the free version of Chrome, using the command\nsudo apt-get install chromium-browser\n\n\nA: I think that you are trying to install an x86 package on a x64 machine. Is it true? \nIf so, you should download and install the x64 version.\n", "Q: Is there any general guideline to follow in order to know why I get a Permission Denied error while running a particular command? I had recently tried to move a file to overwrite /dev/null and had encountered a Permission denied Error. From using Ubuntu for the last couple of years, I know that if I get this error, I need to be sudo to invoke the command and then it would succeed. This is what I did to overwrite /dev/null as well.\nHowever, artbristol posted a comment over there saying that blindly invoking sudo to run a command is not a good habit and we should know why we are being denied the permission to run that command before proceeding further. I tend to agree with him along with all the people who have heavily upvoted that comment. But I don't know how to proceed to know the \"why\".\nRecently, I came across this answer and tried to run the command as mentioned (393222 is the inode of examples.desktop file in ~):\n$ find . -inum 393222 -exec nano {} \\;\nfind: `./.gvfs': Permission denied\nfind: `./.cache/dconf': Permission denied\n\nRunning the above command did open examples.desktop file in nano, but also gave Permission denied for the two folders. Following are the attributes of the two folders (truncated output of ls -la):\ndrwx------  2 root   root    4096 Mar 11 21:04 .gvfs\ndrwx------  2 root   root    4096 Mar 11 21:04 dconf\n\nIs there any general guideline to follow in order to know \"why\" I get a Permission Denied error while running a particular command?\n\nA: You have to use your brain a little and  ask yourself the question:\nWhat is the application actually trying to do?\nThere isn't going to be a single answer to this as \"Permission denied\" errors  transcend filesystems, networks and authentication regimes (to name just three)... There's just no single way to find the problem... Other than to say, \"you probably don't have permission to do what you're doing\".\nBut we can look at your examples and work out where the problem is in those.\n\nIn mv testfile /dev/null you are reading from ./testfile and writing to /dev/ (to supplant /dev/null). This is what mv does when you try to move a file to a file.\nA quick stat testfile /dev/null /dev/ will show you:\n  File: ‘testfile’\n  Size: 7944        Blocks: 16         IO Block: 4096   regular file\nDevice: fc01h/64513d    Inode: 5284807     Links: 1\nAccess: (0644/-rw-r--r--)  Uid: ( 1000/     oli)   Gid: ( 1000/     oli)\nAccess: 2014-03-19 11:35:42.027427288 +0000\nModify: 2014-03-19 12:25:17.343476867 +0000\nChange: 2014-03-19 12:25:17.343476867 +0000\n Birth: -\n\n  File: ‘/dev/null’\n  Size: 0           Blocks: 0          IO Block: 4096   character special file\nDevice: 5h/5d   Inode: 31128501    Links: 1     Device type: 1,3\nAccess: (0666/crw-rw-rw-)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2014-03-18 14:33:16.742165089 +0000\nModify: 2014-03-18 14:33:16.742165089 +0000\nChange: 2014-03-18 14:33:16.742165089 +0000\n Birth: -\n\n  File: ‘/dev/’\n  Size: 4740        Blocks: 0          IO Block: 4096   directory\nDevice: 5h/5d   Inode: 1025        Links: 17\nAccess: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2014-03-20 09:51:04.408762425 +0000\nModify: 2014-03-20 09:51:04.396762425 +0000\nChange: 2014-03-20 09:51:04.396762425 +0000\n Birth: -\n\n\n*\n\n*You have read access to ./testfile\n\n*You have write access into the /dev/null pseudo character device.\n\n*You don't have permission to write into /dev/ (which you would need to replace /dev/null)\n\n*Permission denied.\n\n\nThe second example is much easier to read. From your output:\ndrwx------  2 root   root    4096 Mar 11 21:04 .gvfs\ndrwx------  2 root   root    4096 Mar 11 21:04 dconf\n\nThese directories are owned by root and they give no permission for anybody else to read or enter them. find just bounces off because it doesn't have permission to enter.\n\nA: It all depends on what the command is doing.  The list is very long.  Let's take your example from above.\nYou're trying to use nano to open a directory called .gvfs.  Unless you are root (via sudo) then you won't be able to.\nWhy?\nLook at the file permissions on the left.\nThe first character is d.  This means .gvfs is a directory.  Opening a directory in a text editor isn't going to do you much good but it's possible all the same.\nThe next three characters are rwx.  R=read, W=write & X=execute.  This means that the user root has read, write and execute permissions on that directory.\nHow do we know only root has these permissions?\nGenerally there are 10 characters that you can see for a file permission.  In this case they are drwx------.\nAfter the first character the permissions are read in blocks of 3.  The first 3 are owner permissions, the next 3 are group permissions and the final 3 are world permissions.\nSo, the directory, as we can see, is owned by user root and the group attributes are also root as can be seen by the root   root bit.  Therefore, only the root user has any permission to do anything with .gvfs.  Any other user that is a member of the root group doesn't have any permissions - as can be seen with the second block of 3 file permissions: ---.  The same goes for any other user regardless of their group membership as can be seen with the third block of 3 file permisisons: ---.\nIf .gvfs has permissions of drwxrw-r--, the following will apply:\n\n*\n\n*rwx = the owner (root) of the directory has read, write & execute permissions on this directory.\n\n\n*rw- = any user in the group root has read, write permissions but no execute permission.\n\n\n*r-- = any other user has read only permission.  No write or execute permissions.\nWhenever you get a Permission Denied error you need to know what it is you, or the command you are executing, is trying to do.\nSometimes only root has the permission to run the command or only root has the permission to carry out the instructions the command you are running as a different user is trying to do - such as editing a system configuration file.\nI hope this hasn't confused you even more.\n\nA: \nIs there any general guideline to follow in order to know \"why\" I get a Permission Denied error while running a particular command?\n\nThe general idea is that those directories are not owned by the user you used to search with and it is also not in the group. So the command informs you it can not enter that directory to perform your find. Inside /home there are some files not belonging to the user.\nYou can use this:\n find /home/ -uid 0\n\n(or a similar command: ls -la| awk '{ if ($3 == \"root\") print $9}') to find all files in /home owned by root. Files it self will not give an error with find, just directories so you could expand that to find /home/ -type d -uid 0 (-type f for just files).\nAs to this example:\ndrwx------  2 root   root    4096 Mar 11 21:04 .gvfs\ndrwx------  2 root   root    4096 Mar 11 21:04 dconf\n\nyour command, in this case, should have included sudo to prevent the message since those 2 are not owned by your username and both the group and others are excluded from r(ead). So ...\nsudo find . -inum 393222 -exec nano {} \\;\n\nBut the notice about the permission itself is harmless. You can even suppress error messages by adding 2>/dev/null to your find. \nAnd yes, we will all agree that any command needs to be examined up front. There are some common things to look for though: like rm or mv, /dev/null, /dev/random and things like forkbombs (not giving examples of those :) ). \n", "Q: Battery Life In Ubuntu 13.10 I have an acer aspire 5742g. My battery life is not good at all. I bought a new battery(not original) and my battery life is about 1h and 40 minutes. With the last battery I had(the original one) my battery life was about 30 minutes. TLP is installed and I have the closed source nvidia drivers installed. Any ideas what can be wrong??? I have Ubuntu 13.10 64bit with Unity. Those times where while using firefox or chromium, skype(logged in but not using it), dropbox and ubuntu one.\nP.S. I know that there is a serious chance the problem to be with my battery but I still want to know if there is any other problem and if it is possible to find out what is it. \n\nA: You have a usual problem with Nvidia Optimus technology. Search Internet for solutions that would fit you, for there are many. If you are not gaming, just disable nvidia card. \n", "Q: Should Ubuntu users be concerned about \"Operation Windigo\"? Should desktop users of Ubuntu (and other Linux distros) be concerned about the malware-infection drive described as \"Operation Windigo\"?\nWhat threat does it pose to us immediately and are there any longer term ramifications?\n\nA: Just reread the question. If you're on an install without SSH or your SSH server is not available online (eg it is blocked by a NAT router, et al), you have nothing to fear from this news. The whole attack requires SSH.\nAdditionally, if you're not running a webserver (and by extension you're not on an awesome internet connection), it seems unlikely —though, and importantly, not impossible— that Windigo is going to bother you, even if you do have an exposed SSH server.\nThat's not to say you're free from any risk. There is other malware and there will be even more as time goes on and Ubuntu gains users. It's also stupidly easy to manipulate people. I had a little rant a few years ago: Linux isn't invulnerable. Don't say it is.\n\nAnyway, if you're still reading, I'm going to assume you're running a SSH server on the internet.\nThe ESET post and PDF writeup on \"Operation Windigo\" should tell you everything you need in order to tell if you're at risk or are currently infected. They have sample code that can be copied out and run to test your system.\nThe whole thing is certainly worth a read but this isn't the security apocalypse some might suggest. The primary route by which these servers became infected was human idiocy:\n\nNo vulnerabilities were exploited on the Linux servers; only stolen credentials were leveraged. We conclude that password-authentication on servers should be a thing of the past\n\nSo for all the fanfare, this is a very basic infection technique. They're either cracking passwords (dictionary-attacks most likely) or they're stealing SSH keys off client computers, backups, etc. I'd like to think it's the first.\nThere is nothing clever or new about this. Everybody running a SSH server faces those risks and they're really easy to protect against. Just practise basic SSH security and you'll be fine: use password protected keys and not passwords, run sshd on a high port, fail2ban, no root user. If you ignore these basics and run a SSH server where you're allowing root logins with a password, you'll get hacked.\nAnd just because this wasn't an exploit-based infection doesn't mean the next one won't be. Staying up to date with security-release packages is vital. Make it automatic. Making sure your PHP (et al) scripts are updated is vital, subscribe to your authors' RSS feeds.\n\nThe significance of Windigo is the sophistication and portability of the rootkit that gets installed on the servers. There is network resilience through dynamic DNS, not static IPs, multiple httpd configurations to maximise success rates, the lack of dependencies in this whole stack that makes it almost certain to run in all scenarios (even on ARM)... and by all accounts the payloads (the spam, and infection kits for client computers) are very effective. 1% success is epic when you're talking about 500K a day.\nThe \"this is happening on Linux so Linux is insecure\" inference I can see in some quarters is nonsense. This could happen on any platform and frankly, it already does. What is special here is that this has been pulled together by competent developers. Thankfully the ingress point is pretty much as simple as a burglar finding the spare key under the doormat.\n\nThe Too Long; Didn't Read version...\nIt seems the hacked servers were run by idiots with weak security but don't be complacent. Check to see if your servers are infected and check to see you're not making the same stupid mistakes as the people who are currently infected.\n\nA: Heh. That is exactly why I say PPA's are bad idea. However, the articles you point at tell us about no virus. Usual security measures should be just fine: have the latest updates from main repositories, think what you download and run, no matter if root or user. \nIf you have slightest concerns about some software, lock it with AppArmor or special user ID. \n\nA: Having verified that I have a clean system, according to the suggested check, how can I prevent any future intrustions?\nssh -G 2>&1 | grep -e illegal -e unknown > /dev/null && echo “System clean” || echo “System infected”\n\n", "Q: Choose an Application When I try to install an application from the Ubuntu Software Center or Internet, I keep getting a screen called \"Launch Application\", which says:\n\"This link needs to be opened with an application. Send to:\nChoose an Application. As a newcomer to Ubuntu and just a user (not an IT expert), I don't know what to choose. Please help.\nI use Ubuntu 12.04 on a dual-boot Acer XP laptop.\n\nA: Here's Reader:\nhttp://www.liberiangeek.net/2012/10/install-adobe-reader-in-ubuntu-12-10-quantal-quetzal/\nAs for google chrome, or \"Chromium\" I suggest trying it like you probably already have before from the terminal;\n\n Sudo apt-get install chromium\n\n When it asks for your password it will say the username of the account which the expected password belongs.\nNote: Your password will not be displayed as you type.\nHowever it will be received by the terminal. \nAs for Flash, and hopefully to fix the initial problem, Try this;\n From The Terminal \nSudo apt-get purge software-center\n\nThen,..\n\nSudo apt-get install software-center\n That will remove and re-install the software center hopefully sorting out any issues its having. Then procede to search for \"Flash Player\" and I'm sure you get it from there... Anyway I'm new at all this also so I know how frustrating it can be. Let me know if it works for you. \n", "Q: encrypting text editor Is there an encrypting text editor for ubuntu?  In other words, the text editor, preferably GUI capable, should always save an encrypted file and always prompt for the password to re-open the file.  The point is to combine the functionality of a text editor with an encryption tool.  \n\nA: You could try vim with the gnupg.vim plugin, which is for transparent editing of gpg encrypted files.\ngnupg.vim description:\n\nThis script implements transparent editing of gpg\n  encrypted files. The filename must have a \".gpg\", \".pgp\" or \".asc\"\n  suffix. When opening such a file the content is decrypted, when\n  opening a new file the script will ask for the recipients of the\n  encrypted file. The file content will be encrypted to all recipients\n  before it is written. The script turns off viminfo and swapfile to\n  increase security.\n\n\nA: If you like Geany, there's a plugin (sudo apt-get install geany-plugin-pg):\n\nGeanyPG is a plugin for Geany that allows the user to encrypt, decrypt and verify signatures with GnuPG.\n\nAlso: http://plugins.geany.org/geanypg.html\n\nA: EncryptPad - an application for viewing and editing symmetrically encrypted text. It also provides a tool for encrypting and decrypting binary files on disk. It is compatible with OpenPGP. So you can open files encrypted with OpenPGP software. There is also key file protection and a password generator. Platforms: Linux, Mac OS X and Windows.\nMain Window in Windows\n\nBinary Encryptor Dialogue in Lubuntu\n\n\nA: Vi/Vim\nJust use vim or vi which offers file encryption with blowfish when using -x option.\ncreate a file for encryption as follows:\nvim -x filename.txt\n\nThen it will prompt to enter encryption key\nEnter encryption key:\n\nOnce a file has been encrypted by Vim once, you never need to use the -x option when opening that file again. Vim will automatically recognize it as an encrypted file and do the right thing.\nBecause Blowfish is a symmetric key encryption system, the same key is used for both encryption and decryption. When Vim opens a file for the first time with the -x option, the first thing it will do is ask you to give it a key you can use to encrypt and decrypt the file, with this prompt:\nNeed encryption key for \"abc.txt\"\nEnter encryption key:\n\nAfter entering the key, you will then be asked to confirm the key, to ensure you did not mistype it.\nEnter same key again:\n\nThen it will open as normally as usual.\nRead more here\nCryptoTE\nAccording to the website.\nCryptoTE is a text editor with integrated strong cryptography. \nIt is based on the popular Scintilla widget and automatically stores \ntext data in secure encrypted container files. \nCompared to other \"password keeper\" programs, CryptoTE does not force \nany structure upon your data: it works with plain ASCII text \nand does not require you to fill in grids, key-value attributes,descriptions etc. \nEncryption is transparently performed using the \nhighly-secure Serpent cipher. The editing interface is thoroughly \noptimized for speed and ease of use. \nMultiple subfiles, Quick-Find and a two-click random password generator \nmake daily use very convenient.\n\n\nfor ubuntu see.\n\nA: Gedit.\nREQUIREMENTS\n\n*\n\n*Gedit\n\n*Gedit plugin – External tools (enabled)\n\n*A valid gpg key\n\nENABLE GnuPG\nThis will only work if you have enabled GnuPG in your system.\n\nGnuPG is an implementation of PGP (Pretty Good Privacy), which is a form of public key/private key encryption.\n\nInstall GnuPG\nsudo apt-get install gnupg\n\nGenerate your keys:\ngpg --gen-key \n\nWhen generating the keys, you can just press enter at any time to accept the default value in brackets. The most important part of your key generation is choosing your passphrase.\nYour public keyring should just contain your own public key for now, you can view the keyring with the --list-keys option and your private key with the --list-secret-keys option.\ngpg --list-keys\ngpg --list-secret-keys\n\nGnuPG source: http://www.ianatkinson.net/computing/gnupg.htm\n\nSETUP\nJust go to Tools > Manage External Tools, and add the scripts:\nENCRYPT\nPaste the following code on a new command, called “Encrypt”:\n#!/bin/bash\nstdin=$(cat)\n\nif [ ! \"${stdin:0:27}\" == \"-----BEGIN PGP MESSAGE-----\"  ]; then \n    echo \"$stdin\" | gpg -a -e -r email@email.com --no-tty -\nelse\n    echo \"$stdin\"\nfi\n\nwith the options:\n\n*\n\n*ShortCut - Control + Shift + E\n\n*Save - Nothing\n\n*Input - Current document\n\n*Output - Replace current document\n\n*Applicability - All documents / All languages\n\n\nDECRYPT\nPaste the following code on a new command, called “Decrypt”:\n#!/bin/bash\nstdin=$(cat)\n \nif [ \"${stdin:0:27}\" == \"-----BEGIN PGP MESSAGE-----\"  ]; then \n    echo \"$stdin\" | gpg -d --no-tty - 2> /dev/null\nelse\n    echo \"$stdin\"\nfi\n\nwith the options:\n\n*\n\n*ShortCut - Control + Shift + D\n\n*Save - Nothing\n\n*Input - Current document\n\n*Output - Replace current document\n\n*Applicability - All documents / All languages\n\n\n\nUSAGE\nOnce that is done, then you can open encrypted files (asc – ascii files, not binary), or create new ones on spot using the shortcuts.\nExample:\n\n\nSOURCE\nhttp://blog.brunobraga.net/encrypting-and-decrypting-with-gedit/\n\nMETHOD 2\nAnother way is to install zillo.\n\nA simple plugin for gedit 3 that encode and decode selected text to base64.\n\nSee this question on how to install the plugin\n\nA: Naturally, you can also do this in emacs. The emacs wiki has a very nice page on this, providing 7 different approaches:\n\n\n*\n\n*EasyPG Assistant\n\n*Mc-Auto-Encrypt\n\n*Mc-gpg-file-mode\n\n*crypt++ and gnupg\n\n*auto-crypt (patch)\n\n*ccrypt\nThe simplest would probably be EasyPG Assistant since it is an interface to GnuPG and should work out of the box.\n\nA: DeadboltEdit - A secure encrypting text editor for Linux, Mac OS X, and Windows.\nIt uses Blowfish encryption, compatible with the OpenSSL implementation.\nWebsite: www.deadboltedit.org\n\nA: You can do it all in the command line interface with nano editor and gpg as encryption. But I don't know how secure this is. Maybe someone else can comment on that\ncreate a text file called text_file \nencrypt it with: gpg -c text_file \nthis will ask you to set a passphrase\nnow you have the encrypted text_file.gpg and the unencrypted text_file\nyou can delete the unencrypted text_file\nI wrote a bash script to make the process of updating the text_file.gpg easier. This will:\n  decrypt the text_file.gpg\n  open the text_file in nano editor  \nafter you edited the file it will:\n  delete the old text_file.gpg\n  create a new text_file.gpg\n  delete the new text_file if a new text_file.gpg was successfully created.  \n#!/bin/bash -e\ngpg text_file.gpg\nnano text_file\nshred --remove text_file.gpg\ngpg -c text_file\nif [ -f text_file.gpg ] ; then\n    shred --remove text_file\nelse\n    echo \"new gpg file not found, keeping the text file\"\nfi\n\nSave the bash script as an .sh file for example script_file.sh.\nWhenever you want to edit the text_file.gpg, you can call the script_file.sh with: \nsh script_file.sh\n\n\nA: For me, the easiest was gnu emacs. https://www.gnu.org/software/emacs/ Especially since I already had it installed and I was gleefully surprised that it 'just worked'\nemacs file.gpg\n(gui prompt for passphrase)\nfile opens.\nand Ctrl-x-s (which is how you save in emacs) will prompt you for a new passphrase.\n", "Q: Ubuntu Installer doesn't recognize my partitions I'm trying to dual boot Ubuntu 13.10 along with Win8.1.\nThe problem here is Ubuntu installer does not recognize any of my partitions and shows my whole hdd space as unallocated. That is the case with GParted also.\nThe tricky part is that the Ubuntu itself (in Live mode) is perfectly capable of recognizing and mounting the partitions.\nI did a little searching and came up with this solution but I can not be sure that it applies to my problem too as I can not risk loosing my Windows installation.\nUPDATE: The result of mount:\n/dev/sda2 on /media/ubuntu/585084B850849DFE type fuseblk (rw,nosuid,nodev,allow_other,default_permissions,blksize=4096)\n/dev/sda3 on /media/ubuntu/Linux type fuseblk (rw,nosuid,nodev,allow_other,default_permissions,blksize=4096)\n/dev/sda5 on /media/ubuntu/Linux Home type fuseblk (rw,nosuid,nodev,allow_other,default_permissions,blksize=4096)\n/dev/sda6 on /media/ubuntu/Misc type fuseblk (rw,nosuid,nodev,allow_other,default_permissions,blksize=4096)\n\nUPDATE 2: Upong running GParted I get the following message:\n\n/dev/sda contains GPT signatures, indicating that it has a GPT table. \n  However, it does not have a valid fake msdos partition table, as it\n  should.  Perhaps it was corrupted -- possibly by a program that\n  doesn't understand GPT partition tables.  Or perhaps you deleted the\n  GPT table, and are now using an msdos partition table.  Is this a GPT\n  partition table?\n\nAnd here is a screenshot from GParted.\n\n\nA: I fixed the problem easily using the FixParts package. It simply removed the leftover GPT data on the HDD from the previous partitioning.\n", "Q: How to change directory to the old directory? I am currently in /downloads directory. Before I was in /var/www directory. How can I return back to the old directory in terminal? I do not want to execute  cd /var/www\nI need a simple command to change to old directory.\n\nA: with bash you can use cd - to go to the old directory also known as $OLDPWD\n\nA: cd - : return back to old directory\nexample:\npwd \n\ngives\n/home/julia/Downloads\n\nNow\ncd -\n\nthen \npwd\n\ngives\n/var/www\n\ncd .. : return back to parent directory\ncd ~: go to home directory\n", "Q: New Apache's version in repositories Does anyone has a time frame for an update in Apache's version for repositories/official-repositories?\nUbuntu server is working like a charm and wouldn't like to switch to manual installation for Apache due to PCIDSS flags. Currently ver 2.2.22 (2.2.22-1ubuntu1.4) is distributed from repositories and ASVs find this to be vulnerable although security patches are applied.\n\nA: For various reasons, software already in the main repos aren't updated to a new upstream version unless there are security bugs in the current versions (CVE, denial-of-service, etc.). If there is a published vulnerability for this version, you can file a bug here, and someone may work on a security update.\n", "Q: can't install hardly anything...winbind unstable Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nwinbind is already the newest version.\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n1 not fully installed or removed.\nNeed to get 0 B/2,511 kB of archives.\nAfter this operation, 0 B of additional disk space will be used.\nDo you want to continue [Y/n]? y\ndpkg: error processing winbind (--configure):\n Package is in a very bad inconsistent state - you should\n reinstall it before attempting configuration.\nErrors were encountered while processing:\n winbind\nE: Sub-process /usr/bin/dpkg returned an error code (1)\n\nThis is the general idea anytime I try to do anything with winbind.\n\nA: Try Running:\nsudo apt-get --reinstall install winbind\n\nReference: AptGet manual\n", "Q: CCISS not recognizing new SCSI drives - HP Proliant Server Linux newbie here.\nI have a HP Proliant Server, which I can get details on if they will help.  This blade has been running Windows server 2008 up until last week, when I loaded Ubuntu 12.04 server to implement a FOG server for imaging.\nI started with a 148GB SCSI drive and installed Ubuntu, got the fog working wonderfully.  I decided today that I needed more space for images.  There are three 72GB SCSI drives sitting in the server (unseated) and I want to do a RAID 5 with them.  I pushed all three of the drives in, did several restarts, but still fdisk -l and parted -l do not see them.\n/dev/cciss/c0d0 exists, but c0d1 and so forth do not.\nAm I missing something here?  The drives worked fine a week ago in a Windows environment.\nThanks so much for any help you can provide.\nEdit:\nTo help, here is the readout of fdisk -l:\nroot@S-9782:~# fdisk -l\n\nDisk /dev/cciss/c0d0: 146.8 GB, 146778685440 bytes\n255 heads, 32 sectors/track, 35132 cylinders, total 286677120 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x0002fd38\n\n           Device Boot      Start         End      Blocks   Id  System\n/dev/cciss/c0d0p1   *        2048      499711      248832   83  Linux\n/dev/cciss/c0d0p2          501758   286676991   143087617    5  Extended\n/dev/cciss/c0d0p5          501760   286676991   143087616   8e  Linux LVM\n\nDisk /dev/mapper/S--9782--vg-root: 137.9 GB, 137912909824 bytes\n255 heads, 63 sectors/track, 16766 cylinders, total 269361152 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\nDisk /dev/mapper/S--9782--vg-root doesn't contain a valid partition table\n\nDisk /dev/mapper/S--9782--vg-swap_1: 8585 MB, 8585740288 bytes\n255 heads, 63 sectors/track, 1043 cylinders, total 16769024 sectors\nUnits = sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 512 bytes\nDisk identifier: 0x00000000\n\nDisk /dev/mapper/S--9782--vg-swap_1 doesn't contain a valid partition table\n\n\nA: I figured this out.  Just for posterity sake, I used this resource:\nhttp://www.scottalanmiller.com/linux/2012/04/22/adding-new-drives-to-an-hp-proliant-smartarray-with-lvm/\nEssentially I was missing the HPACUCLI utility that is needed to pass logical drives through to the LVM.  The controller saw them, it just was not passing them through to linux.  Pretty easy fix, getting the HP repository to load was a little annoying.\n", "Q: how to set a default window manager UBuntu 12.04 LTS uses Compiz 0.9.7.12 as a default window manager. Where UBuntu stores an information which window manager is used by default ? I want to permanently switch to the metacity or run compiz with parameters, for example compiz --debug core composite opengl. \n\nA: Ubuntu stores the information in \n/usr/share/gnome-session/sessions/\"YOURSESSION\"\n\nThe property DefaultProvider-windowmanager is where you set your default window manager.\nLike this DefaultProvider-windowmanager=metacity\n", "Q: Deluge keeps crashing I'm using Ubuntu 12.04 for almost a week now and tried Deluge 1.3.6 (through the ppa their website provided), but it keeps crashing. I don't really know why it does though. I had searched the internet for more information on it, but couldn't find the reason nor a solution. I tried deluge 1.3.5 without the ppa, which crashed also.\nI noticed that the versions of libtorrent differ when asking deluge or the package manager.\nuser@pc:~$ deluge -v\ndeluge: 1.3.6\nlibtorrent: 0.15.10.0\n\nWhile it says 0.15.10-1 in the package manager after libtorrent-rasterbar6. Not sure if this is related to the problem though.\nSince the crash report is quite large, I didn't really know what information to provide, but I read deluge was supposedly be a good torrent client for Ubuntu, so what do you think the problem is and what can I do to fix this?\n@Rinzwind: The warning is when starting Deluge, the segmentation fault is when it crashes.\n/usr/lib/python2.7/dist-packages/deluge/ui/gtkui/mainwindow.py:108: Warning: g_object_unref: assertion `G_IS_OBJECT (object)' failed\n  gtk.main_iteration(False)\nSegmentation fault (core dumped)\n\nUpdate\nAfter updating to 0.16.14.0 as mentioned in Cas's answer, the warning remains, though it hasn't crashed yet. I'll update if it crashes again.\n\nA: There is a known libcrypto issue with 0.15 libtorrent on 12.04 so you can use 0.16 libtorrent from the Deluge PPA\n", "Q: Cannot mount encrypted LUKS drive with \"x-gvfs-show\" option I've used Linux Mint 16 Petra's Disks utility to format my external drive as an encrypted LUKS ext4 partition.\nThe problem is that I can't mount it if I use the option \"Show in user interface\", that adds a \"x-gvfs-show\" parameter to my fstab file.\nIf I remove this parameter I can mount it correctly but I don't see the drive in Nemo.\nThe output of \"dmesg | tail\" just after I try to mount the drive is:\n[  724.841456] EXT4-fs (dm-3): mounted filesystem with ordered data mode. Opts: (null)\n[ 2094.754682] EXT4-fs (dm-3): Unrecognized mount option \"x-gvfs-show\" or missing value\n[ 2114.994445] EXT4-fs (dm-3): mounted filesystem with ordered data mode. Opts: (null)\n[ 6286.799200] EXT4-fs (dm-3): Unrecognized mount option \"x-gvfs-show\" or missing value\n\nA workaround that I've found is to disable that option, mount the drive, then add it back and the drive will be showed into Nemo's sidebar, but I'd prefer to avoid this boring steps every time I boot up.\nThanks!\n\nA: Unfortunately, you found this bug: \nhttps://bugs.launchpad.net/ubuntu/+source/util-linux/+bug/1012081\nThe util-linux package in Ubuntu 13.10 is still the version 2.20 (2012). It is a very critical package and must be updated with a lot of caution, and in sync with upstream, although probably in this case there have been a bit of overzealous safety... \nOn the other hand, it can be seen as a bug of gvfs for using features not present in the stable version of the package, here: https://bugs.launchpad.net/ubuntu/+source/gnome-disk-utility/+bug/1011257 \nSo I basically think there is an impasse here. \nI hope (but I do not think) that the update will land in 14.04. \n", "Q: Create a .desktop file that opens and execute a command in a terminal I would like to know how to write the Exec command of a .desktop file to open a new terminal and execute a shell script in it. The shell script is working and accessible by all users. When launching the script from the terminal everything works, but it doesn't when trying to launch the script from a .desktop file.\nHere are some combinations I have already tried:\nExec=gnome-terminal -x sh -c 'echo hello'\nExec=sh -c 'gnome-terminal echo hello'\nExec=sh -c 'echo hello'\nExec=echo hello\n\nThe .desktop terminal option is set to true.\n\nA: The content of your desktop file should look like (see how to create a .desktop file using a text editor):\n[Desktop Entry]\nVersion=1.0\nName=Test        \nComment=Test the terminal running a command inside it\nExec=gnome-terminal -e \"bash -c 'echo hello;$SHELL'\"\nIcon=utilities-terminal\nTerminal=false\nType=Application\nCategories=Application;\n\nOr:\n[Desktop Entry]\nVersion=1.0\nName=Test        \nComment=Test the terminal running a command inside it\nExec=bash -c 'echo hello;$SHELL'\nIcon=utilities-terminal\nTerminal=true \nType=Application\nCategories=Application;\n\nIn the first case, the Terminal field is set to false (perhaps contrary to your expectations) and in second case is set to true, but the result is in both cases the same.\n\nA: !#/bin/bash\n\ngnome-terminal -e YOUR_COMMANDS\n\nMake the above file. Don't forget to sudo chmod +x filename.sh\n\nA: Simply add \n;$SHELL \n\nat the end of your commands. \nLike for me snapd isn't something using full bandwidth of system to refresh snaps anytime almost I work at night.\nSo this worked for me to create a .sh file linked to a .desktop file.\nContents for .sh file were\necho <your password> | sudo -S systemctl stop snapd.service\nsudo systemctl disable snapd.service;$SHELL\n\n-S in the first line of the .sh file is used to send STDINPUT to the sudo command meaning direct execute without entering password.\nContents for the .desktop file were:\n[Desktop Entry]\nVersion=1.0\nName=Test\nComment=Test the terminal running a command inside it\nExec=gnome-terminal -e \"/scripts/disable_snap.sh\"\nIcon=terminal\nTerminal=true\nType=Application\nCategories=Application;\n\n\nA: TL;DR\n[Desktop Entry]\nVersion=1.0\nName=Hello\nExec=sh -c 'echo hello; $SHELL'\nIcon=utilities-terminal\nTerminal=true\nType=Application\n\n\nAs stated in desktop entry specification, Terminal=true tells the launcher to launch your script in a terminal window. The chosen Terminal Emulator depends on your default applications settings and Desktop Environment. In GNOME, it is gnome-terminal, in KDE, it is Konsole. (Without DE, in plain WM there is a bug in xdg-open, and Terminal=true just ignored, see issue)\nYou need this line to run your script and launch a shell after it.\nExec=sh -c 'echo hello; $SHELL'\n\n\n*\n\n*sh -c 'COMMAND' run the \"sh\" binary found in $PATH which\nexecutes COMMAND (on many systems, sh is the symbolic link to\nbash, but for portability \"sh\" is prefered)\n\n*echo hello; $SHELL does two things. First, it runs echo hello\nand then, after the execution of this command, launches $SHELL.\n\nIf you will not add some command that waits for you to exit, a terminal emulator will just run your program and exit.\n\nP.S. If you just want not to close your terminal, you can do\nExec=sh -c 'echo hello; read'\n\nOr\nExec=sh -c 'echo hello; sleep 5'\n\n(read will wait for you to press Enter, sleep will just wait 5 seconds)\nP.P.S $SHELL probably will be the same as last section in /etc/passwd in line with your user.\n$ man login\n\n\nThe value for $HOME, $USER, $SHELL, $PATH, $LOGNAME, and $MAIL are set\nac‐\ncording  to  the  appropriate fields in the password entry.\n\n\nA: I do this. First line of the text file is !#/bin/bash\nSubsequent lines of the text file are the commands (the shell script).\nSave the file as something.sh\nOpen the properties of the file and enable run file as a program.\nNow, when the file is double clicked, I get the option to run it.\n", "Q: Photo viewer / File Manager thumbnails / photos I started working @ a recovery data company and sometimes I have to manualy go through all the photo's and delete the ones that are not 100% correct. \nSomething the thumbnail shows no problem with the picture, but when I open it, it's totally messed up. And it would safe me A LOT of time if there's a program or a file manager kind of thing that shows the photo in a small size instead of showing the thumbnail, since thumbail isn't the same as a small picture.\nHope you all understand and someone has a good solution.\nThanks <3\n\nA: Try to load your images using feh\nsudo apt-get install feh\n\nOpen a terminal and try the thumbnail mode in your Pictures folder:\nfeh -t\n\n\nfeh is an X11 image viewer aimed mostly at console users. Unlike most\n  other viewers, it does not have a fancy GUI, but simply displays\n  images. It is controlled via commandline arguments and configurable\n  key/mouse actions.\n\nVisit: http://feh.finalrewind.org\n\nA: You can try clearing the thumbnail cache before you open the folder.\nRun these commands:\nrm -r ~/.thumbnails\nkillall nautilus \n\nThis will regenerate the thumbnails again with the defects (hopefully). Then in Nautilus, you can use ctrl++ to zoom in on the thumbnails for a clearer larger view. Then you can select and delete the ones you don't want.\n", "Q: Default group permissions for /var folder I accidentally ran sudo chmod -R g+rw /var instead of sudo chmod -R g+rw /var/www. This means that for every file, the group owner now has explicit read-write access.\nI have already seen an example of attempting to fix chown -R www-data:www-data /var but that is a slightly more serious issue that doesn't really apply here. Also the help given doesn't really help me restore the group permission settings to /var.\nIs there an easy way to set the group permissions back to their defaults? What would you advise I do now? I'd really like to avoid reinstalling if possible.\n// edit: I reinstalled Ubuntu. Thanks for your help.\n\nA: /var is used by various processes to write lock files, cache, pid files, log files, ... Some files / sub-directories will need one kind of permissions / ownership, some will need something different.\nI'm afraid to tell you that you cannot solve your problem with only one command (unless you have a backup of /var with all permissions and ownership preserved).\nTo help you to understand the challenge, here is a printout of my /var :\ndrwxr-xr-x  2 root   root      4096 mar 15 21:36 backups\ndrwxr-xr-x 29 root   root      4096 mar  4 10:53 cache\ndrwxrwsrwt  2 root   whoopsie  4096 fév  6 20:21 crash\ndrwxr-xr-x  2 root   root     12288 oct 27 10:48 games\ndrwxr-xr-x 98 root   root      4096 mar  4 11:40 lib\ndrwxrwsr-x  2 root   staff     4096 oct 20  2009 local\nlrwxrwxrwx  1 root   root         9 mai 31  2012 lock -> /run/lock\ndrwxr-xr-x 27 root   root     12288 mar 20 07:44 log\ndrwxrwsrwt  2 root   mail      4096 jan 29  2013 mail\ndrwxrwsrwt  2 root   whoopsie  4096 mai 12  2013 metrics\ndrwxr-xr-x  3 root   root      4096 oct 11  2011 opt\nlrwxrwxrwx  1 root   root         4 oct 26 22:52 run -> /run\ndrwxr-xr-x 11 root   root      4096 mai 12  2013 spool\ndrwxrwxrwt  5 root   root      4096 mar 20 07:52 tmp\ndrwx------  3 root   bin       4096 mar  9 12:13 webmin\ndrwxr-xr-x  6 benoit root      4096 oct 31 21:22 www\n\nYou will remark that some of these directories need to be setuid (the s flag in the permissions - sudo chmod g+s /var/metrics).\ntmp will be with the sticky bit (sudo chmod 1777 /var/tmp)\nAnd you still have to go inside each of these directories !\nBy the way, setting the ownership of the whole /var with read-write rights for the group is a bad idea. This means that if the web server is badly configured, a hacker may have the possibility to read and write the whole /var directory.\nRemember that under /var/lib you will find the data files of MySQL, Postgres, ... if you use it.\nIf you want to fix the permissions and the ownership without reinstalling the system, you will have to do a second installation of Ubuntu elsewhere and check what are the exact permissions and ownership on /var (ls -lR /var)\n", "Q: How do you create a script to batch add repositories and then batch install packages? I've used Synaptic Package Manager to save markings for all installed packages to a file. Here's a snippet:\nlibmono-system-drawing-design4.0-cil    install\nspotify-client  install\nmono-2.0-service    install\nxtrans-dev      install\ninputattach     install\nibus-gtk        install\nlibappindicator3-1  install\n\nspotify-client, though, is not part of the default SPM set of repos. And the script that SPM generated for me doesn't appear to add external sources.\nSo, how I do I create a script that add external sources, updates the package lists, simulates the installation, and then does an actual batch install?\nI assume the programs I've installed through the Ubuntu Software Center are reflected in Synaptic Package Manager--USC is a frontend for a frontend, no?\n\n\nA: \nStep 1\n\nsudo apt-get install python-software-properties\n\n\nStep 2\n\n# For example - \n# http://www.webupd8.org/2012/01/install-oracle-java-jdk-7-in-ubuntu-via.html\nsudo add-apt-repository ppa:webupd8team/java\n\n\nStep 3\n\nsudo apt-get update\nsudo apt-get upgrade\n\n\nStep 4\n\nPKGLIST=\"oracle-java7-installer\" # Whatever packages you want to bulk install\nsudo apt-get install $PKGLIST\n\n", "Q: Is it possible to add things such as internet searches to the default unity search? If I wanted to search the internet from the Unity search utility, is it possible to add that? Would it be possible to add something to it that shows only internet shopping results?\n\nA: Unless you use website lenses and not all websites have them. I will give you an example with this site:\nInstall the Ask Ubuntu lens:\nsudo apt-get install unity-lens-askubuntu\n\nIn your Dash, you will get an askubuntu icon. See screenshot below after I have searched for 'ubuntu'.\n\nHere is a list of available unity lenses: What lenses for Unity are available?\n", "Q: How can I check for apt-get errors in a bash script? I am writing a bash script to install software and update Ubuntu 12.04. I would like the script to be able to check for apt-get errors especially during apt-get update so that I can include corrective commands or exit the script with a message. How can I have my bash script check for these types of errors?\nEdit March 21st:\nThank you terdon for the providing just the information I needed! Here is the script I created with a combination of your suggestions to check for updates and recheck when errors occur and then report back. I will be adding this to a longer script that I am using to customize new Ubuntu installations.\n\n#!/bin/bash\n\napt-get update\n\nif [ $? != 0 ]; \nthen\n    echo \"That update didn't work out so well. Trying some fancy stuff...\"\n    sleep 3\n    rm -rf /var/lib/apt/lists/* -vf\n    apt-get update -f || echo \"The errors have overwhelmed us, bro.\" && exit\nfi\n\necho \"You are all updated now, bro!\"\n\n\nA: The simplest approach is to have your script continue only if apt-get exits correctly. For example:\nsudo apt-get install BadPackageName && \n## Rest of the script goes here, it will only run\n## if the previous command was succesful\n\nAlternatively, exit if any steps failed:\nsudo apt-get install BadPackageName || echo \"Installation failed\" && exit\n\nThis would give the following output:\nterdon@oregano ~ $ foo.sh\n[sudo] password for terdon: \nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package BadPackageName\nInstallation failed\n\nThis is taking advantage of a basic feature of bash and most (if not all) shells:\n\n\n*\n\n*&& : continue only if the previous command succeeded (had an exit status of 0)\n\n*||: continue only if the previous command failed (had an exit status of not 0)\n\n\nIt is the equivalent of writing something like this:\n#!/usr/bin/env bash\n\nsudo apt-get install at\n\n## The exit status of the last command run is \n## saved automatically in the special variable $?.\n## Therefore, testing if its value is 0, is testing\n## whether the last command ran correctly.\nif [[ $? > 0 ]]\nthen\n    echo \"The command failed, exiting.\"\n    exit\nelse\n    echo \"The command ran succesfuly, continuing with script.\"\nfi\n\nNote that if a package is already installed, apt-get will run successfully, and the exit status will be 0.\n\nA: Yo can set options to stop your script like this:\nset -o pipefail  # trace ERR through pipes\nset -o errexit   # same as set -e : exit the script if any statement returns a non-true return value\n\n", "Q: What is the significance of permission of `/etc`? Trying to replicate the problem described in \"/etc/profile permission denied!\" where OP of the post in her comments mentions the permission string for her /etc directory being drw-r--r--. I issued sudo chmod 644 /etc and yes that did replicate the problem. Then in live environment I corrected the permission back to 755. (I thought thought that would do no harm, I was just changing the permissions!) With /etc permission reverted back to original, the login problems and others like not being able to sudo were fixed but I'm facing lots of problems in the GUI. Unity doesn't load, no Launcher, no Dash appears! helped to some extent but other problems still persist.\nThe Question:\nWhat's the reason behind this? I just toggled the execute bit of /etc's permission! Why did that have significant effect on Unity?\n\nA: Right, I tried this (on a VM :-)) and got the same behavior you describe. I  changed the permissions on /etc, and rebooted and since I had configured my system to log me in automatically, it attempted to log me in directly and failed. \nI don't know enough about Unity's internals to be understand the details but my guess is that when you attempted to login, since the system didn't have access to /etc it couldn't read all sorts of essential files such as /etc/passwd or /etc/group or anything to let it map your username to the appropriate UID and GID. Therefore, upon the attempted login, file details were somehow screwed up.\nMy guess, and I stress that I'm guessing, is that changes were made to your gconf configuration settings which then screwed with Unity. \nI fixed this on my VM by simply deleting all files from my $HOME, removing my user and recreating him. Obviously this is not a solution on the system that you actually use.\nThe only workaround I can think of is to move/rename all the configuration files and directories:\nmkdir old_dotfiles\nfor file in .*; do mv \"$file\" old_dotfiles; done\n\nThis will move all of your configuration files and directories to ~/old_dotfiles. You can then log out and log in again or reboot and things should be back to normal though you will have lost your config settings. You can then try copying them back again. If this is just a file ownership issue, copying them back should reset the ownership and might fix your problem. If the change was made within one of the conf file, this will break your system all over again so proceed with caution.\nBear in mind that most configuration files will be created automatically so you only need to worry about cases where you have made changes to the defaults. Also, you should make sure that \"system\" folders of your GUI such as ~/Desktop are correctly set up.\nMy guess is that this should be enough to return you to a working system, with a newfound  love for virtual machines.\n", "Q: Occasional Freeze at Boot My recently installed Ubuntu (and ALL the other distros I used before) sometimes (not-always) hangs on boot.\n It's a hard-to-debug problem because it just happens 'sometimes' (I never know when the boot will hang).\n When the problem arrives, the screen STOPS in a \"Ubuntu purple\" empty screen, just after the \"purple GRUB\" screen. In the other distros, the boot used to stop in a black screen, which appears in the EXACTLY same point of the \"Ubuntu purple\" screen.\n I'm relatively new to the GNU/Linux world, so please, be patient.\n\nA: To debug more, I advise to change the boot options so that the boot is more verbose. \nIf you edit (as root, with gksudo gedit /etc/default/grub) you can see a line somewhere with is similar to: \nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\n\nremove \"quiet\" (or the two of them to have an old-style, no graphic, verbose boot) and save. Then you have to run\nsudo update-grub \n\nNow your system will be much more verbose on boot, and maybe you can see where the problem is. \n\nA: Install Xubuntu 12.04.4 LTS and see if you experience the same hang/freeze issues. You can install Xubuntu on a linux partition or you can test it on a NTFS partition in Windows with Wubi. If you use wubi.exe to install Xubuntu do not allocate more than 30GB for the virtual disk(s).\nI got rid of a similar problem with yours after replacing lightdm with mdm . Now I have MDM as default display manager, and the login greeter for mdm can be customized in all possible ways, and I like it better than the Unity Greeter which enters into low graphics mode everytime you make a tiny adjustment to your default Ubuntu settings.\n", "Q: Ownership of .Xauthority transferred to root Somehow, while playing around with LightDM and Webkit Greeter, the ownership of the .Xauthority file in my home dir was given to the root user and I couldn't login because I hadn't the privilegues to lock the file.\nI was able to regain ownership of the file and I could login again. (After several hours of reinstalling LightDM and it's greeters)\nSo now everything's working fine again. But I'd like to know how this happened. Is this a bug in LightDM or Webkit Greeter or something else?\n\nA: It happened to me too. I think that it could be caused by running\nsudo graphic_application\n\ninstead of \ngksudo graphic_application \n\nfor some (unknown) app. There is a paragraph in the sudo help page about that...  scroll down to \"Graphical sudo\".\nSee also What is the difference between \"gksudo nautilus\" and \"sudo nautilus\"?\n\nA: Almost certainly not, no. You either started an X session as root (not sure how you managed that) or simply used touch or otherwise wrote .Xauthority with sudo. For more details, you'd have to explain what you were actually doing.\nNext time, don't reinstall anything, just delete the ~/.Xauthority file, it will be recreated automatically next time you log in:\nsudo rm ~/.Xauthority\n\nThen log in normally.\n", "Q: Searching through output of more command When searching through the output of more command how can I search for a phrase that includes spaces in between? When I search for a phrase like \"typedef struct audiodev\" it doesn't find the phrase in the file and I'm assuming this is because I need to express the space between the words with a certain symbol.\n\nA: I'd use a regexp to match spaces:\negrep 'typedef\\s+struct\\s+audiodev' your_file\n\nHere \\s+ corresponds to one or more spaces\n\nA: You can combine the command more with other tools like grep.\nOpen a console and try:\nmore yourfile | grep \"typedef struct audiodev\"\n\n\nA: In the search function of more, spaces (all special characters actually) need to be escaped, so you could search like this:\n/typedef\\ struct\\ audiodev\n\n", "Q: Oracle java giving me trouble with strange warning. Details Below Heres the error:warning: current package is oracle-java8, but binary format already installed by openjdk-7. i used the purge command on openjdk before i tried to  install Oracle Java 8 . now I'm at a loss.\n\nA: First, reinstall openjdk. Then install Java 8. Then run update-java-alternatives to select Java8. Finally, (optionally) try to remove openjdk. The cost of keeping the previous version (in disk space) is pretty low (because modern disks just keep getting bigger).\nOnce you have Java 8 installed, you need to set it as your JVM -\nsudo update-java-alternatives -s java-8-oracle\n\nThen you can verify that you have it selected correctly by\njava -version\n\n", "Q: Internet Dongle Help Ubuntu 12.04 I have a 3Gmobile broadband dongle that is supposed to go on windows XP, Vista, and 7. Is there any way i can use this dongle for ubuntu 12.04? Model #- SCT-UM300\n\nA: As I understand you need to install usb-modeswitch and usb-modeswitch-data packages, and to do that you have to use your Ubuntu CD/DVD as a repository, meaning you have to add it to the Software Sources list. Unless you also have a wired connection and you can already use the Internet. Anyway, you have to type this code in terminal:\n  sudo apt-get install usb-modeswitch usb-modeswitch-data\n\nThose 2 packages should be already present on your system and you may get a message in the terminal saying that they are installed but if they are not you need them. \nNext step is to visit this page to learn how to setup a 3g connection using ubuntu network manager. I hope this helps because I am no expert in this kind of problems but I thought you can find a solution following the instructions from the link I gave you.\nThe intructions are targeted to people living in the UK, so you should choose your own location and all the other required data. \n", "Q: How can I fix Ubuntu When I turn on my computer I have the choice of Windows 7 and Ubuntu.  I click Ubuntu and it shows wubildr is missing error:oxcoooooof.  To fix that error I run bcdedit in a Windows cmd-prompt, but it returns the following:\nThe boot configuration data store could not be opened. Access is denied.\nWhat should I do?\n\nA: It looks like you installed Ubuntu inside Windows with Wubi. If that is the case you can use  this solution which worked for me too. The easiest way to fix Ubuntu is to:\nKeep your Windows untouched, as it is, no need to make any change in Windows. As for your Ubuntu, you have to move first both the root.disk and the swap.disk files which are located in folder ubuntu/disks where you previously installed Ubuntu with Wubi. Move root.disk and the swap.disk into some temporary directory, and after that uninstall ubuntu from Control Panel like you do when you have to uninstall any other windows software.\nNext step is to reinstall the same release of Ubuntu with Wubi again (you can allocate less disk space than before, it does not matter because you'll be replacing the new root.disk with the old root.disk anyway). Use the same username and the same password as before. Wait until Wubi installer asks you whether you want to 'Reboot now' or 'Reboot Later', and choose to reboot later, do not reboot the computer.\nNext, before rebooting to complete the installation of Ubuntu, copy back the old root.disk and swap.disk files that you saved in a temporary folder and override the new ones present in folder ubuntu/disks where your new ubuntu installation is. After that you can reboot, and Ubuntu should boot as before preserving all your system settings and packages.\nAfter you login into Ubuntu, open a terminal and run this command in the terminal:\n sudo update-grub\n\nAnd I think that is all. The only thing you should not do for this to work is to install a different version of Ubuntu. Nothing will work if you do that.\n", "Q: New Lenovo X1 Carbon 2nd Generation - function key bar and vertical scrolling I just installed ubuntu 13.10 on a new x1 Carbon (second generation) and everything works fine so far. I adjusted the touchpad to disable \"tap-to-click\" and enabled \"middle-mouse-button\" and just fine tuning the touchpad (it is really bad in the default setup).\nNow I have two problems left:\n\n\n*\n\n*How can I make use of the function key bar? I can use F1-F12 just fine, but with \"Fn\" you should switch the OLEd to other keys. This does not work. Brightness/Settings/WLAN key does not work either. \n\n*How can I enable vertical scrolling with trackpoint and middle mouse button. On my lenovo T530 it worked out of the box.\n\nA: I managed to find a work around by enabling the proposed updates in \"Software Sources\", otherwise known as \"Software and Updates\" in Lubuntu 14.04\nCheck this out; this issue has been fixed if you can't wait for the 3.15 kernel to release\nhttps://bugs.launchpad.net/ubuntu/+source/linux/+bug/1309609\nGot it working only on the 3.13.9-27 kernel. Tried 3.14 with adaptive keyboard cycling as it should but not returning after resume from suspend. \n", "Q: Ubuntu 14.04 Unity or Gnome? There is no problem at this time with any software, as I am simply trying to get ready for 14.04.\nDo I need to uninstall the gnome from 13.10 or will everything upgrade properly. I cannot find any information on the internet about 14.04\nAgain, THERE IS NO BUG.\n\nA: If you have installed GNOME (3.8) from the standard Ubuntu 13.10 repositories, there is no need to uninstall before upgrading.\nIf you have installed the more recent version of GNOME 3.10 through the GNOME PPA, you should remove it first with the ppa-purge utility following the instructions in the linked article. This will downgrade the GNOME packages to the versions in the official Ubuntu repository so that the distribution upgrade can proceed smoothly.\n", "Q: Where is mysqldbcompare? The MySQL docs refer to a utility mysqldbcompare. But it doesn't seem like I have it installed, and when I type mysqldbcompare it doesn't suggest any packages (Ubuntu 12.04). Where can I find this utility?\n\nA: Since mysql-utilities is not available from the 12.04 repo, you'll have to install the quantal version instead\n\n\n*\n\n*Download this deb file\n\n*Install python-mysql.connector: sudo apt-get install python-mysql.connector \n\n*Run sudo dpkg -i mysql-utilities_1.0.5-1_all.deb\n", "Q: compressed block device I wanted to experiment with combining bcache and a compressed block device on a hdd and seeing if this will speedup the boot time. Are there any means of compressing a block device at the block level? something like cloop but with read-write capabilies. \nThe write need not be very fast. I was thinking of something similar to how the zram deals with it's pages.\nI know the future will bring us ubiquitous ssds and stable btrfs with compression, but that really doesn't scratch my itch now :P\n\nA: \nAre there any means of compressing a block device at the block level? something like cloop but with read-write capabilies\n\nNo, since you can't predict what compression ratio you are going to get, so you don't know how much real storage you need to hold the compressed data.  The fecal matter would hit the rotary air impeller if you started filling such a device with very non compressible data.\nzram gets around it by not allocating memory to hold the compressed data until it actually needs it, and assumes that you have plenty more ram than the maximum size of the zram device.\n", "Q: Stop the recording after some period of time I have a device that recording the video using the webcam with ffmpeg. It is working great,\nwhen the recording is started I am getting the USR1 signal. And after stoping the recording we receive the USR2 signal.\nBut I want to stop the recording after 1 hour recording time. \nI don't know but I think I have to pass the USR2 signal to the device after 1 hour.\nSo how can I do this...!!!\nThanks in advance.\n\nA: If you're running ffmpeg or avconv from the command line, you could use the timeout command:\ntimeout 3600 avconv -f video4linux2 -r 25 -i /dev/video0  -vcodec mpeg4 -y out.mp4\n\n\nA: Use the -t option. From man ffmpeg:\n\n-t duration (input/output)\nWhen used as an input option (before -i), limit the duration of data read from the input file.\nWhen used as an output option (before an output filename), stop\n  writing the output after its duration reaches duration.\nduration must be a time duration specification, see the Time duration\n  section in the ffmpeg-utils(1) manual.\n-to and -t are mutually exclusive and -t has priority.\n\nExample that records for one hour:\nffmpeg -f v4l2 -i /dev/video0 -t 01:00:00 output\n\nOr in seconds:\nffmpeg -f v4l2 -i /dev/video0 -t 3600 output\n\n\nA: If you know in advance the timeout you should definetely use the methods given, however, if you really want to send a signal to the process you can use the kill command (despite being used 90% for TERM or KILL, can send ANY signal - kill -s USR2 pid)\n", "Q: svn SQLite compiled for 3.7.17, but running with 3.6.1 Trying to update a svn working copy using\nsvn update .\n\nI get the following error:\nsvn: E200029: Couldn't perform atomic initialization\nsvn: E200030: SQLite compiled for 3.7.17, but running with 3.6.1\n\nI am working with kubuntu 13.10 (with latest updates). I think that this suggests an error in in the packages (version mismatch). However I have this problem since a while and find only older similar reports on different OS's. So I wonder if something is wrong on my system. It would be useful to know what 3.6.1 is supposed to be the version of. It is of course not svn which is version 1.7.9 and sqlite -version yields 2.8.17.\nEDIT\nIt turned out that the apparent version mismatch is due to the to the simultaneous presence of a second version of sqlite (version 3.6.1 installed by Mathematica). Since this installation path is in the environment variable LD_LIBRARY_PATH svn seems to prefer this version and hence the mismatch. I could define an alias for svn or Mathematica which exports LD_LIBRARY_PATH before running the respective application, but I would prefer a more elegant solution. So, what is the recommended way to maintain two sqlite installations at the same time? \n\nA: The saucy version of libsqlite3-0 is 3.7.17-1ubuntu1. It should not be 3.6.1\nTry to run:\nsudo apt-get --reinstall install libsqlite3-0\n\nAnd check the version with:\ndpkg-query -s libsqlite3-0\n\n", "Q: how to install CryptoTE CryptoTE instructions for Ubuntu indicate that deb should be invoked.  My 12.04 (Precise) system shows there is no such command.  What's wrong with this installation procedure?\n\nImport repository public key:\nwget -O- https://panthema.net/repo/key.asc | apt-key add - \nor with sudo:\nwget -O- https://panthema.net/repo/key.asc | sudo apt-key add - \nAdd binary repository line to /etc/apt/sources.list:\ndeb http://panthema.net/repo/ubuntu precise main \nUpdate package listings and install the package cryptote:\napt-get update\n  apt-get install cryptote\n\nNote that I had to use sudo for wget as well as for apt-key so there might be an error in that regard.\n\nA: Deb is not a command. The given command deb http://panthema.net/repo/ubuntu precise main is not the command that will add the source  into /etc/apt/sources.list.\nInstead it is a line that has to be added to the file /etc/apt/sources.list\n You need to edit your /etc/apt/sources.list file and add the following line\ndeb http://panthema.net/repo/ubuntu precise main\n\nto the end of the file.\nOr you can add it sources.list from command line using apt-add-repository as follows:\nsudo add-apt-repository \"deb http://panthema.net/repo/ubuntu precise main\"\n\nIf you get the error Cannot add PPA: 'No JSON object could be decoded' then add it manually.\nThen, update your system and then install cryptoTE by running \nsudo apt-get update\nsudo apt-get install cryptote\n\n", "Q: Is Bitcoin core V.0.9 not updated on PPA ppa:bitcoin/bitcoin? Version 0.9 of Bitcoin-Qt just came out. When will ppa:bitcoin/bitcoin be updated? In the meanwhile, any steps showing how to upgrade are welcome!\nEqually posted on https://bitcoin.stackexchange.com/questions/23773/is-bitcoin-core-v-0-9-not-updated-on-ppa-ppabitcoin-bitcoin\n\nA: It depends on the owner of the ppa.\n", "Q: Does Lubuntu have a future? I have some old, lower-end hardware (P4, 2.0 GHz, 1 GB RAM) onto which I have installed Lubuntu 13. 10 as my first venture into Linux. For the most part, everything has been fine and the learning curve hasn't yet been too bad to overcome.\nThe machine is mostly being used for web browsing and basic office type functions using LibreOffice.\nAfter reading this post, https://wiki.ubuntu.com/Lubuntu/Testing/14.04, I'm wondering about the future of Lubuntu and whether I should stick with it. My plan for this particular machine was to upgrade it to Lubuntu 14.04 (hopefully it will released as a LTS version) and then give this machine to a relative who needs something for basic tasks.\nIs it worth sticking with Lubuntu for something like this (a LTS release will probably outlive the machine's usefulness) or does it look like there isn't a future for Lubuntu and I should look into one of the other minimal distros.\n\nA: Lubuntu just started releasing LTS versions so why should the project end? As long as there is Ubuntu, there will be Lubuntu.\nIn fact, Lubuntu is Ubuntu, but uses the desktop environment LXDE and its software instead of the default DE called Unity.\nBasically you can use every Linux system with the Xorg graphics server and install LXDE, which would look the same as Lubuntu, but would be have a bit differently.\nAnother lightweight environment would be XFCE (which is also available as Xubuntu)\nBasically you can choose any distro- and desktop-combo. But for an older PC you should stay with LXDE or XFCE.\n", "Q: What is the public address of installed app? I've installed Discourse, wordpress, etc by juju. The below show the result for Discourse. how can I see it in my browser? what's the address?\njuju status\nenvironment: local\nmachines:\n  \"0\":\n    agent-state: started\n    agent-version: 1.17.5.1\n    dns-name: localhost\n    instance-id: localhost\n    series: saucy\n      \"1\":\n    agent-state: started\n    agent-version: 1.17.5.1\n    dns-name: 10.0.3.3\n    instance-id: onrea-local-machine-1\n    series: precise\n    hardware: arch=amd64\n  \"2\":\n    agent-state: started\n    agent-version: 1.17.5.1\n    dns-name: 10.0.3.121\n    instance-id: onrea-local-machine-2\n    series: precise\n    hardware: arch=amd64\nservices:\n  discourse:\n    charm: local:precise/discourse-0\n    exposed: true\n    relations:\n      db:\n      - postgresql\n      discourse:\n      - discourse\n    units:\n      discourse/0:\n        agent-state: started\n        agent-version: 1.17.5.1\n        machine: \"1\"\n        public-address: 10.0.3.3\n  postgresql:\n    charm: cs:precise/postgresql-62\n    exposed: false\n    relations:\n      db-admin:\n      - discourse\n      replication:\n      - postgresql\n    units:\n      postgresql/0:\n        agent-state: started\n        agent-version: 1.17.5.1\n        machine: \"2\"\n        open-ports:\n    - 5432/tcp\n    public-address: 10.0.3.121\n\n\nA: The public-address is the address assigned to the machine so in the case of discourse here it would be public-address: 10.0.3.3\n\nA: To build off of Hatch's answer, the address of the Discourse unit is the public-address line in the status display.\nThere are a few things at play here that can cause a problem with this particular installation.\n1) Is your LAN using the same IP Scheme as whats being used in the LXC Container? eg: 10.0.3.x on your home lan, you may be having an ip collision with another PC. Which would prevent you from being able to access this unit\n2) Is your bridge device up? When you run ifconfig do you see lxcbr0 in the output?\n3) Are you able to reach the machine with juju ssh? juju ssh discourse/0 (this will tell you network connectivity is present to the unit, and you can move on to the service level of debugging)\n4) Is Apache/NGINX running on the host? If so, is it started and do the logs give you any output? Check in /var/log/nginx/\n5) Can you connect to the Discourse service running on port 3000 directly? If you can, there is a problem with NGINX's reverse proxy to Discourse\n6) Check that your UFW firewall rulesets are not to blame here. Temporarily bring down your UFW firewall (if any is present) using ufw disable, and try connecting again.\n", "Q: my wireless card does not work Everything was working just fine until I followed the instructions here. Now the driver seems to be there but for some unknown reason the wireless card cannot connect to any network.\nlspci | grep Network\n\nNetwork controller: Realtek Semiconductor Co., Ltd. RTL8723AE PCIe\nWireless Network Adapter\n\nhere is the results of running iwconfig:\niwconfig\n\nwlan0     IEEE 802.11bgn  ESSID:\"SSID-E5172-DC7B\"\n          Mode:Managed  Frequency:2.462 GHz  Access Point: Not-Associated\n          Tx-Power=20 dBm\n          Retry  long limit:7   RTS thr=2347 B   Fragment thr:off\n          Encryption key:off\n          Power Management:off\n\nI was thinking, when I first installed ubuntu 13.04, ubuntu automatically installed the right network drivers. So, can I make it do that without having to reinstall it again??\n\nA: Aircrack disables your WiFi card for normal usage. To reenable it, have a look at this question asked on ubuntuforums.org\n\nA: i have had the same problem and you can use the terminal and type:\n   rfkill list\n   lspci\n   lsmod wlan0\n   nmap -v -iR 10000 -pN www.google.com\n\nit sould work fine.\n", "Q: Installing Windows alongside Ubuntu on last partition I have ubuntu 12.04 installed on my system.I wish to resize my /home (extended) partition and install Windows 7 in the free space. This would result in Windows being installed on the last partition on my hard disk. I have previously setup dual boot systems, but with Windows on the first partition and recovered grub from the live CD when needed. I want to know if there are any known issues I could face in installing Windows to the last partition.\n\nA: Windows (usually) don't install on a HDD with other OS than Windows\nDoes your Windows installer have a utility to choose a partition? Some of them don't.\nIf it does, there's a big chance of recognizing your disc as broken since you have a partition of filesystem other than NTFS, FAT and FAT32.\nBut if you're not going to reinstall Windows (you can simply move it), it should be relatively safe. Well... Safe if you're good at reseting registry and rewriting boot sector. This is how: http://ubuntuforums.org/showthread.php?t=916146\nIf you're not, Windows recovery disc may save you.\n", "Q: \"No bluetooth adapters found\" error on Ubuntu 12.04 I use HP Pavilion g6-2304tx. Initially it came with Windows 8. Then I uninstalled Windows 8 and installed Ubuntu 12.04 LTS. Bluetooth was turned off while removing Windows 8. Now I am not able to use bluetooth. When I open \"Bluetooth\", a message \"No bluetooth adapters found\" is shown. Please help me resolve this issue. \n\nA: try installing bluetooth manager from the ubuntu software center - no guarantee. worked for someone with a similar issue.\n\nA: If you have windows on the same PC configure your Blutooth software to operate in windows generic usb (Google to set up) their own software pre=installed. Your mouse and keyboard should automatically work when you switch to Ubuntu...mine does !!\n", "Q: How do I diagnose \"There was an error launching the application\"? I created a my-app.desktop file for a program I wrote. When I double-click it, I get the error message \"There was an error launching the application\". How can I get more detailed information about what the problem is?\nI saw a reference to a \"details\" section of the dialog box, but there is nothing like that present in the one I see. If I were on my Mac, I'd open the Console app to see if any errors were logged, but I haven't learned of anything similar on Ubuntu.\n(Note that unlike other similarly-titled questions, I am not asking what's wrong with this particular .desktop file; I want to know how to find out in general.)\n\nA: usually, the terminal(-output) gives you a lot of useful information, both on the application as well as the desktop file. An example:\nif I run my application from the terminal, typing the command in the terminal, the application starts. \nHowever, if there is something wrong, you can expect an output like:\nTraceback (most recent call last):\n  File \"/home/jacob/Bureaublad/werkmap_2.0/uploaded_versions/2.1.2/32_en_ppa    /qle-2.1.2/code/qle_quicklisteditor\", line 4044, in <module>\n    MainWindow()\n  File \"/home/jacob/Bureaublad/werkmap_2.0/uploaded_versions/2.1.2/32_en_ppa   /qle-2.1.2/code/qle_quicklisteditor\", line 51, in __init__\n    self.load_sectons()\nAttributeError: 'MainWindow' object has no attribute 'load_sectons'\njacob@Jacobwerkkamer:~/Bureaublad/werkmap_2.0/uploaded_versions/2.1.2/32_en_ppa   /qle-2.1.2/code$ \n\nwhich gives you a lot of usefull information, even the line in your application that causes the error. (I messed it up on purpose)\nThe same with the desktop file, just open a terminal in the directory of the .desktop file and drag it on to the terminal. If you for example remove the Exec= line from a .desktop file, the terminal will tell you it cannot find the command to execute. \nTo test if the application gives an error, just run what you put after theExec= string.\nThe terminal output is usually very specific and useful in bug reports, like here.\n\nA: Found an answer to this question here: https://askubuntu.com/a/836842\nTry this :\ndesktop-file-validate my-app.desktop\n\nIt outputs errors in your .desktop file. For example mine returned :\nerror: first group is not \"Desktrop Entry\"\n\nSo once I corrected the typo to Desktop Entry, the script ran successfully.\n\nA: Here's a trick you can use. Create a wrapper script for your application that will launch it and capture the error output:\n#!/usr/bin/env bash\n\n## Launch 'yourapp' and capture its standard error output\n/path/to/yourapp 2>~/myapp.log\n\nSave that as ~/foo.sh and make it executable with chmod +x ~/foo.sh. Now, point your desktop launcher to it instead. Something like:\n[Desktop Entry]\nVersion=2.0\nType=Application\nExec=/home/kevin/foo.sh\nTerminal=true\nComment=My app!\n\nThat will redirect any error messages to ~/myapp.log and you can examine them at your leisure. You can use 2>>~/myapp.log if you want successive error messages to be appended to the file instead of overwriting it.\n\nAs an aside, the reason that the $PATH is different is because you are probably setting your $PATH in ~/.bahsrc which is not read by the graphical environment. It is also a bad idea since the $PATH will be set every time you open a new terminal and that is needless overhead. Use ~/.profile for this instead. For more details on which files are read when see here and for more on which file should be used for what, see here.\n\nA: By running the following command in terminal:\nawk -F= '/Exec=/{system($2)}' your_desktop_file.desktop\nI am sure that you will find out if there is an error or not in your command assigned to the Exec field from inside of your .desktop file.\n\nA: For me, the problem was a missing Icon= line (which seems like a stupid requirement for a working launcher). My full .desktop file now looks like:\n[Desktop Entry]\nName=LiClipse\nComment=Variant of Eclipse\nExec=/home/tsbertalan/bin/liclipse\nTerminal=true\nType=Application\nIcon=/home/tsbertalan/usr/liclipse/icon.xpm\n\nWhich isn't particularly robust to changes in user, but whatever.\n\nA: This might help other people - this is the official spec of the desktop launcher files\nThe important section is : Recognized desktop entry keys - which shows you which values you need.\n\nA: When I really can't figure it out, I:\ncd ~/Desktop\nln -s /my/binary/thatIwanttorun mybinary\n\nThen right click on the default icon that's created and point to a better graphic.\n", "Q: How to rename deb package? I get package source by typing:\nsudo apt-get source nginx\nand added --add-module=/usr/src/nginx-rtmp-module \\ string to debian/rules \nHow I can rename packages from nginx-* to nginx-rtmp-*?\n\nA: You would change the name in the control file (debain/control), on the Package line.\nSee https://www.debian.org/doc/debian-policy/ch-controlfields.html and https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Package\n\nA: I would not rename the nginx-* binary packages, as you'll also have to rename all their dependencies in debian/control and moreover it will overwrite standard nginx files if you install the packages you built from source (e.g the nginx service file).\nInstead I'd install the one you built without trying to rename them. You'll be able to use the Ubuntu version later using a package manager like synaptic or the apt command line tools.\nTo build the nginx packages from source with the nginx-rtmp-module, use the following procedure:\ncd /tmp && apt-get source nginx\ngit clone https://github.com/arut/nginx-rtmp-module.git\n\nEdit your /tmp/nginx-1.4.1/debian/rules to add --add-module=/usr/src/nginx-rtmp-module \\ under config.status.full\ncd nginx-1.4.1/\nsudo apt-get install libgd2-dev libgeoip-dev liblua5.1-dev libmhash-dev libpam0g-dev libperl-dev\ndpkg-buildpackage -uc -b\n\nThis will create many different debian packages. Grab the ones for the flavor you need and install!\nTo determine if your module got compiled/installed correctly use 'nginx -V' to see the compiled in modules. Your module should be in this list.\n", "Q: VPN Connection only for specific service or port I rented a Virtual Machine and I want to use a VPN Service inside for privacy like Hidemyass & Co.\nI connect to the VM via VNC, but every time I switch on the VPN in the VM the VNC connection fails. I use PPTP as VPN.\nIs there an easy way to exclude VNC from the VPN. There are a few computers that will connect to the VM so excluding single IPs would also work, but I prefer the VNC or Port solution.\nI'm a noob in routing so I need a pretty finished answer.\n\nA: In following script you can add host/route witch is routed to vpn.\nThe rest of traffic will be going to default gateway\n#!/bin/bash\nfunction routeadd {\n    route add -host xxx.xxx.xxx.xxx dev ppp0\n    route add -net xxx.xxx.xxx.xxx/xx dev ppp0\n}\nfunction makepptp {\n   echo pty \\\"pptp xxx.xxx.xxx.xxx --nolaunchpppd\\\" >> /etc/ppp/peers/vpn;\n   echo remotename PPTP >> /etc/ppp/peers/vpn;\n   echo require-mppe-128 >> /etc/ppp/peers/vpn;\n   echo file /etc/ppp/options.pptp >> /etc/ppp/peers/vpn;\n   echo ipparam vpn >> /etc/ppp/peers/vpn;\npppd call vpn &\n}\nif [ -a /etc/ppp/chap-secrets ];\n        then\n        rm /etc/ppp/chap-secrets\n    echo $1 PPTP $2 '*' >> /etc/ppp/chap-secrets;\nelse\n    echo $1 PPTP $2 '*' >> /etc/ppp/chap-secrets;\nfi\n\nif [ -e /etc/ppp/peers/vpn ];\n    then\n    rm /etc/ppp/peers/vpn;\n    echo name $1 >> /etc/ppp/peers/vpn;\n    makepptp;\n    sleep 8;\n    routeadd;\nelse\n    echo name $1 >> /etc/ppp/peers/vpn;\n    makepptp;\n    sleep 8;\n    routeadd;\nfi\n\nUsage:\nsudo /path_to_script/vpn username password\n\nnote: set execute permision to script\nTraffic is routed via vpn only if you add route, anything else go default gw.\nEdit 1\nIn function routeadd you can change\nfunction routeadd {\n        route add -host xxx.xxx.xxx.xxx dev ppp0\n        route add -net xxx.xxx.xxx.xxx/xx dev ppp0\n    }\n\nto\nfunction routeadd {\n        route add -host ip_address_for_vnc dev eth0\n        route add default dev ppp0\n    }\n\nThis will route vnc traffic to specific ip address to eth0 int and all other to ppp0 int.\nTry.\n", "Q: Whenever i suspend when i resume my screen is just black I am running Ubuntu 12.04 on a Sony Vaio machine. System has ran Ubuntu for over 18months and never has this happened before. COnstantly keep update with all updates, however the last half dozen times i have put it into suspend (just shut lid) when i come to wake it up all i have is a totally black screen. No mouse cursor- just blackness!\nCan anyone help please? Thanks\n\nA: happens to me to. is said to be becuase you changed power settings from default. For me the black screen goes away when i move the mouse or press a button. Does this work for you too?\n", "Q: unable to type commands in terminal I was install mpi and I have given the path for it in the .bashrc and I closed my terminal and after some time again I opened terminal it's showing following error in the very first line followed by my terminal prompt  and I was unable to type anything in my terminal \n\nprompt means it is not accepting my key strokes from keyborad\nbash: linux: No such file or directory ubuntu linux@terminal:~$\n\n( here linux is my username )\nFor that I searched and I found one solution is that remove the things which I have updated to the .bashrc. After doing this again I opened the terminal now the error message is not coming but in the terminal prompt I am unable to type anything  \n\nA: You can solve your problem by replacing your .bashrc file with the default .bashrc from the installation time. You can do this from Nautilus (the default file manager in Ubuntu). To do so:\n\n\n*\n\n*Open Nautilus.\n\n*Press Ctrl+L to switch Nautilus path bar to address bar.\n\n*Type /etc/skel and press Enter to go inside /etc/skel directory.\n\n*Press Ctrl+H to view hidden files.\n\n*Copy .bashrc file.\n\n*Go to your home directory.\n\n*Paste .bashrc file.\n\n*Restart your terminal.\n\n\nA: I suggest:\n\n\n*\n\n*Rename your .bashrc so that it’s not capable of causing problems, then reboot.\n\n\n*\n\n*If that works, fix your .bashrc.\n\n\n*Type Enterstty saneEnter to clear any tty-related problems.\n\n\n*\n\n*If this works, fix your .bash_aliases or whatever.\n\n\n*Log on as another user.\n\n\n*\n\n*If this works, fix your offending .bash* file.\n\n\n*Try another keyboard.\n\n\nGood luck.\n", "Q: Reliable UEFI GPT multiboot environment creation for Ubuntu on Thinkpads Dear Ubuntu community members,\nI am planning on a fresh multiboot installation environment which initially includes Ubuntu for general open software development, Windows 7 pro and later on maybe other OSes.\nComputer model I will be using is a Thinkpad W520 with latest system firmware.\nMy reported disk size is 465,76GB.\nDeadlock is: I prefer to have a more reliable GPT based harddisk partitioning scheme instead of MBR. Contrary to other OSes, windows lets GPT partitioning only if the system's firmware is UEFI enabled. Even if I have had before enabled this generically may be buggy UEFI as default firmware and installed windows 7 pro with fresh GPT partition with no big issues, I wasn't certainly able to assure same production environment reliability for any other OSes including Ubuntu. Unspecific reported UEFI Linux installation risks include bricking! system motherboard even on newest generation Thinkpads, and also latest W540 models.\nI would be glad if you experienced users can address my interdependent UEFI *nix multiboot installation questions and concerns, which may also hopefully help us to better document the overall experience on these particular Thinkpad systems.\n\n\n*\n\n*I am planning depending on microsoft bootloader if there is not a established consensus that prevents microsoft from wiping others, does it have any drawbacks on non-MS side, do I have another reliable/surefooted alternative approach ?\n\n*I will be reserving only a small (120-160GB) ntfs formatted GPT partition for windows at the end of the disk space, ie. at the innermost physical sectors.\n100MB ms reserved partition, ~300GB blank partition left unformatted for ext4 formatting during Ubuntu installation, and lastly if I don't left any extra blank partition for unix lastly a 120-160GB ntfs partition for windows use. Is it safe to use windows setup partitioners, DISKPART,etc. for GPT/MBR partitioning? What about 100MB reserved and 125MB UEFI partition use out of windows, should I salvage them or let stay? and do you have any amendment to partitions/partitioning that may be useful in a multiboot environment, ie. I am beware of more partitions leading to lost space, but also concerned in resulting swap performance and fail safe conditions of not creating a home (I hope through live boot I can any time recover or clean reinstall without deleting some backup folders on a single ext4?)?\n\n*I am planning file sharing through lightweight virtual machine shared folders when in windows or *nix. There will be no intermediary partition and almost all files will reside natively on single ext4 partition of Ubuntu. I don't want to have any separate partition for swap or home, would that impact swap file contagiousness and performance on Ubuntu, (though, hopefully surely it will prevent moving files between separate ext4 physical partition locations of OS and home)?\nI have intended to keep my questions and setup generic so that its resolution may help millions of other UEFI Linux multiboot use case and especially UEFI bricking prone thinkpad alike mobile computers.\nI may just use MBR and BIOS old style, but your replies will be really useful for my installation environment resolution considerations.\nThank you in advance.\n\nA: First, I think you're overestimating the problems and dangers of EFI. The bricking problem was most prominent with certain Samsung laptops, although I've heard claims that some other EFIs were also affected. In any event, fixes rapidly made their way into Linux kernels, so I doubt if you'll run into such problems with a modern version of Ubuntu. More broadly speaking, although there are lots of buggy EFI implementations, most of them work reasonably well.\nSecond, be aware of the difference between a boot loader and a boot manager. A boot loader loads an OS kernel into memory and kicks off control to it. A boot manager enables the user to choose which OS to boot, typically via a menu. Many programs, including GRUB, combine both functions into one program; but many others don't, and in fact splitting them up is much more common in EFI than in BIOS. Most EFIs, in fact, provide a primitive boot manager. The Windows boot program is mostly a boot loader, not a boot manager; although it does have boot management capabilities, I have yet to see a coherent description of how to actually configure it to chainload another boot program in EFI mode. (Getting it to do so in BIOS mode is relatively well-documented, by contrast.) In any event, you'll need boot loaders for both OSes. Given all the factors, IMHO it's unwise to attempt to use the Windows boot program as a multi-OS boot manager, at least under EFI. Instead, use GRUB, rEFInd, gummiboot, or even the EFI's built-in boot manager for this job. (See my page on EFI boot loaders and boot managers for my thoughts on several options.)\nThe main new issues for partitioning for EFI and GPT are that GPT supports up to 128 partitions with no distinction drawn between primary, extended, and logical; and you need an EFI System Partition (ESP) to hold boot loaders. The first of these is an advantage and simplification, not a drawback. The second is a fairly simple new wrinkle on the overall partitioning task. Issues like partition sizing and placement are the same for GPT and MBR, aside from the need to place the ESP on the disk.\nBeyond this, I recommend you read up on EFI. Three specific sites I recommend are:\n\n\n*\n\n*My page on EFI-mode Linux installations\n\n*The Ubuntu community wiki on the topic\n\n*Adam Williamson's blog entry on how EFI works\nAny one of those will help you understand EFI and navigate the EFI waters. Reading all three will help a lot, although you'll glean less new knowledge from each subsequent one you read. The first two are likely to help the most in terms of conveying practical knowledge.\n", "Q: Finding Volume Label of a usb mass storage device using python Could someone please tell me how I could obtain a usb mass storage device's volume label(the name displayed in the explorer, not the device name::/dev/sdX) using python?\nlibraries/modules though HAL has deprecated so please don't suggest it as an option.\n\nA: You can query UDisks2 using the dbus API from python:\nInstall python-dbus: \nsudo apt-get install python-dbus\n\nRun this small python snippet:\ncat <<EOF | python -\nimport dbus\nbus = dbus.SystemBus()\nud_manager_obj = bus.get_object('org.freedesktop.UDisks2', '/org/freedesktop/UDisks2')\nom = dbus.Interface(ud_manager_obj, 'org.freedesktop.DBus.ObjectManager')\nfor k,v in om.GetManagedObjects().iteritems():\n    drive_info = v.get('org.freedesktop.UDisks2.Drive', {})\n    if drive_info.get('ConnectionBus') == 'usb' and drive_info.get('Removable'):\n        print(\"Device Label: %s\" % drive_info['Id'])\nEOF\n\nWith a USB drive attached I get:\nDevice Label: Generic-Flash-Disk-EEA1EE5B\n\n", "Q: How to delete Ubuntu's hidden or trash files and folders (like .trash-1000) on Windows volumes, from Windows? Previously I used have Ubuntu on my laptop, but currently I am using Windows 8.\nI found .trash-1000 file appearing in my drive. I knew that this is due to deleting few files while using Ubuntu.\nHow to delete that file in Windows 8?\n\nA: If a trash folder is created in Ubuntu on a volume that Windows can read from and write to, then you can delete it in Windows like any other folder.\nThat is, in Windows Explorer (the Windows file browser, not to be confused with the related Internet Explorer, a web browser):\n\n\n*\n\n*Select the file(s) and/or folder(s) you want to permanently delete. In this case, that's the .trash-1000 folder. (This is almost certainly a folder rather than a file. But if it were a file, this would still work.)\n\n*Make sure no other files or folders are selected, to avoid accidentally deleting something you don't want to delete.\n\n*Press Shift+Delete.\n\n\nThis will delete the selected items. It does not send them to the Recycle Bin first. So be careful! It's still sometimes possible to recover data deleted in this way--that is, this is not a secure delete. But it's often not possible to recover data deleted in this way.\n\nThat procedure also works in Ubuntu. In almost any file browser (such as Nautilus, the default file browser; or Thunar, Xubuntu's file browser; or PCManFM, Lubuntu's file browser), you can select items and use Shift+Delete to delete them without first sending them to the trash. (But if you're in Ubuntu and wish to clear out the contents of a trash folder, you can typically just empty the trash.)\n\nIn Ubuntu, files and folders whose names start with a . are hidden by default. In just about any file browser in Ubuntu, you can press Ctrl+H to show hidden files. Pressing it again hides them again. As an alternative to the Ctrl+H shortcut key combination, you may instead check (and uncheck) View > Show Hidden Files in the menu bar.\n\nYou can see .trash-1000 in Windows, suggesting either that Windows is not treating it as a hidden file (Windows doesn't automatically do this for \"dotfiles\") or that you have Windows Explorer configured to show hidden files by default.\nHowever, if you know (or believe) a hidden file is present but you can't see it in Windows, you can tell Windows Explorer to show hidden files. One way to do this, which will apply inside all folders, is to open Folder Options in the Control Panel, click the View tab, and under Advanced settings, select the \"Show hidden files, folders, and drives\" option button under \"Hidden files and folders.\" (Then click Apply and OK.)\n\nNote that you do not generally have to uncheck the separate \"Hide protected operating system files (Recommended)\" box, and you shouldn't uncheck that unless you know what you're doing.\n\nA: To expand a bit on Eliah Kagan's answer:\n\n\n*\n\n*The 1000 in .trash-1000 is the UID of the user who deleted the files. 1000 is the typical UID of the user who installed the system in Debian and Ubuntu.\n\n*You can, and probably should, browse the .trash-1000/files directory to look for files you may want to keep.\n\n\nA: These .Trash folders appear in any operating system used when files are deleted using Linux to delete.  All our computers run both Windows & Linux, accessing the same Archive, Data & Storage drives, regardless of operating system. \nIf deleting is difficult, try renaming the folder to a simple name, then try again.  On a Linux system, try emptying the Trash Bin.  On any Windows system, sometimes Shot-Del sometimes works.  Otherwise third-part \"shredder\" applications sometimes work.  In Windows, the best luck we consistently have is the freeware version of \"Advanced SystemCare\".\n", "Q: What is the name of the \"username@hostname:~$\" line? Simple question! what is the name of the ubuntu@ubuntu:~$ or the username@hostname:~$ line? How should I refer to it?\n\nA: It has been called the system prompt for as long as I can remember.\nThe part before the @ is the username, the part after it is the hostname.\n\nA: That appears to be your bash prompt or just \"prompt\". You might also use the tag you gave your question, it is a command-line.\n", "Q: Ubuntu 2D working fine, but not Ubuntu virtual machine in VMWare Workstation 9 Windows 7 Host I'm using Windows 7 as the host machine with VMWare Workstation 9. I created a virtual machine Ubuntu Desktop 12.04 LTS 64 bit version. There are two options for log in, Ubuntu and Ubuntu 2D. Whenever I log in to Ubuntu, the task bar will not show up, is like having a black margin all around the desktop background and only the center is visible. \nI wish I could attached a pic, but I need at least 10 reputation.\nWhen I move my mouse over the left side of the desktop I can see that something is there but it is shown only as a black square. I tried deleting the virtual machine I created for Ubuntu and re-installed it, but it keeps appearing like that.  When I switched to log in with the Ubuntu 2D version everything worked alright. I could see the task bar, the icons, the clock etc.\nWhat might be causing this problem?\n\nA: OK I fixed it! I just needed to turn off 3D Acceleration in the VMware. On the menu bar go to VM > Settings > Display > Uncheck Accelerate 3D graphics. ;)\n", "Q: Help with Synaptiks touchpad I bought a laptop 2 weeks ago, wiped Windows8 off and installed Ubuntu 12.04.\nI've been trying to install synaptiks for the past 6 days trying multiple fix's, so I could configure my touchpad because the touchpad hits my left palm when I type and consistently erases most things because of it and I cant 2 finger vert scroll.\nI believed the problem was related to my touchpad driver but I had the its-saucy synaptics installed for everything. When I use xlist it shows my touchpad is identified yet when I run synaptiks it says it can't find a touchpad. Any help greatly appreciated.\nThe internal error I have is:\nExecutablePath: usr/bin/synaptiks\nPackage: kde-config-touchpad 0.8.1-1ubuntu1.2\nProblemType: Crash\nTitle:\nsynaptiks crashed with AttributeError in show_configuration_dialog():'SynaptiksNotifierItem'object has no attribute 'touchpad'\nTraceback:\nFile\"usr/lib/python2,7/dist-packages/synaptiks/kde/trayapplication.py\",line 260, in newInstance self.icon.show_configuration_dialog()\nFile\"usr/lib/python2.7/dist-packages/synaptiks/kde/trayapplication.py\",line 241, in show_configuration_dialogself.touchpad, self.touchpad_manager,self_config)\nAttribute error:'SynaptiksNotifierItem' object has no attribute 'touchpad'\nApportVersion: 2.0.1-0ubuntu17.6\nArchitecture: amd64\ndistro: Ubuntu 12.04\nif there's any directory spelling mistakes it's because I typed it all out\n\nA: 1.Enabling two finger scroll:\nGo to Mouse and Touchpad in System Settings. There you can find\nTwo Finger Scroll under Touchpad tab. I hope this solves your problem.\n2.Enable/disable Touchpad\nThis is not an exact solution. But it might solve the issue. You can write a bash script to toggle the touchpad on/off. And give a keyboard shortcut for this script to run.\n\n\n*\n\n*Step 1:\nOpen terminal. (press ctrl+alt+t)\n\n*Step 2:\nType gedit touchpad and press enter.\n\n*Step 3:\nCopy the following script.\nSYNSTATE=$(xinput list-props \"XXX\" | grep Enabled | grep -Eo     '.$')\nif [ $SYNSTATE = 0 ]; then xinput set-prop \"XXX\" \"Device    Enabled\" 1\nelse xinput set-prop \"XXX\" \"Device Enabled\" 0; fi\nReplace XXX with the name of the touchpad.\nTo find out the name of the touchpad just execute command \"xinput list\" in the terminal.\nSave the document.\n\n*Step 4:\nNow execute the following commands one by one.\nchmod +x touchpad\nsudo mv touchpad /bin/\n\n*Step 5:\nDone!!! You can now enable/disable the touchpad just by executing \"touchpad\" command in the terminal.\n\n*Step 6:\nTo add keyboard shortcut for enabling and disabling touchpad, open Keyboard in System Settings. Under Shortcuts tab, select Custom Shortcuts and add command  \"touchpad\" to the list. Assign a keyboard shortcut to it.\n", "Q: Adding file paths to Python code I am currently running the code for a program called HotNet.\nIn its simpleRun.py file, there is a place to insert a file path to be run.\nparser.add_argument('-mf', '--infmat_file', required=True,\n                    help='Path to .mat file containing influence matrix')\n\nMy path file is /home/lai/Downloads/influence_matrix_files/hprd_inf_.mat; and I have tried to add it in as such:\nparser.add_argument('-mf', '--infmat_file', required=True,\n                    help= /home/lai/Downloads/influence_matrix_file/hprd_inf_.mat)\n\nBut I get SyntaxError when running the code:\nFile \"simpleRun.py\", line 29\n    help= ~/home/lai/Downloads/influence_matrix_files/hprd_inf_.mat)\n           ^\nSyntaxError: invalid syntax\n\nI have also tried to place the path in quotes (as strings ' ') but that isn't processed.\nI have tried removing the / however that just returns the following error:\nNameError: global name 'home' is not defined\n\nHow do I fix this?\n\nA: Instead of editing the py file, you would simply call the simpleRun.py with the argument:\npython simpleRun.py -mf /home/lai/Downloads/influence_matrix_file/hprd_inf_.mat\n\nor\npython simpleRun.py --infmat_file=/home/lai/Downloads/influence_matrix_file/hprd_inf_.mat\n\n\nA: @cyberbills answer is completely correct, but I wanted to add a little more explanation. \nYou aren't supposed to edit simpleRun.py to add your path -- it's already defined, and the \"help\" argument is there to give you help when you actually run the simpleRun.py script from the command line.\nTo put it another way, the help argument doesn't hold the path, but gives usage help for using the -mf flag. \nWhen you use simpleRun.py with \"mf\", you'll run it as simpleRun.py -mf <file.mat>. \n(Note: do a chmod +x on simpleRun.py if you want to run it by typing ./simpleRun.py . Otherwise use python ./simpleRun.py as cyberbill indicates). \nAll of the parser arguments in simpleRun.py work this way. The text field in the help arg is command line feedback. \nYou can see it by supplying the --help flag to the command:\n$python simpleRun.py --help\nusage: simpleRun.py [-h] [-r RUNNAME] -mf INFMAT_FILE -if INFMAT_INDEX_FILE\n                    -hf HEAT_FILE [-ms MIN_HEAT_SCORE] [-ccs MIN_CC_SIZE] -pnp\n                    PERMUTED_NETWORKS_PATH [-n NUM_PERMUTATIONS]\n                    [-o OUTPUT_DIRECTORY] [--parallel] [--no-parallel]\n                    [-ef EDGE_FILE] [-nn NETWORK_NAME]\n\nHelper script for simple runs of generalized HotNet2, including automated\nparameter selection.\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -r RUNNAME, --runname RUNNAME\n                        Name of run / disease.\n  -mf INFMAT_FILE, --infmat_file INFMAT_FILE\n                        Path to .mat file containing influence matrix\n\n\nA: ~/ is the same as /home/lai, so you want to be using ~/Downloads or /home/lai/Downloads.\n", "Q: linux command to prevent dos attack by using netstat and iptables I want to DROP more than 200 requests per ip to prevent ddos attack.\nthis is command that i used to detect requests count per ip :\nnetstat -alpn | grep :80 | awk '{print $5}' |awk -F: '{print $(NF-1)}' |sort | uniq -c | sort -nr\n\nnow i want add all ip addresses that made more than 200 requests into IPtables to DROP input and out put.\n\nA: Well you can not prevent ddos, and 200 requests is rather trivial.\nBest you can do , IMO, is to set limits\nsudo iptables -A INPUT -m limit --limit 50/minute --limit-burst 200 -j ACCEPT\nsudo iptables -A INPUT -j REJECT\n\nFor port 80, use\nsudo iptables -A INPUT -p tcp --dport 80 -m state --state NEW -m limit --limit 50/minute --limit-burst 200 -j ACCEPT\nsudo iptables -A INPUT -m state --state RELATED,ESTABLISHED -m limit --limit 50/second --limit-burst 50 -j ACCEPT\nsudo iptables -A INPUT -j REJECT\n\nYou should be able to adjust those limits to your server.\nSee: http://blog.bodhizazen.com/linux/prevent-dos-with-iptables/\n", "Q: itunes2rhythm python3 script returns syntax error I am trying to execute this script with Python3\n\n\n*\n\n*itunes2rhythm\nUsing this command: \npython3 /media/trunk/SOUNDS/itunes/itunes2rhythm-master/itunes2rhythm.py\nI am getting the error:\nTraceback (most recent call last):\nFile \"/media/trunk/SOUNDS/itunes/itunes2rhythm-master/itunes2rhythm.py\", line 285, in <module>\nexec(open(sys.argv[0][:-2]+\"conf\").read(), cfg)\nFile \"<string>\", line 20\niLib=\"\"/media/trunk/SOUNDS/itunes/Library.xml\"\"\n^\nSyntaxError: invalid syntax\n\nCould someone explain what needs to be done to execute this script properly?\n\nA: Just edit your itunes2rhythm.conf file to remove the extra quotes:\niLib=\"\"/media/trunk/SOUNDS/itunes/Library.xml\"\"\nIt should be:\niLib=\"/media/trunk/SOUNDS/itunes/Library.xml\"\nin order to exec this line with Python.\n", "Q: Mounting/Unmounting devices I mount a device with this commands:\nsudo mkdir /media/(device uuid) \nsudo mount (device path) /media/(device uuid)\nThen when it comes to unmount it:\nsudo umount (device path)\nsudo rmdir /media/(device uuid)\nThe problem is that when I do this, the icon remains the launcher, but if I mounted and unmounted the same device using the mouse (not using the command line) there will be no problem. \nHow can I get the same result than doing it graphically but using the command line?\n\nA: This is because auto mounting of disks does not use mount and umount, it is more complex and uses udevadm and udisks.\nTo detach\nsudo udisks --detach /dev/sdb\n\nFor additional information on this moderately complex Subject, see\nhttp://manpages.ubuntu.com/manpages/trusty/man7/udisks.7.html\nhttps://help.ubuntu.com/community/Mount/USB#Automounting\nand\nhttps://help.ubuntu.com/community/UsbDriveDoSomethingHowto\nAnd also this discussion:\nhttps://unix.stackexchange.com/questions/7051/how-to-re-mount-a-usb-stick-after-unmounting-from-nautilus-without-disconnecting \n", "Q: Ubuntu cannot start first setup. HELP! I finished installing Ubuntu 12.10 today. When I booted the OS, it booted normally, but the setup would not start. A few minutes later, it said in white text \"Continue to wait, Or Press S to skip mounting or press M for Manual Recovery.\" A few minutes later, the computer rebooted. I chose \"Ubuntu\" and it booted to the grub shell. I do not know the command to load the kernel and start Ubuntu. I need to know the command to start Ubuntu and get rid if this screen every time I go to start Ubuntu. Thanks!\n\nA: This is a bit more clarified answer: If you dont know how to access the shell in ubuntu press Ctrl + Alt + F1 - F6  any of these will work.  It will ask you to log in with your username and passowrd. Once logged in, use the next code \nsudo start lightdm\n\nIt will ask for your password.\nOnce finished press Ctrl + Alt + F7 and see if the kernel loadsand you see everything correctly.\n", "Q: What is the default font in Ubuntu? What is the default font in Ubuntu?\nCould someone tell me please?\n\nA: The default font for Ubuntu is called Ubuntu.\nQuote from http://en.wikipedia.org/wiki/Ubuntu_(typeface):\n\"The Ubuntu Font Family is the default font for the current and development releases of the Ubuntu operating system and is used for the Ubuntu project branding\"\n\nA: \"Ubuntu\" is default font for Ubuntu OS\nVisit this site to test and download the Ubuntu Font Family.\n", "Q: Hiding an application from switcher (alt+tab) I would like to hide cairo-dock from the switcher since it is redundant to have it there.\nI've searched for solutions without any luck.\n\nA: I solved it after finding a small thread on Ubuntu forums. I think this solution can be applied to any program\nInstall compizconfig-settings-manager:\nsudo apt-get install compizconfig-settings-manager\n\nGo into Window Managment and Window Rules, there add:\nSkip taskbar: title=Cairo-Dock\nSkip pager: title=Cairo-Dock\n\nand finally go back to the main settings and enable the Window Rules by checking the box\n\nIt is also possible to change the switcher by activating the ring or shift switcher and replacing the Unity shortcut with the custom switcher. In their respective menus you can choose what kind of windows it should display.\n", "Q: undefined symbol: PyExc_TypeError I'm using Ubuntu 12.04 and I have weird problem that started appearing.\nI've been using virtualenv command for working with my Python projects and I never had trouble with it.\nHowever, for some reason (I really don't know what) now it doesn't work anymore.\nI've tried to create new virtualenvironment for one of my projects but it keeps giving me error:\nTraceback (most recent call last):\n  File \"/usr/local/bin/pip\", line 9, in <module>\n    load_entry_point('pip==1.4.1', 'console_scripts', 'pip')()\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 337, in load_entry_point\n    return get_distribution(dist).load_entry_point(group, name)\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 2279, in load_entry_point\n    return ep.load()\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 1989, in load\n    entry = __import__(self.module_name, globals(),globals(), ['__name__'])\n  File \"/usr/local/lib/python2.7/dist-packages/pip/__init__.py\", line 10, in <module>\n    from pip.util import get_installed_distributions, get_prog\n  File \"/usr/local/lib/python2.7/dist-packages/pip/util.py\", line 8, in <module>\n    import zipfile\n  File \"/usr/lib/python2.7/zipfile.py\", line 6, in <module>\n    import io\n  File \"/usr/lib/python2.7/io.py\", line 60, in <module>\n    import _io\nImportError: /usr/lib/python2.7/lib-dynload/_io.so: undefined symbol: PyExc_TypeError\nError in sys.excepthook:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/dist-packages/apport_python_hook.py\", line 66, in apport_excepthook\n    from apport.fileutils import likely_packaged, get_recent_crashes\n  File \"/usr/lib/python2.7/dist-packages/apport/__init__.py\", line 1, in <module>\n    from apport.report import Report\n  File \"/usr/lib/python2.7/dist-packages/apport/report.py\", line 16, in <module>\n    from xml.parsers.expat import ExpatError\n  File \"/usr/lib/python2.7/xml/parsers/expat.py\", line 4, in <module>\n    from pyexpat import *\nImportError: /usr/lib/python2.7/lib-dynload/pyexpat.so: undefined symbol: PyExc_TypeError\n\nOriginal exception was:\nTraceback (most recent call last):\n  File \"/usr/local/bin/pip\", line 9, in <module>\n    load_entry_point('pip==1.4.1', 'console_scripts', 'pip')()\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 337, in load_entry_point\n    return get_distribution(dist).load_entry_point(group, name)\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 2279, in load_entry_point\n    return ep.load()\n  File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 1989, in load\n    entry = __import__(self.module_name, globals(),globals(), ['__name__'])\n  File \"/usr/local/lib/python2.7/dist-packages/pip/__init__.py\", line 10, in <module>\n    from pip.util import get_installed_distributions, get_prog\n  File \"/usr/local/lib/python2.7/dist-packages/pip/util.py\", line 8, in <module>\n    import zipfile\n  File \"/usr/lib/python2.7/zipfile.py\", line 6, in <module>\n    import io\n  File \"/usr/lib/python2.7/io.py\", line 60, in <module>\n    import _io\nImportError: /usr/lib/python2.7/lib-dynload/_io.so: undefined symbol: PyExc_TypeError\n\nDo you have any idea why is that and how to fix it?\nThanks\n\nA: This error means that the dynloader tried to find PyExc_TypeError call entries and couldn't find any. \nThis error often happens if you use different libraries which are not binary compatible.\nYou are not saying where you virtualenv have. Have you downloaded binaries, or is it the dist package? So try to get the right version.\n", "Q: HP 250 g2 - problem with graphics I bought hp 250 g2 without OS and tried to install Ubuntu 13.10 / Ubuntu 12.04.2 LTS.\nI am not able to run and even install Ubuntu because everytime I try to run it, my display turns off. I know the system is running well (I can hear login sound), but I can not see anything on my display. I am only able to run it correctly with nomodeset, but there is only 1024x768 or 800x600 resolution. Because my laptop is 16:9, I would like to set higher resolution. \nI tried to install official Intel drivers (01.org) - installed successfully, but othing happens. \nThis is my configuration:\nHP 250 g2 (ubuntu.com says it was tested successfully - http://www.ubuntu.com/certification/hardware/201309-14164/) ;\nScreen: 39.6 cm (15.6 \") ;\nGraphics: Intel HD 4000 , Discrete Nvidia 820M (dedicated DD3 memory 1 GB) (switchable graphics) ;\nCPU: Intel® Core™ i3-3110M with Intel HD 4000 graphic card (2,4 GHz, cache 3 MB, 2 cores) ;\nRAM: 2GB\nAppreciate your suggestions.\n\nA: I have the same model (and similar HW parameters) and installed Ubuntu 13.10 with use of external display. Then, I upgraded it to 14.04, but the display on laptop had been still turned off.\nIn System settings -> Colors, I'd noticed that my laptop display had assigned no color profile, while my external (working) display had some. So, I had assigned a right color profile to the laptop display and rebooted the laptop.\nFinally the laptop display has turned on and is still working.\n", "Q: Sterio Mix in Ubuntu 13.10? I've been wondering if in Ubuntu, I can \"spoof\" another microphone that is actually the Speakers and the Microphone fused together. My audio card supports this. What I mean is, for example, If i'm on a Skype call, since I usually wear headphones, I want them to be able to hear what my PC speakers are outputting and what my microphone is picking up. That way, I can get together with a friend and watch Netflix (Using Wine) or play a game and have him hear the audio. This can also be useful in other scenarios. In Windows, this is referred to as \"Sterio Mix\"\n\nA: First install pavucontrol:\nsudo apt-get install pavucontrol\n\nLaunch PulseAudio Volume Control (from the dash or a terminal):\npavucontrol\n\nOn Input devices tab, see that you have \"Monitor of Built-in Analog Stereo\"\nthis is a virtual recording device with which you can record whatever's coming out of your speakers.\n\nNow we just need to route your microphone to your speakers too.\nDo this by typing the following command in a terminal:\npactl load-module module-loopback latency_msec=1\n\nIf you now record with audacity, or recordmydesktop, from the \"Monitor of Built-in Analogy Stereo\" (see Recording tab of pavucontrol after you start recording)\nyou'll get your microphone as well as whatever's coming out of the speakers.\nThis means that you can now easily record Skype meetings or private Google+ Hangouts.\n", "Q: Transferring NetBeans IDE for Windows to NetBeans IDE for an Ubuntu based distro I'm not exactly using Ubuntu but I am using Elementary OS Luna 0.2, which is based on Ubuntu so I'm hoping the same instructions can be applied.\nI want to start using Luna as my primary OS and move away from Windows. Luna is installed on the hard drive because I wanted the OS to have the freedom to use all or most system resources to function at optimal efficiency, instead of having to share resources like you would with visualization software. As such I can't easily switch between OSes.\nI've been learning Java from home-and-learn and I use NetBeans IDE to construct and compile code for the exercises given(For Loops, Array, etc). Project folders are created for each new exercise and they come in handy for when I need to look back and refresh my memory. I would like to transfer my NetBeans folders from Windows to NetBeans for Linux. So here are my questions.\n\n\n*\n\n*Can I use a USB flash drive or cloud storage to transfer the folders from Windows to Linux and keep the integrity of the data?\n\n*Where in Luna should I place the folders so that my projects show up in the NetBeans IDE app?\n\n*Can this data transfer be done through the command line?\nWindows is stored on the OS partition and Luna is stored on the Data partition\nThanks in advance for the help, however helpful.\nSorry if this was asked before.\nSorry for the typos.\n\nA: \nCan I use a USB flash drive or cloud storage to transfer the folders from Windows to Linux and keep the integrity of the data?\n\nYes you can:\n\n\n*\n\n*format USB with FAT32 because is windows GNU/Linux compatible\n\n*copy into your home/your-user-name/netbeansprj linux directory\n\n*convert the EOLs from win to GNU/Linux\n\n*use chmod to change your file bit mode to -rw-r--r-- for files and drwxr-xr-x for directories\n\n\n\nWhere in Luna should I place the folders so that my projects show up in the NetBeans IDE app?\n\nWherever you like:\n\n\n*\n\n*for examplein home/your-user-name/netbeansprj\n\n*than in Netbeans choose File > Open project... and navigate to home/your-user-name/netbeansprj\n\n*finally select your project folder\n\n\n\nCan this data transfer be done through the command line?\n\nNot necessarily.\n", "Q: Ubuntu USB boot not working I am trying to install Ubuntu 12.04. I put it on an USB stick because my netbook does not have an optical drive and when I put it in it boots right back to Windows. I set it to boot to USB and I do not know if I need to download any additional software for it to be seen.\n\nA: Check the boot menu for sequence of bootable partition.\n\n\n*\n\n*Power On your computer\n\n*Press the Boot Menu Key, usually Esc or F12 when the display starts\n\n\n*select boot menu\n\n\n*Select USB-HDD\n\nA: Did you make your USB bootable? if not check this out: bootable usb \n", "Q: S Video performance using ati-driver-installer-9-3-x86.x86_64.run on U 12.4 I have a new installation of Ubuntu 12.4 using the ati-driver-installer-9-3-x86.x86_64.run driver for my Radeon 9600.  Graphics in Details shows Gallium 0.4 on ATI RV350.  When S Video is connected an Unknown monitor is detected and the video output is unusable.  I have tried a dozen ways to set an xorg.config file for this so that I can set the output of the card to NTSC for the s video but have been unable to get an xorg.config to configure.\nBelieve me I have tried many of the posts and commands to get this file made and I am not even sure that setting the s video output will help.\nI am VERY new to Ubuntu but have gotten everything I needed working fixed, due to posts on AskUbuntu.\nIs there any help for this?  Id' sure like the s video working as well as it used to on XP.\n\nA: It is so simple but easily missed.  For the s-video output on this card to be configured correctly on Ubuntu, the output MUST be connected to the TV BEFORE bootup.  If you are already running, shut down, connect the cable to the TV and reboot.  Voila! After a few seconds of various screen attempts, Ubuntu selects the correct configuration for the S-Video output and your computer monitor.\nFound this out through experimentation and more web searches.\n", "Q: How to get \"Don't Starve\" game to work from its .rar file? I am trying to get Don't starve for my Samsung Chromebook with Ubuntu and I can't figure out if i can play it since it's a .rar file. If anybody knows please let me know.\n\nA: A .rar file is basically the same as a .zip compressed folder.  It doesn't run the game, it probably extracts the game or an installer for the game.\nYou will need to read up on the exact procedures for installing the game, but to extract the .rar you can do the following:\nsudo apt-get install unrar\ncd /path/to/rar/file/\nunrar e file.rar\n\nReplace /path/to/rar/file/ with the path to the folder that the .rar exists in.  Then, replace file.rar with the actual filename.  This will extract the .rar file's contents.\n\nHowever, as I have said, you will need to look at the README for the specific program, or its INSTALL guide to know how to either run or install the game, after the files in the .rar are extracted.\n", "Q: /home automatically ecrypted during multi boot? I was attempting to add a Mint partition to my Ubuntu 12.04/Win7 box, when the whole process went south on me. Mint installed correctly but removed the Ubuntu/Win options from my Grub menu. Attempting to fix that was where things got messed up -- currently the box boots to a grub> prompt. \nUsing grub I can find a kernal image and boot to a busybox prompt, but if I attempt to continue the boot process, it enters a kernal panic (exit code is 00000200). \nWhat seems really weird is that my old Ubuntu home folder is accessible if I boot with a Mint or Ubuntu LiveCD (mounted under /media), however my /home/liav subdirectory has been ecrypted. I don't recall ever setting up any /home/liav encryption. I can sudo into /media/home/liav and cat the README file therein which only says \"THIS DIRECTORY HAS BEEN UNMOUNTED TO PROTECT YOUR DATA\" plus instructions to 'ecryptfs-mount-private', which I obviously can't do as root in a liveCD session (returns 'Encrypted private directory is not setup properly'). Using 'chown -R' to take ownership of the directories made no difference.\n\n\n*\n\n*Why was /home/liav ecrypted? \n\n*Is there a way I can recreate the user account which would have access to the encrypt keys?\n\n\nI did do a back up of my main /home subdirectory, but would prefer not to lose the dir if possible.\n\nA: Assuming you can't recover your Ubuntu installation, you can use ecryptfs-recover-private to mount your home directory.\nFirst start by making sure that the partition that contains the home directory you want to open is mounted and opened. Then, in a Terminal, run sudo ecryptfs-recover-private /path/to/home/directory. By default, it will be mounted in read-only mode, but you can have it in read-write mode by passing in the flag --rw. Follow the prompts, and your home directory will be mounted in a temporary location.\n", "Q: Apache vhosts stop working after update I am running several websites on my server. For example, one of them is on /var/www/mysite.com/.\nI upgraded the Apache2 in my Ubuntu 12.04 webserver to version 2.4, and the installation rewrote ports.conf and apache2.conf, so I added the configuration items that were missing, but now when I try to access http://mysite.com, what I get is the directory listing to /var/www.\nWhat am I missing?\nImportant: I am using port 8080 because I am using nginx as reverse proxy on port 80. That part is working allright.\nports.conf\n# If you just change the port or add more ports here, you will likely also\n# have to change the VirtualHost statement in\n# /etc/apache2/sites-enabled/000-default.conf\n\nListen 8080\n\n<IfModule ssl_module>\n    Listen 443\n</IfModule>\n\n<IfModule mod_gnutls.c>\n    Listen 443\n</IfModule>\n\napache2.conf\n# This is the main Apache server configuration file.  It contains the\n# configuration directives that give the server its instructions.\n# See http://httpd.apache.org/docs/2.4/ for detailed information about\n# the directives and /usr/share/doc/apache2/README.Debian about Debian specific\n# hints.\n#\n#\n# Summary of how the Apache 2 configuration works in Debian:\n# The Apache 2 web server configuration in Debian is quite different to\n# upstream's suggested way to configure the web server. This is because Debian's\n# default Apache2 installation attempts to make adding and removing modules,\n# virtual hosts, and extra configuration directives as flexible as possible, in\n# order to make automating the changes and administering the server as easy as\n# possible.\n\n# It is split into several files forming the configuration hierarchy outlined\n# below, all located in the /etc/apache2/ directory:\n#\n#       /etc/apache2/\n#       |-- apache2.conf\n#       |       `--  ports.conf\n#       |-- mods-enabled\n#       |       |-- *.load\n#       |       `-- *.conf\n#       |-- conf-enabled\n#       |       `-- *.conf\n#       `-- sites-enabled\n#               `-- *.conf\n#\n#\n# * apache2.conf is the main configuration file (this file). It puts the pieces\n#   together by including all remaining configuration files when starting up the\n#   web server.\n#\n# * ports.conf is always included from the main configuration file. It is\n#   supposed to determine listening ports for incoming connections which can be\n#   customized anytime.\n#\n# * Configuration files in the mods-enabled/, conf-enabled/ and sites-enabled/\n#   directories contain particular configuration snippets which manage modules,\n#   global configuration fragments, or virtual host configurations,\n#   respectively.\n#\n#   They are activated by symlinking available configuration files from their\n#   respective *-available/ counterparts. These should be managed by using our\n#   helpers a2enmod/a2dismod, a2ensite/a2dissite and a2enconf/a2disconf. See\n#   their respective man pages for detailed information.\n#\n# * The binary is called apache2. Due to the use of environment variables, in\n#   the default configuration, apache2 needs to be started/stopped with\n#   /etc/init.d/apache2 or apache2ctl. Calling /usr/bin/apache2 directly will not\n#   work with the default configuration.\n\n\n# Global configuration\n#\n\n#\n# ServerRoot: The top of the directory tree under which the server's\n# configuration, error, and log files are kept.\n#\n# NOTE!  If you intend to place this on an NFS (or otherwise network)\n# mounted filesystem then please read the Mutex documentation (available\n# at <URL:http://httpd.apache.org/docs/2.4/mod/core.html#mutex>);\n# you will save yourself a lot of trouble.\n#\n# Do NOT add a slash at the end of the directory path.\n#\n#ServerRoot \"/etc/apache2\"\n\n#\n# The accept serialization lock file MUST BE STORED ON A LOCAL DISK.\n#\nMutex file:${APACHE_LOCK_DIR} default\n\n#\n# PidFile: The file in which the server should record its process\n# identification number when it starts.\n# This needs to be set in /etc/apache2/envvars\n#\nPidFile ${APACHE_PID_FILE}\n\n#\n# Timeout: The number of seconds before receives and sends time out.\n#\nTimeout 300\n\n#\n# KeepAlive: Whether or not to allow persistent connections (more than\n# one request per connection). Set to \"Off\" to deactivate.\n#\nKeepAlive On\n\n#\n# MaxKeepAliveRequests: The maximum number of requests to allow\n# during a persistent connection. Set to 0 to allow an unlimited amount.\n# We recommend you leave this number high, for maximum performance.\n#\nMaxKeepAliveRequests 100\n\n#\n# KeepAliveTimeout: Number of seconds to wait for the next request from the\n# same client on the same connection.\n#\nKeepAliveTimeout 5\n\n\n# These need to be set in /etc/apache2/envvars\nUser ${APACHE_RUN_USER}\nGroup ${APACHE_RUN_GROUP}\n\n#\n# HostnameLookups: Log the names of clients or just their IP addresses\n# e.g., www.apache.org (on) or 204.62.129.132 (off).\n# The default is off because it'd be overall better for the net if people\n# had to knowingly turn this feature on, since enabling it means that\n# each client request will result in AT LEAST one lookup request to the\n# nameserver.\n#\nHostnameLookups Off\n\n# ErrorLog: The location of the error log file.\n# If you do not specify an ErrorLog directive within a <VirtualHost>\n# container, error messages relating to that virtual host will be\n# logged here.  If you *do* define an error logfile for a <VirtualHost>\n# container, that host's errors will be logged there and not here.\n#\nErrorLog ${APACHE_LOG_DIR}/error.log\n\n#\n# LogLevel: Control the severity of messages logged to the error_log.\n# Available values: trace8, ..., trace1, debug, info, notice, warn,\n# error, crit, alert, emerg.\n# It is also possible to configure the log level for particular modules, e.g.\n# \"LogLevel info ssl:warn\"\n#\nLogLevel warn\n\n# Include module configuration:\nIncludeOptional mods-enabled/*.load\nIncludeOptional mods-enabled/*.conf\n\n# Include list of ports to listen on\nInclude ports.conf\n\n\n# Sets the default security model of the Apache2 HTTPD server. It does\n# not allow access to the root filesystem outside of /usr/share and /var/www.\n# The former is used by web applications packaged in Debian,\n# the latter may be used for local directories served by the web server. If\n# your system is serving content from a sub-directory in /srv you must allow\n# access here, or in any related virtual host.\n<Directory />\n        Options FollowSymLinks\n        AllowOverride None\n        Require all denied\n</Directory>\n\n<Directory /usr/share>\n        AllowOverride None\n        Require all granted\n</Directory>\n\n<Directory /var/www/>\n        Options Indexes FollowSymLinks\n        AllowOverride None\n        Require all granted\n</Directory>\n\n#<Directory /srv/>\n#       Options Indexes FollowSymLinks\n#       AllowOverride None\n#       Require all granted\n#</Directory>\n\n\n\n\n# AccessFileName: The name of the file to look for in each directory\n# for additional configuration directives.  See also the AllowOverride\n# directive.\n#\nAccessFileName .htaccess\n\n#\n# The following lines prevent .htaccess and .htpasswd files from being\n# viewed by Web clients.\n#\n<FilesMatch \"^\\.ht\">\n        Require all denied\n</FilesMatch>\n\n\n#\n# The following directives define some format nicknames for use with\n# a CustomLog directive.\n#\n# These deviate from the Common Log Format definitions in that they use %O\n# (the actual bytes sent including headers) instead of %b (the size of the\n# requested file), because the latter makes it impossible to detect partial\n# requests.\n#\n# Note that the use of %{X-Forwarded-For}i instead of %h is not recommended.\n# Use mod_remoteip instead.\n#\nLogFormat \"%v:%p %h %l %u %t \\\"%r\\\" %>s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" vhost_combined\nLogFormat \"%h %l %u %t \\\"%r\\\" %>s %O \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined\nLogFormat \"%h %l %u %t \\\"%r\\\" %>s %O\" common\nLogFormat \"%{Referer}i -> %U\" referer\nLogFormat \"%{User-agent}i\" agent\n\n# Include of directories ignores editors' and dpkg's backup files,\n# see README.Debian for details.\n\n# Include generic snippets of statements\nIncludeOptional conf-enabled/*.conf\n\n# Include the virtual host configurations:\nIncludeOptional sites-enabled/*.conf\n\nServerName localhost\n\n# vim: syntax=apache ts=4 sw=4 sts=4 sr noet\n\nMy virtual host\n<VirtualHost 127.0.0.1:8080>\n\n    ServerName mysite.com \n    ServerAlias www.mysite.com\n    DocumentRoot /var/www/mysite.com\n\n    # BEGIN WordPress\n    <Directory /var/www/mysite.com/>\n        <IfModule mod_rewrite.c>\n            RewriteEngine On\n            RewriteBase /\n            RewriteRule ^index\\.php$ - [L]\n            RewriteCond %{REQUEST_FILENAME} !-f\n            RewriteCond %{REQUEST_FILENAME} !-d\n            RewriteRule . /index.php [L]\n        </IfModule>\n    </Directory>\n    # END WordPress\n\n</VirtualHost>\n\n\nA: I had the similar problem.\nThe apache deb maintener guys did a modification in apache2.conf:\nInclude /etc/apache2/sites-enabled/ -> IncludeOptional sites-enabled/*.conf\nSo if your file in sites-enabled doesn't have the .conf extension, it is no longer read and so disabled and no error is shown.\n", "Q: Waiting for network configuration error When  I  want  to  login into  my Ubuntu System, it  appears\n\nwaiting  for  network  configuration\n\nand the  second  is \n\nwaiting  for  more 60  seconds\n\nthen it appear when we  use  the  common Ctrl+ALt+F1 the  Screen  System, which  caused  the  problem  I  think is  I can't connect to the  Internet.\nSo  I   changed  something  in /etc/network/, but now  I  want  to  it  go back  to the  original  the  network configuration,  but  I  don't know  what  to  do.\nAnyone  can  help?\nCan anyone  give  detailed answers?\nThank  you\n\nA: If you edited your /etc/network/interfaces file and want to return to a default Server config, try this:\n# This file describes the network interfaces available on your system\n# and how to activate them. For more information, see interfaces(5).\n\n# The loopback network interface\nauto lo eth0\niface lo inet loopback\n\n# The primary network interface\niface eth0 inet dhcp\n\nThis assumes that you are getting an IP address from DHCP on the eth0 (primary) Ethernet interface.\n\nA: Edit this file\nsudo nano /etc/init/rc-sysinit.conf\nGo to the line;\nstart on (filesystem and static-network-up) or failsafe-boot\nChange to;\nstart on (filesystem) or failsafe-boot\nThan restart..\n", "Q: After I installed some DVD programs and cheese, audio input doesn't work in 12.04 I installed some DVD programs and cheese (webcam program) in 12.04 64-bit and after that the only program that recognizes my input Audio  webcam is Skype. The sound manager in the System Settings tool doesn't show me any devices and I can't configure input for audio and (for example) the default audio recorder doesn't work.\n\nA: I generated a custom installation of my Ubuntu using Remastersys, reinstalled the custom distribution and now all is working well. I will investigate the other applications I installed in order to determine which one broke my GNOME audio control.\n", "Q: Ubuntu 13.10: Trying to set default applications for .py files that aren't in the 'Open With' applications I have followed the instructions in this thread: How do I set IDLE as the default editor for Python scripts?, but it hasn't resulted in the option to open in IDLE being shown. \nSo I used the 'Find applications online' option in the 'Open with...' menu and installed SPE (Stanli's Python Editor) at it's recommendation, but the option to open .py files with that also isn't in the menu. \nDoes anyone have any suggestions? I'm running ubuntu 13.10 and am trying to use Python 3.3.\nThanks in advance.\nScreenshots:\nOption 1:\n\n\nOption 2:\nidle.desktop\nmore open with options\n\nA: I had the same problem. This how I solved it:\n\n\n*\n\n*Uninstall idle from where you installed it.\n\n*Install IDLE (using Python-3.3) from the Ubuntu Software Center. (It didn't work when I installed from Synaptic)\n\n*Enter in terminal: gksudo gedit /usr/share/applications/idle-python3.3.desktop\n\n*Edit file so it looks like this (exactly):\n\n\n\n[Desktop Entry]\nName=IDLE (using Python-3.3)\nComment=Integrated Development Environment for Python (using Python-3.3)\nExec=/usr/bin/idle-python3.3 %F\nIcon=/usr/share/pixmaps/python3.3.xpm\nTerminal=false\nType=Application\nCategories=Application;Development;\nMimeType=text/x-python;\nStartupNotify=true\n\n\nThen it was visible in the menu for me.\n\nA: OPTION 1:\nEdit your $HOME/.local/share/applications/mimeapps.list if you want such association to be only applied for your user.\nAdd the following lines:\n[Default Applications]\ntext/x-python=idle.desktop\n\n[Added Associations]\ntext/x-python=idle.desktop;\n\nNote, if you want the .py association for all users the file to modify is (using sudo):\n/usr/share/applications/defaults.list\n\n\nOPTION 2:\nTo set up IDLE as the default editor you'll have to make the idle.desktop file visible in the \"Open with\" list. To to so edit this file using sudo:\nsudo gedit /usr/share/applications/idle.desktop\n\nAnd replace its content by the following lines:\n[Desktop Entry]\nName=IDLE\nComment=Integrated Development Environment for Python\nExec=/usr/bin/idle %F\nIcon=/usr/share/pixmaps/idle.xpm\nTerminal=false\nType=Application\nCategories=Application;Development;\nMimeType=text/x-python;\nStartupNotify=true\n\nNeedless to restart your session or computer, to set the default application for the python type, locate a file of that type (*.py) in the file manager, right-click it, and select Properties.\nClick the \"Open With\" tab and select the application you want to use for that file type. \nUse the Set as default button to make the application the default application.\n\nFrom now, clicking on a python file should open your preferred editor.\n\nA: Thank you Sylvain Pineau for your contribution.\nBut I just want to add something to your answer for those who have installed python3 and use IDLE3. None of the two options there worked, but then I figured out that maybe it could work if I modify it, because I have python3.\nHere we go, for python3:\nTo set up IDLE as the default editor you'll have to make the idle.desktop file visible in the \"Open with\" list. To to so edit this file using sudo:\nsudo gedit /usr/share/applications/idle3.desktop\n\nAnd replace its content by the following lines:\n[Desktop Entry]\nName=IDLE 3\nComment=Integrated DeveLopment Environment for Python3\nExec=/usr/bin/idle3 %F\nIcon=/usr/share/pixmaps/idle3.xpm\nTerminal=false\nType=Application\nCategories=Application;Development;\nMimeType=text/x-python3;\nStartupNotify=true\n\nNeedless to restart your session or computer, to set the default application for the python type, locate a file of that type (*.py) in the file manager, right-click it, and select Properties.\nClick the \"Open With\" tab and select the application you want to use for that file type.\nUse the Set as default button to make the application the default application.\nThank you so much!\n", "Q: Brightness problem in Ubuntu 12.04 Precise Pangolin I own a ACER ASPIRE5734Z that has a Pentium(R) Dual-Core CPU T4500 @ 2.30GHz × 2. I tried this solution,but did not work out:\nOpen terminal ( Ctrl+Alt+T ) and type:\nsudo gedit /etc/default/grub\n\nYou will find this line in the new opened window:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\n\nChange it to:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi_backlight=vendor\"\n\nSave and close the window and type this in the terminal:\nsudo update-grub\n\nThis will update your grub and while rebooting your PC, it will set an extra parameter on the grub menu during boot. This problem might have occur on due to the upgrade on kernel.\nCould there be another solution to problem?\n\nA: This solution worked for me:\n\n\n*\n\n*gksu gedit /etc/default/grub\n\n*find the line starting with \nGRUB_CMDLINE_LINUX_DEFAULT\n\n\n*add \"acpi_osi=Linux acpi_backlight=vendor\" to the options, for example:\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash acpi_osi=Linux acpi_backlight=vendor\"\n\n\n*run sudo update-grub2\n\n*reboot\n\n", "Q: Ubuntu 12.04 not booting after upgrade error drm:gen6_santiize_pm I am using Ubuntu 12.04 on my HP Envy laptop since a few years without any problems. I also regularly update Ubuntu. Yesterday (on 20.3.2014) when I updated, it stopped booting. I get the login screen but after logging in then unity does not load. If I open the command prompt using Ctrl+Alt+F1, I get the following error:\n[   33.650398] [drm:gen6_sanitize_pm] *ERROR* Power management discrepancy: GEN6_RP_INTERRUPT_LIMITS expected 15070000, was 15000000\n\nCan anybody please help me\nKiran \n\nA: I do not know which Kernel you are using. I had the same problem with 3.2.0-58-generic #88 and I recently updated it to 3.2.0-61 (the latest one available from the update manager) but since this problem appears when I didn't reboot since long time I am not sure if this solved the problem (I guess it didn't)\nI have found that in principle 3.3.6 fixed this problem but I am not sure how to do it with Ubuntu 12.04 or if it is safe. Have a look here:\nhttps://bugs.launchpad.net/ubuntu/+source/gnome-nettool/+bug/1168467\n", "Q: optimal ubuntu home server/raid setup I have two machines at home (plus laptop and work laptop) that I just put in rackmount cases. Right now each machine has several drives not set up with RAID.\nIn the not too distant future, I want to use the machine that is my main win/ubuntu desktop for a server. The case has lots of room for 10/15 drives or so, so I want to make a good size raid partition. \nI use the server for a web server, mysql host, mercurial code repo host, samba share file storage. \nI want to centralize all my file storage, especially music and photos which are currently on my desktop and will take up a lot of space.\nIs it common to build one big raid partition and put everything I want on it? Or should mysql, and the web server be in their own area?\n\nA: I think the first big hurdle you will face is having enough drive interface ports for that number of drives, and then ensuring that the case has enough power and cooling capacity for that many drives as well. If those can be addressed, then the question becomes what type of RAID are you going to run, or use multiple RAIDs?\nSupport for hardware RAIDs is fairly good, though not all RAID cards are fully supported or without issues. Ubuntu/Linux is flexible enough to handle multiple software RAID setups in one box.\nUltimately, you need to match up your needs of speed/redundancy and your mix of drives to determine what RAID configs are going provide for each purpose.\n", "Q: E: Unable to locate package I'd like to install a program called my weather indicator, i installed via terminal:\n$ sudo add-apt-repository ppa:atareao/atareao\n$ sudo apt-get update\n\nAnd finaly it's ready to install my-weather-indicator package:\n$ sudo apt-get install my-weather-indicator\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nE: Unable to locate package my-weather-indicator\n\nI try add repo and update again but still no result, could anyone help me solve this problem ?\n\nA: First off, 13.04 has reached End-Of-Life, and it is recommended that you upgrade to Saucy.\nSecond, the PPA doesn't contain any packages for Raring anymore (most likely because it is EOL), and so you can't install my-weather-indicator.\n", "Q: Phonegap Error installation in ubuntu Good day every one,\nI tried to install Phonegap in my PC but i counter the problem hopefully any can help me.\nHere's the ubuntu version \nDistributor ID: Ubuntu \nDescription:    Ubuntu 12.04.4 LTS \nRelease:    12.04 \nCodename:   precise \n\nHere's the error during my installation \n$ npm http GET https://registry.npmjs.org/phonegap \nnpm ERR! Error: SSL Error: CERT_UNTRUSTED \nnpm ERR! at ClientRequest. (/usr/local/lib/node_modules/npm/node_modules/request/main.js:483:26) \nnpm ERR! at ClientRequest.g (events.js:156:14) \nnpm ERR! at ClientRequest.emit (events.js:67:17) \nnpm ERR! at HTTPParser.onIncoming (http.js:1294:11) \nnpm ERR! at HTTPParser.parserOnHeadersComplete [as onHeadersComplete] (http.js:91:29) \nnpm ERR! at CleartextStream.ondata (http.js:1176:24) \nnpm ERR! at CleartextStream._push (tls.js:375:27) \nnpm ERR! at SecurePair.cycle (tls.js:734:20) \nnpm ERR! at EncryptedStream.write (tls.js:130:13) \nnpm ERR! at Socket.ondata (stream.js:38:26) \nnpm ERR! You may report this log at: \nnpm ERR! \nnpm ERR! or email it to: \nnpm ERR! \nnpm ERR! \nnpm ERR! System Linux 3.8.0-37-generic \nnpm ERR! command \"node\" \"/usr/local/bin/npm\" \"install\" \"-gf\" \"phonegap\" \nnpm ERR! cwd /home/my_name \nnpm ERR! node -v v0.6.17 \nnpm ERR! npm -v 1.1.21 \nnpm ERR! message SSL Error: CERT_UNTRUSTED \nnpm ERR! \nnpm ERR! Additional logging details can be found in: \nnpm ERR! /home/my_name/npm-debug.log \nnpm not ok \n\nThanks,\nWang\n\nA: Hopefully you found an answer in the last 6 months, but in case anyone is still running into this problem, here are some options:\nUpdate Node + NPM\nIf you installed Node.js through the official 12.04 repositories (which looks like the case, from this line: node -v v0.6.17), your Node version is badly out of date by now.\nBack in late February, shortly before this question was posted, npm stopped supporting self-signed certificates. As a result, lots of people working on Node projects ran into similar issues.  The fix? Update npm.\nFor instructions on upgrading, see this question on AskUbuntu.  Personally, I recommend managing Node versions using NVM, but you can also get the latest version via PPA.\nLiving behind a proxy\nIt's also possible to run into issues like these if you're trying to access the npm repository from behind a proxy (e.g. at a corporate office).  While this is less likely to be your issue, it can be solved by the following (taken from here):\nnpm config set proxy http://proxy.company.com:8080\nnpm config set https-proxy http://proxy.company.com:8080\n\nYou can also set a proxy for a single npm install command by running:\nnpm --https-proxy=http://proxy.company.com install express -g\n\nDon't disable SSL checks\nIt's true that you can suppress the error by setting npm's strict-ssl setting to false. Disabling security warnings is a bad idea.\n\nA: Try setting:\nnpm config set strict-ssl false\n\n", "Q: Ubuntu Equivalent to Microsoft Windows Shortcuts Is there an equivalent to Microsoft Windows' shortcuts in Ubuntu?\nI am already aware of both hardlinks and symlinks but they miss one feature I find really interesting. If the target file is moved the shortcut is updated and knows the new location of the file.  Hardlinks I believe have this functionality but only on the same file system while symlinks do not.\nIs there a link that automatically updates the target location?\n\nA: \nIs there an equivalent to Microsoft Windows' shortcuts in Ubuntu?\n\nLets remember that shortcuts in Windows (those files with a .lnk extension) are files with metadata which represent a file/directory redirection only recognized by the Windows file manager, explorer.exe.\nLinux, ergo Ubuntu, doesn't have the same behavior. Instead of a file that can only be interpreted by only the file manager, it uses the Freedesktop specification of .desktop files. There's a counterpart for directories which uses .directory extension, but the behavior \"you open one of these files, and some file/directory gets executed\" is the same as explorer shortcuts. These are supported by most (if not all) file managers available in Ubuntu and Linux.\nYou can read the complete specification in Freedesktop.org\n\nIf the target file is moved the shortcut is updated and knows the new location of the file.\n\nNeither, Freedesktop and Windows Explorer, have such functionality. The only thing that is able to realize it are hard links.\n\nA: You can create a .desktop file. It's just like Windows shortcuts. You can add your own icon, change the name, add description and so on. And you can also add the name and description for different languages in the same shortcut.\nMore... Creating a .desktop file for a new application\n", "Q: Play subtitle on online streaming movies I want a player which can play subtitles while I am watching online movies.\nI have tried VLC network streaming. It's not happening.\nWell, there is a Windows app called Greenfish Subtitle Player, which allows me to play subtitles on top of my browser, but it is not available for Ubuntu. Is there any software like this ?\nEdit: I have found a similar question but it is from 2012 and doesn't quite fit my requirement: Subtitle players like Greenfish.\n\nA: The answer to your question is actually VLC, it indeed shows subtitles on streaming videos.\nJust add the streaming video address by going to Media > Open Network Stream and then follow these steps:\n\n\n*\n\n*Click Play to start reproducing the video\n\n*Right click in the video and select Subtitle > Open File...\n\n*Browse the file system to the appropriate .sub file and click Open\nSubtitles should then appear. \n\nEDIT:\nVLC will play the stream if it has access to the real URL of the video, which is not so obvious on all websites.\nTo get the proper URL stream, take a look at the answers under this question. To just start a video in an external player like VLC (using a Firefox addon that finds the proper URL), take a look at this answer here.\nVLC will even download the subtitles for you - look at this answer. \n\nA: I had the same problem and then come up with an open-source cross-platform subtitle player, Penguin Subtitle Player. It works in the same way as greenfish but it works well also on Linux and OSX so one can play srt files on top of a web browser (or whatever).\n\n\n*\n\n*Download: https://sourceforge.net/projects/penguinsubtitleplayer/\n\n*Source: https://github.com/carsonip/Penguin-Subtitle-Player\n\nA: When the automatic search of subtitle of your player don't work for wished language, go to http://opensubtitle.org.\nYou always got the syncronized subtitle for the right CODEC of stream. This is the repository used by Popcorn-Time service.\nJust load on VLC as explained above.\n\nA: Okay i will answer this myself ;)\nPlayer like GreenFish subtitle player\nWell i didn't find any other player like greenfish on Ubuntu but you can still run greenfish in Ubuntu using wine.\nfor those of you who don't know what is wine:\n\nWine is a free and open source software application that aims to\n  allow applications designed for Microsoft Windows to run on Unix-like\n  operating systems\n\nUsing this you can run greenfish or any other player like Titledrome to play subtitles on top of your browser.\nSee this for wine installation and configuration : Wine \nEasiest Way\nAs @Luís de Sousa mentioned you can use VLC player.\nRead Above answer\n\nA: You should definitely give Substital a try.\nIt is a browser extension I created for Chrome and Firefox that will let you add subtitles on online streaming movies. I am myself using it on Ubuntu.\nIt's easier than VLC since you won't have to worry about finding the stream URL. If the video player on the web page is supported (and it supports many common video players used in streaming), then it's just easy! Once it is loaded in the video, you can directly search and load your subtitles from it. If needed you can even synchronize your subtitles with a slider, in live, while watching.\n\nA: Use website The Subtitles\nFor example, if you choose OpenLoad as your online video player, the page with the movie will look like the image below:\nLet us take as an example the movie Flight (2012)\nTo add subtitles to the movie, click on the \"CC\" button - this is a button in the bottom right corner of the video player.\n\nThere will pop-up two possible selections: Load srt/vtt from PC and Load srt/vtt from URL. In our case, for the subtitles to load fast, you need to click Load srt/vtt from URL.\nAfter that the invitation: Please enter the Url of the .srt file You want to use appears.\nTo enter the requested URL, please utilize the The Subtitles website: find the requested subtitles for the movie (eg Flight (2012) on the The Subtitles website and click the button Copy Url. As soon as the copying is completed, you will see in the right upper corner the notification Url Copied.\nGo back to OpenLoad Player and insert the copied Url in the bar below the invitation: Please enter the Url of the .srt file You want to use and click OK\nWhen you do this, subtitles start showing immediately. Enjoy your favorite movies with OpenLoad and TheSubtitles!\n", "Q: Adobe Source Code Pro has two extensions? I found a thread that explained how to install the Adobe Source Code Pro font here: How to use the new Adobe Source Code Pro font?\nI followed the instructions, logged out and logged back in, opened LibreOFfice Writer, and the font still wasn't available.\nOne thing I noticed that I don't understand is that the TTF and OTF fonts have .woff extensions. So the extensions are .otf.woff and .ttf.woff. I don't actually see any naked .otf or .ttf extensions. Just deleting the .woff out of the filename doesn't seem to fix anything.\nAm I missing something fundamental? I'm a total Ubuntu newbie. Do I need to drag the entire folder for the \".fonts\" folder to recognize it as a family?\n\nA: In order to install Source Code Pro, you can:\n\n\n*\n\n*Go to Google Fonts\n\n*Type source code in the search box (the only match should be Source Code Pro)\n\n*Click \"Add to collection\"\n\n*Click on the text sample (this should present all the font styles)\n\n*Tick all the check boxes\n\n*Click the download icon (a down arrow on the top right) and download as Zip file\n\n\nNow you just need to decompress the Zip file into your ~/.fonts folder:\nmkdir -p ~/.fonts/Source_Code_Pro\nunzip Source_Code_Pro.zip  -d ~/.fonts/Source_Code_Pro\n\nYou may need to run\nfc-cache -f\n\nto make the fonts available (no need to log out).\n", "Q: How to configure socks5 proxy in irssi I have been trying to configure irssi to run through a socks 5 proxy. In the documnetation there is no mention of how to use a socks5 proxy. Some threads the net say it can be done but there is no mention on how to do it. Also, these threads are atleast 3 to 4 years old.\nI even tried running irssi through tsocks but it does not seem to be working\nSo, is it even possible to run irssi through a socks5 proxy and if so how do I do it?\n\nA: According to the irssi website, irssi needs to be compiled with socks proxy support, in order for that to work. The necessary compilation flag is --with-socks\nsource: http://irssi.org/beginner/\nsearch for \"socks\"\n", "Q: search for files and delete from the whole system file search for files and delete from the whole system file\nIf you create a file or just open a file with some programs like gedit, it will make auto save files named like this file~. For example if i do this gedit file.txt then when i close the file i can find two files file.txt and file.txt~.\nWhat i want to do is to search the \"/\" whole file system for these files and then delete them.\nNote that those files could be other things not just text files.Thanks foe helping\n\nA: To delete all backup files ending in ~ from the whole system, you can use:\nsudo find / -type f -name '*~' -exec rm -f {} \\;\n\nWarning: I suggest you to run first find / -type f -name '*~' to see exactly what you will delete.\n", "Q: How to check the current value of IFS? I am currently running a shell script and I suspect the problem may be because I accidentally changed the default value of IFS which is a space  to something else.\nI want to check the current value of IFS, but I don't know how to go about finding it .\nI am running my Ubuntu on VMWare.\n\nA: $ echo -n \"$IFS\" | od -abc\n0000000  sp  ht  nl\n        040 011 012\n             \\t  \\n\n0000003\n\nhttp://www.fvue.nl/wiki/Bash:_Show_IFS_value\n\nA: > printf %q \"$IFS\"\n' \\t\\n'\n\nThe %q format argument is used to interpolate the quoted variable $IFS and escapes control characters that would be interpreted by the shell.\nHere you can see that IFS separates on spaces, tabs, and newlines.\n\nA: As you probably already know, the default value of IFS is <space><tab><newline>. Using:\necho \"$IFS\"\n\nyou can probably deduce that there is a newline character and some other white space characters, but nothing sure. \nTo be sure about the exact value of theIFS variable, you can appeal to the help of cat command as follow:\necho \"$IFS\" | cat -ETv\n\nwhich is equivalent with:\ncat -ETv <<< \"$IFS\"\n\nSample output for the default value of IFS:\ncat -ETv <<< \"$IFS\"\n ^I$\n$\n\nFrom the previous output you can deduce that there sure is one space character at the beginning and a newline character. But what is with the others strange characters. Let's look at the man cat:\n\n   -E, --show-ends\n          display $ at end of each line\n\n   -T, --show-tabs\n          display TAB characters as ^I\n\n   -v, --show-nonprinting\n          use ^ and M- notation, except for LFD (n.a. linefeed or newline character) and TAB\n\n\nSo, the ^I sequence from the above output means one TAB character and the other two $ characters means the end of the line.\n\nA: The command echo $IFS (note the absence of double quotes) may not show the value of IFS correctly because of word splitting.\nFor example:\nIFS=:\necho $IFS  # shows a blank line\n\nSo, the right way to display IFS is:\necho \"$IFS\"\n\nOther ways are:\nset | grep -w IFS # shows IFS=$' \\t\\n'\nprintf '[%s]\\n' \"$IFS\"\n\n\nRelated:\n\n\n*\n\n*Word splitting in Bash with IFS set to a non-whitespace character\n\n*Word Splitting - Greg's Wiki\n\nA: I know this is an old post but another answer, and easy one that I have not seen posted yet is the following command\necho \"${IFS@Q}\" # which will result in the following (defaults)\n' \\t\\n'\n\nIf you simply use\necho \"$IFS\" #Your result will be this\n\n...an empty line showing the invisible characters which isnt much help.\nHope this helps\nAloha\n", "Q: How can I get boot menu after Ubuntu installation? I would like to thank you for taking the time to read this.\nMy problem: I tried to install Ubuntu 12.04.4 LTS on a system in my Lab but after the installation when I restarted the system it booted straight to Windows. I restarted it many times but I did not get a boot option to load Ubuntu. During the installation I do remember the installer showing that it was installing GRUB so I want to know how I can boot to Ubuntu.\nThe system I used has Windows 7 Enterprise edition. I created 100 GB partition (/dev/sda6) and a 5GB swap partition (/dev/sda7) before installing Ubuntu in the 100 GB partition. I chose /dev/sda for boot loader installation. Before installation I noticed that there already was a 26 GB ext4 partition so I am guessing that someone had previously tried installing Linux on this system. Anyway I needed more space so I carried out my installation in the 100GB partition.\nI have tried all different boot orders possible in the BIOS, I have tried re-formatting and re-installing Ubuntu but it still boots into Windows directly. In windows, System and security → System → Advanced system settings → Advanced → Startup & Recovery → Settings:  lists Windows 7 as the default OS and doesn't give me a choice to select Ubuntu in the drop down menu.\nI have tried the recommended repair in boot-repair but it gives me an error:\nBoot repair: Please open a terminal and type this:\nsudo chroot \"/mnt/boot-sav/sda6\" dpkg --configure -a\nsudo chroot \"/mnt/boot-sav/sda6\" apt-get install -fy\nsudo chroot \"/mnt/boot-sav/sda6\" apt-get purge -y --force-yes grub* shim-signed\n\nI type them but nothing seems to happen. Then when I click the forward button I get this message:\n\nGRUB is still present. Please try again.\n\nI have used Boot-repair to make a Boot-info summary \nPlease tell me how to proceed. \nThanks.\n\nA: Since i can't comment :\n possibly a duplicate question\nSecond thing: As you have stated\n\nIn windows, System and security>System>Advanced system\n  settings>Advanced>Startup &recovery>Settings: lists windows 7 as the\n  default OS and doesn’t give me a choice to select Ubuntu in the drop\n  down menu.\n\nwindows can't handle the ext4 file-system(Ubuntu partition) by default hence you can't access Ubuntu partition while in windows without a third-party software.\n", "Q: VM runs very slow using QEMU When I create a virtual machine using qemu-system-x86_64, it doesn't even boot up. This is how I boot the VM:\nqemu-system-x86_64 -m 1024 -name mac -hda ~/Documents/ubuntu1\n\nBut when I create the same VM with Oracle VirtualBox or VMware Player, it runs fine.\nWhat is the issue with QEMU, and how do I resolve it?\n\nA: Be sure to add the -enable-kvm option to allow QEMU to use hardware virtualization capabilities (requires Intel VT-x or AMD AMD-V CPU extensions). Without those options, everything will be emulated in software (which is much slower). Example:\n\nqemu-system-x86_64 -enable-kvm -m 1024 -name mac -hda ~/Documents/ubuntu1\n\n", "Q: \"configure: error: C++ preprocessor \"/lib/cpp\" fails sanity check\" apcoer@apcoer-Aspire-Series:~$ cd Desktop\napcoer@apcoer-Aspire-Series:~/Desktop$ cd libgraph-1.0.2\napcoer@apcoer-Aspire-Series:~/Desktop/libgraph-1.0.2$ ./configure\nchecking build system type... x86_64-unknown-linux-gnu\nchecking host system type... x86_64-unknown-linux-gnu\nchecking target system type... x86_64-unknown-linux-gnu\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking whether to enable maintainer-specific portions of Makefiles... no\nchecking for gcc... gcc\nchecking for C compiler default output file name... a.out\nchecking whether the C compiler works... yes\nchecking whether we are cross compiling... no\nchecking for suffix of executables... \nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to accept ANSI C... none needed\nchecking for style of include used by make... GNU\nchecking dependency style of gcc... gcc3\nchecking how to run the C preprocessor... gcc -E\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether ln -s works... yes\nchecking whether make sets $(MAKE)... (cached) yes\nchecking for a sed that does not truncate output... /bin/sed\nchecking for egrep... grep -E\nchecking for ld used by gcc... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... yes\nchecking for /usr/bin/ld option to reload object files... -r\nchecking for BSD-compatible nm... /usr/bin/nm -B\nchecking how to recognise dependent libraries... pass_all\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking dlfcn.h usability... yes\nchecking dlfcn.h presence... yes\nchecking for dlfcn.h... yes\nchecking for g++... no\nchecking for c++... no\nchecking for gpp... no\nchecking for aCC... no\nchecking for CC... no\nchecking for cxx... no\nchecking for cc++... no\nchecking for cl... no\nchecking for FCC... no\nchecking for KCC... no\nchecking for RCC... no\nchecking for xlC_r... no\nchecking for xlC... no\nchecking whether we are using the GNU C++ compiler... no\nchecking whether g++ accepts -g... no\nchecking dependency style of g++... none\nchecking how to run the C++ preprocessor... /lib/cpp\nconfigure: error: C++ preprocessor \"/lib/cpp\" fails sanity check\nSee `config.log' for more details.\napcoer@apcoer-Aspire-Series:~/Desktop/libgraph-1.0.2$ \napcoer@apcoer-Aspire-Series:~/Desktop/libgraph-1.0.2$ \napcoer@apcoer-Aspire-Series:~/Desktop/libgraph-1.0.2$ sudo make\n[sudo] password for apcoer: \nmake: *** No targets specified and no makefile found.  Stop.\napcoer@apcoer-Aspire-Series:~/Desktop/libgraph-1.0.2$ \n\nCan anyone solve this error urgently...?\n\nA: You should try\nsudo apt-get install gcc build-essential\n\nThen\n./configure && make\n\nThe problem is you don't have compiler so configure script does not generate the Makefile properly.\n", "Q: Ubuntu Hide Desktop Icon Problem Ubuntu 13.10 I am facing the scenario as below whenever I try to hide the Desktop Icon for Ubuntu 13.10.\n\n\n*\n\n*When my default File Manager is set to Nautilus, everything is working fine even after I set the Desktop Icon to \"Hide\" from Ubuntu Tweak tool.\n\n*Problem is when I set my default File Manager (xdg-mime default nemo.desktop inode/directory application/x-gnome-saved-search) to either Nemo or Caja, whenever the file manager start, the Desktop will be shown with icon and I will need to manually kill the file manager process for the Desktop Icon to be hidden again. \n\n\nAny advice on what is the cause of this?\nRegards and thank you,\nRoger.\n\nA: Run the following command in a Terminal (Ctrl-Alt-T):\ngsettings set org.nemo.desktop show-desktop-icons false\n\nThis will disable the desktop-items when starting nemo.\n\nA: This worked for me. Run these commands in terminal\ngsettings set  org.nemo.desktop home-icon-visible false\ngsettings set  org.nemo.desktop trash-icon-visible false\ngsettings set  org.nemo.desktop computer-icon-visible false\ngsettings set  org.nemo.desktop volumes-visible false\n\n", "Q: Help with the installation of Ubuntu 13.10 I'm trying to download ubuntu 13.10 on my laptop which is currently running windows 7. I want to install to where I can dual boot either. \n\nA: You need to explain more in detail, I am assuming you already have downloaded the Ubuntu ISO file and you want to setup a dual boot with your windows OS.\nto do so I'd suggest you follow the instruction mentioned here.\nFirst Backup\nInstall Ubuntu after installing windows\nA Windows OS should be installed first, because its boot loader is very particular and the installer tends to overwrite the entire hard drive, wiping out any data stored on it. If Windows isn’t already installed, install it first. If you are able to partition the drive prior to installing Windows, leave space for Ubuntu during the initial partitioning process. Then you won’t have to resize your NTFS partition to make room for Ubuntu later, saving a bit of time.\nWhen a Windows installation already occupies the entire hard drive, its partition needs to be shrunk, creating free space for the Ubuntu partition. You can do this during the Ubuntu installation procedure.\nthen create separate partition\nGo To “Computer Management”.\n\n1.2 Go To “Disk Management”.\n\n1.3 Right Click on Disk you want to Partitioned, Select “Shrink Volume”.\n\n1.4 Enter the amount of space to shrink in MB. Then click Shrink. This will create New Partitioned Disk with disk amount entered by you.\n\nOnce done you need to reboot and boot from your Ubuntu Live CD or USB (Read this for more info: http://www.ubuntu.com/download/desktop/install-desktop-latest)\nWhen you are ready to install Ubuntu on your hard disk, click the Install Ubuntu button. The installation wizard will appear:\n\n\nClick Continue\nand select the desired options. Click Continue. The Installation type window appears.\nInstallation Type\nIf you want to install Ubuntu alongside you other systems (eg alongside Windows), select the Install Ubuntu alongside them.\n\n\nthen Click Continue and follow the on screen instructions.\nFor more info Have a look on these pages:\n\n\n*\n\n*http://www.linuxbsdos.com/2014/02/01/dual-boot-windows-8-or-windows-7-and-ubuntu-13-10-with-ubuntu-on-a-btrfs-filesystem/\n\n*http://techsultan.com/install-ubuntu-13-10-dual-boot-windows-7-8/\n\n*http://www.ubuntu.com/download/desktop/install-desktop-latest\n"]